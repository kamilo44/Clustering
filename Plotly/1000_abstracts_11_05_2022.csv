Título,Autores,Fecha,Tema,Abstract
Topologically-Aware Deformation Fields for Single-View 3DReconstruction,"ShivamDuggal, DeepakPathak",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We present a new framework for learning 3D object shapes and dense cross-object 3D correspondences from just an unaligned category-specific image collection. The 3D shapes are generated implicitly as deformations to a category-specific signed distance field and are learned in an unsupervised manner solely from unaligned image collections without any 3D supervision. Generally, image collections on the internet contain several intra-category geometric and topological variations, for example, different chairs can have different topologies, which makes the task of joint shape and correspondence estimation much more challenging. Because of this, prior works either focus on learning each 3D object shape individually without modeling cross- instance correspondences or perform joint shape and correspondence estimation on categories with minimal intra-category topological variations. We overcome these restrictions by learning a topologically-aware implicit deformation field that maps a 3D point in the object space to a higher dimensional point in the category-specific canonical space. At inference time, given a single image, we reconstruct the underlying 3D shape by first implicitly deforming each 3D point in the object space to the learned category-specific canonical space using the topologically-aware deformation field and then reconstructing the 3D shape as a canonical signed distance field. Both canonical shape and deformation field are learned end-to-end in an inverse-graphics fashion using a learned recurrent ray marcher (SRN) as a differentiable rendering module. Our approach, dubbed TARS, achieves state- of-the-art reconstruction fidelity on several datasets: ShapeNet, Pascal3D+, CUB, and Pix3D chairs. Result videos and code at [this https URL](https://shivamduggal4.github.io/tars-3D/)"
Lifting the Curse of Multilinguality by Pre-training ModularTransformers,"JonasPfeiffer, Naman Goyal, Xi VictoriaLin, XianLi, JamesCross, SebastianRiedel, MikelArtetxe",12 May 2022,Computation and Language (cs.CL)," Multilingual pre-trained models are known to suffer from the curse of multilinguality, which causes per-language performance to drop as they cover more languages. We address this issue by introducing language-specific modules, which allows us to grow the total capacity of the model, while keeping the total number of trainable parameters per language constant. In contrast with prior work that learns language-specific components post-hoc, we pre-train the modules of our Cross-lingual Modular (X-Mod) models from the start. Our experiments on natural language inference, named entity recognition and question answering show that our approach not only mitigates the negative interference between languages, but also enables positive transfer, resulting in improved monolingual and cross-lingual performance. Furthermore, our approach enables adding languages post-hoc with no measurable drop in performance, no longer limiting the model usage to the set of pre-trained languages."
ELODI: Ensemble Logit Difference Inhibition for Positive-CongruentTraining,"YueZhao, YantaoShen, YuanjunXiong, ShuoYang, WeiXia, ZhuowenTu, BerntShiele, StefanoSoatto",12 May 2022,Machine Learning (cs.LG)," Negative flips are errors introduced in a classification system when a legacy model is replaced with a new one. Existing methods to reduce the negative flip rate (NFR) either do so at the expense of overall accuracy using model distillation, or use ensembles, which multiply inference cost prohibitively. We present a method to train a classification system that achieves paragon performance in both error rate and NFR, at the inference cost of a single model. Our method introduces a generalized distillation objective, Logit Difference Inhibition (LDI), that penalizes changes in the logits between the new and old model, without forcing them to coincide as in ordinary distillation. LDI affords the model flexibility to reduce error rate along with NFR. The method uses a homogeneous ensemble as the reference model for LDI, hence the name Ensemble LDI, or ELODI. The reference model can then be substituted with a single model at inference time. The method leverages the observation that negative flips are typically not close to the decision boundary, but often exhibit large deviations in the distance among their logits, which are reduced by ELODI."
FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue,"AlonAlbalak, Yi-Lin Tuan, PegahJandaghi, ConnorPryor, LukeYoffe, DeepakRamachandran, LiseGetoor, JayPujara, William YangWang",12 May 2022,Computation and Language (cs.CL)," Task transfer, transferring knowledge contained in related tasks, holds the promise of reducing the quantity of labeled data required to fine- tune language models. Dialogue understanding encompasses many diverse tasks, yet task transfer has not been thoroughly studied in conversational AI. This work explores conversational task transfer by introducing FETA: a benchmark for few-sample task transfer in open-domain dialogue. FETA contains two underlying sets of conversations upon which there are 10 and 7 tasks annotated, enabling the study of intra-dataset task transfer; task transfer without domain adaptation. We utilize three popular language models and three learning algorithms to analyze the transferability between 132 source- target task pairs and create a baseline for future work. We run experiments in the single- and multi-source settings and report valuable findings, e.g., most performance trends are model-specific, and span extraction and multiple-choice tasks benefit the most from task transfer. In addition to task transfer, FETA can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning."
Computing Programs for Generalized Planning as Heuristic Search,"Javier Segovia-Aguas, SergioJiménez, AndersJonsson",12 May 2022,Artificial Intelligence (cs.AI)," Although heuristic search is one of the most successful approaches to classical planning, this planning paradigm does not apply straightforwardly to Generalized Planning (GP). This paper adapts the planning as heuristic search paradigm to the particularities of GP, and presents the first native heuristic search approach to GP. First, the paper defines a program-based solution space for GP that is independent of the number of planning instances in a GP problem, and the size of these instances. Second, the paper defines the BFGP algorithm for GP, that implements a best-first search in our program-based solution space, and that is guided by different evaluation and heuristic functions."
Coded Data Rebalancing for Distributed Data Storage Systems withCyclic Storage,"AthreyaChandramouli, AbhinavVaishya, PrasadKrishnan",12 May 2022,Information Theory (cs.IT)," We consider replication-based distributed storage systems in which each node stores the same quantum of data and each data bit stored has the same replication factor across the nodes. Such systems are referred to as \textit{balanced distributed databases}. When existing nodes leave or new nodes are added unto this system, the balanced nature of the database is lost, either due to the reduction in the replication factor, or due to non- uniformity of the storage at the nodes. This triggers a \textit{rebalancing} algorithm, which exchanges data between the nodes so that the balance of the database is reinstated. In a recent work by Krishnan et al., coded transmissions were used to rebalance a carefully designed distributed database from a node removal or addition. These coded rebalancing schemes have optimal communication load, however require the file-size to be at least exponential in the system parameters. In this work, we consider a \textit{cyclic balanced database} (where data is cyclically placed in the system nodes) and present coded rebalancing schemes for node removal and addition in such a database. These databases (and the associated rebalancing schemes) require the file-size to be only \textit{cubic} in the number of nodes in the system. We show that the communication load of the node-removal rebalancing scheme is strictly smaller than the load of the uncoded scheme. In the node addition scenario, the rebalancing scheme presented is a simple uncoded scheme, which we show has optimal load."
3D Moments from Near-Duplicate Photos,"QianqianWang, ZhengqiLi, DavidSalesin, NoahSnavely, BrianCurless, JanneKontkanen",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We introduce 3D Moments, a new computational photography effect. As input we take a pair of near-duplicate photos, i.e., photos of moving subjects from similar viewpoints, common in people's photo collections. As output, we produce a video that smoothly interpolates the scene motion from the first photo to the second, while also producing camera motion with parallax that gives a heightened sense of 3D. To achieve this effect, we represent the scene as a pair of feature-based layered depth images augmented with scene flow. This representation enables motion interpolation along with independent control of the camera viewpoint. Our system produces photorealistic space-time videos with motion parallax and scene dynamics, while plausibly recovering regions occluded in the original views. We conduct extensive experiments demonstrating superior performance over baselines on public datasets and in-the-wild photos. Project page: [this https URL](https://3d-moments.github.io/)"
Learned Vertex Descent: A New Direction for 3D Human Model Fitting,"EnricCorona, Gerard Pons-Moll, GuillemAlenyà, Francesc Moreno-Noguer",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We propose a novel optimization-based paradigm for 3D human model fitting on images and scans. In contrast to existing approaches that directly regress the parameters of a low-dimensional statistical body model (e.g. SMPL) from input images, we train an ensemble of per-vertex neural fields network. The network predicts, in a distributed manner, the vertex descent direction towards the ground truth, based on neural features extracted at the current vertex projection. At inference, we employ this network, dubbed LVD, within a gradient-descent optimization pipeline until its convergence, which typically occurs in a fraction of a second even when initializing all vertices into a single point. An exhaustive evaluation demonstrates that our approach is able to capture the underlying body of clothed people with very different body shapes, achieving a significant improvement compared to state-of-the-art. LVD is also applicable to 3D model fitting of humans and hands, for which we show a significant improvement to the SOTA with a much simpler and faster method."
What's in a Caption? Dataset-Specific Linguistic Diversity and ItsEffect on Visual Description Models and Metrics,"David M.Chan, AustinMyers, SudheendraVijayanarasimhan, David A.Ross, BryanSeybold, John F.Canny",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," While there have been significant gains in the field of automated video description, the generalization performance of automated description models to novel domains remains a major barrier to using these systems in the real world. Most visual description methods are known to capture and exploit patterns in the training data leading to evaluation metric increases, but what are those patterns? In this work, we examine several popular visual description datasets, and capture, analyze, and understand the dataset-specific linguistic patterns that models exploit but do not generalize to new domains. At the token level, sample level, and dataset level, we find that caption diversity is a major driving factor behind the generation of generic and uninformative captions. We further show that state-of-the-art models even outperform held-out ground truth captions on modern metrics, and that this effect is an artifact of linguistic diversity in datasets. Understanding this linguistic diversity is key to building strong captioning models, we recommend several methods and approaches for maintaining diversity in the collection of new data, and dealing with the consequences of limited diversity when using current models and metrics."
Optimal-Degree Polynomial Approximations for Exponentials and GaussianKernel Density Estimation,"AmolAggarwal, Josh Alman",12 May 2022,Computational Complexity (cs.CC)," For any real numbers $B \ge 1$ and $\delta \in (0, 1)$ and function $f: [0, B] \rightarrow \mathbb{R}$, let $d_{B; \delta} (f) \in \mathbb{Z}_{ 0}$ denote the minimum degree of a polynomial $p(x)$ satisfying $\sup_{x \in [0, B]} \big| p(x) - f(x) \big| < \delta$. In this paper, we provide precise asymptotics for $d_{B; \delta} (e^{-x})$ and $d_{B; \delta} (e^{x})$ in terms of both $B$ and $\delta$, improving both the previously known upper bounds and lower bounds. In particular, we show $$d_{B; \delta} (e^{-x}) = \Theta\left( \max \left\\{ \sqrt{B \log(\delta^{-1})}, \frac{\log(\delta^{-1}) }{ \log(B^{-1} \log(\delta^{-1}))} \right\\}\right), \text{ and}$$ $$d_{B; \delta} (e^{x}) = \Theta\left( \max \left\\{ B, \frac{\log(\delta^{-1}) }{ \log(B^{-1} \log(\delta^{-1}))} \right\\}\right).$$   Polynomial approximations for $e^{-x}$ and $e^x$ have applications to the design of algorithms for many problems, and our degree bounds show both the power and limitations of these algorithms.   We focus in particular on the Batch Gaussian Kernel Density Estimation problem for $n$ sample points in $\Theta(\log n)$ dimensions with error $\delta = n^{-\Theta(1)}$. We show that the running time one can achieve depends on the square of the diameter of the point set, $B$, with a transition at $B = \Theta(\log n)$ mirroring the corresponding transition in $d_{B; \delta} (e^{-x})$:   \- When $B=o(\log n)$, we give the first algorithm running in time $n^{1 + o(1)}$.   \- When $B = \kappa \log n$ for a small constant $\kappa0$, we give an algorithm running in time $n^{1 + O(\log \log \kappa^{-1} /\log \kappa^{-1})}$. The $\log \log \kappa^{-1} /\log \kappa^{-1}$ term in the exponent comes from analyzing the behavior of the leading constant in our computation of $d_{B; \delta} (e^{-x})$.   \- When $B = \omega(\log n)$, we show that time $n^{2 - o(1)}$ is necessary assuming SETH."
"Can counterfactual explanations of AI systems' predictions skew layusers' causal intuitions about the world? If so, can we correct for that?","MarkoTesic, Ulrike Hahn",12 May 2022,Artificial Intelligence (cs.AI)," Counterfactual (CF) explanations have been employed as one of the modes of explainability in explainable AI-both to increase the transparency of AI systems and to provide recourse. Cognitive science and psychology, however, have pointed out that people regularly use CFs to express causal relationships. Most AI systems are only able to capture associations or correlations in data so interpreting them as casual would not be justified. In this paper, we present two experiment (total N = 364) exploring the effects of CF explanations of AI system's predictions on lay people's causal beliefs about the real world. In Experiment 1 we found that providing CF explanations of an AI system's predictions does indeed (unjustifiably) affect people's causal beliefs regarding factors/features the AI uses and that people are more likely to view them as causal factors in the real world. Inspired by the literature on misinformation and health warning messaging, Experiment 2 tested whether we can correct for the unjustified change in causal beliefs. We found that pointing out that AI systems capture correlations and not necessarily causal relationships can attenuate the effects of CF explanations on people's causal beliefs."
Knowledge Distillation for Multi-Target Domain Adaptation in Real-TimePerson Re-Identification,"FélixRemigereau, DjebrilMekhazni, SajjadAbdoli, LeThanh Nguyen-Meidine, Rafael M. O.Cruz, EricGranger",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Despite the recent success of deep learning architectures, person re-identification (ReID) remains a challenging problem in real-word applications. Several unsupervised single-target domain adaptation (STDA) methods have recently been proposed to limit the decline in ReID accuracy caused by the domain shift that typically occurs between source and target video data. Given the multimodal nature of person ReID data (due to variations across camera viewpoints and capture conditions), training a common CNN backbone to address domain shifts across multiple target domains, can provide an efficient solution for real-time ReID applications. Although multi-target domain adaptation (MTDA) has not been widely addressed in the ReID literature, a straightforward approach consists in blending different target datasets, and performing STDA on the mixture to train a common CNN. However, this approach may lead to poor generalization, especially when blending a growing number of distinct target domains to train a smaller CNN.   To alleviate this problem, we introduce a new MTDA method based on knowledge distillation (KD-ReID) that is suitable for real-time person ReID applications. Our method adapts a common lightweight student backbone CNN over the target domains by alternatively distilling from multiple specialized teacher CNNs, each one adapted on data from a specific target domain. Extensive experiments conducted on several challenging person ReID datasets indicate that our approach outperforms state-of-art methods for MTDA, including blending methods, particularly when training a compact CNN backbone like OSNet. Results suggest that our flexible MTDA approach can be employed to design cost-effective ReID systems for real-time video surveillance applications."
Verifying Catamorphism-Based Contracts using Constrained Horn Clauses,Emanuele DeAngelis(1) FabioFioravanti(2) AlbertoPettorossi(3) MaurizioProietti(1) ((1) IASI-CNR Rome Italy (2) DEc University 'G. d'Annunzio' Chieti-Pescara Pescara Italy ,12 May 2022,Logic in Computer Science (cs.LO)," We address the problem of verifying that the functions of a program meet their contracts, specified by pre/postconditions. We follow an approach based on constrained Horn clauses (CHCs) by which the verification problem is reduced to the problem of checking satisfiability of a set of clauses derived from the given program and contracts. We consider programs that manipulate algebraic data types (ADTs) and a class of contracts specified by catamorphisms, that is, functions defined by simple recursion schemata on the given ADTs. We show by several examples that state-of-the- art CHC satisfiability tools are not effective at solving the satisfiability problems obtained by direct translation of the contracts into CHCs. To overcome this difficulty, we propose a transformation technique that removes the ADT terms from CHCs and derives new sets of clauses that work on basic sorts only, such as integers and booleans. Thus, when using the derived CHCs there is no need for induction rules on ADTs. We prove that the transformation is sound, that is, if the derived set of CHCs is satisfiable, then so is the original set. We also prove that the transformation always terminates for the class of contracts specified by catamorphisms. Finally, we present the experimental results obtained by an implementation of our technique when verifying many non-trivial contracts for ADT manipulating programs."
SIBILA: High-performance computing and interpretable machine learningjoin efforts toward personalised medicine in a novel decision-making tool,"Antonio Jesús Banegas-Luna, Horacio Pérez-Sánchez",12 May 2022,Machine Learning (cs.LG)," Background and Objectives: Personalised medicine remains a major challenge for scientists. The rapid growth of Machine learning and Deep learning has made it a feasible alternative for predicting the most appropriate therapy for individual patients. However, the lack of interpretation of their results and high computational requirements make many reluctant to use these methods.   Methods: Several Machine learning and Deep learning models have been implemented into a single software tool, SIBILA. Once the models are trained, SIBILA applies a range of interpretability methods to identify the input features that each model considered the most important to predict. In addition, all the features obtained are put in common to estimate the global attribution of each variable to the predictions. To facilitate its use by non-experts, SIBILA is also available to all users free of charge as a web server at [this https URL](https://bio-hpc.ucam.edu/sibila/).   Results: SIBILA has been applied to three case studies to show its accuracy and efficiency in classification and regression problems. The first two cases proved that SIBILA can make accurate predictions even on uncleaned datasets. The last case demonstrates that SIBILA can be applied to medical contexts with real data.   Conclusion: With the aim of becoming a powerful decision-making tool for clinicians, SIBILA has been developed. SIBILA is a novel software tool that leverages interpretable machine learning to make accurate predictions and explain how models made those decisions. SIBILA can be run on high- performance computing platforms, drastically reducing computing times."
Simple Open-Vocabulary Object Detection with Vision Transformers,"MatthiasMinderer, AlexeyGritsenko, AustinStone, MaximNeumann, DirkWeissenborn, AlexeyDosovitskiy, AravindhMahendran, AnuragArnab, MostafaDehghani, Zhuoran Shen, Xiao Wang, Xiaohua Zhai, Thomas Kipf, NeilHoulsby",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Combining simple architectures with large-scale pre-training has led to massive improvements in image classification. For object detection, pre-training and scaling approaches are less well established, especially in the long-tailed and open-vocabulary setting, where training data is relatively scarce. In this paper, we propose a strong recipe for transferring image-text models to open-vocabulary object detection. We use a standard Vision Transformer architecture with minimal modifications, contrastive image-text pre-training, and end-to-end detection fine-tuning. Our analysis of the scaling properties of this setup shows that increasing image-level pre-training and model size yield consistent improvements on the downstream detection task. We provide the adaptation strategies and regularizations needed to attain very strong performance on zero-shot text- conditioned and one-shot image-conditioned object detection. Code and models are available on GitHub."
Sketching sparse low-rank matrices with near-optimal sample- and time-complexity,"XiaoqiLiu, RamjiVenkataramanan",12 May 2022,Information Theory (cs.IT)," We consider the problem of recovering an $n_1 \times n_2$ low-rank matrix with $k$-sparse singular vectors from a small number of linear measurements (sketch). We propose a sketching scheme and an algorithm that can recover the singular vectors with high probability, with a sample complexity and running time that both depend only on $k$ and not on the ambient dimensions $n_1$ and $n_2$. Our sketching operator, based on a scheme for compressed sensing by Li et al. and Bakshi et al., uses a combination of a sparse parity check matrix and a partial DFT matrix. Our main contribution is the design and analysis of a two-stage iterative algorithm which recovers the singular vectors by exploiting the simultaneously sparse and low-rank structure of the matrix. We derive a nonasymptotic bound on the probability of exact recovery. We also show how the scheme can be adapted to tackle matrices that are approximately sparse and low-rank. The theoretical results are validated by numerical simulations."
The Mechanism of Prediction Head in Non-contrastive Self-supervisedLearning,"ZixinWen, YuanzhiLi",12 May 2022,Machine Learning (cs.LG)," Recently the surprising discovery of the Bootstrap Your Own Latent (BYOL) method by Grill et al. shows the negative term in contrastive loss can be removed if we add the so-called prediction head to the network. This initiated the research of non-contrastive self-supervised learning. It is mysterious why even when there exist trivial collapsed global optimal solutions, neural networks trained by (stochastic) gradient descent can still learn competitive representations. This phenomenon is a typical example of implicit bias in deep learning and remains little understood.   In this work, we present our empirical and theoretical discoveries on non- contrastive self-supervised learning. Empirically, we find that when the prediction head is initialized as an identity matrix with only its off- diagonal entries being trainable, the network can learn competitive representations even though the trivial optima still exist in the training objective. Theoretically, we present a framework to understand the behavior of the trainable, but identity-initialized prediction head. Under a simple setting, we characterized the substitution effect and acceleration effect of the prediction head. The substitution effect happens when learning the stronger features in some neurons can substitute for learning these features in other neurons through updating the prediction head. And the acceleration effect happens when the substituted features can accelerate the learning of other weaker features to prevent them from being ignored. These two effects enable the neural networks to learn all the features rather than focus only on learning the stronger features, which is likely the cause of the dimensional collapse phenomenon. To the best of our knowledge, this is also the first end-to-end optimization guarantee for non-contrastive methods using nonlinear neural networks with a trainable prediction head and normalization."
Delving into High-Quality Synthetic Face Occlusion SegmentationDatasets,"Kenny T. R.Voo, LimingJiang, ChenChange Loy",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," This paper performs comprehensive analysis on datasets for occlusion-aware face segmentation, a task that is crucial for many downstream applications. The collection and annotation of such datasets are time-consuming and labor-intensive. Although some efforts have been made in synthetic data generation, the naturalistic aspect of data remains less explored. In our study, we propose two occlusion generation techniques, Naturalistic Occlusion Generation (NatOcc), for producing high-quality naturalistic synthetic occluded faces; and Random Occlusion Generation (RandOcc), a more general synthetic occluded data generation method. We empirically show the effectiveness and robustness of both methods, even for unseen occlusions. To facilitate model evaluation, we present two high- resolution real-world occluded face datasets with fine-grained annotations, RealOcc and RealOcc-Wild, featuring both careful alignment preprocessing and an in-the-wild setting for robustness test. We further conduct a comprehensive analysis on a newly introduced segmentation benchmark, offering insights for future exploration."
Contingency-constrained economic dispatch with safe reinforcementlearning,"MichaelEichelbeck, HannahMarkgraf, MatthiasAlthoff",12 May 2022,Systems and Control (eess.SY)," Future power systems will rely heavily on micro grids with a high share of decentralised renewable energy sources and energy storage systems. The high complexity and uncertainty in this context might make conventional power dispatch strategies infeasible. Reinforcement-learning based (RL) controllers can address this challenge, however, cannot themselves provide safety guarantees, preventing their deployment in practice. To overcome this limitation, we propose a formally validated RL controller for economic dispatch. We extend conventional constraints by a time-dependent constraint encoding the islanding contingency. The contingency constraint is computed using set-based backwards reachability analysis and actions of the RL agent are verified through a safety layer. Unsafe actions are projected into the safe action space while leveraging constrained zonotope set representations for computational efficiency. The developed approach is demonstrated on a residential use case using real-world measurements."
CiteSum: Citation Text-guided Scientific Extreme Summarization andLow-resource Domain Adaptation,"YuningMao, MingZhong, Jiawei Han",12 May 2022,Computation and Language (cs.CL)," Scientific extreme summarization (TLDR) aims to form ultra-short summaries of scientific papers. Previous efforts on curating scientific TLDR datasets failed to scale up due to the heavy human annotation and domain expertise required. In this paper, we propose a simple yet effective approach to automatically extracting TLDR summaries for scientific papers from their citation texts. Based on the proposed approach, we create a new benchmark CiteSum without human annotation, which is around 30 times larger than the previous human-curated dataset SciTLDR. We conduct a comprehensive analysis of CiteSum, examining its data characteristics and establishing strong baselines. We further demonstrate the usefulness of CiteSum by adapting models pre-trained on CiteSum (named CITES) to new tasks and domains with limited supervision. For scientific extreme summarization, CITES outperforms most fully-supervised methods on SciTLDR without any fine- tuning and obtains state-of-the-art results with only 128 examples. For news extreme summarization, CITES achieves significant gains on XSum over its base model (not pre-trained on CiteSum), e.g., +7.2 ROUGE-1 zero-shot performance and state-of-the-art few-shot performance. For news headline generation, CITES performs the best among unsupervised and zero-shot methods on Gigaword."
kNN-Embed: Locally Smoothed Embedding Mixtures For Multi-interestCandidate Retrieval,"Ahmed El-Kishky, ThomasMarkovich, Kenny Leung, FrankPortman, AriaHaghighi",12 May 2022,Information Retrieval (cs.IR)," Candidate generation is the first stage in recommendation systems, where a light-weight system is used to retrieve potentially relevant items for an input user. These candidate items are then ranked and pruned in later stages of recommender systems using a more complex ranking model. Since candidate generation is the top of the recommendation funnel, it is important to retrieve a high-recall candidate set to feed into downstream ranking models. A common approach for candidate generation is to leverage approximate nearest neighbor (ANN) search from a single dense query embedding; however, this approach this can yield a low-diversity result set with many near duplicates. As users often have multiple interests, candidate retrieval should ideally return a diverse set of candidates reflective of the user's multiple interests. To this end, we introduce kNN-Embed, a general approach to improving diversity in dense ANN-based retrieval. kNN- Embed represents each user as a smoothed mixture over learned item clusters that represent distinct `interests' of the user. By querying each of a user's mixture component in proportion to their mixture weights, we retrieve a high-diversity set of candidates reflecting elements from each of a user's interests. We experimentally compare kNN-Embed to standard ANN candidate retrieval, and show significant improvements in overall recall and improved diversity across three datasets. Accompanying this work, we open source a large Twitter follow-graph dataset, to spur further research in graph-mining and representation learning for recommender systems."
F3A-GAN: Facial Flow for Face Animation with Generative AdversarialNetworks,"XintianWu, QihangZhang, Yiming Wu, Huanyu Wang, Songyuan Li, Lingyun Sun, Xi Li",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Formulated as a conditional generation problem, face animation aims at synthesizing continuous face images from a single source image driven by a set of conditional face motion. Previous works mainly model the face motion as conditions with 1D or 2D representation (e.g., action units, emotion codes, landmark), which often leads to low-quality results in some complicated scenarios such as continuous generation and largepose transformation. To tackle this problem, the conditions are supposed to meet two requirements, i.e., motion information preserving and geometric continuity. To this end, we propose a novel representation based on a 3D geometric flow, termed facial flow, to represent the natural motion of the human face at any pose. Compared with other previous conditions, the proposed facial flow well controls the continuous changes to the face. After that, in order to utilize the facial flow for face editing, we build a synthesis framework generating continuous images with conditional facial flows. To fully take advantage of the motion information of facial flows, a hierarchical conditional framework is designed to combine the extracted multi-scale appearance features from images and motion features from flows in a hierarchical manner. The framework then decodes multiple fused features back to images progressively. Experimental results demonstrate the effectiveness of our method compared to other state-of-the-art methods."
Predicting Human Psychometric Properties Using Computational LanguageModels,"Antonio LaverghettaJr., AnimeshNighojkar, JamshidbekMirzakhalov, John Licato",12 May 2022,Computation and Language (cs.CL)," Transformer-based language models (LMs) continue to achieve state- of-the-art performance on natural language processing (NLP) benchmarks, including tasks designed to mimic human-inspired ""commonsense"" competencies. To better understand the degree to which LMs can be said to have certain linguistic reasoning skills, researchers are beginning to adapt the tools and concepts from psychometrics. But to what extent can benefits flow in the other direction? In other words, can LMs be of use in predicting the psychometric properties of test items, when those items are given to human participants? If so, the benefit for psychometric practitioners is enormous, as it can reduce the need for multiple rounds of empirical testing. We gather responses from numerous human participants and LMs (transformer- and non-transformer-based) on a broad diagnostic test of linguistic competencies. We then use the human responses to calculate standard psychometric properties of the items in the diagnostic test, using the human responses and the LM responses separately. We then determine how well these two sets of predictions correlate. We find that transformer-based LMs predict the human psychometric data consistently well across most categories, suggesting that they can be used to gather human-like psychometric data without the need for extensive human trials."
Conversational DevBots for Secure Programming: An Empirical Study onSKF Chatbot,"CatherineTony, MohanaBalasubramanian, Nicolás E. DíazFerreyra, RiccardoScandariato",12 May 2022,Human-Computer Interaction (cs.HC)," Conversational agents or chatbots are widely investigated and used across different fields including healthcare, education, and marketing. Still, the development of chatbots for assisting secure coding practices is in its infancy. In this paper, we present the results of an empirical study on SKF chatbot, a software-development bot (DevBot) designed to answer queries about software security. To the best of our knowledge, SKF chatbot is one of the very few of its kind, thus a representative instance of conversational DevBots aiding secure software development. In this study, we collect and analyse empirical evidence on the effectiveness of SKF chatbot, while assessing the needs and expectations of its users (i.e., software developers). Furthermore, we explore the factors that may hinder the elaboration of more sophisticated conversational security DevBots and identify features for improving the efficiency of state-of-the-art solutions. All in all, our findings provide valuable insights pointing towards the design of more context-aware and personalized conversational DevBots for security engineering."
Embodied vision for learning object representations,"ArthurAubret, CélineTeulière, JochenTriesch",12 May 2022,Machine Learning (cs.LG)," Recent time-contrastive learning approaches manage to learn invariant object representations without supervision. This is achieved by mapping successive views of an object onto close-by internal representations. When considering this learning approach as a model of the development of human object recognition, it is important to consider what visual input a toddler would typically observe while interacting with objects. First, human vision is highly foveated, with high resolution only available in the central region of the field of view. Second, objects may be seen against a blurry background due to infants' limited depth of field. Third, during object manipulation a toddler mostly observes close objects filling a large part of the field of view due to their rather short arms. Here, we study how these effects impact the quality of visual representations learnt through time-contrastive learning. To this end, we let a visually embodied agent ""play"" with objects in different locations of a near photo-realistic flat. During each play session the agent views an object in multiple orientations before turning its body to view another object. The resulting sequence of views feeds a time-contrastive learning algorithm. Our results show that visual statistics mimicking those of a toddler improve object recognition accuracy in both familiar and novel environments. We argue that this effect is caused by the reduction of features extracted in the background, a neural network bias for large features in the image and a greater similarity between novel and familiar background regions. We conclude that the embodied nature of visual learning may be crucial for understanding the development of human object perception."
Image Segmentation with Topological Priors,"Shakir ShowkatSofi, NadezhdaAlsahanova",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Solving segmentation tasks with topological priors proved to make fewer errors in fine-scale structures. In this work, we use topological priors both before and during the deep neural network training procedure. We compared the results of the two approaches with simple segmentation on various accuracy metrics and the Betti number error, which is directly related to topological correctness, and discovered that incorporating topological information into the classical UNet model performed significantly better. We conducted experiments on the ISBI EM segmentation dataset."
Efficient Deep Visual and Inertial Odometry with Adaptive VisualModality Selection,"MingyuYang, YuChen, Hun-Seok Kim",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In recent years, deep learning-based approaches for visual- inertial odometry (VIO) have shown remarkable performance outperforming traditional geometric methods. Yet, all existing methods use both the visual and inertial measurements for every pose estimation incurring potential computational redundancy. While visual data processing is much more expensive than that for the inertial measurement unit (IMU), it may not always contribute to improving the pose estimation accuracy. In this paper, we propose an adaptive deep-learning based VIO method that reduces computational redundancy by opportunistically disabling the visual modality. Specifically, we train a policy network that learns to deactivate the visual feature extractor on the fly based on the current motion state and IMU readings. A Gumbel-Softmax trick is adopted to train the policy network to make the decision process differentiable for end-to-end system training. The learned strategy is interpretable, and it shows scenario-dependent decision patterns for adaptive complexity reduction. Experiment results show that our method achieves a similar or even better performance than the full-modality baseline with up to 78.8% computational complexity reduction for KITTI dataset evaluation. Our code will be shared in [this https URL](https://github.com/mingyuyng/Visual-Selective-VIO)"
Improved Meta Learning for Low Resource Speech Recognition,"SatwinderSingh, RuiliWang, FengHou",11 May 2022,Computation and Language (cs.CL)," We propose a new meta learning based framework for low resource speech recognition that improves the previous model agnostic meta learning (MAML) approach. The MAML is a simple yet powerful meta learning approach. However, the MAML presents some core deficiencies such as training instabilities and slower convergence speed. To address these issues, we adopt multi-step loss (MSL). The MSL aims to calculate losses at every step of the inner loop of MAML and then combines them with a weighted importance vector. The importance vector ensures that the loss at the last step has more importance than the previous steps. Our empirical evaluation shows that MSL significantly improves the stability of the training procedure and it thus also improves the accuracy of the overall system. Our proposed system outperforms MAML based low resource ASR system on various languages in terms of character error rates and stable training behavior."
FACTOID: A New Dataset for Identifying Misinformation Spreaders andPolitical Bias,"FloraSakketou, Joan Plepi, RiccardoCervero, Henri-JacquesGeiss, PaoloRosso, LucieFlek",11 May 2022,Social and Information Networks (cs.SI)," Proactively identifying misinformation spreaders is an important step towards mitigating the impact of fake news on our society. In this paper, we introduce a new contemporary Reddit dataset for fake news spreader analysis, called FACTOID, monitoring political discussions on Reddit since the beginning of 2020\. The dataset contains over 4K users with 3.4M Reddit posts, and includes, beyond the users' binary labels, also their fine- grained credibility level (very low to very high) and their political bias strength (extreme right to extreme left). As far as we are aware, this is the first fake news spreader dataset that simultaneously captures both the long-term context of users' historical posts and the interactions between them. To create the first benchmark on our data, we provide methods for identifying misinformation spreaders by utilizing the social connections between the users along with their psycho-linguistic features. We show that the users' social interactions can, on their own, indicate misinformation spreading, while the psycho-linguistic features are mostly informative in non-neural classification settings. In a qualitative analysis, we observe that detecting affective mental processes correlates negatively with right- biased users, and that the openness to experience factor is lower for those who spread fake news."
Massively Scalable Wavelength Diverse Integrated Photonic LinearNeuron,"Matthew vanNiekerk, AnthonyRizzo, Hector RubioRivera, GeraldLeake, DanielColeman, ChristopherTison, MichaelFanto, KerenBergman, StefanPreble",11 May 2022,Emerging Technologies (cs.ET)," As computing resource demands continue to escalate in the face of big data, cloud-connectivity and the internet of things, it has become imperative to develop new low-power, scalable architectures. Neuromorphic photonics, or photonic neural networks, have become a feasible solution for the physical implementation of efficient algorithms directly on-chip. This application is primarily due to the linear nature of light and the scalability of silicon photonics, specifically leveraging the wide-scale complementary metal-oxide-semiconductor (CMOS) manufacturing infrastructure used to fabricate microelectronics chips. Current neuromorphic photonic implementations stem from two paradigms: wavelength coherent and incoherent. Here, we introduce a novel architecture that supports coherent and incoherent operation to increase the capability and capacity of photonic neural networks with a dramatic reduction in footprint compared to previous demonstrations. As a proof-of-principle, we experimentally demonstrate simple addition and subtraction operations on a foundry-fabricated silicon photonic chip. Additionally, we experimentally validate an on-chip network to predict the logical 2-bit gates AND, OR, and XOR to accuracies of $96.8\%, 99\%,$ and $98.5\%$, respectively. This architecture is compatible with highly wavelength parallel sources, enabling massively scalable photonic neural networks."
Ensemble Classifier Design Tuned to Dataset Characteristics forNetwork Intrusion Detection,"ZeinabZoghi, GurselSerpen",8 May 2022,Cryptography and Security (cs.CR)," Machine Learning-based supervised approaches require highly customized and fine-tuned methodologies to deliver outstanding performance. This paper presents a dataset-driven design and performance evaluation of a machine learning classifier for the network intrusion dataset UNSW-NB15. Analysis of the dataset suggests that it suffers from class representation imbalance and class overlap in the feature space. We employed ensemble methods using Balanced Bagging (BB), eXtreme Gradient Boosting (XGBoost), and Random Forest empowered by Hellinger Distance Decision Tree (RF-HDDT). BB and XGBoost are tuned to handle the imbalanced data, and Random Forest (RF) classifier is supplemented by the Hellinger metric to address the imbalance issue. Two new algorithms are proposed to address the class overlap issue in the dataset. These two algorithms are leveraged to help improve the performance of the testing dataset by modifying the final classification decision made by three base classifiers as part of the ensemble classifier which employs a majority vote combiner. The proposed design is evaluated for both binary and multi-category classification. Comparing the proposed model to those reported on the same dataset in the literature demonstrate that the proposed model outperforms others by a significant margin for both binary and multi-category classification cases."
Local Motif Clustering via (Hyper)Graph Partitioning,"AdilChhabra, Marcelo FonsecaFaraj, ChristianSchulz",11 May 2022,Social and Information Networks (cs.SI)," A widely-used operation on graphs is local clustering, i.e., extracting a well-characterized community around a seed node without the need to process the whole graph. Recently local motif clustering has been proposed: it looks for a local cluster based on the distribution of motifs. Since this local clustering perspective is relatively new, most approaches proposed for it are extensions of statistical and numerical methods previously used for edge-based local clustering, while the available combinatorial approaches are still few and relatively simple. In this work, we build a hypergraph and a graph model which both represent the motif- distribution around the seed node. We solve these models using sophisticated combinatorial algorithms designed for (hyper)graph partitioning. In extensive experiments with the triangle motif, we observe that our algorithm computes communities with a motif conductance value being one third on average in comparison against the communities computed by the state-of-the- art tool MAPPR while being 6.3 times faster on average."
A Generalist Agent,"ScottReed, KonradZolna, EmilioParisotto, Sergio GomezColmenarejo, AlexanderNovikov, Gabriel Barth-Maron, MaiGimenez, YurySulsky, Jackie Kay, Jost TobiasSpringenberg, Tom Eccles, Jake Bruce, Ali Razavi, AshleyEdwards, NicolasHeess, Yutian Chen, RaiaHadsell, OriolVinyals, MahyarBordbar, Nando deFreitas",12 May 2022,Artificial Intelligence (cs.AI)," Inspired by progress in large-scale language modeling, we apply a similar approach towards building a single generalist agent beyond the realm of text outputs. The agent, which we refer to as Gato, works as a multi- modal, multi-task, multi-embodiment generalist policy. The same network with the same weights can play Atari, caption images, chat, stack blocks with a real robot arm and much more, deciding based on its context whether to output text, joint torques, button presses, or other tokens. In this report we describe the model and the data, and document the current capabilities of Gato."
Single-Server Private Information Retrieval with Side InformationUnder Arbitrary Popularity Profiles,"Alejandro Gomez-Leos, AnooshehHeidarzadeh",12 May 2022,Information Theory (cs.IT)," This paper introduces a generalization of the Private Information Retrieval with Side Information (PIR-SI) problem called Popularity-Aware PIR-SI (PA-PIR-SI). The PA-PIR-SI problem includes one or more remote servers storing copies of a dataset of $K$ messages, and a user who knows $M$ out of $K$ messages -- the identities of which are unknown to the server -- as a prior side information, and wishes to retrieve one of the remaining $K-M$ messages. The goal of the user is to minimize the amount of information they must download from the server while revealing no information about the identity of the desired message. In contrast to PIR- SI, in PA-PIR-SI, the dataset messages are not assumed to be equally popular. That is, given the $M$ side information messages, each of the remaining $K-M$ messages is not necessarily equally likely to be the message desired by the user. In this work, we focus on the single-server setting of PA-PIR-SI, and establish lower and upper bounds on the capacity of this setting -- defined as the maximum possible achievable download rate. Our upper bound holds for any message popularity profile, and is the same as the capacity of single-server PIR-SI. We prove the lower bound by presenting a PA-PIR-SI scheme which takes a novel probabilistic approach -- carefully designed based on the popularity profile -- to integrate two existing PIR-SI schemes. The rate of our scheme is strictly higher than that of the only existing PIR-SI scheme applicable to the PA-PIR-SI setting."
Using dependency parsing for few-shot learning in distributionalsemantics,"StefaniaPreda, GuyEmerson",12 May 2022,Computation and Language (cs.CL)," In this work, we explore the novel idea of employing dependency parsing information in the context of few-shot learning, the task of learning the meaning of a rare word based on a limited amount of context sentences. Firstly, we use dependency-based word embedding models as background spaces for few-shot learning. Secondly, we introduce two few-shot learning methods which enhance the additive baseline model by using dependencies."
Dynamic Prefix-Tuning for Generative Template-based Event Extraction,"XiaoLiu, HeyanHuang, GeShi, BoWang",12 May 2022,Computation and Language (cs.CL)," We consider event extraction in a generative manner with template- based conditional generation. Although there is a rising trend of casting the task of event extraction as a sequence generation problem with prompts, these generation-based methods have two significant challenges, including using suboptimal prompts and static event type information. In this paper, we propose a generative template-based event extraction method with dynamic prefix (GTEE-DynPref) by integrating context information with type-specific prefixes to learn a context-specific prefix for each context. Experimental results show that our model achieves competitive results with the state-of- the-art classification-based model OneIE on ACE 2005 and achieves the best performances on ERE. Additionally, our model is proven to be portable to new types of events effectively."
Sparse Random Khatri-Rao Product Codes for Distributed MatrixMultiplication,"RuowanJi, AnooshehHeidarzadeh, Krishna R.Narayanan",12 May 2022,Information Theory (cs.IT)," We introduce two generalizations to the paradigm of using Random Khatri-Rao Product (RKRP) codes for distributed matrix multiplication. We first introduce a class of codes called Sparse Random Khatri-Rao Product (SRKRP) codes which have sparse generator matrices. SRKRP codes result in lower encoding, computation and communication costs than RKRP codes when the input matrices are sparse, while they exhibit similar numerical stability to other state of the art schemes. We empirically study the relationship between the probability of the generator matrix (restricted to the set of non-stragglers) of a randomly chosen SRKRP code being rank deficient and various parameters of the coding scheme including the degree of sparsity of the generator matrix and the number of non-stragglers. Secondly, we show that if the master node can perform a very small number of matrix product computations in addition to the computations performed by the workers, the failure probability can be substantially improved."
Localized Vision-Language Matching for Open-vocabulary ObjectDetection,"Maria A.Bravo, SudhanshuMittal, Thomas Brox",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In this work, we propose an open-world object detection method that, based on image-caption pairs, learns to detect novel object classes along with a given set of known classes. It is a two-stage training approach that first uses a location-guided image-caption matching technique to learn class labels for both novel and known classes in a weakly-supervised manner and second specializes the model for the object detection task using known class annotations. We show that a simple language model fits better than a large contextualized language model for detecting novel objects. Moreover, we introduce a consistency-regularization technique to better exploit image- caption pair information. Our method compares favorably to existing open- world detection approaches while being data-efficient."
Direct optimization of BPX preconditioners,"VladimirFanaskov, IvanOseledets",12 May 2022,Numerical Analysis (math.NA)," We consider an automatic construction of locally optimal preconditioners for positive definite linear systems. To achieve this goal, we introduce a differentiable loss function that does not explicitly include the estimation of minimal eigenvalue. Nevertheless, the resulting optimization problem is equivalent to a direct minimization of the condition number. To demonstrate our approach, we construct a parametric family of modified BPX preconditioners. Namely, we define a set of empirical basis functions for coarse finite element spaces and tune them to achieve better condition number. For considered model equations (that includes Poisson, Helmholtz, Convection-diffusion, Biharmonic, and others), we achieve from two to twenty times smaller condition numbers for symmetric positive definite linear systems."
Smooth-Reduce: Leveraging Patches for Improved Certified Robustness,"AmeyaJoshi, MinhPham, MinsuCho, LeonidBoytsov, FilipeCondessa, J. ZicoKolter, ChinmayHegde",12 May 2022,Machine Learning (cs.LG)," Randomized smoothing (RS) has been shown to be a fast, scalable technique for certifying the robustness of deep neural network classifiers. However, methods based on RS require augmenting data with large amounts of noise, which leads to significant drops in accuracy. We propose a training- free, modified smoothing approach, Smooth-Reduce, that leverages patching and aggregation to provide improved classifier certificates. Our algorithm classifies overlapping patches extracted from an input image, and aggregates the predicted logits to certify a larger radius around the input. We study two aggregation schemes -- max and mean -- and show that both approaches provide better certificates in terms of certified accuracy, average certified radii and abstention rates as compared to concurrent approaches. We also provide theoretical guarantees for such certificates, and empirically show significant improvements over other randomized smoothing methods that require expensive retraining. Further, we extend our approach to videos and provide meaningful certificates for video classifiers. A project page can be found at [this https URL](https://nyu-dice- lab.github.io/SmoothReduce/)"
TreeMix: Compositional Constituency-based Data Augmentation forNatural Language Understanding,"LeZhang, Zichao Yang, Diyi Yang",12 May 2022,Computation and Language (cs.CL)," Data augmentation is an effective approach to tackle over-fitting. Many previous works have proposed different data augmentations strategies for NLP, such as noise injection, word replacement, back-translation etc. Though effective, they missed one important characteristic of language-- compositionality, meaning of a complex expression is built from its sub- parts. Motivated by this, we propose a compositional data augmentation approach for natural language understanding called TreeMix. Specifically, TreeMix leverages constituency parsing tree to decompose sentences into constituent sub-structures and the Mixup data augmentation technique to recombine them to generate new sentences. Compared with previous approaches, TreeMix introduces greater diversity to the samples generated and encourages models to learn compositionality of NLP data. Extensive experiments on text classification and SCAN demonstrate that TreeMix outperforms current state- of-the-art data augmentation methods."
Probabilistic Program Verification via Inductive Synthesis ofInductive Invariants,"KevinBatz, MingshuaiChen, SebastianJunges, Benjamin LucienKaminski, Joost-PieterKatoen, ChristophMatheja",12 May 2022,Logic in Computer Science (cs.LO)," A desired property of randomized systems, represented by probabilistic programs, is that the probability to reach some error state is sufficiently small; verification of such properties is often addressed by probabilistic model checking. We contribute an inductive synthesis approach for proving quantitative reachability properties by finding inductive invariants on source-code level. Our prototype implementation of various flavors of this approach shows promise: it finds inductive invariants for (in)finite-state programs, while beating state-of-the-art model checkers on some benchmarks and often outperforming monolithic alternatives."
Direct Foundations for Compositional Programming,AndongFan (1)XuejingHuang (2)Han Xu (3)Yaozhu Sun(2) Bruno C. d. S.Oliveira(2) ((1) Zhejiang University (2) The University of Hong Kong ,12 May 2022,Programming Languages (cs.PL)," The recently proposed CP language adopts Compositional Programming: a new modular programming style that solves challenging problems such as the Expression Problem. CP is implemented on top of a polymorphic core language with disjoint intersection types called Fi+. The semantics of Fi+ employs an elaboration to a target language and relies on a sophisticated proof technique to prove the coherence of the elaboration. Unfortunately, the proof technique is technically challenging and hard to scale to many common features, including recursion or impredicative polymorphism. Thus, the original formulation of Fi+ does not support the two later features, which creates a gap between theory and practice, since CP fundamentally relies on them.   This paper presents a new formulation of Fi+ based on a type-directed operational semantics (TDOS). The TDOS approach was recently proposed to model the semantics of languages with disjoint intersection types (but without polymorphism). Our work shows that the TDOS approach can be extended to languages with disjoint polymorphism and model the full Fi+ calculus. Unlike the elaboration semantics, which gives the semantics to Fi+ indirectly via a target language, the TDOS approach gives a semantics to Fi+ directly. With a TDOS, there is no need for a coherence proof. Instead, we can simply prove that the semantics is deterministic. The proof of determinism only uses simple reasoning techniques, such as straightforward induction, and is able to handle problematic features such as recursion and impredicative polymorphism. This removes the gap between theory and practice and validates the original proofs of correctness for CP. We formalized the TDOS variant of the Fi+ calculus and all its proofs in the Coq proof assistant."
Is the Computation of Abstract Sameness Relations Human-Like in NeuralLanguage Models?,"LukasThoma, Benjamin Roth",12 May 2022,Computation and Language (cs.CL)," In recent years, deep neural language models have made strong progress in various NLP tasks. This work explores one facet of the question whether state-of-the-art NLP models exhibit elementary mechanisms known from human cognition. The exploration is focused on a relatively primitive mechanism for which there is a lot of evidence from various psycholinguistic experiments with infants. The computation of ""abstract sameness relations"" is assumed to play an important role in human language acquisition and processing, especially in learning more complex grammar rules. In order to investigate this mechanism in BERT and other pre-trained language models (PLMs), the experiment designs from studies with infants were taken as the starting point. On this basis, we designed experimental settings in which each element from the original studies was mapped to a component of language models. Even though the task in our experiments was relatively simple, the results suggest that the cognitive faculty of computing abstract sameness relations is stronger in infants than in all investigated PLMs."
Multimodal Indoor Localisation for Measuring Mobility in Parkinson'sDisease using Transformers,"FerdianJovan, RyanMcConville, CatherineMorgan, EmmaTonkin, Alan Whone, IanCraddock",12 May 2022,Machine Learning (cs.LG)," Parkinson's disease (PD) is a slowly progressive debilitating neurodegenerative disease which is prominently characterised by motor symptoms. Indoor localisation, including number and speed of room to room transitions, provides a proxy outcome which represents mobility and could be used as a digital biomarker to quantify how mobility changes as this disease progresses. We use data collected from 10 people with Parkinson's, and 10 controls, each of whom lived for five days in a smart home with various sensors. In order to more effectively localise them indoors, we propose a transformer-based approach utilizing two data modalities, Received Signal Strength Indicator (RSSI) and accelerometer data from wearable devices, which provide complementary views of movement. Our approach makes asymmetric and dynamic correlations by a) learning temporal correlations at different scales and levels, and b) utilizing various gating mechanisms to select relevant features within modality and suppress unnecessary modalities. On a dataset with real patients, we demonstrate that our proposed method gives an average accuracy of 89.9%, outperforming competitors. We also show that our model is able to better predict in-home mobility for people with Parkinson's with an average offset of 1.13 seconds to ground truth."
IVOIRE Deliverable 1.1: Classification of existing VOs & tools andFormalization of VOs semantics,"SebastianStock, Fabian Vu, AtifMashkoor, MichaelLeuschel, AlexanderEgyed",12 May 2022,Logic in Computer Science (cs.LO)," This report discusses the foundations of the VO approach. Then, it explores multiple directions and argues about structure and applications."
Fair NLP Models with Differentially Private Text Encoders,"GauravMaheshwari, PascalDenis, MikaelaKeller, AurélienBellet",12 May 2022,Computation and Language (cs.CL)," Encoded text representations often capture sensitive attributes about individuals (e.g., race or gender), which raise privacy concerns and can make downstream models unfair to certain groups. In this work, we propose FEDERATE, an approach that combines ideas from differential privacy and adversarial training to learn private text representations which also induces fairer models. We empirically evaluate the trade-off between the privacy of the representations and the fairness and accuracy of the downstream model on four NLP datasets. Our results show that FEDERATE consistently improves upon previous methods, and thus suggest that privacy and fairness can positively reinforce each other."
Core-Stability in Assignment Markets with Financially ConstrainedBuyers,"EleniBatziou, MartinBichler, MaximilianFichtl",12 May 2022,Computer Science and Game Theory (cs.GT)," We study markets where a set of indivisible items is sold to bidders with unit-demand valuations, subject to a hard budget limit. Without financial constraints and pure quasilinear bidders, this assignment model allows for a simple ascending auction format that maximizes welfare and is incentive-compatible and core-stable. Introducing budget constraints, the ascending auction requires strong additional conditions on the unit-demand preferences to maintain its properties. We show that, without these conditions, we cannot hope for an incentive-compatible and core-stable mechanism. We design an iterative algorithm that depends solely on a trivially verifiable ex-post condition and demand queries, and with appropriate decisions made by an auctioneer, always yields a welfare- maximizing and core-stable outcome. If these conditions do not hold, we cannot hope for incentive-compatibility and computing welfare-maximizing assignments and core-stable prices is hard: Even in the presence of value queries, where bidders reveal their valuations and budgets truthfully, we prove that the problem becomes NP-complete for the assignment market model. The analysis complements complexity results for markets with more complex valuations and shows that even with simple unit-demand bidders the problem becomes intractable. This raises doubts on the efficiency of simple auction designs as they are used in high-stakes markets, where budget constraints typically play a role."
Multi Task Learning For Zero Shot Performance Prediction ofMultilingual Models,"KabirAhuja, ShanuKumar, SandipanDandapat, MonojitChoudhury",12 May 2022,Computation and Language (cs.CL)," Massively Multilingual Transformer based Language Models have been observed to be surprisingly effective on zero-shot transfer across languages, though the performance varies from language to language depending on the pivot language(s) used for fine-tuning. In this work, we build upon some of the existing techniques for predicting the zero-shot performance on a task, by modeling it as a multi-task learning problem. We jointly train predictive models for different tasks which helps us build more accurate predictors for tasks where we have test data in very few languages to measure the actual performance of the model. Our approach also lends us the ability to perform a much more robust feature selection and identify a common set of features that influence zero-shot performance across a variety of tasks."
Space-Efficient Graph Coarsening with Applications to Succinct PlanarEncodings,"FrankKammer, JohannesMeintrup",12 May 2022,Data Structures and Algorithms (cs.DS)," We present a novel space-efficient graph coarsening technique for n-vertex separable graphs G, in particular for planar graphs, called cloud partition, which partitions the vertices V(G) into disjoint sets C of size O(log n) such that each C induces a connected subgraph of G. Using this partition P we construct a so-called structure-maintaining minor F of G via specific contractions within the disjoint sets such that F has O(n/log n) vertices. The combination of (F, P) is referred to as a cloud decomposition. We call a graph G=(V, E) separable if it admits to an O(n^c)-separator theorem for some constant c < 1 meaning there exists a separator S subset V that partitions V into {A, S, B} such that no vertices of A and B are adjacent in G and neither A nor B contain more than c'n vertices for a fixed constant c' < 1\. Due to the last property such separators are called balanced. This famously includes planar graphs, which admit an O(sqrt(n) n)-separator theorem. For planar graphs we show that a cloud decomposition can be constructed in O(n) time and using O(n) bits. Given a cloud decomposition (F, P) constructed for a planar graph G we are able to find a balanced separator of G in O(n/log n) time. Contrary to related publications, we do not make use of an embedding of the input graph. This allows us to construct the succinct encoding scheme for planar graphs due to Blelloch and Farzan (CPM 2010) in O(n) time and O(n) bits improving both runtime and space by a factor of Theta(log n). As an additional application of our cloud decomposition we show that a tree decomposition for planar graphs of width O(n^(1/2 + epsilon)) for any epsilon  0 can be constructed in O(n) bits and a time linear in the size of the tree decomposition. Finally, we generalize our cloud decomposition from planar graphs to arbitrary separable graphs."
Sample Complexity Bounds for Robustly Learning Decision Lists againstEvasion Attacks,"PascaleGourdeau, VarunKanade, MartaKwiatkowska, JamesWorrell",12 May 2022,Machine Learning (cs.LG)," A fundamental problem in adversarial machine learning is to quantify how much training data is needed in the presence of evasion attacks. In this paper we address this issue within the framework of PAC learning, focusing on the class of decision lists. Given that distributional assumptions are essential in the adversarial setting, we work with probability distributions on the input data that satisfy a Lipschitz condition: nearby points have similar probability. Our key results illustrate that the adversary's budget (that is, the number of bits it can perturb on each input) is a fundamental quantity in determining the sample complexity of robust learning. Our first main result is a sample-complexity lower bound: the class of monotone conjunctions (essentially the simplest non-trivial hypothesis class on the Boolean hypercube) and any superclass has sample complexity at least exponential in the adversary's budget. Our second main result is a corresponding upper bound: for every fixed $k$ the class of $k$-decision lists has polynomial sample complexity against a $\log(n)$-bounded adversary. This sheds further light on the question of whether an efficient PAC learning algorithm can always be used as an efficient $\log(n)$-robust learning algorithm under the uniform distribution."
"One Model, Multiple Modalities: A Sparsely Activated Approach forText, Sound, Image, Video and Code","YongDai, DuyuTang, Liangxin Liu, Minghuan Tan, Cong Zhou, JingquanWang, ZhangyinFeng, FanZhang, XueyuHu, ShumingShi",12 May 2022,Computation and Language (cs.CL)," People perceive the world with multiple senses (e.g., through hearing sounds, reading words and seeing objects). However, most existing AI systems only process an individual modality. This paper presents an approach that excels at handling multiple modalities of information with a single model. In our ""{SkillNet}"" model, different parts of the parameters are specialized for processing different modalities. Unlike traditional dense models that always activate all the model parameters, our model sparsely activates parts of the parameters whose skills are relevant to the task. Such model design enables SkillNet to learn skills in a more interpretable way. We develop our model for five modalities including text, image, sound, video and code. Results show that, SkillNet performs comparably to five modality-specific fine-tuned models. Moreover, our model supports self- supervised pretraining with the same sparsely activated way, resulting in better initialized parameters for different modalities. We find that pretraining significantly improves the performance of SkillNet on five modalities, on par with or even better than baselines with modality-specific pretraining. On the task of Chinese text-to-image retrieval, our final system achieves higher accuracy than existing leading systems including Wukong{ViT-B} and Wenlan 2.0 while using less number of activated parameters."
Zero-shot Code-Mixed Offensive Span Identification through RationaleExtraction,"ManikandanRavikiran, Bharathi RajaChakravarthi",12 May 2022,Computation and Language (cs.CL)," This paper investigates the effectiveness of sentence-level transformers for zero-shot offensive span identification on a code-mixed Tamil dataset. More specifically, we evaluate rationale extraction methods of Local Interpretable Model Agnostic Explanations (LIME) \cite{DBLP:conf/kdd/Ribeiro0G16} and Integrated Gradients (IG) \cite{DBLP:conf/icml/SundararajanTY17} for adapting transformer based offensive language classification models for zero-shot offensive span identification. To this end, we find that LIME and IG show baseline $F_{1}$ of 26.35\% and 44.83\%, respectively. Besides, we study the effect of data set size and training process on the overall accuracy of span identification. As a result, we find both LIME and IG to show significant improvement with Masked Data Augmentation and Multilabel Training, with $F_{1}$ of 50.23\% and 47.38\% respectively. \textit{Disclaimer : This paper contains examples that may be considered profane, vulgar, or offensive. The examples do not represent the views of the authors or their employers/graduate schools towards any person(s), group(s), practice(s), or entity/entities. Instead they are used to emphasize only the linguistic research challenges.}"
Findings of the Shared Task on Offensive Span Identification fromCode-Mixed Tamil-English Comments,"ManikandanRavikiran, Bharathi RajaChakravarthi, Anand KumarMadasamy, SangeethaSivanesan, RatnavelRajalakshmi, SajeethaThavareesan, RahulPonnusamy, ShankarMahadevan./",12 May 2022,Computation and Language (cs.CL)," Offensive content moderation is vital in social media platforms to support healthy online discussions. However, their prevalence in codemixed Dravidian languages is limited to classifying whole comments without identifying part of it contributing to offensiveness. Such limitation is primarily due to the lack of annotated data for offensive spans. Accordingly, in this shared task, we provide Tamil-English code-mixed social comments with offensive spans. This paper outlines the dataset so released, methods, and results of the submitted systems"
Secure Aggregation for Federated Learning in Flower,"Kwing HeiLi, PedroPorto Buarque deGusmão, Daniel J.Beutel, Nicholas D.Lane",12 May 2022,Machine Learning (cs.LG)," Federated Learning (FL) allows parties to learn a shared prediction model by delegating the training computation to clients and aggregating all the separately trained models on the server. To prevent private information being inferred from local models, Secure Aggregation (SA) protocols are used to ensure that the server is unable to inspect individual trained models as it aggregates them. However, current implementations of SA in FL frameworks have limitations, including vulnerability to client dropouts or configuration difficulties.   In this paper, we present Salvia, an implementation of SA for Python users in the Flower FL framework. Based on the SecAgg(+) protocols for a semi- honest threat model, Salvia is robust against client dropouts and exposes a flexible and easy-to-use API that is compatible with various machine learning frameworks. We show that Salvia's experimental performance is consistent with SecAgg(+)'s theoretical computation and communication complexities."
How are Drivers' Stress Levels and Emotions Associated with theDriving Context? A Naturalistic Study,"ArashTavakoli, Nathan Lai, VahidBalali, ArsalanHeydarian",12 May 2022,Human-Computer Interaction (cs.HC)," Understanding and mitigating drivers' negative emotions, stress levels, and anxiety is of high importance for decreasing accident rates, enhancing road safety, and providing a healthy lifestyle to the community of drivers. While detecting drivers' stress and negative emotions can significantly help with this goal, understanding what might be associated with increases in drivers' negative emotions and high stress level, might better help with planning interventions. While studies have provided significant insight into detecting drivers' emotions and stress levels; not many studies focused on the reasons behind changes in stress levels and negative emotions. In this study, by using a naturalistic driving study database, we analyze the changes in the driving scene, including road objects and the dynamical relationship between the ego vehicle and the lead vehicle with respect to changes in drivers' psychophysiological metrics (i.e., heart rate (HR) and facial expressions). We find that different road objects might be associated with varying levels of increase in drivers' HR as well as different proportions of negative facial emotions detected through computer vision. Our results indicate that larger vehicles on the road, such as trucks and buses, are associated with the highest amount of increase in drivers' HR as well as negative emotions. Additionally, we provide evidence that shorter distances to the lead vehicle in naturalistic driving, as well as the higher standard deviation in the distance, might be associated with a higher number of abrupt increases in drivers' HR, depicting a possible increase in stress level. Lastly, our results indicate more positive emotions, lower facial engagement, and a lower abrupt increase in HR at a higher speed of driving, which often happens in highway driving."
Evil Never Sleeps: When Wireless Malware Stays On After Turning OffiPhones,"JiskaClassen, AlexanderHeinrich, RobertReith, MatthiasHollick",12 May 2022,Cryptography and Security (cs.CR)," When an iPhone is turned off, most wireless chips stay on. For instance, upon user-initiated shutdown, the iPhone remains locatable via the Find My network. If the battery runs low, the iPhone shuts down automatically and enters a power reserve mode. Yet, users can still access credit cards, student passes, and other items in their Wallet. We analyze how Apple implements these standalone wireless features, working while iOS is not running, and determine their security boundaries. On recent iPhones, Bluetooth, Near Field Communication (NFC), and Ultra-wideband (UWB) keep running after power off, and all three wireless chips have direct access to the secure element. As a practical example what this means to security, we demonstrate the possibility to load malware onto a Bluetooth chip that is executed while the iPhone is off."
Mask Wearing Status Estimation with Smartwatches,"HuinaMeng, XileiWu, XinWang, YuhanFan, JingangShi, HanDing, FeiWang",12 May 2022,Human-Computer Interaction (cs.HC)," We present MaskReminder, an automatic mask-wearing status estimation system based on smartwatches, to remind users who may be exposed to the COVID-19 virus transmission scenarios, to wear a mask. MaskReminder with the powerful MLP-Mixer deep learning model can effectively learn long- short range information from the inertial measurement unit readings, and can recognize the mask-related hand movements such as wearing a mask, lowering the metal strap of the mask, removing the strap from behind one side of the ears, etc. Extensive experiments on 20 volunteers and 8000+ data samples show that the average recognition accuracy is 89%. Moreover, MaskReminder is capable to remind a user to wear with a success rate of 90% even in the user-independent setting."
Asking for Knowledge: Training RL Agents to Query External KnowledgeUsing Language,"Iou-JenLiu, XingdiYuan, Marc-AlexandreCôté, Pierre-YvesOudeyer, Alexander G.Schwing",12 May 2022,Artificial Intelligence (cs.AI)," To solve difficult tasks, humans ask questions to acquire knowledge from external sources. In contrast, classical reinforcement learning agents lack such an ability and often resort to exploratory behavior. This is exacerbated as few present-day environments support querying for knowledge. In order to study how agents can be taught to query external knowledge via language, we first introduce two new environments: the grid-world-based Q-BabyAI and the text-based Q-TextWorld. In addition to physical interactions, an agent can query an external knowledge source specialized for these environments to gather information. Second, we propose the ""Asking for Knowledge"" (AFK) agent, which learns to generate language commands to query for meaningful knowledge that helps solve the tasks. AFK leverages a non-parametric memory, a pointer mechanism and an episodic exploration bonus to tackle (1) a large query language space, (2) irrelevant information, (3) delayed reward for making meaningful queries. Extensive experiments demonstrate that the AFK agent outperforms recent baselines on the challenging Q-BabyAI and Q-TextWorld environments."
Social Distancing Alert with Smartwatches,"XinWang, XileiWu, HuinaMeng, YuhanFan, JingangShi, HanDing, FeiWang",12 May 2022,Human-Computer Interaction (cs.HC)," Social distancing is an efficient public health practice during the COVID-19 pandemic. However, people would violate the social distancing practice unconsciously when they conduct some social activities such as handshaking, hugging, kissing on the face or forehead, etc. In this paper, we present SoDA, a social distancing practice violation alert system based on smartwatches, for preventing COVID-19 virus transmission. SoDA utilizes recordings of accelerometers and gyroscopes to recognize activities that may violate social distancing practice with simple yet effective Vision Transformer models. Extensive experiments over 10 volunteers and 1800+ samples demonstrate that SoDA achieves social activity recognition with the accuracy of 94.7%, 1.8% negative alert, and 2.2% missing alert."
Tensor-based Emotion Editing in the StyleGAN Latent Space,"RenéHaas, StellaGraßhof, Sami S.Brandt",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In this paper, we use a tensor model based on the Higher-Order Singular Value Decomposition (HOSVD) to discover semantic directions in Generative Adversarial Networks. This is achieved by first embedding a structured facial expression database into the latent space using the e4e encoder. Specifically, we discover directions in latent space corresponding to the six prototypical emotions: anger, disgust, fear, happiness, sadness, and surprise, as well as a direction for yaw rotation. These latent space directions are employed to change the expression or yaw rotation of real face images. We compare our found directions to similar directions found by two other methods. The results show that the visual quality of the resultant edits are on par with State-of-the-Art. It can also be concluded that the tensor-based model is well suited for emotion and yaw editing, i.e., that the emotion or yaw rotation of a novel face image can be robustly changed without a significant effect on identity or other attributes in the images."
A Smart Contract based Crowdfunding Mechanism for HierarchicalFederated Learning,"HongzeLiu, JieLi, ShijingYuan, WenqiCao, BowenLi",12 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Hierarchical Federated Learning (HFL) is introduced as a promising technique that allows model owners to fully exploit computational resources and bandwidth resources to train the global model. However, due to the high training cost, a single model owner may not be able to deploy HFL. To address this issue, we develop a smart contract based trust crowdfunding mechanism for HFL, which enables multiple model owners to obtain a crowdfunding model with high social utility for multiple crowdfunding participants. To ensure the authenticity of the crowdfunding mechanism, we implemented the Vickey-Clark-Croves (VCG) mechanism to encourage all crowdfunding participants and clients to provide realistic bids and offers. At the same time, in order to ensure guaranteed trustworthiness of crowdfunding and automatic distribution of funds, we develop and implement a smart contract to record the crowdfunding process and training results in the blockchain. We prove that the proposed scheme satisfies the budget balance and participant constraint. Finally, we implement a prototype of this smart contract on an Ethereoum private chain and evaluate the proposed VCG mechanism. The experimental results demonstrate that the proposed scheme can effectively improve social utility while ensuring the authenticity and trustworthiness of the crowdfunding process."
Viable Algorithmic Options for Creating and Adapting Emergent SoftwareSystems,"ToddWareham, Ronald deHaan",12 May 2022,Software Engineering (cs.SE)," Given the complexity of modern software systems, it is of great importance that such systems be able to autonomously modify themselves, i.e., self-adapt, with minimal human supervision. It is critical that this adaptation both results in reliable systems and scales reasonably in required memory and runtime to non-trivial systems. In this paper, we apply computational complexity analysis to evaluate algorithmic options for the reliable creation and adaptation of emergent software systems relative to several popular types of exact and approximate efficient solvability. We show that neither problem is solvable for all inputs when no restrictions are placed on software system structure. This intractability continues to hold relative to all examined types of efficient exact and approximate solvability when software systems are restricted to run (and hence can be verified against system requirements) in polynomial time. Moreover, both of our problems when so restricted remain intractable under a variety of additional restrictions on software system structure, both individually and in many combinations. That being said, we also give sets of additional restrictions that do yield tractability for both problems, as well as circumstantial evidence that emergent software system adaptation is computationally easier than emergent software system creation."
Deep morphological recognition of kidney stones using intra-operativeendoscopic digital videos,"VincentEstrade, MichelDaudon, EmmanuelRichard, Jean-ChristopheBernhard, FranckBladou, GregoireRobert, Laurent Facq, Baudouin Denis deSenneville",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The collection and the analysis of kidney stone morphological criteria are essential for an aetiological diagnosis of stone disease. However, in-situ LASER-based fragmentation of urinary stones, which is now the most established chirurgical intervention, may destroy the morphology of the targeted stone. In the current study, we assess the performance and added value of processing complete digital endoscopic video sequences for the automatic recognition of stone morphological features during a standard- of-care intra-operative session. To this end, a computer-aided video classifier was developed to predict in-situ the morphology of stone using an intra-operative digital endoscopic video acquired in a clinical setting.   The proposed technique was evaluated on pure (i.e. include one morphology) and mixed (i.e. include at least two morphologies) stones involving ""Ia/Calcium Oxalate Monohydrate (COM)"", ""IIb/ Calcium Oxalate Dihydrate (COD)"" and ""IIIb/Uric Acid (UA)"" morphologies. 71 digital endoscopic videos (50 exhibited only one morphological type and 21 displayed two) were analyzed using the proposed video classifier (56840 frames processed in total). Using the proposed approach, diagnostic performances (averaged over both pure and mixed stone types) were as follows: balanced accuracy=88%, sensitivity=80%, specificity=95%, precision=78% and F1-score=78%.   The obtained results demonstrate that AI applied on digital endoscopic video sequences is a promising tool for collecting morphological information during the time-course of the stone fragmentation process without resorting to any human intervention for stone delineation or selection of good quality steady frames. To this end, irrelevant image information must be removed from the prediction process at both frame and pixel levels, which is now feasible thanks to the use of AI-dedicated networks."
Synergia: Hardening High-Assurance Security Systems with Confidentialand Trusted Computing,"WojciechOzga, RashaFaqeh, Do LeQuoc, FranzGregor, SilvioDragone, ChristofFetzer",12 May 2022,Cryptography and Security (cs.CR)," High-assurance security systems require strong isolation from the untrusted world to protect the security-sensitive or privacy-sensitive data they process. Existing regulations impose that such systems must execute in a trustworthy operating system (OS) to ensure they are not collocated with untrusted software that might negatively impact their availability or security. However, the existing techniques to attest to the OS integrity fall short due to the cuckoo attack. In this paper, we first show a novel defense mechanism against the cuckoo attack, and we formally prove it. Then, we implement it as part of an integrity monitoring and enforcement framework that attests to the trustworthiness of the OS from 3.7x to 8.5x faster than the existing integrity monitoring systems. We demonstrate its practicality by protecting the execution of a real-world eHealth application, performing micro and macro-benchmarks, and assessing the security risk."
From IP to transport and beyond: cross-layer attacks againstapplications,"TianxiangDai, PhilippJeitner, HayaShulman, MichaelWaidner",12 May 2022,Cryptography and Security (cs.CR)," We perform the first analysis of methodologies for launching DNS cache poisoning: manipulation at the IP layer, hijack of the inter-domain routing and probing open ports via side channels. We evaluate these methodologies against DNS resolvers in the Internet and compare them with respect to effectiveness, applicability and stealth. Our study shows that DNS cache poisoning is a practical and pervasive threat.   We then demonstrate cross-layer attacks that leverage DNS cache poisoning for attacking popular systems, ranging from security mechanisms, such as RPKI, to applications, such as VoIP. In addition to more traditional adversarial goals, most notably impersonation and Denial of Service, we show for the first time that DNS cache poisoning can even enable adversaries to bypass cryptographic defences: we demonstrate how DNS cache poisoning can facilitate BGP prefix hijacking of networks protected with RPKI even when all the other networks apply route origin validation to filter invalid BGP announcements. Our study shows that DNS plays a much more central role in the Internet security than previously assumed.   We recommend mitigations for securing the applications and for preventing cache poisoning."
Consensus Capacity of Noisy Broadcast Channels,"NehaSangwan, VarunNarayanan, Vinod M.Prabhakaran",12 May 2022,Information Theory (cs.IT)," We study communication with consensus over a broadcast channel - the receivers reliably decode the sender's message when the sender is honest, and their decoder outputs agree even if the sender acts maliciously. We characterize the broadcast channels which permit this byzantine consensus and determine their capacity."
SimRelUz: Similarity and Relatedness scores as a Semantic Evaluationdataset for Uzbek language,"UlugbekSalaev, ElmurodKuriyozov, Carlos Gómez-Rodríguez",12 May 2022,Computation and Language (cs.CL)," Semantic relatedness between words is one of the core concepts in natural language processing, thus making semantic evaluation an important task. In this paper, we present a semantic model evaluation dataset: SimRelUz - a collection of similarity and relatedness scores of word pairs for the low-resource Uzbek language. The dataset consists of more than a thousand pairs of words carefully selected based on their morphological features, occurrence frequency, semantic relation, as well as annotated by eleven native Uzbek speakers from different age groups and gender. We also paid attention to the problem of dealing with rare words and out-of- vocabulary words to thoroughly evaluate the robustness of semantic models."
Sequential algorithms for testing identity and closeness ofdistributions,"OmarFawzi, NicolasFlammarion, AurélienGarivier, AadilOufkir",12 May 2022,Data Structures and Algorithms (cs.DS)," What advantage do \emph{sequential} procedures provide over batch algorithms for testing properties of unknown distributions? Focusing on the problem of testing whether two distributions $\mathcal{D}_1$ and $\mathcal{D}_2$ on $\\{1,\dots, n\\}$ are equal or $\epsilon$-far, we give several answers to this question. We show that for a small alphabet size $n$, there is a sequential algorithm that outperforms any batch algorithm by a factor of at least $4$ in terms sample complexity. For a general alphabet size $n$, we give a sequential algorithm that uses no more samples than its batch counterpart, and possibly fewer if the actual distance $TV(\mathcal{D}_1, \mathcal{D}_2)$ between $\mathcal{D}_1$ and $\mathcal{D}_2$ is larger than $\epsilon$. As a corollary, letting $\epsilon$ go to $0$, we obtain a sequential algorithm for testing closeness when no a priori bound on $TV(\mathcal{D}_1, \mathcal{D}_2)$ is given that has a sample complexity $\tilde{\mathcal{O}}(\frac{n^{2/3}}{TV(\mathcal{D}_1, \mathcal{D}_2)^{4/3}})$: this improves over the $\tilde{\mathcal{O}}(\frac{n/\log n}{TV(\mathcal{D}_1, \mathcal{D}_2)^{2} })$ tester of \cite{daskalakis2017optimal} and is optimal up to multiplicative constants. We also establish limitations of sequential algorithms for the problem of testing identity and closeness: they can improve the worst case number of samples by at most a constant factor."
Data-aided Underwater Acoustic Ray Propagation Modeling,"KexinLi, MandarChitre",12 May 2022,Sound (cs.SD)," Acoustic propagation models are widely used in numerous oceanic and other underwater applications. Most conventional models are approximate solutions of the acoustic wave equation, and require accurate environmental knowledge to be available beforehand. Environmental parameters may not always be easily or accurately measurable. While data-driven techniques might allow us to model acoustic propagation without the need for extensive prior environmental knowledge, such techniques tend to be data-hungry and often infeasible in oceanic applications where data collection is difficult and expensive. We propose a data-aided ray physics based high frequency acoustic propagation modeling approach that enables us to train models with only a small amount of data. The proposed framework is not only data- efficient, but also offers flexibility to incorporate varying degrees of environmental knowledge, and generalizes well to permit extrapolation beyond the area where data was collected. We demonstrate the feasibility and applicability of our method through four numerical case studies, and one controlled experiment. We also benchmark our method's performance against classical data-driven techniques."
Stalloris: RPKI Downgrade Attack,"TomasHlavacek, PhilippJeitner, DonikaMirdita, HayaShulman, MichaelWaidner",12 May 2022,Cryptography and Security (cs.CR)," We demonstrate the first downgrade attacks against RPKI. The key design property in RPKI that allows our attacks is the tradeoff between connectivity and security: when networks cannot retrieve RPKI information from publication points, they make routing decisions in BGP without validating RPKI. We exploit this tradeoff to develop attacks that prevent the retrieval of the RPKI objects from the public repositories, thereby disabling RPKI validation and exposing the RPKI-protected networks to prefix hijack attacks.   We demonstrate experimentally that at least 47% of the public repositories are vulnerable against a specific version of our attacks, a rate-limiting off-path downgrade attack. We also show that all the current RPKI relying party implementations are vulnerable to attacks by a malicious publication point. This translates to 20.4% of the IPv4 address space.   We provide recommendations for preventing our downgrade attacks. However, resolving the fundamental problem is not straightforward: if the relying parties prefer security over connectivity and insist on RPKI validation when ROAs cannot be retrieved, the victim AS may become disconnected from many more networks than just the one that the adversary wishes to hijack. Our work shows that the publication points are a critical infrastructure for Internet connectivity and security. Our main recommendation is therefore that the publication points should be hosted on robust platforms guaranteeing a high degree of connectivity."
Outage Analysis of Aerial Semi-Grant-Free NOMA Systems,"HongjiangLei, ChenZhu, Ki-HongPark, ImranShafiqueAnsari, Weijia Lei, Hong Tang, Kyeong JinKim",12 May 2022,Information Theory (cs.IT)," In this paper, we analyze the outage performance of unmanned aerial vehicles (UAVs)-enabled downlink non-orthogonal multiple access (NOMA) communication systems with the semi-grant-free (SGF) transmission scheme. A UAV provides coverage services for a grant-based (GB) user and one user is allowed to utilize the same channel resource opportunistically. The hybrid successive interference cancellation scheme is implemented in the downlink NOMA scenarios for the first time. The analytical expressions for the exact and asymptotic outage probability (OP) of the grant-free (GF) user are derived. The results demonstrate that no-zero diversity order can be achieved only under stringent conditions on users' quality of service requirements. Subsequently, we propose an efficient dynamic power allocation (DPA) scheme to relax such data rate constraints to address this issue. The analytical expressions for the exact and asymptotic OP of the GF user with the DPA scheme are derived. Finally, Monte Carlo simulation results are presented to validate the correctness of the derived analytical expressions and demonstrate the effects of the UAV's location and altitude on the OP of the GF user."
$H^1$-stability of an L2-type method on general nonuniform meshes forsubdiffusion equation,"ChaoyuQuan, XuWu",12 May 2022,Numerical Analysis (math.NA)," In this work the $H^1$-stability of an L2 method on general nonuniform meshes is established for the subdiffusion equation. Under some mild constraints on the time step ratio $\rho_k$, for example $0.4573328\leq \rho_k\leq 3.5615528$ for all $k\geq 2$, a crucial bilinear form associated with the L2 fractional-derivative operator is proved to be positive semidefinite. As a consequence, the $H^1$-stability of L2 schemes can be derived for the subdiffusion equation. In the special case of graded mesh, such positive semidefiniteness holds when the grading parameter $1<r\leq 3.2016538$ and therefore the $H^1$-stability of L2 schemes holds. To the best of our knowledge, this is the first work on the $H^1$-stability of L2 method on general nonuniform meshes for subdiffusion equation."
"CURL: Continuous, Ultra-compact Representation for LiDAR","KaichengZhang, Ziyang Hong, Shida Xu, SenWang",12 May 2022,Robotics (cs.RO)," Increasing the density of the 3D LiDAR point cloud is appealing for many applications in robotics. However, high-density LiDAR sensors are usually costly and still limited to a level of coverage per scan (e.g., 128 channels). Meanwhile, denser point cloud scans and maps mean larger volumes to store and longer times to transmit. Existing works focus on either improving point cloud density or compressing its size. This paper aims to design a novel 3D point cloud representation that can continuously increase point cloud density while reducing its storage and transmitting size. The pipeline of the proposed Continuous, Ultra-compact Representation of LiDAR (CURL) includes four main steps: meshing, upsampling, encoding, and continuous reconstruction. It is capable of transforming a 3D LiDAR scan or map into a compact spherical harmonics representation which can be used or transmitted in low latency to continuously reconstruct a much denser 3D point cloud. Extensive experiments on four public datasets, covering college gardens, city streets, and indoor rooms, demonstrate that much denser 3D point clouds can be accurately reconstructed using the proposed CURL representation while achieving up to 80% storage space-saving. We open- source the CURL codes for the community."
"Positive, Negative and Neutral: Modeling Implicit Feedback in Session-based News Recommendation","ShansanGong, KennyQ. Zhu",12 May 2022,Information Retrieval (cs.IR)," News recommendation for anonymous readers is a useful but challenging task for many news portals, where interactions between readers and articles are limited within a temporary login session. Previous works tend to formulate session-based recommendation as a next item prediction task, while they neglect the implicit feedback from user behaviors, which indicates what users really like or dislike. Hence, we propose a comprehensive framework to model user behaviors through positive feedback (i.e., the articles they spend more time on) and negative feedback (i.e., the articles they choose to skip without clicking in). Moreover, the framework implicitly models the user using their session start time, and the article using its initial publishing time, in what we call ""neutral feedback"". Empirical evaluation on three real-world news datasets shows the framework's promising performance of more accurate, diverse and even unexpectedness recommendations than other state-of-the-art session-based recommendation approaches."
A Qualitative Evaluation of Service Mesh-based Traffic Management forMobile Edge Cloud,"Aleksandra ObesoDuque, CristianKlein, Jinhua Feng, Xuejun Cai, BjörnSkubic, ErikElmroth",12 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Service mesh is getting widely adopted as the cloud-native mechanism for traffic management in microservice-based applications, in particular for generic IT workloads hosted in more centralized cloud environments. Performance-demanding applications continue to drive the decentralization of modern application execution environments, as in the case of mobile edge cloud.   This paper presents a systematic and qualitative analysis of state-of-the- art service mesh to evaluate how suitable its design is for addressing the traffic management needs of performance-demanding application workloads hosted in a mobile edge cloud environment. With this analysis, we argue that today's dependability-centric service mesh design fails at addressing the needs of the different types of emerging mobile edge cloud workloads and motivate further research in the directions of performance-efficient architectures, stronger QoS guarantees and higher complexity abstractions of cloud-native traffic management frameworks."
Unified Source-Filter GAN with Harmonic-plus-Noise Source ExcitationGeneration,"ReoYoneyama, Yi-Chiao Wu, Tomoki Toda",12 May 2022,Sound (cs.SD)," This paper introduces a unified source-filter network with a harmonic-plus-noise source excitation generation mechanism. In our previous work, we proposed unified Source-Filter GAN (uSFGAN) for developing a high- fidelity neural vocoder with flexible voice controllability using a unified source-filter neural network architecture. However, the capability of uSFGAN to model the aperiodic source excitation signal is insufficient, and there is still a gap in sound quality between the natural and generated speech. To improve the source excitation modeling and generated sound quality, a new source excitation generation network separately generating periodic and aperiodic components is proposed. The advanced adversarial training procedure of HiFiGAN is also adopted to replace that of Parallel WaveGAN used in the original uSFGAN. Both objective and subjective evaluation results show that the modified uSFGAN significantly improves the sound quality of the basic uSFGAN while maintaining the voice controllability."
Link recommendations: Their impact on network structure and minorities,"AntonioFerrara, Lisette Espín-Noboa, FaribaKarimi, ClaudiaWagner",12 May 2022,Social and Information Networks (cs.SI)," Network-based people recommendation algorithms are widely employed on the Web to suggest new connections in social media or professional platforms. While such recommendations bring people together, the feedback loop between the algorithms and the changes in network structure may exacerbate social biases. These biases include rich-get-richer effects, filter bubbles, and polarization. However, social networks are diverse complex systems and recommendations may affect them differently, depending on their structural properties. In this work, we explore five people recommendation algorithms by systematically applying them over time to different synthetic networks. In particular, we measure to what extent these recommendations change the structure of bi-populated networks and show how these changes affect the minority group. Our systematic experimentation helps to better understand when link recommendation algorithms are beneficial or harmful to minority groups in social networks. In particular, our findings suggest that, while all algorithms tend to close triangles and increase cohesion, all algorithms except Node2Vec are prone to favor and suggest nodes with high in-degree. Furthermore, we found that, especially when both classes are heterophilic, recommendation algorithms can reduce the visibility of minorities."
Ultra-Reliable Low-Latency Communication for Aerial Vehicles viaMulti-Connectivity,"FatemeSalehi, MustafaOzger, NaaserNeda, CicekCavdar",12 May 2022,Systems and Control (eess.SY)," Aerial vehicles (AVs) such as electric vertical take-off and landing (eVTOL) make aerial passenger transportation a reality in urban environments. However, their communication connectivity is still under research to realize their safe and full-scale operation, which requires stringent end-to-end (E2E) reliability and delay. In this paper, we evaluate reliability and delay for the downlink communication of AVs, i.e., remote piloting, control/telemetry traffic of AVs. We investigate direct air-to- ground (DA2G) and air-to-air (A2A) communication technologies, along with high altitude platforms (HAPs) to explore the conditions of how multi- connectivity (MC) options satisfy the demanding E2E connectivity requirements under backhaul link bottleneck. Our considered use case is ultra-reliable low-latency communication (URLLC) under the finite blocklength (FBL) regime due to the nature of downlink control communication to AVs. In our numerical study, we find that providing requirements by single connectivity to AVs is very challenging due to the line-of-sight (LoS) interference and reduced gains of downtilt ground base station (BS) antenna. We also find that even with very efficient interference mitigation, existing cellular networks designed for terrestrial users are not capable of meeting the URLLC requirements calling for MC solutions."
Reactive Synthesis of Smart Contract Control Flows,"BerndFinkbeiner, JanaHofmann, Florian Kohn, NoemiPassing",12 May 2022,Logic in Computer Science (cs.LO)," Smart contracts are small but highly error-prone programs that implement agreements between multiple parties. We present a reactive synthesis workflow for the automatic construction of finite-state machines implementing the control flow of a smart contract. As specification language, we use temporal stream logic (TSL), which builds on LTL but adds additional mechanisms to reason about the control flow of infinite data. Our specifications not only reason about the order of transactions based on guards like access rights, but also include the updates of fields necessary for a correct control flow. We show how to comprehensively specify the control flow of various types of common smart contracts, including auctions, asset transfers, and crowd funding protocols. Our tool \tool implements the approach using BDD-based symbolic algorithms, resulting in a fast reactive control flow synthesis."
Sampling with Attribute-Related Information for Controlling LanguageModels,"ShangdaWu, MaosongSun",12 May 2022,Computation and Language (cs.CL)," The dominant approaches for controlling language models are based on fine-tuning large language models or prompt engineering. However, these methods often require condition-specific data or considerable hand-crafting. We propose a new simple guided decoding method, Gamma Sampling, which does not require complex engineering and any extra data. Gamma Sampling introduces attribute-related information (provided by humans or language models themselves) into the sampling process to guide language models to generate texts with desired attributes. Experiments on controlling topics and sentiments of generated text show Gamma Sampling to be superior in diversity, attribute relevance and overall quality of generated samples while maintaining a fast generation speed. In addition, we successfully applied Gamma Sampling to control other attributes of language such as relatedness and repetition, which further demonstrates the versatility and effectiveness of this method. Gamma Sampling is now available in the python package samplings via import gamma sampling from samplings."
D3T-GAN: Data-Dependent Domain Transfer GANs for Few-shot ImageGeneration,"XintianWu, HuanyuWang, YimingWu, XiLi",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," As an important and challenging problem, few-shot image generation aims at generating realistic images through training a GAN model given few samples. A typical solution for few-shot generation is to transfer a well- trained GAN model from a data-rich source domain to the data-deficient target domain. In this paper, we propose a novel self-supervised transfer scheme termed D3T-GAN, addressing the cross-domain GANs transfer in few-shot image generation. Specifically, we design two individual strategies to transfer knowledge between generators and discriminators, respectively. To transfer knowledge between generators, we conduct a data-dependent transformation, which projects and reconstructs the target samples into the source generator space. Then, we perform knowledge transfer from transformed samples to generated samples. To transfer knowledge between discriminators, we design a multi-level discriminant knowledge distillation from the source discriminator to the target discriminator on both the real and fake samples. Extensive experiments show that our method improve the quality of generated images and achieves the state-of-the-art FID scores on commonly used datasets."
Order-Degree-Height Surfaces for Linear Operators,"HuiHuang, ManuelKauers, GargiMukherjee",12 May 2022,Symbolic Computation (cs.SC)," It is known for linear operators with polynomial coefficients annihilating a given D-finite function that there is a trade-off between order and degree. Raising the order may give room for lowering the degree. The relationship between order and degree is typically described by a hyperbola known as the order-degree curve. In this paper, we add the height into the picture, i.e., a measure for the size of the coefficients in the polynomial coefficients. For certain situations, we derive relationships between order, degree, and height that can be viewed as order-degree-height surfaces."
A Family of Algorithms for Computing Information-Theoretic Forms ofStrong Converse Exponents in Channel Coding and Lossy Source Coding,"YutakaJitsumatsu, YasutadaOohama",12 May 2022,Information Theory (cs.IT)," This paper studies the computation of error and correct decoding probability exponents in channel coding and lossy source coding. For channel coding, we show that the recently proposed algorithm of Tridenski and Zamir for computing strong converse exponent has the attractive property that the objective function alternately takes the forms appearing in Arimoto's and Dueck and Körner's exponents. Because of this property, the convergence of the algorithm directly implies the match of the two exponents. Then, we consider a special case of Tridenski et al.'s generalized algorithm of that has not been examined in depth. We show that the objective function of this algorithm also has the interesting property that it takes the forms of Dueck and Körner's exponent and another representation of the strong converse exponent derived by Arimoto's algorithm. This particular case is important because the objective function in this case can be used to prove that the Gallager and Csiszár and Körner error exponents agree.63 For lossy source coding, we propose two new algorithms for computing the Csiszár and Körner's strong converse exponent. We also define a function similar to Blahut's error exponent with a negative slope parameter for source coding. We show that one of the proposed algorithms has the property that the objective function alternately takes the forms of Csiszár and Körner's exponent and the newly defined exponent function. The convergence of the algorithm proves that the new exponent function coincides with the Csiszár and Körner exponent. We also prove that Arimoto algorithm for computing error exponent of lossy source coding can work for negative $\rho \ge -1$ and thus can be used to compute the new exponent function. Computation of Arikan and Merhav's guessing exponent is also discussed."
DTW at Qur'an QA 2022: Utilising Transfer Learning with Transformersfor Question Answering in a Low-resource Domain,"DamithPremasiri, TharinduRanasinghe, WajdiZaghouani, RuslanMitkov",12 May 2022,Computation and Language (cs.CL)," The task of machine reading comprehension (MRC) is a useful benchmark to evaluate the natural language understanding of machines. It has gained popularity in the natural language processing (NLP) field mainly due to the large number of datasets released for many languages. However, the research in MRC has been understudied in several domains, including religious texts. The goal of the Qur'an QA 2022 shared task is to fill this gap by producing state-of-the-art question answering and reading comprehension research on Qur'an. This paper describes the DTW entry to the Quran QA 2022 shared task. Our methodology uses transfer learning to take advantage of available Arabic MRC data. We further improve the results using various ensemble learning strategies. Our approach provided a partial Reciprocal Rank (pRR) score of 0.49 on the test set, proving its strong performance on the task."
Anomaly detection and community detection in networks,"HadisehSafdari, Caterina DeBacco",12 May 2022,Social and Information Networks (cs.SI)," Anomaly detection is a relevant problem in the area of data analysis. In networked systems, where individual entities interact in pairs, anomalies are observed when pattern of interactions deviates from patterns considered regular. Properly defining what regular patterns entail relies on developing expressive models for describing the observed interactions. It is crucial to address anomaly detection in networks. Among the many well-known models for networks, latent variable models - a class of probabilistic models - offer promising tools to capture the intrinsic features of the data. In this work, we propose a probabilistic generative approach which incorporates domain knowledge, i.e., community membership, as a fundamental model for regular behavior, and thus flag potential anomalies deviating from this pattern. In fact, community membership act as the building blocks of a null model to identify the regular interaction patterns. The structural information is included in the model through latent variables for community membership and anomaly parameter. The algorithm aims at inferring these latent parameters and then output the labels identifying anomalies on the network edges."
Mobility-Aware Resource Allocation for mmWave IAB Networks: A Multi-Agent RL Approach,"BiboZhang, IlarioFilippini",12 May 2022,Networking and Internet Architecture (cs.NI)," MmWaves have been envisioned as a promising direction to provide Gbps wireless access. However, they are susceptible to high path losses and blockages, which directional antennas can only partially mitigate. That makes mmWave networks coverage-limited, thus requiring dense deployments. Integrated access and backhaul (IAB) architectures have emerged as a cost- effective solution for network densification. Resource allocation in mmWave IAB networks must face big challenges to cope with heavy temporal dynamics, such as intermittent links caused by user mobility and blockages from moving obstacles. This makes it extremely difficult to find optimal and adaptive solutions. In this article, exploiting the distributed structure of the problem, we propose a Multi-Agent Reinforcement Learning (MARL) framework to optimize user throughput via flow routing and link scheduling in mmWave IAB networks characterized by user mobility and link outages generated by moving obstacles. The proposed approach implicitly captures the environment dynamics, coordinates the interference, and manages the buffer levels of IAB relay nodes. We design different MARL components, considering full-duplex and half-duplex IAB-nodes. In addition, we provide a communication and coordination scheme for RL agents in an online training framework, addressing the feasibility issues of practical systems. Numerical results show the effectiveness of the proposed approach."
Falsesum: Generating Document-level NLI Examples for RecognizingFactual Inconsistency in Summarization,"Prasetya AjieUtama, JoshuaBambrick, Nafise SadatMoosavi, IrynaGurevych",12 May 2022,Computation and Language (cs.CL)," Neural abstractive summarization models are prone to generate summaries which are factually inconsistent with their source documents. Previous work has introduced the task of recognizing such factual inconsistency as a downstream application of natural language inference (NLI). However, state-of-the-art NLI models perform poorly in this context due to their inability to generalize to the target task. In this work, we show that NLI models can be effective for this task when the training data is augmented with high-quality task-oriented examples. We introduce Falsesum, a data generation pipeline leveraging a controllable text generation model to perturb human-annotated summaries, introducing varying types of factual inconsistencies. Unlike previously introduced document- level NLI datasets, our generated dataset contains examples that are diverse and inconsistent yet plausible. We show that models trained on a Falsesum- augmented NLI dataset improve the state-of-the-art performance across four benchmarks for detecting factual inconsistency in summarization.   The code to obtain the dataset is available online at [this https URL](https://github.com/joshbambrick/Falsesum)"
Predictability Exponent of Stochastic Dynamical Systems,"Tao Xu, Jianping He, Yushan Li",12 May 2022,Information Theory (cs.IT)," Predicting the trajectory of stochastic dynamical systems (SDSs) is an intriguing problem in numerous fields, where characterizing the predictability of SDSs is of fundamental importance. Prior works have tackled this issue by indirectly investigating the uncertainty of distribution in each prediction. How accurately the trajectory of SDSs can be directly predicted still remains open. This paper proposes a new metric, namely predictability exponent, to characterize the decaying rate of probability that the prediction error never exceeds arbitrary $\epsilon$. To evaluate predictability exponent, we begin with providing a complete framework for model-known cases. Then, we bring to light the explicit relationship between predictability exponent and entropy by discrete approximation techniques. The definition and evaluation on predictability exponent are further extended to model-unknown cases by optimizing over model spaces, which build a bridge between the accuracy of trajectory predictions and popular entropy-based uncertainty measures. Examples of unpredictable trajectory design are presented to elaborate the applicability of the proposed predictability metric. Simulations are conducted to illustrate the efficiency of the obtained results."
Learning Generalized Policies Without Supervision Using GNNs,"SimonStåhlberg, Blai Bonet, HectorGeffner",12 May 2022,Artificial Intelligence (cs.AI)," We consider the problem of learning generalized policies for classical planning domains using graph neural networks from small instances represented in lifted STRIPS. The problem has been considered before but the proposed neural architectures are complex and the results are often mixed. In this work, we use a simple and general GNN architecture and aim at obtaining crisp experimental results and a deeper understanding: either the policy greedy in the learned value function achieves close to 100% generalization over instances larger than those used in training, or the failure must be understood, and possibly fixed, logically. For this, we exploit the relation established between the expressive power of GNNs and the $C_{2}$ fragment of first-order logic (namely, FOL with 2 variables and counting quantifiers). We find for example that domains with general policies that require more expressive features can be solved with GNNs once the states are extended with suitable ""derived atoms"" encoding role compositions and transitive closures that do not fit into $C_{2}$. The work follows the GNN approach for learning optimal general policies in a supervised fashion (Stahlberg, Bonet, Geffner, 2022); but the learned policies are no longer required to be optimal (which expands the scope, as many planning domains do not have general optimal policies) and are learned without supervision. Interestingly, value-based reinforcement learning methods that aim to produce optimal policies, do not always yield policies that generalize, as the goals of optimality and generality are in conflict in domains where optimal planning is NP-hard."
Accounting for the Sequential Nature of States to Learn Features forReinforcement Learning,"NathanMichlo, DevonJarvis, RichardKlein, Steven James",12 May 2022,Machine Learning (cs.LG)," In this work, we investigate the properties of data that cause popular representation learning approaches to fail. In particular, we find that in environments where states do not significantly overlap, variational autoencoders (VAEs) fail to learn useful features. We demonstrate this failure in a simple gridworld domain, and then provide a solution in the form of metric learning. However, metric learning requires supervision in the form of a distance function, which is absent in reinforcement learning. To overcome this, we leverage the sequential nature of states in a replay buffer to approximate a distance metric and provide a weak supervision signal, under the assumption that temporally close states are also semantically similar. We modify a VAE with triplet loss and demonstrate that this approach is able to learn useful features for downstream tasks, without additional supervision, in environments where standard VAEs fail."
Blueprint Separable Residual Network for Efficient Image Super-Resolution,"ZheyuanLi, YingqiLiu, XiangyuChen, HaomingCai, JinjinGu, YuQiao, ChaoDong",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Recent advances in single image super-resolution (SISR) have achieved extraordinary performance, but the computational cost is too heavy to apply in edge devices. To alleviate this problem, many novel and effective solutions have been proposed. Convolutional neural network (CNN) with the attention mechanism has attracted increasing attention due to its efficiency and effectiveness. However, there is still redundancy in the convolution operation. In this paper, we propose Blueprint Separable Residual Network (BSRN) containing two efficient designs. One is the usage of blueprint separable convolution (BSConv), which takes place of the redundant convolution operation. The other is to enhance the model ability by introducing more effective attention modules. The experimental results show that BSRN achieves state-of-the-art performance among existing efficient SR methods. Moreover, a smaller variant of our model BSRN-S won the first place in model complexity track of NTIRE 2022 Efficient SR Challenge. The code is available at [this https URL](https://github.com/xiaom233/BSRN)."
Controlling Formality in Low-Resource NMT with Domain Adaptation andRe-Ranking: SLT-CDT-UoS at IWSLT2022,"Sebastian T.Vincent, LoïcBarrault, CarolinaScarton",12 May 2022,Computation and Language (cs.CL)," This paper describes the SLT-CDT-UoS group's submission to the first Special Task on Formality Control for Spoken Language Translation, part of the IWSLT 2022 Evaluation Campaign. Our efforts were split between two fronts: data engineering and altering the objective function for best hypothesis selection. We used language-independent methods to extract formal and informal sentence pairs from the provided corpora; using English as a pivot language, we propagated formality annotations to languages treated as zero-shot in the task; we also further improved formality controlling with a hypothesis re-ranking approach. On the test sets for English-to-German and English-to-Spanish, we achieved an average accuracy of .935 within the constrained setting and .995 within unconstrained setting. In a zero-shot setting for English-to-Russian and English-to-Italian, we scored average accuracy of .590 for constrained setting and .659 for unconstrained."
AiSocrates: Towards Answering Ethical Quandary Questions,"YejinBang, NayeonLee, TiezhengYu, LeilaKhalatbari, Yan Xu, DanSu, Elham J.Barezi, AndreaMadotto, Hayden Kee, Pascale Fung",12 May 2022,Computation and Language (cs.CL)," Considerable advancements have been made in various NLP tasks based on the impressive power of large pre-trained language models (LLMs). These results have inspired efforts to understand the limits of LLMs so as to evaluate how far we are from achieving human level general natural language understanding. In this work, we challenge the capability of LLMs with the new task of Ethical Quandary Generative Question Answering. Ethical quandary questions are more challenging to address because multiple conflicting answers may exist to a single quandary. We propose a system, AiSocrates, that provides an answer with a deliberative exchange of different perspectives to an ethical quandary, in the approach of Socratic philosophy, instead of providing a closed answer like an oracle. AiSocrates searches for different ethical principles applicable to the ethical quandary and generates an answer conditioned on the chosen principles through prompt- based few-shot learning. We also address safety concerns by providing a human controllability option in choosing ethical principles. We show that AiSocrates generates promising answers to ethical quandary questions with multiple perspectives, 6.92% more often than answers written by human philosophers by one measure, but the system still needs improvement to match the coherence of human philosophers fully. We argue that AiSocrates is a promising step toward developing an NLP system that incorporates human values explicitly by prompt instructions. We are releasing the code for research purposes."
Vectorized and performance-portable Quicksort,"MarkBlacher, JoachimGiesen, PeterSanders, JanWassenberg",12 May 2022,Information Retrieval (cs.IR)," Recent works showed that implementations of Quicksort using vector CPU instructions can outperform the non-vectorized algorithms in widespread use. However, these implementations are typically single-threaded, implemented for a particular instruction set, and restricted to a small set of key types. We lift these three restrictions: our proposed 'vqsort' algorithm integrates into the state-of-the-art parallel sorter 'ips4o', with a geometric mean speedup of 1.59. The same implementation works on seven instruction sets (including SVE and RISC-V V) across four platforms. It also supports floating-point and 16-128 bit integer keys. To the best of our knowledge, this is the fastest sort for non-tuple keys on CPUs, up to 20 times as fast as the sorting algorithms implemented in standard libraries. This paper focuses on the practical engineering aspects enabling the speed and portability, which we have not yet seen demonstrated for a Quicksort implementation. Furthermore, we introduce compact and transpose-free sorting networks for in-register sorting of small arrays, and a vector-friendly pivot sampling strategy that is robust against adversarial input."
"""Teaching Independent Parts Separately""(TIPS-GAN) : Improving Accuracyand Stability in Unsupervised Adversarial 2D to 3D Human Pose Estimation","PeterHardy, SrinandanDasmahapatra, Hansung Kim",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We present TIPS-GAN, a new approach to improve the accuracy and stability in unsupervised adversarial 2D to 3D human pose estimation. In our work we demonstrate that the human kinematic skeleton should not be assumed as one spatially dependent structure. In fact, we believe when a full 2D pose is provided during training, there is an inherent bias learned where the 3D coordinate of a keypoint is spatially codependent on the 2D locations of all other keypoints. To investigate our theory we follow previous adversarial approaches but trained two generators on spatially independent parts of the kinematic skeleton, the torso and the legs. During our study we find that improving self-consistency is key to lowering the evaluation error and therefore introduce new consistency constraints within the standard adversarial cycle. We then produced a final TIPS model via knowledge distillation which can predict the 3D coordinates for the entire 2D pose with improved results. Furthermore we help address the question left unanswered in prior adversarial learning papers of how long to train for a truly unsupervised scenario. We show that two independent generators training adversarially can hold a minimum error against a discriminator for a longer period of time than that of a solo generator which will diverge due to the adversarial network becoming unstable. TIPS decreases the average error by 18\% when compared to that of a baseline solo generator. TIPS improves upon other unsupervised approaches while also performing strongly against supervised and weakly-supervised approaches during evaluation on both the Human3.6M and MPI-INF-3DHP dataset."
MPPNet: Multi-Frame Feature Intertwining with Proxy Points for 3DTemporal Object Detection,"XuesongChen, Shaoshuai Shi, Benjin Zhu, Ka ChunCheung, Hang Xu, Hongsheng Li",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Accurate and reliable 3D detection is vital for many applications including autonomous driving vehicles and service robots. In this paper, we present a flexible and high-performance 3D detection framework, named MPPNet, for 3D temporal object detection with point cloud sequences. We propose a novel three-hierarchy framework with proxy points for multi-frame feature encoding and interactions to achieve better detection. The three hierarchies conduct per-frame feature encoding, short-clip feature fusion, and whole-sequence feature aggregation, respectively. To enable processing long-sequence point clouds with reasonable computational resources, intra- group feature mixing and inter-group feature attention are proposed to form the second and third feature encoding hierarchies, which are recurrently applied for aggregating multi-frame trajectory features. The proxy points not only act as consistent object representations for each frame, but also serve as the courier to facilitate feature interaction between frames. The experiments on largeWaymo Open dataset show that our approach outperforms state-of-the-art methods with large margins when applied to both short (e.g., 4-frame) and long (e.g., 16-frame) point cloud sequences. Specifically, MPPNet achieves 74.21%, 74.62% and 73.31% for vehicle, pedestrian and cyclist classes on the LEVEL 2 mAPH metric with 16-frame input."
TaDeR: A New Task Dependency Recommendation for Project ManagementPlatform,"QuynhNguyen, DacH. Nguyen, Son T.Huynh, HoaK. Dam, BinhT. Nguyen",12 May 2022,Information Retrieval (cs.IR)," Many startups and companies worldwide have been using project management software and tools to monitor, track and manage their projects. For software projects, the number of tasks from the beginning to the end is quite a large number that sometimes takes a lot of time and effort to search and link the current task to a group of previous ones for further references. This paper proposes an efficient task dependency recommendation algorithm to suggest tasks dependent on a given task that the user has just created. We present an efficient feature engineering step and construct a deep neural network to this aim. We performed extensive experiments on two different large projects (MDLSITE from [this http URL](http://moodle.org) and FLUME from [this http URL](http://apache.org)) to find the best features in 28 combinations of features and the best performance model using two embedding methods (GloVe and FastText). We consider three types of models (GRU, CNN, LSTM) using Accuracy@K, MRR@K, and Recall@K (where K = 1, 2, 3, and 5) and baseline models using traditional methods: TF-IDF with various matching score calculating such as cosine similarity, Euclidean distance, Manhattan distance, and Chebyshev distance. After many experiments, the GloVe Embedding and CNN model reached the best result in our dataset, so we chose this model as our proposed method. In addition, adding the time filter in the post-processing step can significantly improve the recommendation system's performance. The experimental results show that our proposed method can reach 0.2335 in Accuracy@1 and MRR@1 and 0.2011 in Recall@1 of dataset FLUME. With the MDLSITE dataset, we obtained 0.1258 in Accuracy@1 and MRR@1 and 0.1141 in Recall@1. In the top 5, our model reached 0.3040 in Accuracy@5, 0.2563 MRR@5, and 0.2651 Recall@5 in FLUME. In the MDLSITE dataset, our model got 0.5270 Accuracy@5, 0.2689 MRR@5, and 0.2651 Recall@5."
CorAl: Introspection for Robust Radar and Lidar Perception in DiverseEnvironments Using Differential Entropy,"DanielAdolfsson, Manuel Castellano-Quero, MartinMagnusson, Achim J.Lilienthal, HenrikAndreasson",12 May 2022,Robotics (cs.RO)," Robust perception is an essential component to enable long-term operation of mobile robots. It depends on failure resilience through reliable sensor data and preprocessing, as well as failure awareness through introspection, for example the ability to self-assess localization performance. This paper presents CorAl: a principled, intuitive, and generalizable method to measure the quality of alignment between pairs of point clouds, which learns to detect alignment errors in a self-supervised manner. CorAl compares the differential entropy in the point clouds separately with the entropy in their union to account for entropy inherent to the scene. By making use of dual entropy measurements, we obtain a quality metric that is highly sensitive to small alignment errors and still generalizes well to unseen environments. In this work, we extend our previous work on lidar-only CorAl to radar data by proposing a two-stage filtering technique that produces high-quality point clouds from noisy radar scans. Thus we target robust perception in two ways: by introducing a method that introspectively assesses alignment quality, and applying it to an inherently robust sensor modality. We show that our filtering technique combined with CorAl can be applied to the problem of alignment classification, and that it detects small alignment errors in urban settings with up to 98% accuracy, and with up to 96% if trained only in a different environment. Our lidar and radar experiments demonstrate that CorAl outperforms previous methods both on the ETH lidar benchmark, which includes several indoor and outdoor environments, and the large-scale Oxford and MulRan radar data sets for urban traffic scenarios The results also demonstrate that CorAl generalizes very well across substantially different environments without the need of retraining."
A Computational Acquisition Model for Multimodal Word Categorization,"UriBerger, GabrielStanovsky, Omri Abend, LeaFrermann",12 May 2022,Computation and Language (cs.CL)," Recent advances in self-supervised modeling of text and images open new opportunities for computational models of child language acquisition, which is believed to rely heavily on cross-modal signals. However, prior studies have been limited by their reliance on vision models trained on large image datasets annotated with a pre-defined set of depicted object categories. This is (a) not faithful to the information children receive and (b) prohibits the evaluation of such models with respect to category learning tasks, due to the pre-imposed category structure. We address this gap, and present a cognitively-inspired, multimodal acquisition model, trained from image-caption pairs on naturalistic data using cross- modal self-supervision. We show that the model learns word categories and object recognition abilities, and presents trends reminiscent of those reported in the developmental literature. We make our code and trained models public for future reference and use."
Target Aware Network Architecture Search and Compression for EfficientKnowledge Transfer,"S.H.ShabbeerBasha, DebapriyaTula, SravanKumarVinakota, Shiv RamDubey",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Transfer Learning enables Convolutional Neural Networks (CNN) to acquire knowledge from a source domain and transfer it to a target domain, where collecting large-scale annotated examples is both time-consuming and expensive. Conventionally, while transferring the knowledge learned from one task to another task, the deeper layers of a pre-trained CNN are finetuned over the target dataset. However, these layers that are originally designed for the source task are over-parameterized for the target task. Thus, finetuning these layers over the target dataset reduces the generalization ability of the CNN due to high network complexity. To tackle this problem, we propose a two-stage framework called TASCNet which enables efficient knowledge transfer. In the first stage, the configuration of the deeper layers is learned automatically and finetuned over the target dataset. Later, in the second stage, the redundant filters are pruned from the fine- tuned CNN to decrease the network's complexity for the target task while preserving the performance. This two-stage mechanism finds a compact version of the pre-trained CNN with optimal structure (number of filters in a convolutional layer, number of neurons in a dense layer, and so on) from the hypothesis space. The efficacy of the proposed method is evaluated using VGG-16, ResNet-50, and DenseNet-121 on CalTech-101, CalTech-256, and Stanford Dogs datasets. The proposed TASCNet reduces the computational complexity of pre-trained CNNs over the target task by reducing both trainable parameters and FLOPs which enables resource-efficient knowledge transfer."
FPSRS: A Fusion Approach for Paper Submission Recommendation System,"Son T.Huynh, NhiDang, Dac H.Nguyen, Phong T.Huynh, Binh T.Nguyen",12 May 2022,Information Retrieval (cs.IR)," Recommender systems have been increasingly popular in entertainment and consumption and are evident in academics, especially for applications that suggest submitting scientific articles to scientists. However, because of the various acceptance rates, impact factors, and rankings in different publishers, searching for a proper venue or journal to submit a scientific work usually takes a lot of time and effort. In this paper, we aim to present two newer approaches extended from our paper [13] presented at the conference IAE/AIE 2021 by employing RNN structures besides using Conv1D. In addition, we also introduce a new method, namely DistilBertAims, using DistillBert for two cases of uppercase and lower-case words to vectorize features such as Title, Abstract, and Keywords, and then use Conv1d to perform feature extraction. Furthermore, we propose a new calculation method for similarity score for Aim & Scope with other features; this helps keep the weights of similarity score calculation continuously updated and then continue to fit more data. The experimental results show that the second approach could obtain a better performance, which is 62.46% and 12.44% higher than the best of the previous study [13] in terms of the Top 1 accuracy."
GPN: A Joint Structural Learning Framework for Graph Neural Networks,"QianggangDing, DehengYe, TingyangXu, PeilinZhao",12 May 2022,Machine Learning (cs.LG)," Graph neural networks (GNNs) have been applied into a variety of graph tasks. Most existing work of GNNs is based on the assumption that the given graph data is optimal, while it is inevitable that there exists missing or incomplete edges in the graph data for training, leading to degraded performance. In this paper, we propose Generative Predictive Network (GPN), a GNN-based joint learning framework that simultaneously learns the graph structure and the downstream task. Specifically, we develop a bilevel optimization framework for this joint learning task, in which the upper optimization (generator) and the lower optimization (predictor) are both instantiated with GNNs. To the best of our knowledge, our method is the first GNN-based bilevel optimization framework for resolving this task. Through extensive experiments, our method outperforms a wide range of baselines using benchmark datasets."
Economical Precise Manipulation and Auto Eye-Hand Coordination withBinocular Visual Reinforcement Learning,"YiwenChen, ShengGuo, LeiZhou, XianYao Ng, Marcelo H. AngJr",12 May 2022,Robotics (cs.RO)," Precision robotic manipulation tasks (insertion, screwing, precisely pick, precisely place) are required in many scenarios. Previous methods achieved good performance on such manipulation tasks. However, such methods typically require tedious calibration or expensive sensors. 3D/RGB-D cameras and torque/force sensors add to the cost of the robotic application and may not always be economical. In this work, we aim to solve these but using only weak-calibrated and low-cost webcams. We propose Binocular Alignment Learning (BAL), which could automatically learn the eye-hand coordination and points alignment capabilities to solve the four tasks. Our work focuses on working with unknown eye-hand coordination and proposes different ways of performing eye-in-hand camera calibration automatically. The algorithm was trained in simulation and used a practical pipeline to achieve sim2real and test it on the real robot. Our method achieves a competitively good result with minimal cost on the four tasks."
Subgroup discovery of Parkinson's Disease by utilizing a multi-modalsmart device system,"Catharina Marie vanAlen, AlexanderBrenner, TobiasWarnecke, JulianVarghese",12 May 2022,Machine Learning (cs.LG)," In recent years, sensors from smart consumer devices have shown great diagnostic potential in movement disorders. In this context, data modalities such as electronic questionnaires, hand movement and voice captures have successfully captured biomarkers and allowed discrimination between Parkinson's disease (PD) and healthy controls (HC) or differential diagnosis (DD). However, to the best of our knowledge, a comprehensive evaluation of assessments with a multi-modal smart device system has still been lacking. In a prospective study exploring PD, we used smartwatches and smartphones to collect multi-modal data from 504 participants, including PD patients, DD and HC. This study aims to assess the effect of multi-modal vs. single-modal data on PD vs. HC and PD vs. DD classification, as well as on PD group clustering for subgroup identification. We were able to show that by combining various modalities, classification accuracy improved and further PD clusters were discovered."
Robot Cooking with Stir-fry: Bimanual Non-prehensile Manipulation ofSemi-fluid Objects,"JunjiaLiu, YitingChen, ZhipengDong, ShixiongWang, SylvainCalinon, Miao Li, FeiChen",12 May 2022,Robotics (cs.RO)," This letter describes an approach to achieve well-known Chinese cooking art stir-fry on a bimanual robot system. Stir-fry requires a sequence of highly dynamic coordinated movements, which is usually difficult to learn for a chef, let alone transfer to robots. In this letter, we define a canonical stir-fry movement, and then propose a decoupled framework for learning this deformable object manipulation from human demonstration. First, the dual arms of the robot are decoupled into different roles (a leader and follower) and learned with classical and neural network-based methods separately, then the bimanual task is transformed into a coordination problem. To obtain general bimanual coordination, we secondly propose a Graph and Transformer based model -- Structured-Transformer, to capture the spatio-temporal relationship between dual-arm movements. Finally, by adding visual feedback of content deformation, our framework can adjust the movements automatically to achieve the desired stir-fry effect. We verify the framework by a simulator and deploy it on a real bimanual Panda robot system. The experimental results validate our framework can realize the bimanual robot stir-fry motion and have the potential to extend to other deformable objects with bimanual coordination."
Communicative Subgraph Representation Learning for Multi-RelationalInductive Drug-Gene Interaction Prediction,"JiahuaRao, ShuangjiaZheng, SijieMai, YuedongYang",12 May 2022,Machine Learning (cs.LG)," Illuminating the interconnections between drugs and genes is an important topic in drug development and precision medicine. Currently, computational predictions of drug-gene interactions mainly focus on the binding interactions without considering other relation types like agonist, antagonist, etc. In addition, existing methods either heavily rely on high- quality domain features or are intrinsically transductive, which limits the capacity of models to generalize to drugs/genes that lack external information or are unseen during the training process. To address these problems, we propose a novel Communicative Subgraph representation learning for Multi-relational Inductive drug-Gene interactions prediction (CoSMIG), where the predictions of drug-gene relations are made through subgraph patterns, and thus are naturally inductive for unseen drugs/genes without retraining or utilizing external domain features. Moreover, the model strengthened the relations on the drug-gene graph through a communicative message passing mechanism. To evaluate our method, we compiled two new benchmark datasets from DrugBank and DGIdb. The comprehensive experiments on the two datasets showed that our method outperformed state-of-the-art baselines in the transductive scenarios and achieved superior performance in the inductive ones. Further experimental analysis including LINCS experimental validation and literature verification also demonstrated the value of our model."
"Emerging Immersive Communication Systems: Overview, Taxonomy, and GoodPractises for QoE Assessment","PabloPérez, Ester Gonzalez-Sosa, JesúsGutiérrez, NarcisoGarcía",12 May 2022,Human-Computer Interaction (cs.HC)," Several technological and scientific advances have been achieved recently in the fields of immersive systems, which are offering new possibilities to applications and services in different communication domains, such as entertainment, virtual conferencing, working meetings, social relations, healthcare, and industry. Users of these immersive technologies can explore and experience the stimuli in a more interactive and personalized way than previous technologies. Thus, considering the new technological challenges related to these systems and the new perceptual dimensions and interaction behaviors involved, a deep understanding of the users' Quality of Experience is required to satisfy their demands and expectations. In this sense, it is essential to foster the research on evaluating the QoE of immersive communication systems, since this will provide useful outcomes to optimize them and to identify the factors that can deteriorate the user experience. With this aim, subjective tests are usually performed following standard methodologies, which are designed for specific technologies and services. Although numerous user studies have been already published, there are no recommendations or standards that define common testing methodologies to be applied to evaluate immersive communication systems, such as those developed for images and video. Therefore, a revision of the QoE evaluation methods designed for previous technologies is required to develop robust and reliable methodologies for immersive communication systems. Thus, the objective of this paper is to provide an overview of existing immersive communication systems and related user studies, which can help on the definition of basic guidelines and testing methodologies to be used when performing user tests of immersive communication systems, such as 360-degree video-based telepresence, avatar- based social VR, cooperative AR, etc."
Analytic solutions and numerical method for a coupled thermo-neutronicproblem,"FrançoisDubois, OlivierLafitte",12 May 2022,Numerical Analysis (math.NA)," We consider in this contribution a simplified idealized one- dimensional coupled model for neutronics and thermo-hydraulics under the low Mach number approximation. We propose a numerical method treating globally the coupled problem for finding its unique solution. Simultaneously, we use incomplete elliptic integrals to represent analytically the neutron flux. Both methods match perfectly. Note that the multiplication factor, classical output of neutronics problems, depends considerably of the representation of the cross sections."
Exploiting Inductive Bias in Transformers for UnsupervisedDisentanglement of Syntax and Semantics with VAEs,"GhaziFelhi, Joseph LeRoux, DjaméSeddah",12 May 2022,Computation and Language (cs.CL)," We propose a generative model for text generation, which exhibits disentangled latent representations of syntax and semantics. Contrary to previous work, this model does not need syntactic information such as constituency parses, or semantic information such as paraphrase pairs. Our model relies solely on the inductive bias found in attention-based architectures such as Transformers.   In the attention of Transformers, keys handle information selection while values specify what information is conveyed. Our model, dubbed QKVAE, uses Attention in its decoder to read latent variables where one latent variable infers keys while another infers values. We run experiments on latent representations and experiments on syntax/semantics transfer which show that QKVAE displays clear signs of disentangled syntax and semantics. We also show that our model displays competitive syntax transfer capabilities when compared to supervised models and that comparable supervised models need a fairly large amount of data (more than 50K samples) to outperform it on both syntactic and semantic transfer. The code for our experiments is publicly available."
SimCPSR: Simple Contrastive Learning for Paper SubmissionRecommendation System,"Duc H.Le, Tram T.Doan, SonT. Huynh, Binh T.Nguyen",12 May 2022,Information Retrieval (cs.IR)," The recommendation system plays a vital role in many areas, especially academic fields, to support researchers in submitting and increasing the acceptance of their work through the conference or journal selection process. This study proposes a transformer-based model using transfer learning as an efficient approach for the paper submission recommendation system. By combining essential information (such as the title, the abstract, and the list of keywords) with the aims and scopes of journals, the model can recommend the Top K journals that maximize the acceptance of the paper. Our model had developed through two states: (i) Fine-tuning the pre-trained language model (LM) with a simple contrastive learning framework. We utilized a simple supervised contrastive objective to fine-tune all parameters, encouraging the LM to learn the document representation effectively. (ii) The fine-tuned LM was then trained on different combinations of the features for the downstream task. This study suggests a more advanced method for enhancing the efficiency of the paper submission recommendation system compared to previous approaches when we respectively achieve 0.5173, 0.8097, 0.8862, 0.9496 for Top 1, 3, 5, and 10 accuracies on the test set for combining the title, abstract, and keywords as input features. Incorporating the journals' aims and scopes, our model shows an exciting result by getting 0.5194, 0.8112, 0.8866, and 0.9496 respective to Top 1, 3, 5, and 10."
NLOS Error Mitigation Using Weighted Least Squares and Kalman Filterin UWB Positioning,"RuixinFan, XinDu",12 May 2022,Systems and Control (eess.SY)," In wireless positioning systems, non-line-of-sight (NLOS) is a challenging problem. NLOS causes great ranging bias and location error, so NLOS mitigation is essential for high accuracy positioning. In this letter, we propose the Weighted-Least-Squares Robust Kalman Filter (WLS-RKF) for NLOS identification and mitigation. WLS-RKF employs a hypothesis test based on Mahalanobis distance for NLOS identification, and updates the corresponding Kalman filter using the WLS solution. It requires no prior knowledge about NLOS distribution or signal features. We perform simulations and experiments for ultra-wideband (UWB) positioning in various scenarios. The results confirm that WLS-RKF effectively mitigates NLOS error and achieves 5cm positioning accuracy."
Query Complexity Based Optimal Processing of Raw Data,"MayankPatel, MinalBhise",12 May 2022,Databases (cs.DB), The paper aims to find an efficient way for processing large datasets having different types of workload queries with minimal replication. The work first identifies the complexity of queries best suited for the given data processing tool . The paper proposes Query Complexity Aware partitioning technique QCA with a lightweight query identification and partitioning algorithm. Different replication approaches have been studied to cover more use-cases for different application workloads. The technique is demonstrated using a scientific dataset known as Sloan Digital Sky Survey SDSS. The results show workload execution time WET reduced by 94.6% using only 6.7% of the dataset in loaded format compared to the original dataset. The QCA technique also reduced multi-node replication by 5.8x times compared to state-of-the-art workload aware WA techniques. The multi-node and multi- core execution of workload using QCA proposed partitions reduced WET by 42.66% and 25.46% compared to WA.
Ensemble Clustering via Co-association Matrix Self-enhancement,"YuhengJia, SiruiTao, RanWang, Yongheng Wang",12 May 2022,Machine Learning (cs.LG)," Ensemble clustering integrates a set of base clustering results to generate a stronger one. Existing methods usually rely on a co-association (CA) matrix that measures how many times two samples are grouped into the same cluster according to the base clusterings to achieve ensemble clustering. However, when the constructed CA matrix is of low quality, the performance will degrade. In this paper, we propose a simple yet effective CA matrix self-enhancement framework that can improve the CA matrix to achieve better clustering performance. Specifically, we first extract the high-confidence (HC) information from the base clusterings to form a sparse HC matrix. By propagating the highly-reliable information of the HC matrix to the CA matrix and complementing the HC matrix according to the CA matrix simultaneously, the proposed method generates an enhanced CA matrix for better clustering. Technically, the proposed model is formulated as a symmetric constrained convex optimization problem, which is efficiently solved by an alternating iterative algorithm with convergence and global optimum theoretically guaranteed. Extensive experimental comparisons with twelve state-of-the-art methods on eight benchmark datasets substantiate the effectiveness, flexibility and efficiency of the proposed model in ensemble clustering. The codes and datasets can be downloaded at [this https URL](https://github.com/Siritao/EC-CMS)."
Energy efficiency of network-coding enabled mobile small cells,"Georgios P.Koudouridis, HenrikLundqvist, Hong Li, XavierGelabert",12 May 2022,Networking and Internet Architecture (cs.NI)," Energy efficiency becomes increasingly important due to the limited battery capacity in wireless devices while at the same time user throughput requirements are relentlessly increasing. In this paper, we study an energy efficient cooperation scheme which employs network coding to enhance the energy efficiency for mobile devices. Herein we propose that the mobile devices are clustered into mobile small cells with one of the mobile devices acting as a group head with basic transceiver, coding and relaying functionalities. Group heads coordinate the transmissions from the mobile devices in the mobile small cell to the network's base stations. The objective function of the cooperative scheme is to minimize mobile devices' energy consumption subject to a certain bit error probability. The proposed network-coding based scheme has been evaluated by means of numerical simulations and compared to both a conventional direct transmit scheme, with no cooperation groups, and a cooperative relaying scheme. Results show that, with network-coded cooperation, energy efficiency may significantly increase provided the density of base stations and mobile devices is below a certain value. Above this value none of the compared cooperation schemes may improve energy efficiency, but rather power consumption is reduced only when mobile devices transmit via base stations in their close proximity."
Digital Enablers Of Construction Project Governance,"Paolo EugenioDemagistris, SandroPetruzzi, RodolfoPampaloni, MilanŠmigić, Alberto DeMarco, Waseem Khan, Filippo MariaOttaviani",12 May 2022,Computers and Society (cs.CY)," Construction project governance relies on agreements between the actors along the construction industry value chain. The mutual obligations arising from these contracts rely on timely monetary transactions. Despite the advantages of automation in payment systems and improved access to digital progress data, several payment applications rely nonetheless on inefficient and time-consuming procedures and documentation. This study examines the present technological advancements that can lead to fix this problem. A smart contract-based approach is ideal for managing construction progress payments that support autonomous process, it fills the gap between payments and project site progress evaluations. This article offers a way for automating construction payments by formalizing smart contracts execution on a decentralized block-chain-based system."
Enhanced Single-shot Detector for Small Object Detection in RemoteSensing Images,"PouryaShamsolmoali, MasoumehZareapoor, EricGranger, JocelynChanussot, Jie Yang",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Small-object detection is a challenging problem. In the last few years, the convolution neural networks methods have been achieved considerable progress. However, the current detectors struggle with effective features extraction for small-scale objects. To address this challenge, we propose image pyramid single-shot detector (IPSSD). In IPSSD, single-shot detector is adopted combined with an image pyramid network to extract semantically strong features for generating candidate regions. The proposed network can enhance the small-scale features from a feature pyramid network. We evaluated the performance of the proposed model on two public datasets and the results show the superior performance of our model compared to the other state-of-the-art object detectors."
Ray Priors through Reprojection: Improving Neural Radiance Fields forNovel View Extrapolation,"JianZhang, YuanqingZhang, HuanFu, XiaoweiZhou, BowenCai, JinchiHuang, Rongfei Jia, BinqiangZhao, XingTang",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Neural Radiance Fields (NeRF) have emerged as a potent paradigm for representing scenes and synthesizing photo-realistic images. A main limitation of conventional NeRFs is that they often fail to produce high- quality renderings under novel viewpoints that are significantly different from the training viewpoints. In this paper, instead of exploiting few-shot image synthesis, we study the novel view extrapolation setting that (1) the training images can well describe an object, and (2) there is a notable discrepancy between the training and test viewpoints' distributions. We present RapNeRF (RAy Priors) as a solution. Our insight is that the inherent appearances of a 3D surface's arbitrary visible projections should be consistent. We thus propose a random ray casting policy that allows training unseen views using seen views. Furthermore, we show that a ray atlas pre- computed from the observed rays' viewing directions could further enhance the rendering quality for extrapolated views. A main limitation is that RapNeRF would remove the strong view-dependent effects because it leverages the multi-view consistency property."
Group R-CNN for Weakly Semi-supervised Object Detection with Points,"ShilongZhang, Zhuoran Yu, Liyang Liu, XinjiangWang, AojunZhou, KaiChen",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We study the problem of weakly semi-supervised object detection with points (WSSOD-P), where the training data is combined by a small set of fully annotated images with bounding boxes and a large set of weakly-labeled images with only a single point annotated for each instance. The core of this task is to train a point-to-box regressor on well-labeled images that can be used to predict credible bounding boxes for each point annotation. We challenge the prior belief that existing CNN-based detectors are not compatible with this task. Based on the classic R-CNN architecture, we propose an effective point-to-box regressor: Group R-CNN. Group R-CNN first uses instance-level proposal grouping to generate a group of proposals for each point annotation and thus can obtain a high recall rate. To better distinguish different instances and improve precision, we propose instance- level proposal assignment to replace the vanilla assignment strategy adopted in the original R-CNN methods. As naive instance-level assignment brings converging difficulty, we propose instance-aware representation learning which consists of instance-aware feature enhancement and instance-aware parameter generation to overcome this issue. Comprehensive experiments on the MS-COCO benchmark demonstrate the effectiveness of our method. Specifically, Group R-CNN significantly outperforms the prior method Point DETR by 3.9 mAP with 5% well-labeled images, which is the most challenging scenario. The source code can be found at [this https URL](https://github.com/jshilong/GroupRCNN)"
Fall detection using multimodal data,"Thao V.Ha, HoangNguyen, SonT. Huynh, Trung T.Nguyen, Binh T.Nguyen",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In recent years, the occurrence of falls has increased and has had detrimental effects on older adults. Therefore, various machine learning approaches and datasets have been introduced to construct an efficient fall detection algorithm for the social community. This paper studies the fall detection problem based on a large public dataset, namely the UP-Fall Detection Dataset. This dataset was collected from a dozen of volunteers using different sensors and two cameras. We propose several techniques to obtain valuable features from these sensors and cameras and then construct suitable models for the main problem. The experimental results show that our proposed methods can bypass the state-of-the-art methods on this dataset in terms of accuracy, precision, recall, and F1 score."
Dynamic Dense RGB-D SLAM using Learning-based Visual Odometry,"ShihaoShen, YilinCai, JiayiQiu, GuangzhaoLi",12 May 2022,Robotics (cs.RO)," We propose a dense dynamic RGB-D SLAM pipeline based on a learning-based visual odometry, TartanVO. TartanVO, like other direct methods rather than feature-based, estimates camera pose through dense optical flow, which only applies to static scenes and disregards dynamic objects. Due to the color constancy assumption, optical flow is not able to differentiate between dynamic and static pixels. Therefore, to reconstruct a static map through such direct methods, our pipeline resolves dynamic/static segmentation by leveraging the optical flow output, and only fuse static points into the map. Moreover, we rerender the input frames such that the dynamic pixels are removed and iteratively pass them back into the visual odometry to refine the pose estimate."
Joint Tracking of Groups of Users with Uplink Reference Signals,"HenrikLundqvist, George P.Koudouridis, XavierGelabert",12 May 2022,Networking and Internet Architecture (cs.NI)," In cellular networks user equipment (UE) need to be tracked so that they can be reached by incoming data and to keep context information such as encryption keys available for UE originated transmission. Typically UEs measure reference signal transmissions that are broadcasted by the network, and report to the network based on some criterion that allows the network to know the UE location with sufficient accuracy. An alternative approach is to let the UEs send out reference signals that the network can detect to track the UE location. This reduces the need for the UEs to measure and report, while it requires some resources for uplink transmission. In this paper we propose and evaluate a solution for jointly tracking groups of UEs that are moving together. The results show that UEs can be tracked efficiently with low resource consumption."
Observer-Based Consensus of Nonlinear Positive Multi-Agent Systemswith Saturated Control Input,"AmirrezaZaman, WolfgangBirk, Khalid TourkeyAtta",12 May 2022,Systems and Control (eess.SY)," This paper presents the distributed pinning consensus solution for nonlinear positive multi-agent systems with nonlinear control input by applying observer-based control protocols. The network topology is considered as a directed and fully connected structure. By considering sector input nonlinearities and various forms of topologies, two kinds of state observers involving standard observer and distributed pinning observer are presented for each regarded nonlinear agent by applying a novel analysis directly dealing with the nonlinear input and nonlinear system dynamics. The measured local output detail outlines the first observer, and the other observer is achieved via the corresponding output detail of its adjacent agents. Based on further observed state details, a distributed pinning observer-based strategy is derived for the leader-follower non-negative global consensus of the nonlinear positive multi-agent system. Additionally, two multi-step algorithms are proposed to set up the observer gains and each protocol criterion. Performance evaluations are provided to confirm the proposed control method and illustrate the effectiveness of the derived non- negative consensus observer-based protocols."
Comparison of nonlinear field-split preconditioners for two-phase flowin heterogeneous porous media,"MamadouN'diaye, Francois P.Hamon, Hamdi A.Tchelepi",12 May 2022,Numerical Analysis (math.NA)," This work focuses on the development of a two-step field-split nonlinear preconditioner to accelerate the convergence of two-phase flow and transport in heterogeneous porous media. We propose a field-split algorithm named Field-Split Multiplicative Schwarz Newton (FSMSN), consisting in two steps: first, we apply a preconditioning step to update pressure and saturations nonlinearly by solving approximately two subproblems in a sequential fashion; then, we apply a global step relying on a Newton update obtained by linearizing the system at the preconditioned state. Using challenging test cases, FSMSN is compared to an existing field-split preconditioner, Multiplicative Schwarz Preconditioned for Inexact Newton (MSPIN), and to standard solution strategies such as the Sequential Fully Implicit (SFI) method or the Fully Implicit Method (FIM). The comparison highlights the impact of the upwinding scheme in the algorithmic performance of the preconditioners and the importance of the dynamic adaptation of the subproblem tolerance in the preconditioning step. Our results demonstrate that the two-step nonlinear preconditioning approach-and in particular, FSMSN-results in a faster outer-loop convergence than with the SFI and FIM methods. The impact of the preconditioners on computational performance-i.e., measured by wall-clock time-will be studied in a subsequent publication."
Building Facade Parsing R-CNN,"SijieWang, QiyuKang, RuiShe, Wee PengTay, DiegoNavarroNavarro, AndreasHartmannsgruber",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Building facade parsing, which predicts pixel-level labels for building facades, has applications in computer vision perception for autonomous vehicle (AV) driving. However, instead of a frontal view, an on- board camera of an AV captures a deformed view of the facade of the buildings on both sides of the road the AV is travelling on, due to the camera perspective. We propose Facade R-CNN, which includes a transconv module, generalized bounding box detection, and convex regularization, to perform parsing of deformed facade views. Experiments demonstrate that Facade R-CNN achieves better performance than the current state-of-the-art facade parsing models, which are primarily developed for frontal views. We also publish a new building facade parsing dataset derived from the Oxford RobotCar dataset, which we call the Oxford RobotCar Facade dataset. This dataset contains 500 street-view images from the Oxford RobotCar dataset augmented with accurate annotations of building facade objects. The published dataset is available at [this https URL](https://github.com/sijieaaa/Oxford-RobotCar-Facade)"
Infrared Invisible Clothing:Hiding from Infrared Detectors at MultipleAngles in Real World,"XiaopeiZhu, ZhanhaoHu, SiyuanHuang, Jianmin Li, Xiaolin Hu",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Thermal infrared imaging is widely used in body temperature measurement, security monitoring, and so on, but its safety research attracted attention only in recent years. We proposed the infrared adversarial clothing, which could fool infrared pedestrian detectors at different angles. We simulated the process from cloth to clothing in the digital world and then designed the adversarial ""QR code"" pattern. The core of our method is to design a basic pattern that can be expanded periodically, and make the pattern after random cropping and deformation still have an adversarial effect, then we can process the flat cloth with an adversarial pattern into any 3D clothes. The results showed that the optimized ""QR code"" pattern lowered the Average Precision (AP) of YOLOv3 by 87.7%, while the random ""QR code"" pattern and blank pattern lowered the AP of YOLOv3 by 57.9% and 30.1%, respectively, in the digital world. We then manufactured an adversarial shirt with a new material: aerogel. Physical- world experiments showed that the adversarial ""QR code"" pattern clothing lowered the AP of YOLOv3 by 64.6%, while the random ""QR code"" pattern clothing and fully heat-insulated clothing lowered the AP of YOLOv3 by 28.3% and 22.8%, respectively. We used the model ensemble technique to improve the attack transferability to unseen models."
Machine Learning Workflow to Explain Black-box Models for EarlyAlzheimer's Disease Classification Evaluated for Multiple Datasets,"LouiseBloch, Christoph M.Friedrich",12 May 2022,Machine Learning (cs.LG)," Purpose: Hard-to-interpret Black-box Machine Learning (ML) were often used for early Alzheimer's Disease (AD) detection.   Methods: To interpret eXtreme Gradient Boosting (XGBoost), Random Forest (RF), and Support Vector Machine (SVM) black-box models a workflow based on Shapley values was developed. All models were trained on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset and evaluated for an independent ADNI test set, as well as the external Australian Imaging and Lifestyle flagship study of Ageing (AIBL), and Open Access Series of Imaging Studies (OASIS) datasets. Shapley values were compared to intuitively interpretable Decision Trees (DTs), and Logistic Regression (LR), as well as natural and permutation feature importances. To avoid the reduction of the explanation validity caused by correlated features, forward selection and aspect consolidation were implemented.   Results: Some black-box models outperformed DTs and LR. The forward-selected features correspond to brain areas previously associated with AD. Shapley values identified biologically plausible associations with moderate to strong correlations with feature importances. The most important RF features to predict AD conversion were the volume of the amygdalae, and a cognitive test score. Good cognitive test performances and large brain volumes decreased the AD risk. The models trained using cognitive test scores significantly outperformed brain volumetric models ($p<0.05$). Cognitive Normal (CN) vs. AD models were successfully transferred to external datasets.   Conclusion: In comparison to previous work, improved performances for ADNI and AIBL were achieved for CN vs. Mild Cognitive Impairment (MCI) classification using brain volumes. The Shapley values and the feature importances showed moderate to strong correlations."
NER-MQMRC: Formulating Named Entity Recognition as Multi QuestionMachine Reading Comprehension,"AnubhavShrimal, Avi Jain, KartikMehta, PromodYenigalla",12 May 2022,Machine Learning (cs.LG)," NER has been traditionally formulated as a sequence labeling task. However, there has been recent trend in posing NER as a machine reading comprehension task (Wang et al., 2020; Mengge et al., 2020), where entity name (or other information) is considered as a question, text as the context and entity value in text as answer snippet. These works consider MRC based on a single question (entity) at a time. We propose posing NER as a multi- question MRC task, where multiple questions (one question per entity) are considered at the same time for a single text. We propose a novel BERT-based multi-question MRC (NER-MQMRC) architecture for this formulation. NER-MQMRC architecture considers all entities as input to BERT for learning token embeddings with self-attention and leverages BERT-based entity representation for further improving these token embeddings for NER task. Evaluation on three NER datasets show that our proposed architecture leads to average 2.5 times faster training and 2.3 times faster inference as compared to NER-SQMRC framework based models by considering all entities together in a single pass. Further, we show that our model performance does not degrade compared to single-question based MRC (NER-SQMRC) (Devlin et al., 2019) leading to F1 gain of +0.41%, +0.32% and +0.27% for AE-Pub, Ecommerce5PT and Twitter datasets respectively. We propose this architecture primarily to solve large scale e-commerce attribute (or entity) extraction from unstructured text of a magnitude of 50k+ attributes to be extracted on a scalable production environment with high performance and optimised training and inference runtimes."
Mitigating Gender Stereotypes in Hindi and Marathi,"NeerajaKirtane, Tanvi Anand",12 May 2022,Computation and Language (cs.CL)," As the use of natural language processing increases in our day-to- day life, the need to address gender bias inherent in these systems also amplifies. This is because the inherent bias interferes with the semantic structure of the output of these systems while performing tasks like machine translation. While research is being done in English to quantify and mitigate bias, debiasing methods in Indic Languages are either relatively nascent or absent for some Indic languages altogether. Most Indic languages are gendered, i.e., each noun is assigned a gender according to each language's grammar rules. As a consequence, evaluation differs from what is done in English. This paper evaluates the gender stereotypes in Hindi and Marathi languages. The methodologies will differ from the ones in the English language because there are masculine and feminine counterparts in the case of some words. We create a dataset of neutral and gendered occupation words, emotion words and measure bias with the help of Embedding Coherence Test (ECT) and Relative Norm Distance (RND). We also attempt to mitigate this bias from the embeddings. Experiments show that our proposed debiasing techniques reduce gender bias in these languages."
Weakly-Supervised Action Detection Guided by Audio Narration,"KerenYe, AdrianaKovashka",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Videos are more well-organized curated data sources for visual concept learning than images. Unlike the 2-dimensional images which only involve the spatial information, the additional temporal dimension bridges and synchronizes multiple modalities. However, in most video detection benchmarks, these additional modalities are not fully utilized. For example, EPIC Kitchens is the largest dataset in first-person (egocentric) vision, yet it still relies on crowdsourced information to refine the action boundaries to provide instance-level action annotations.   We explored how to eliminate the expensive annotations in video detection data which provide refined boundaries. We propose a model to learn from the narration supervision and utilize multimodal features, including RGB, motion flow, and ambient sound. Our model learns to attend to the frames related to the narration label while suppressing the irrelevant frames from being used. Our experiments show that noisy audio narration suffices to learn a good action detection model, thus reducing annotation expenses."
Bridging the Gap between Reality and Ideality of Entity Matching: ARevisiting and Benchmark Re-Construction,"TianshuWang, HongyuLin, ChengFu, XianpeiHan, LeSun, FeiyuXiong, HuiChen, MinlongLu, XiuwenZhu",12 May 2022,Computation and Language (cs.CL)," Entity matching (EM) is the most critical step for entity resolution (ER). While current deep learningbased methods achieve very impressive performance on standard EM benchmarks, their realworld application performance is much frustrating. In this paper, we highlight that such the gap between reality and ideality stems from the unreasonable benchmark construction process, which is inconsistent with the nature of entity matching and therefore leads to biased evaluations of current EM approaches. To this end, we build a new EM corpus and re-construct EM benchmarks to challenge critical assumptions implicit in the previous benchmark construction process by step-wisely changing the restricted entities, balanced labels, and single-modal records in previous benchmarks into open entities, imbalanced labels, and multimodal records in an open environment. Experimental results demonstrate that the assumptions made in the previous benchmark construction process are not coincidental with the open environment, which conceal the main challenges of the task and therefore significantly overestimate the current progress of entity matching. The constructed benchmarks and code are publicly released"
How does Feedback Signal Quality Impact Effectiveness of PseudoRelevance Feedback for Passage Retrieval?,"HangLi, AhmedMourad, BevanKoopman, GuidoZuccon",12 May 2022,Information Retrieval (cs.IR)," Pseudo-Relevance Feedback (PRF) assumes that the top results retrieved by a first-stage ranker are relevant to the original query and uses them to improve the query representation for a second round of retrieval. This assumption however is often not correct: some or even all of the feedback documents may be irrelevant. Indeed, the effectiveness of PRF methods may well depend on the quality of the feedback signal and thus on the effectiveness of the first-stage ranker. This aspect however has received little attention before.   In this paper we control the quality of the feedback signal and measure its impact on a range of PRF methods, including traditional bag-of-words methods (Rocchio), and dense vector-based methods (learnt and not learnt). Our results show the important role the quality of the feedback signal plays on the effectiveness of PRF methods. Importantly, and surprisingly, our analysis reveals that not all PRF methods are the same when dealing with feedback signals of varying quality. These findings are critical to gain a better understanding of the PRF methods and of which and when they should be used, depending on the feedback signal quality, and set the basis for future research in this area."
Bottleneck Matching in the Plane,"Matthew J.Katz, MichaSharir",12 May 2022,Computational Geometry (cs.CG)," We present an algorithm for computing a bottleneck matching in a set of $n=2\ell$ points in the plane, which runs in $O(n^{\omega/2}\log n)$ deterministic time, where $\omega\approx 2.37$ is the exponent of matrix multiplication."
A Chit-Chats Enhanced Task-Oriented Dialogue Corpora for Fuse-MotiveConversation Systems,"ChanghongYu, ChunhongZhang, QiSun",12 May 2022,Computation and Language (cs.CL)," The goal of building intelligent dialogue systems has largely been separately pursued under two motives: task-oriented dialogue (TOD) systems, and open-domain systems for chit-chat (CC). Although previous TOD dialogue systems work well in the testing sets of benchmarks, they would lead to undesirable failure when being exposed to natural scenarios in practice, where user utterances can be of high motive-diversity that fusing both TOD and CC in multi-turn interaction. Since an industrial TOD system should be able to converse with the user between TOD and CC motives, constructing a fuse-motive dialogue dataset that contains both TOD or CC is important. Most prior work relies on crowd workers to collect and annotate large scale dataset and is restricted to English language setting. Our work, on the contrary, addresses this problem in a more effective way and releases a multi-turn dialogues dataset called CCET (Chinese Chat-Enhanced-Task). Meanwhile, we also propose a line of fuse-motive dialogues formalization approach, along with several evaluation metrics for TOD sessions that are integrated by CC utterances."
Sampling Online Social Networks: Metropolis Hastings Random Walk andRandom Walk,Xiao Qi,12 May 2022,Social and Information Networks (cs.SI)," As social network analysis (SNA) has drawn much attention in recent years, one bottleneck of SNA is these network data are too massive to handle. Furthermore, some network data are not accessible due to privacy problems. Therefore, we have to develop sampling methods to draw representative sample graphs from the population graph. In this paper, Metropolis-Hastings Random Walk (MHRW) and Random Walk with Jumps (RWwJ) sampling strategies are introduced, including the procedure of collecting nodes, the underlying mathematical theory, and corresponding estimators. We compared our methods and existing research outcomes and found that MHRW performs better when estimating degree distribution (61% less error than RWwJ) and graph order (0.69% less error than RWwJ), while RWwJ estimates follower and following ratio average and mutual relationship proportion in adjacent relationship with better results, with 13% less error and 6% less error than MHRW. We analyze the reasons for the outcomes and give possible future work directions."
SeGraM: A Universal Hardware Accelerator for Genomic Sequence-to-Graphand Sequence-to-Sequence Mapping,"Damla SenolCali, KonstantinosKanellopoulos, JoelLindegger, ZülalBingöl, Gurpreet S.Kalsi, Ziyi Zuo, CanFirtina, Meryem BanuCavlak, Jeremie Kim, Nika MansouriGhiasi, GagandeepSingh, JuanGómez-Luna, Nour AlmadhounAlserr, MohammedAlser, SreenivasSubramoney, Can Alkan, SaugataGhose, OnurMutlu",12 May 2022,Hardware Architecture (cs.AR)," A critical step of genome sequence analysis is the mapping of sequenced DNA fragments (i.e., reads) collected from an individual to a known linear reference genome sequence (i.e., sequence-to-sequence mapping). Recent works replace the linear reference sequence with a graph-based representation of the reference genome, which captures the genetic variations and diversity across many individuals in a population. Mapping reads to the graph-based reference genome (i.e., sequence-to-graph mapping) results in notable quality improvements in genome analysis. Unfortunately, while sequence-to-sequence mapping is well studied with many available tools and accelerators, sequence-to-graph mapping is a more difficult computational problem, with a much smaller number of practical software tools currently available.   We analyze two state-of-the-art sequence-to-graph mapping tools and reveal four key issues. We find that there is a pressing need to have a specialized, high-performance, scalable, and low-cost algorithm/hardware co- design that alleviates bottlenecks in both the seeding and alignment steps of sequence-to-graph mapping.   To this end, we propose SeGraM, a universal algorithm/hardware co-designed genomic mapping accelerator that can effectively and efficiently support both sequence-to-graph mapping and sequence-to-sequence mapping, for both short and long reads. To our knowledge, SeGraM is the first algorithm/hardware co-design for accelerating sequence-to-graph mapping. SeGraM consists of two main components: (1) MinSeed, the first minimizer- based seeding accelerator; and (2) BitAlign, the first bitvector-based sequence-to-graph alignment accelerator.   We demonstrate that SeGraM provides significant improvements for multiple steps of the sequence-to-graph and sequence-to-sequence mapping pipelines."
E-Mail Assistant -- Automation of E-Mail Handling and Management usingRobotic Process Automation,"ArpitKhare, SudhakarSingh, RichaMishra, ShivPrakash, PratibhaDixit",12 May 2022,Machine Learning (cs.LG)," In this paper, a workflow for designing a bot using Robotic Process Automation (RPA), associated with Artificial Intelligence (AI) that is used for information extraction, classification, etc., is proposed. The bot is equipped with many features that make email handling a stress-free job. It automatically login into the mailbox through secured channels, distinguishes between the useful and not useful emails, classifies the emails into different labels, downloads the attached files, creates different directories, and stores the downloaded files into relevant directories. It moves the not useful emails into the trash. Further, the bot can also be trained to rename the attached files with the names of the sender/applicant in case of a job application for the sake of convenience. The bot is designed and tested using the UiPath tool to improve the performance of the system. The paper also discusses the further possible functionalities that can be added on to the bot."
Deep Decomposition and Bilinear Pooling Network for Blind Night-TimeImage Quality Evaluation,"QiupingJiang, JiawuXu, WeiZhou, Xiongkuo Min, Guangtao Zhai",12 May 2022,Multimedia (cs.MM)," Blind image quality assessment (BIQA), which aims to accurately predict the image quality without any pristine reference information, has been highly concerned in the past decades. Especially, with the help of deep neural networks, great progress has been achieved so far. However, it remains less investigated on BIQA for night-time images (NTIs) which usually suffer from complicated authentic distortions such as reduced visibility, low contrast, additive noises, and color distortions. These diverse authentic degradations particularly challenges the design of effective deep neural network for blind NTI quality evaluation (NTIQE). In this paper, we propose a novel deep decomposition and bilinear pooling network (DDB-Net) to better address this issue. The DDB-Net contains three modules, i.e., an image decomposition module, a feature encoding module, and a bilinear pooling module. The image decomposition module is inspired by the Retinex theory and involves decoupling the input NTI into an illumination layer component responsible for illumination information and a reflectance layer component responsible for content information. Then, the feature encoding module involves learning multi-scale feature representations of degradations that are rooted in the two decoupled components separately. Finally, by modeling illumination-related and content-related degradations as two-factor variations, the two multi-scale feature sets are bilinearly pooled and concatenated together to form a unified representation for quality prediction. The superiority of the proposed DDB-Net is well validated by extensive experiments on two publicly available night-time image databases."
"Distinction Maximization Loss: Efficiently Improving ClassificationAccuracy, Uncertainty Estimation, and Out-of-Distribution Detection SimplyReplacing the Loss and Calibrating","DavidMacêdo, CleberZanchettin, TeresaLudermir",12 May 2022,Machine Learning (cs.LG)," Building robust deterministic deep neural networks is still a challenge. On the one hand, some approaches improve out-of-distribution detection at the cost of reducing classification accuracy in some situations. On the other hand, some methods simultaneously increase classification accuracy, out-of-distribution detection, and uncertainty estimation, but reduce inference efficiency, in addition to training the same model many times to tune hyperparameters. In this paper, we propose training deterministic deep neural networks using our DisMax loss, which works as a drop-in replacement for the commonly used SoftMax loss (i.e., the combination of the linear output layer, the SoftMax activation, and the cross-entropy loss). Starting from the IsoMax+ loss, we created novel logits that are based on the distance to all prototypes rather than just the one associated with the correct class. We also propose a novel way to augment images to construct what we call fractional probability regularization. Moreover, we propose a new score to perform out-of-distribution detection and a fast way to calibrate the network after training. Our experiments show that DisMax usually outperforms all current approaches simultaneously in classification accuracy, uncertainty estimation, inference efficiency, and out-of-distribution detection, avoiding hyperparameter tuning and repetitive model training. The code to replace the SoftMax loss with the DisMax loss and reproduce the results in this paper is available at [this https URL](https://github.com/dlmacedo/distinction-maximization-loss)."
Towards Robust Unsupervised Disentanglement of Sequential Data -- ACase Study Using Music Audio,"Yin-JyunLuo, SebastianEwert, SimonDixon",12 May 2022,Sound (cs.SD)," Disentangled sequential autoencoders (DSAEs) represent a class of probabilistic graphical models that describes an observed sequence with dynamic latent variables and a static latent variable. The former encode information at a frame rate identical to the observation, while the latter globally governs the entire sequence. This introduces an inductive bias and facilitates unsupervised disentanglement of the underlying local and global factors. In this paper, we show that the vanilla DSAE suffers from being sensitive to the choice of model architecture and capacity of the dynamic latent variables, and is prone to collapse the static latent variable. As a countermeasure, we propose TS-DSAE, a two-stage training framework that first learns sequence-level prior distributions, which are subsequently employed to regularise the model and facilitate auxiliary objectives to promote disentanglement. The proposed framework is fully unsupervised and robust against the global factor collapse problem across a wide range of model configurations. It also avoids typical solutions such as adversarial training which usually involves laborious parameter tuning, and domain- specific data augmentation. We conduct quantitative and qualitative evaluations to demonstrate its robustness in terms of disentanglement on both artificial and real-world music audio datasets."
View Synthesis with Sculpted Neural Points,"YimingZuo, JiaDeng",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We address the task of view synthesis, which can be posed as recovering a rendering function that renders new views from a set of existing images. In many recent works such as NeRF, this rendering function is parameterized using implicit neural representations of scene geometry. Implicit neural representations have achieved impressive visual quality but have drawbacks in computational efficiency. In this work, we propose a new approach that performs view synthesis using point clouds. It is the first point-based method to achieve better visual quality than NeRF while being more than 100x faster in rendering speed. Our approach builds on existing works on differentiable point-based rendering but introduces a novel technique we call ""Sculpted Neural Points (SNP)"", which significantly improves the robustness to errors and holes in the reconstructed point cloud. Experiments show that on the task of view synthesis, our sculpting technique closes the gap between point-based and implicit representation- based methods. Code is available at [this https URL](https://github.com/princeton-vl/SNP) and supplementary video at [this https URL](https://youtu.be/dBwCQP9uNws)."
Over-the-Air Federated Learning with Joint Adaptive Computation andPower Control,"HaiboYang, PeiwenQiu, JiaLiu, AylinYener",12 May 2022,Machine Learning (cs.LG)," This paper considers over-the-air federated learning (OTA-FL). OTA-FL exploits the superposition property of the wireless medium, and performs model aggregation over the air for free. Thus, it can greatly reduce the communication cost incurred in communicating model updates from the edge devices. In order to fully utilize this advantage while providing comparable learning performance to conventional federated learning that presumes model aggregation via noiseless channels, we consider the joint design of transmission scaling and the number of local iterations at each round, given the power constraint at each edge device. We first characterize the training error due to such channel noise in OTA-FL by establishing a fundamental lower bound for general functions with Lipschitz-continuous gradients. Then, by introducing an adaptive transceiver power scaling scheme, we propose an over-the-air federated learning algorithm with joint adaptive computation and power control (ACPC-OTA-FL). We provide the convergence analysis for ACPC-OTA-FL in training with non-convex objective functions and heterogeneous data. We show that the convergence rate of ACPC- OTA-FL matches that of FL with noise-free communications."
Towards a Cybersecurity Testbed for Agricultural Vehicles andEnvironments,"MarkFreyhof, GeorgeGrispos, SantoshPitla, CodyStolle",12 May 2022,Computers and Society (cs.CY)," In today's modern farm, an increasing number of agricultural systems and vehicles are connected to the Internet. While the benefits of networked agricultural machinery are attractive, this technological shift is also creating an environment that is conducive to cyberattacks. While previous research has focused on general cybersecurity concerns in the farming and agricultural industries, minimal research has focused on techniques for identifying security vulnerabilities within actual agricultural systems that could be exploited by cybercriminals. Hence, this paper presents STAVE - a Security Testbed for Agricultural Vehicles and Environments - as a potential solution to assist with the identification of cybersecurity vulnerabilities within commercially available off-the-shelf components used in certain agricultural systems. This paper reports ongoing research efforts to develop and refine the STAVE testbed, along with describing initial cybersecurity experimentation which aims to identify security vulnerabilities within wireless and Controller Area Network (CAN) Bus agricultural vehicle components."
Optimal convergence rate of the explicit Euler method for convection-diffusion equations II: high dimensional cases,"QifengZhang, JiyuanZhang, Zhi-zhongSun",12 May 2022,Numerical Analysis (math.NA)," This is the second part of study on the optimal convergence rate of the explicit Euler discretization in time for the convection-diffusion equations [Appl. Math. Lett. \textbf{131} (2022) 108048] which focuses on high-dimensional linear/nonlinear cases under Dirichlet or Neumann boundary conditions. Several new corrected difference schemes are proposed based on the explicit Euler discretization in temporal derivative and central difference discretization in spatial derivatives. The priori estimate of the corrected scheme with application to constant convection coefficients is provided at length by the maximum principle and the optimal convergence rate four is proved when the step ratios along each direction equal to $1/6$. The corrected difference schemes have essentially improved {\rm \textbf{CFL}} condition and the numerical accuracy comparing with the classical difference schemes. Numerical examples involving two-/three-dimensional linear/nonlinear problems under Dirichlet/Neumann boundary conditions such as the Fisher equation, the Chafee-Infante equation, the Burgers' equation and classification to name a few substantiate the good properties claimed for the corrected difference scheme."
AdaVAE: Exploring Adaptive GPT-2s in Variational Auto-Encoders forLanguage Modeling,"HaoqinTu, ZhongliangYang, JinshuaiYang, SiyuZhang, YongfengHuang",12 May 2022,Computation and Language (cs.CL)," Variational Auto-Encoder (VAE) has become the de-facto learning paradigm in achieving both representation learning and generation for natural language. However, existing VAE-based language models either employ elementary RNNs, which is not powerful to handle multi-tasks, or fine-tunes two pre-trained language models (PLMs) for any downstream task, which requires huge energy consumption. In this paper, we introduce the first VAE framework empowered with adaptive GPT-2s (AdaVAE). Different from mentioned systems, we unify both the encoder and decoder of VAE model using GPT-2s with adaptive parameter-efficient components. Experiments from multiple dimensions validate that AdaVAE is competent to better organize language in generation and representation modeling, even with less than $15\%$ additionally activated parameters during training. Our code is available at \url{[this https URL](https://github.com/ImKeTT/adavae)}."
S3E-GNN: Sparse Spatial Scene Embedding with Graph Neural Networks forCamera Relocalization,"RanCheng, XinyuJiang, YuanChen, LigeLiu, TaoSun",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Camera relocalization is the key component of simultaneous localization and mapping (SLAM) systems. This paper proposes a learning- based approach, named Sparse Spatial Scene Embedding with Graph Neural Networks (S3E-GNN), as an end-to-end framework for efficient and robust camera relocalization. S3E-GNN consists of two modules. In the encoding module, a trained S3E network encodes RGB images into embedding codes to implicitly represent spatial and semantic embedding code. With embedding codes and the associated poses obtained from a SLAM system, each image is represented as a graph node in a pose graph. In the GNN query module, the pose graph is transformed to form a embedding-aggregated reference graph for camera relocalization. We collect various scene datasets in the challenging environments to perform experiments. Our results demonstrate that S3E-GNN method outperforms the traditional Bag-of-words (BoW) for camera relocalization due to learning-based embedding and GNN powered scene matching mechanism."
Comparing Open Arabic Named Entity Recognition Tools,"AbdullahAldumaykhi, Saad Otai, AbdulkareemAlsudais",12 May 2022,Computation and Language (cs.CL)," The main objective of this paper is to compare and evaluate the performances of three open Arabic NER tools: CAMeL, Hatmi, and Stanza. We collected a corpus consisting of 30 articles written in MSA and manually annotated all the entities of the person, organization, and location types at the article (document) level. Our results suggest a similarity between Stanza and Hatmi with the latter receiving the highest F1 score for the three entity types. However, CAMeL achieved the highest precision values for names of people and organizations. Following this, we implemented a ""merge"" method that combined the results from the three tools and a ""vote"" method that tagged named entities only when two of the three identified them as entities. Our results showed that merging achieved the highest overall F1 scores. Moreover, merging had the highest recall values while voting had the highest precision values for the three entity types. This indicates that merging is more suitable when recall is desired, while voting is optimal when precision is required. Finally, we collected a corpus of 21,635 articles related to COVID-19 and applied the merge and vote methods. Our analysis demonstrates the tradeoff between precision and recall for the two methods."
Entity-aware and Motion-aware Transformers for Language-driven ActionLocalization in Videos,"ShuoYang, XinxiaoWu",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Language-driven action localization in videos is a challenging task that involves not only visual-linguistic matching but also action boundary prediction. Recent progress has been achieved through aligning language query to video segments, but estimating precise boundaries is still under-explored. In this paper, we propose entity-aware and motion-aware Transformers that progressively localizes actions in videos by first coarsely locating clips with entity queries and then finely predicting exact boundaries in a shrunken temporal region with motion queries. The entity- aware Transformer incorporates the textual entities into visual representation learning via cross-modal and cross-frame attentions to facilitate attending action-related video clips. The motion-aware Transformer captures fine-grained motion changes at multiple temporal scales via integrating long short-term memory into the self-attention module to further improve the precision of action boundary prediction. Extensive experiments on the Charades-STA and TACoS datasets demonstrate that our method achieves better performance than existing methods."
Tutorial: Analog Matrix Computing (AMC) with Crosspoint ResistiveMemory Arrays,"ZhongSun, DanieleIelmini",12 May 2022,Emerging Technologies (cs.ET)," Matrix computation is ubiquitous in modern scientific and engineering fields. Due to the high computational complexity in conventional digital computers, matrix computation represents a heavy workload in many data-intensive applications, e.g., machine learning, scientific computing, and wireless communications. For fast, efficient matrix computations, analog computing with resistive memory arrays has been proven to be a promising solution. In this Tutorial, we present analog matrix computing (AMC) circuits based on crosspoint resistive memory arrays. AMC circuits are able to carry out basic matrix computations, including matrix multiplication, matrix inversion, pseudoinverse and eigenvector computation, all with one single operation. We describe the main design principles of the AMC circuits, such as local/global or negative/positive feedback configurations, with/without external inputs. Mapping strategies for matrices containing negative values will be presented. The underlying requirements for circuit stability will be described via the transfer function analysis, which also defines time complexity of the circuits towards steady-state results. Lastly, typical applications, challenges, and future trends of AMC circuits will be discussed."
On the Capacity-Achieving Input of the Gaussian Channel with PolarQuantization,"Neil IrwinBernardo, Jingge Zhu, Jamie Evans",12 May 2022,Information Theory (cs.IT)," The polar receiver architecture is a receiver design that captures the envelope and phase information of the signal rather than its in-phase and quadrature components. Several studies have demonstrated the robustness of polar receivers to phase noise and other nonlinearities. Yet, the information-theoretic limits of polar receivers with finite-precision quantizers have not been investigated in the literature. The main contribution of this work is to identify the optimal signaling strategy for the additive white Gaussian noise (AWGN) channel with polar quantization at the output. More precisely, we show that the capacity-achieving modulation scheme has an amplitude phase shift keying (APSK) structure. Using this result, the capacity of the AWGN channel with polar quantization at the output is established by numerically optimizing the probability mass function of the amplitude. The capacity of the polar-quantized AWGN channel with $b_1$-bit phase quantizer and optimized single-bit magnitude quantizer is also presented. Our numerical findings suggest the existence of signal- to-noise ratio (SNR) thresholds, above which the number of amplitude levels of the optimal APSK scheme and their respective probabilities change abruptly. Moreover, the manner in which the capacity-achieving input evolves with increasing SNR depends on the number of phase quantization bits."
e-CARE: a New Dataset for Exploring Explainable Causal Reasoning,"Li Du, Xiao Ding, Kai Xiong, Ting Liu, Bing Qin",12 May 2022,Artificial Intelligence (cs.AI)," Understanding causality has vital importance for various Natural Language Processing (NLP) applications. Beyond the labeled instances, conceptual explanations of the causality can provide deep understanding of the causal facts to facilitate the causal reasoning process. However, such explanation information still remains absent in existing causal reasoning resources. In this paper, we fill this gap by presenting a human-annotated explainable CAusal REasoning dataset (e-CARE), which contains over 21K causal reasoning questions, together with natural language formed explanations of the causal questions. Experimental results show that generating valid explanations for causal facts still remains especially challenging for the state-of-the-art models, and the explanation information can be helpful for promoting the accuracy and stability of causal reasoning models."
An MMSE Lower Bound via Poincaré Inequality,"IanZieder, Alex Dytso, MartinaCardone",12 May 2022,Information Theory (cs.IT)," This paper studies the minimum mean squared error (MMSE) of estimating $\mathbf{X} \in \mathbb{R}^d$ from the noisy observation $\mathbf{Y} \in \mathbb{R}^k$, under the assumption that the noise (i.e., $\mathbf{Y}|\mathbf{X}$) is a member of the exponential family. The paper provides a new lower bound on the MMSE. Towards this end, an alternative representation of the MMSE is first presented, which is argued to be useful in deriving closed-form expressions for the MMSE. This new representation is then used together with the Poincaré inequality to provide a new lower bound on the MMSE. Unlike, for example, the Cramér-Rao bound, the new bound holds for all possible distributions on the input $\mathbf{X}$. Moreover, the lower bound is shown to be tight in the high-noise regime for the Gaussian noise setting under the assumption that $\mathbf{X}$ is sub-Gaussian. Finally, several numerical examples are shown which demonstrate that the bound performs well in all noise regimes."
Zero-Knowledge Authentication,"JakobPovsic, AndrejBrodnik",12 May 2022,Cryptography and Security (cs.CR), In the thesis we focus on designing an authentication system to authenticate users over a network with a username and a password. The system uses the zero-knowledge proof (ZKP) system as a password verification mechanism. The ZKP protocol used is based on the quadratic residuosity problem. The authentication system is defined as a method in the extensible authentication protocol (EAP). Using a ZKP system yields interesting security properties that make the system favourable to be used over insecure networks.
Bi-level Alignment for Cross-Domain Crowd Counting,"ShenjianGong, ShanshanZhang, JianYang, DengxinDai, BerntSchiele",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Recently, crowd density estimation has received increasing attention. The main challenge for this task is to achieve high-quality manual annotations on a large amount of training data. To avoid reliance on such annotations, previous works apply unsupervised domain adaptation (UDA) techniques by transferring knowledge learned from easily accessible synthetic data to real-world datasets. However, current state-of-the-art methods either rely on external data for training an auxiliary task or apply an expensive coarse-to-fine estimation. In this work, we aim to develop a new adversarial learning based method, which is simple and efficient to apply. To reduce the domain gap between the synthetic and real data, we design a bi-level alignment framework (BLA) consisting of (1) task-driven data alignment and (2) fine-grained feature alignment. In contrast to previous domain augmentation methods, we introduce AutoML to search for an optimal transform on source, which well serves for the downstream task. On the other hand, we do fine-grained alignment for foreground and background separately to alleviate the alignment difficulty. We evaluate our approach on five real-world crowd counting benchmarks, where we outperform existing approaches by a large margin. Also, our approach is simple, easy to implement and efficient to apply. The code is publicly available at [this https URL](https://github.com/Yankeegsj/BLA)."
Supplementary Material: Implementation and Experiments for GAU-basedModel,ZhenjieLiu,12 May 2022,Computation and Language (cs.CL)," In February this year Google proposed a new Transformer variant called FLASH, which has a faster speed, lower VRAM footprint and better performance. This is achieved by designing a performant layer named GAU (Gated Attention Unit), which combines the Attention layer and FFN. In this paper, some implementation details are re-analyzed both theoretically and practically. We then propose a novel GAU-based model and pre-train it model on a Chinese corpus. Results of the CLUE benchmark show that our model achieves a dev average score of 75.02, 1% higher than RoFormerV1 and being 45% faster, which is also competitive with RoFormerV2."
Multigrid methods for 3$D$ $H(\mathbf{curl})$ problems withnonoverlapping domain decomposition smoothers,Duk-SoonOh,12 May 2022,Numerical Analysis (math.NA)," We propose V--cycle multigrid methods for vector field problems arising from the lowest order hexahedral Nédélec finite element. Since the conventional scalar smoothing techniques do not work well for the problems, a new type of smoothing method is necessary. We introduce new smoothers based on substructuring with nonoverlapping domain decomposition methods. We provide the convergence analysis and numerical experiments that support our theory."
Orthogonal Gromov-Wasserstein Discrepancy with Efficient Lower Bound,"HongweiJin, ZishunYu, XinhuaZhang",12 May 2022,Machine Learning (cs.LG)," Comparing structured data from possibly different metric-measure spaces is a fundamental task in machine learning, with applications in, e.g., graph classification. The Gromov-Wasserstein (GW) discrepancy formulates a coupling between the structured data based on optimal transportation, tackling the incomparability between different structures by aligning the intra-relational geometries. Although efficient local solvers such as conditional gradient and Sinkhorn are available, the inherent non- convexity still prevents a tractable evaluation, and the existing lower bounds are not tight enough for practical use. To address this issue, we take inspiration from the connection with the quadratic assignment problem, and propose the orthogonal Gromov-Wasserstein (OGW) discrepancy as a surrogate of GW. It admits an efficient and closed-form lower bound with the complexity of $\mathcal{O}(n^3)$, and directly extends to the fused Gromov- Wasserstein (FGW) distance, incorporating node features into the coupling. Extensive experiments on both the synthetic and real-world datasets show the tightness of our lower bounds, and both OGW and its lower bounds efficiently deliver accurate predictions and satisfactory barycenters for graph sets."
Surrogate Infeasible Fitness Acquirement FI-2Pop for ProceduralContent Generation,"RobertoGallotta, KaiArulkumaran, L. B.Soros",12 May 2022,Neural and Evolutionary Computing (cs.NE)," When generating content for video games using procedural content generation (PCG), the goal is to create functional assets of high quality. Prior work has commonly leveraged the feasible-infeasible two-population (FI-2Pop) constrained optimisation algorithm for PCG, sometimes in combination with the multi-dimensional archive of phenotypic-elites (MAP- Elites) algorithm for finding a set of diverse solutions. However, the fitness function for the infeasible population only takes into account the number of constraints violated. In this paper we present a variant of FI-2Pop in which a surrogate model is trained to predict the fitness of feasible children from infeasible parents, weighted by the probability of producing feasible children. This drives selection towards higher-fitness, feasible solutions. We demonstrate our method on the task of generating spaceships for Space Engineers, showing improvements over both standard FI-2Pop, and the more recent multi-emitter constrained MAP-Elites algorithm."
NFLAT: Non-Flat-Lattice Transformer for Chinese Named EntityRecognition,"ShuangWu, XiaoningSong, ZhenhuaFeng, XiaojunWu",12 May 2022,Computation and Language (cs.CL)," Recently, FLAT has achieved great success in Chinese Named Entity Recognition (NER). This method achieves lexical enhancement by constructing a flat lattice, which mitigates the difficulties posed by blurred word boundaries and the lack of word semantics. To this end, FLAT uses the position information of the starting and ending characters to connect the matching words. However, this method is likely to match more words when dealing with long texts, resulting in very long input sequences. Therefore, it increases the memory used by self-attention and computational costs. To deal with this issue, we advocate a novel lexical enhancement method, InterFormer, that effectively reduces the amount of computational and memory costs by constructing the non-flat-lattice. Furthermore, we implement a complete model, namely NFLAT, for the Chinese NER task. NFLAT decouples lexicon fusion and context feature encoding. Compared with FLAT, it reduces unnecessary attention calculations in ""word-character"" and ""word-word"". This reduces the memory usage by about 50\% and can use more extensive lexicons or higher batches for network training. The experimental results obtained on several well-known benchmarks demonstrate the superiority of the proposed method over the state-of-the-art character-word hybrid models."
Cross-domain Few-shot Meta-learning Using Stacking,"HongyuWang, EibeFrank, BernhardPfahringer, Michael Mayo, GeoffreyHolmes",12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Cross-domain few-shot meta-learning (CDFSML) addresses learning problems where knowledge needs to be transferred from several source domains into an instance-scarce target domain with an explicitly different input distribution. Recently published CDFSML methods generally construct a ""universal model"" that combines knowledge of multiple source domains into one backbone feature extractor. This enables efficient inference but necessitates re-computation of the backbone whenever a new source domain is added. Moreover, state-of-the-art methods derive their universal model from a collection of backbones -- normally one for each source domain -- and the backbones may be constrained to have the same architecture as the universal model. We propose a CDFSML method that is inspired by the classic stacking approach to meta learning. It imposes no constraints on the backbones' architecture or feature shape and does not incur the computational overhead of (re-)computing a universal model. Given a target-domain task, it fine- tunes each backbone independently, uses cross-validation to extract meta training data from the task's instance-scarce support set, and learns a simple linear meta classifier from this data. We evaluate our stacking approach on the well-known Meta-Dataset benchmark, targeting image classification with convolutional neural networks, and show that it often yields substantially higher accuracy than competing methods."
An Efficient Operator-Splitting Method for the Eigenvalue Problem ofthe Monge-Ampère Equation,"HaoLiu, ShingyuLeung, JianliangQian",12 May 2022,Numerical Analysis (math.NA)," We develop an efficient operator-splitting method for the eigenvalue problem of the Monge-Ampère operator in the Aleksandrov sense. The backbone of our method relies on a convergent Rayleigh inverse iterative formulation proposed by Abedin and Kitagawa (Inverse iteration for the {M}onge-{A}mp{è}re eigenvalue problem, {\it Proceedings of the American Mathematical Society}, 148 (2020), no. 11, 4975-4886). Modifying the theoretical formulation, we develop an efficient algorithm for computing the eigenvalue and eigenfunction of the Monge-Ampère operator by solving a constrained Monge-Ampère equation during each iteration. Our method consists of four essential steps: (i) Formulate the Monge-Ampère eigenvalue problem as an optimization problem with a constraint; (ii) Adopt an indicator function to treat the constraint; (iii) Introduce an auxiliary variable to decouple the original constrained optimization problem into simpler optimization subproblems and associate the resulting new optimization problem with an initial value problem; and (iv) Discretize the resulting initial-value problem by an operator-splitting method in time and a mixed finite element method in space. The performance of our method is demonstrated by several experiments. Compared to existing methods, the new method is more efficient in terms of computational cost and has a comparable rate of convergence in terms of accuracy."
Emotion-Centric Requirements Change Handling in Software Engineering,"KashumiMadampe, Rashina Hoda, John Grundy",12 May 2022,Software Engineering (cs.SE)," Background: Requirements Changes (RCs) -- the additions/modifications/deletions of functional/non-functional requirements in software products -- are challenging for software practitioners to handle. Handling some changes may significantly impact the emotions of the practitioners. Objective: We wanted to know the key challenges that make RC handling difficult, how these impact the emotions of software practitioners, what influences their RC handling, and how RC handling can be made less emotionally challenging. Method: We followed a mixed-methods approach. We conducted two survey studies, with 40 participants and 201 participants respectively. The presentation of key quantitative data was followed by descriptive statistical analysis, and the qualitative data was analysed using Strauss-Corbinian Grounded Theory, and Socio-Technical Grounded Theory analysis techniques. Findings:We found (1) several key factors that make RC handling an emotional challenge, (2) varying emotions that practitioners feel when it is challenging to handle RCs, (3) how stakeholders, including practitioners themselves, peers, managers and customers, influence the RC handling and how practitioners feel due to the stakeholder influence, and (4) practices that can be used to better handle RCs. Conclusion: Some challenges are technical and some are social which also belong to aspects of agile practice, emotional intelligence, and cognitive intelligence. Therefore, to better handle RCs with positive emotions in socio-technical environments, agility, emotional intelligence, and cognitive intelligence need to cooperate with each other."
Sparseloop: An Analytical Approach To Sparse Tensor AcceleratorModeling,"Yannan NellieWu, Po-AnTsai, AngshumanParashar, Vivienne Sze, Joel S.Emer",12 May 2022,Hardware Architecture (cs.AR)," In recent years, many accelerators have been proposed to efficiently process sparse tensor algebra applications (e.g., sparse neural networks). However, these proposals are single points in a large and diverse design space. The lack of systematic description and modeling support for these sparse tensor accelerators impedes hardware designers from efficient and effective design space exploration. This paper first presents a unified taxonomy to systematically describe the diverse sparse tensor accelerator design space. Based on the proposed taxonomy, it then introduces Sparseloop, the first fast, accurate, and flexible analytical modeling framework to enable early-stage evaluation and exploration of sparse tensor accelerators. Sparseloop comprehends a large set of architecture specifications, including various dataflows and sparse acceleration features (e.g., elimination of zero-based compute). Using these specifications, Sparseloop evaluates a design's processing speed and energy efficiency while accounting for data movement and compute incurred by the employed dataflow as well as the savings and overhead introduced by the sparse acceleration features using stochastic tensor density models. Across representative accelerators and workloads, Sparseloop achieves over 2000 times faster modeling speed than cycle-level simulations, maintains relative performance trends, and achieves 0.1% to 8% average error. With a case study, we demonstrate Sparseloop's ability to help reveal important insights for designing sparse tensor accelerators (e.g., it is important to co-design orthogonal design aspects)."
Privacy-Preserving Distributed Machine Learning Made Faster,"Zoe L.Jiang, Jiajing Gu, HongxiaoWang, YulinWu, JunbinFang, Siu-Ming Yiu, Wenjian Luo, Xuan Wang",12 May 2022,Cryptography and Security (cs.CR)," With the development of machine learning, it is difficult for a single server to process all the data. So machine learning tasks need to be spread across multiple servers, turning the centralized machine learning into a distributed one. However, privacy remains an unsolved problem in distributed machine learning. Multi-key homomorphic encryption is one of the suitable candidates to solve the problem. However, the most recent result of the Multi-key homomorphic encryption scheme (MKTFHE) only supports the NAND gate. Although it is Turing complete, it requires efficient encapsulation of the NAND gate to further support mathematical calculation. This paper designs and implements a series of operations on positive and negative integers accurately. First, we design basic bootstrapped gates with the same efficiency as that of the NAND gate. Second, we construct practical $k$-bit complement mathematical operators based on our basic binary bootstrapped gates. The constructed created can perform addition, subtraction, multiplication, and division on both positive and negative integers. Finally, we demonstrated the generality of the designed operators by achieving a distributed privacy-preserving machine learning algorithm, i.e. linear regression with two different solutions. Experiments show that the operators we designed are practical and efficient."
Continuous wavelet transform of multiview images using wavelets basedon voxel patterns,VladimirSaveljev,12 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We propose the multiview wavelets based on voxel patterns of autostereoscopic multiview displays. Direct and inverse continuous wavelet transforms of binary and gray-scale images were performed. The input to the inverse wavelet transform was the array of wavelet coefficients of the direct transform. A restored image reproduces the structure of the multiview image correctly. Also, we modified the dimension of the parallax and the depth of 3D images. The restored and modified images were displayed in 3D using lenticular plates. In each case, the visual 3D picture corresponds to the applied modifications. The results can be applied to the autostereoscopic 3D displays."
Representation Learning for Context-Dependent Decision-Making,"YuzhenQin, TommasoMenara, Samet Oymak, ShiNungChing, FabioPasqualetti",12 May 2022,Machine Learning (cs.LG)," Humans are capable of adjusting to changing environments flexibly and quickly. Empirical evidence has revealed that representation learning plays a crucial role in endowing humans with such a capability. Inspired by this observation, we study representation learning in the sequential decision-making scenario with contextual changes. We propose an online algorithm that is able to learn and transfer context-dependent representations and show that it significantly outperforms the existing ones that do not learn representations adaptively. As a case study, we apply our algorithm to the Wisconsin Card Sorting Task, a well-established test for the mental flexibility of humans in sequential decision-making. By comparing our algorithm with the standard Q-learning and Deep-Q learning algorithms, we demonstrate the benefits of adaptive representation learning."
Open Vocabulary Extreme Classification Using Generative Models,"DanielSimig, FabioPetroni, Pouya Yanki, KashyapPopat, Christina Du, SebastianRiedel, MajidYazdani",12 May 2022,Computation and Language (cs.CL)," The extreme multi-label classification (XMC) task aims at tagging content with a subset of labels from an extremely large label set. The label vocabulary is typically defined in advance by domain experts and assumed to capture all necessary tags. However in real world scenarios this label set, although large, is often incomplete and experts frequently need to refine it. To develop systems that simplify this process, we introduce the task of open vocabulary XMC (OXMC): given a piece of content, predict a set of labels, some of which may be outside of the known tag set. Hence, in addition to not having training data for some labels - as is the case in zero-shot classification - models need to invent some labels on-the-fly. We propose GROOV, a fine-tuned seq2seq model for OXMC that generates the set of labels as a flat sequence and is trained using a novel loss independent of predicted label order. We show the efficacy of the approach, experimenting with popular XMC datasets for which GROOV is able to predict meaningful labels outside the given vocabulary while performing on par with state-of- the-art solutions for known labels."
Performing Video Frame Prediction of Microbial Growth with a RecurrentNeural Network,"ConnorRobertson, Jared L.Wilmoth, ScottRetterer, Miguel Fuentes-Cabrera",12 May 2022,Machine Learning (cs.LG)," A Recurrent Neural Network (RNN) was used to perform video frame prediction of microbial growth for a population of two mutants of Pseudomonas aeruginosa. The RNN was trained on videos of 20 frames that were acquired using fluorescence microscopy and microfluidics. The network predicted the last 10 frames of each video, and the accuracy's of the predictions was assessed by comparing raw images, population curves, and the number and size of individual colonies. Overall, we found the predictions to be accurate using this approach. The implications this result has on designing autonomous experiments in microbiology, and the steps that can be taken to make the predictions even more accurate, are discussed."
AppTek's Submission to the IWSLT 2022 Isometric Spoken LanguageTranslation Task,"PatrickWilken, EvgenyMatusov",12 May 2022,Computation and Language (cs.CL)," To participate in the Isometric Spoken Language Translation Task of the IWSLT 2022 evaluation, constrained condition, AppTek developed neural Transformer-based systems for English-to-German with various mechanisms of length control, ranging from source-side and target-side pseudo-tokens to encoding of remaining length in characters that replaces positional encoding. We further increased translation length compliance by sentence- level selection of length-compliant hypotheses from different system variants, as well as rescoring of N-best candidates from a single system. Length-compliant back-translated and forward-translated synthetic data, as well as other parallel data variants derived from the original MuST-C training corpus were important for a good quality/desired length trade-off. Our experimental results show that length compliance levels above 90% can be reached while minimizing losses in MT quality as measured in BERT and BLEU scores."
SubER: A Metric for Automatic Evaluation of Subtitle Quality,"PatrickWilken, PanayotaGeorgakopoulou, EvgenyMatusov",11 May 2022,Computation and Language (cs.CL)," This paper addresses the problem of evaluating the quality of automatically generated subtitles, which includes not only the quality of the machine-transcribed or translated speech, but also the quality of line segmentation and subtitle timing. We propose SubER - a single novel metric based on edit distance with shifts that takes all of these subtitle properties into account. We compare it to existing metrics for evaluating transcription, translation, and subtitle quality. A careful human evaluation in a post-editing scenario shows that the new metric has a high correlation with the post-editing effort and direct human assessment scores, outperforming baseline metrics considering only the subtitle text, such as WER and BLEU, and existing methods to integrate segmentation and timing features."
Stochastic first-order methods for average-reward Markov decisionprocesses,"TianjiaoLi, FeiyangWu, GuanghuiLan",11 May 2022,Machine Learning (cs.LG)," We study the problem of average-reward Markov decision processes (AMDPs) and develop novel first-order methods with strong theoretical guarantees for both policy evaluation and optimization. Existing on-policy evaluation methods suffer from sub-optimal convergence rates as well as failure in handling insufficiently random policies, e.g., deterministic policies, for lack of exploration. To remedy these issues, we develop a novel variance-reduced temporal difference (VRTD) method with linear function approximation for randomized policies along with optimal convergence guarantees, and an exploratory variance-reduced temporal difference (EVRTD) method for insufficiently random policies with comparable convergence guarantees. We further establish linear convergence rate on the bias of policy evaluation, which is essential for improving the overall sample complexity of policy optimization. On the other hand, compared with intensive research interest in finite sample analysis of policy gradient methods for discounted MDPs, existing studies on policy gradient methods for AMDPs mostly focus on regret bounds under restrictive assumptions on the underlying Markov processes (see, e.g., Abbasi-Yadkori et al., 2019), and they often lack guarantees on the overall sample complexities. Towards this end, we develop an average-reward variant of the stochastic policy mirror descent (SPMD) (Lan, 2022). We establish the first $\widetilde{\mathcal{O}}(\epsilon^{-2})$ sample complexity for solving AMDPs with policy gradient method under both the generative model (with unichain assumption) and Markovian noise model (with ergodic assumption). This bound can be further improved to $\widetilde{\mathcal{O}}(\epsilon^{-1})$ for solving regularized AMDPs. Our theoretical advantages are corroborated by numerical experiments."
Deep-Learned Generators of Porosity Distributions Produced DuringMetal Additive Manufacturing,"FrancisOgoke, KyleJohnson, MichaelGlinsky, ChrisLaursen, SharlotteKramer, Amir BaratiFarimani",11 May 2022,Machine Learning (cs.LG)," Laser Powder Bed Fusion has become a widely adopted method for metal Additive Manufacturing (AM) due to its ability to mass produce complex parts with increased local control. However, AM produced parts can be subject to undesirable porosity, negatively influencing the properties of printed components. Thus, controlling porosity is integral for creating effective parts. A precise understanding of the porosity distribution is crucial for accurately simulating potential fatigue and failure zones. Previous research on generating synthetic porous microstructures have succeeded in generating parts with high density, isotropic porosity distributions but are often inapplicable to cases with sparser, boundary- dependent pore distributions. Our work bridges this gap by providing a method that considers these constraints by deconstructing the generation problem into its constitutive parts. A framework is introduced that combines Generative Adversarial Networks with Mallat Scattering Transform-based autocorrelation methods to construct novel realizations of the individual pore geometries and surface roughness, then stochastically reconstruct them to form realizations of a porous printed part. The generated parts are compared to the existing experimental porosity distributions based on statistical and dimensional metrics, such as nearest neighbor distances, pore volumes, pore anisotropies and scattering transform based auto- correlations."
Robustness Guarantees for Credal Bayesian Networks via ConstraintRelaxation over Probabilistic Circuits,"HjalmarWijk, BenjieWang, MartaKwiatkowska",11 May 2022,Artificial Intelligence (cs.AI)," In many domains, worst-case guarantees on the performance (e.g., prediction accuracy) of a decision function subject to distributional shifts and uncertainty about the environment are crucial. In this work we develop a method to quantify the robustness of decision functions with respect to credal Bayesian networks, formal parametric models of the environment where uncertainty is expressed through credal sets on the parameters. In particular, we address the maximum marginal probability (MARmax) problem, that is, determining the greatest probability of an event (such as misclassification) obtainable for parameters in the credal set. We develop a method to faithfully transfer the problem into a constrained optimization problem on a probabilistic circuit. By performing a simple constraint relaxation, we show how to obtain a guaranteed upper bound on MARmax in linear time in the size of the circuit. We further theoretically characterize this constraint relaxation in terms of the original Bayesian network structure, which yields insight into the tightness of the bound. We implement the method and provide experimental evidence that the upper bound is often near tight and demonstrates improved scalability compared to other methods."
Bridging Model-based Safety and Model-free Reinforcement Learningthrough System Identification of Low Dimensional Linear Models,"ZhongyuLi, JunZeng, AkshayThirugnanam, KoushilSreenath",11 May 2022,Robotics (cs.RO)," Bridging model-based safety and model-free reinforcement learning (RL) for dynamic robots is appealing since model-based methods are able to provide formal safety guarantees, while RL-based methods are able to exploit the robot agility by learning from the full-order system dynamics. However, current approaches to tackle this problem are mostly restricted to simple systems. In this paper, we propose a new method to combine model-based safety with model-free reinforcement learning by explicitly finding a low- dimensional model of the system controlled by a RL policy and applying stability and safety guarantees on that simple model. We use a complex bipedal robot Cassie, which is a high dimensional nonlinear system with hybrid dynamics and underactuation, and its RL-based walking controller as an example. We show that a low-dimensional dynamical model is sufficient to capture the dynamics of the closed-loop system. We demonstrate that this model is linear, asymptotically stable, and is decoupled across control input in all dimensions. We further exemplify that such linearity exists even when using different RL control policies. Such results point out an interesting direction to understand the relationship between RL and optimal control: whether RL tends to linearize the nonlinear system during training in some cases. Furthermore, we illustrate that the found linear model is able to provide guarantees by safety-critical optimal control framework, e.g., Model Predictive Control with Control Barrier Functions, on an example of autonomous navigation using Cassie while taking advantage of the agility provided by the RL-based controller."
Learning to Guide Multiple Heterogeneous Actors from a Single HumanDemonstration via Automatic Curriculum Learning in StarCraft II,"NicholasWaytowich, James Hare, Vinicius G.Goecks, MarkMittrick, JohnRichardson, Anjon Basak, Derrik E.Asher",11 May 2022,Machine Learning (cs.LG)," Traditionally, learning from human demonstrations via direct behavior cloning can lead to high-performance policies given that the algorithm has access to large amounts of high-quality data covering the most likely scenarios to be encountered when the agent is operating. However, in real-world scenarios, expert data is limited and it is desired to train an agent that learns a behavior policy general enough to handle situations that were not demonstrated by the human expert. Another alternative is to learn these policies with no supervision via deep reinforcement learning, however, these algorithms require a large amount of computing time to perform well on complex tasks with high-dimensional state and action spaces, such as those found in StarCraft II. Automatic curriculum learning is a recent mechanism comprised of techniques designed to speed up deep reinforcement learning by adjusting the difficulty of the current task to be solved according to the agent's current capabilities. Designing a proper curriculum, however, can be challenging for sufficiently complex tasks, and thus we leverage human demonstrations as a way to guide agent exploration during training. In this work, we aim to train deep reinforcement learning agents that can command multiple heterogeneous actors where starting positions and overall difficulty of the task are controlled by an automatically-generated curriculum from a single human demonstration. Our results show that an agent trained via automated curriculum learning can outperform state-of-the-art deep reinforcement learning baselines and match the performance of the human expert in a simulated command and control task in StarCraft II modeled over a real military scenario."
MEWS: Real-time Social Media Manipulation Detection and Analysis,"Trenton W.Ford, MichaelYankoski, MichaelYankoski, Tom Henry, FarahKhashman, Katherine R.Dearstyne, TimWeninger",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," This article presents a beta-version of MEWS (Misinformation Early Warning System). It describes the various aspects of the ingestion, manipulation detection, and graphing algorithms employed to determine--in near real-time--the relationships between social media images as they emerge and spread on social media platforms. By combining these various technologies into a single processing pipeline, MEWS can identify manipulated media items as they arise and identify when these particular items begin trending on individual social media platforms or even across multiple platforms. The emergence of a novel manipulation followed by rapid diffusion of the manipulated content suggests a disinformation campaign."
On the Complexity of Determining Whether there is a Unique HamiltonianCycle or Path,"OlivierHudry, AntoineLobstein",11 May 2022,Computational Complexity (cs.CC)," The decision problems of the existence of a Hamiltonian cycle or of a Hamiltonian path in a given graph, and of the existence of a truth assignment satisfying a given Boolean formula $C$, are well-known {\it NP}-complete problems. Here we study the problems of the {\it uniqueness} of a Hamiltonian cycle or path in an undirected, directed or oriented graph, and show that they have the same complexity, up to polynomials, as the problem U-SAT of the uniqueness of an assignment satisfying $C$. As a consequence, these Hamiltonian problems are {\it NP}-hard and belong to the class~{\it DP}, like U-SAT."
LSI: A Learned Secondary Index Structure,"AndreasKipf, DominikHorn, PascalPfeil, RyanMarcus, TimKraska",11 May 2022,Databases (cs.DB)," Learned index structures have been shown to achieve favorable lookup performance and space consumption compared to their traditional counterparts such as B-trees. However, most learned index studies have focused on the primary indexing setting, where the base data is sorted. In this work, we investigate whether learned indexes sustain their advantage in the secondary indexing setting. We introduce Learned Secondary Index (LSI), a first attempt to use learned indexes for indexing unsorted data. LSI works by building a learned index over a permutation vector, which allows binary search to performed on the unsorted base data using random access. We additionally augment LSI with a fingerprint vector to accelerate equality lookups. We show that LSI achieves comparable lookup performance to state- of-the-art secondary indexes while being up to 6x more space efficient."
Deep Learning and Synthetic Media,RaphaëlMillière,11 May 2022,Machine Learning (cs.LG)," Deep learning algorithms are rapidly changing the way in which audiovisual media can be produced. Synthetic audiovisual media generated with deep learning \- often subsumed colloquially under the label ""deepfakes"" - have a number of impressive characteristics; they are increasingly trivial to produce, and can be indistinguishable from real sounds and images recorded with a sensor. Much attention has been dedicated to ethical concerns raised by this technological development. Here, I focus instead on a set of issues related to the notion of synthetic audiovisual media, its place within a broader taxonomy of audiovisual media, and how deep learning techniques differ from more traditional approaches to media synthesis. After reviewing important etiological features of deep learning pipelines for media manipulation and generation, I argue that ""deepfakes"" and related synthetic media produced with such pipelines do not merely offer incremental improvements over previous methods, but challenge traditional taxonomical distinctions, and pave the way for genuinely novel kinds of audiovisual media."
Individual Fairness Guarantees for Neural Networks,EliasBenussi(1) AndreaPatane (1)MatthewWicker (1)LucaLaurenti(2) MartaKwiatkowska(1) ((1) University of Oxford ,11 May 2022,Machine Learning (cs.LG)," We consider the problem of certifying the individual fairness (IF) of feed-forward neural networks (NNs). In particular, we work with the $\epsilon$-$\delta$-IF formulation, which, given a NN and a similarity metric learnt from data, requires that the output difference between any pair of $\epsilon$-similar individuals is bounded by a maximum decision tolerance $\delta \geq 0$. Working with a range of metrics, including the Mahalanobis distance, we propose a method to overapproximate the resulting optimisation problem using piecewise-linear functions to lower and upper bound the NN's non-linearities globally over the input space. We encode this computation as the solution of a Mixed-Integer Linear Programming problem and demonstrate that it can be used to compute IF guarantees on four datasets widely used for fairness benchmarking. We show how this formulation can be used to encourage models' fairness at training time by modifying the NN loss, and empirically confirm our approach yields NNs that are orders of magnitude fairer than state-of-the-art methods."
Co-generation of Collision-Free Shapes for Arbitrary One-ParametricMotion,"Clinton B.Morris, MoradBehandish",11 May 2022,Computational Geometry (cs.CG)," Mechanical assemblies can exhibit complex relative motions, during which collisions between moving parts and their surroundings must be avoided. To define feasible design spaces for each part's shape, ""maximal"" collision-free pointsets can be computed using configuration space modeling techniques such as Minkowski operations and sweep/unsweep. For example, for a pair of parts undergoing a given relative motion, to make the problem well-posed, the geometry of one part (chosen arbitrarily) must be fixed to compute the maximal shape of the other part by an unsweep operation. Making such arbitrary choices in a multi-component assembly can place unnecessary restrictions on the design space. A broader family of collision-free pairs of parts can be explored, if fixing the geometry of a component is not required. In this paper, we formalize this family of collision-free shapes and introduce a generic method for generating a broad subset of them. Our procedure, which is an extension of the unsweep, allows for co-generation of a pair of geometries which are modified incrementally and simultaneously to avoid collision. We demonstrate the effectiveness and scalability of our procedure in both 2D and 3D by generating a variety of collision-free shapes. Notably, we show that our approach can automatically generate freeform cam and follower profiles, gear teeth, and screw threads, starting from colliding blocks of materials, solely from a specification of relative motion and without the use of any feature-informed heuristics. Moreover, our approach provides continuous measures of collision that can be incorporated into standard gradient-descent design optimization, allowing for simultaneous collision-free and physics-informed co-design of mechanical parts for assembly."
Efficient Antenna Optimization Using a Hybrid of EvolutionaryPrograming and Particle Swarm Optimization,"AhmadHoorfar, ShamshaLakhani",11 May 2022,Neural and Evolutionary Computing (cs.NE)," In this paper, we present a hybrid of Evolutionary Programming (EP) and Particle Swarm Optimization (PSO) algorithms for numerically efficient global optimization of antenna arrays and metasurfaces. The hybrid EP-PSO algorithm uses an evolutionary optimization approach that incorporates swarm directions in the standard self-adaptive EP algorithm. As examples, we have applied this hybrid technique to two antenna problems: the side-lobe-level reduction of a non-uniform spaced (aperiodic) linear array and the beam shaping of a printed antenna loaded with a partially reflective metasurface. Detailed comparisons between the proposed hybrid EP-PSO technique and EP-only and PSO-only techniques are given, demonstrating the efficiency of this hybrid technique in the complex antenna design problems."
"""There Is Not Enough Information"": On the Effects of Explanations onPerceptions of Informational Fairness and Trustworthiness in AutomatedDecision-Making","JakobSchoeffer, NiklasKuehl, YvetteMachowski",11 May 2022,Human-Computer Interaction (cs.HC)," Automated decision systems (ADS) are increasingly used for consequential decision-making. These systems often rely on sophisticated yet opaque machine learning models, which do not allow for understanding how a given decision was arrived at. In this work, we conduct a human subject study to assess people's perceptions of informational fairness (i.e., whether people think they are given adequate information on and explanation of the process and its outcomes) and trustworthiness of an underlying ADS when provided with varying types of information about the system. More specifically, we instantiate an ADS in the area of automated loan approval and generate different explanations that are commonly used in the literature. We randomize the amount of information that study participants get to see by providing certain groups of people with the same explanations as others plus additional explanations. From our quantitative analyses, we observe that different amounts of information as well as people's (self- assessed) AI literacy significantly influence the perceived informational fairness, which, in turn, positively relates to perceived trustworthiness of the ADS. A comprehensive analysis of qualitative feedback sheds light on people's desiderata for explanations, among which are (i) consistency (both with people's expectations and across different explanations), (ii) disclosure of monotonic relationships between features and outcome, and (iii) actionability of recommendations."
eFedDNN: Ensemble based Federated Deep Neural Networks for TrajectoryMode Inference,"Daniel OpokuMensah, Godwin Badu-Marfo, Ranwa AlMallah, BilalFarooq",11 May 2022,Machine Learning (cs.LG)," As the most significant data source in smart mobility systems, GPS trajectories can help identify user travel mode. However, these GPS datasets may contain users' private information (e.g., home location), preventing many users from sharing their private information with a third party. Hence, identifying travel modes while protecting users' privacy is a significant issue. To address this challenge, we use federated learning (FL), a privacy- preserving machine learning technique that aims at collaboratively training a robust global model by accessing users' locally trained models but not their raw data. Specifically, we designed a novel ensemble-based Federated Deep Neural Network (eFedDNN). The ensemble method combines the outputs of the different models learned via FL by the users and shows an accuracy that surpasses comparable models reported in the literature. Extensive experimental studies on a real-world open-access dataset from Montreal demonstrate that the proposed inference model can achieve accurate identification of users' mode of travel without compromising privacy."
Visualization Guidelines for Model Performance Communication BetweenData Scientists and Subject Matter Experts,"AshleySuh, GabrielAppleby, Erik W.Anderson, LucaFinelli, Remco Chang, DylanCashman",11 May 2022,Human-Computer Interaction (cs.HC)," Presenting the complexities of a model's performance is a communication bottleneck that threatens collaborations between data scientists and subject matter experts. Accuracy and error metrics alone fail to tell the whole story of a model - its risks, strengths, and limitations - making it difficult for subject matter experts to feel confident in deciding to use a model. As a result, models may fail in unexpected ways if their weaknesses are not clearly understood. Alternatively, models may go unused, as subject matter experts disregard poorly presented models in favor of familiar, yet arguably substandard methods. In this paper, we propose effective use of visualization as a medium for communication between data scientists and subject matter experts. Our research addresses the gap between common practices in model performance communication and the understanding of subject matter experts and decision makers. We derive a set of communication guidelines and recommended visualizations for communicating model performance based on interviews of both data scientists and subject matter experts at the same organization. We conduct a follow-up study with subject matter experts to evaluate the efficacy of our guidelines in presentations of model performance with and without our recommendations. We find that our proposed guidelines made subject matter experts more aware of the tradeoffs of the presented model. Participants realized that current communication methods left them without a robust understanding of the model's performance, potentially giving them misplaced confidence in the use of the model."
Tiny Robot Learning: Challenges and Directions for Machine Learning inResource-Constrained Robots,"Sabrina M.Neuman, BrianPlancher, Bardienus P.Duisterhof, SrivatsanKrishnan, ColbyBanbury, MarkMazumder, ShvetankPrakash, JasonJabbour, AleksandraFaust, GuidoC.H.E. deCroon, Vijay JanapaReddi",11 May 2022,Machine Learning (cs.LG)," Machine learning (ML) has become a pervasive tool across computing systems. An emerging application that stress-tests the challenges of ML system design is tiny robot learning, the deployment of ML on resource- constrained low-cost autonomous robots. Tiny robot learning lies at the intersection of embedded systems, robotics, and ML, compounding the challenges of these domains. Tiny robot learning is subject to challenges from size, weight, area, and power (SWAP) constraints; sensor, actuator, and compute hardware limitations; end-to-end system tradeoffs; and a large diversity of possible deployment scenarios. Tiny robot learning requires ML models to be designed with these challenges in mind, providing a crucible that reveals the necessity of holistic ML system design and automated end- to-end design tools for agile development. This paper gives a brief survey of the tiny robot learning space, elaborates on key challenges, and proposes promising opportunities for future work in ML system design."
Trusted Container Extensions for Container-based ConfidentialComputing,"FerdinandBrasser, PatrickJauernig, FrederikPustelnik, Ahmad-RezaSadeghi, EmmanuelStapf",11 May 2022,Cryptography and Security (cs.CR)," Cloud computing has emerged as a corner stone of today's computing landscape. More and more customers who outsource their infrastructure benefit from the manageability, scalability and cost saving that come with cloud computing. Those benefits get amplified by the trend towards microservices. Instead of renting and maintaining full VMs, customers increasingly leverage container technologies, which come with a much more lightweight resource footprint while also removing the need to emulate complete systems and their devices.   However, privacy concerns hamper many customers from moving to the cloud and leveraging its benefits. Furthermore, regulatory requirements prevent the adaption of cloud computing in many industries, such as health care or finance. Standard software isolation mechanisms have been proven to be insufficient if the host system is not fully trusted, e.g., when the cloud infrastructure gets compromised by malicious third-party actors. Consequently, confidential computing is gaining increasing relevance in the cloud computing field.   We present Trusted Container Extensions (TCX), a novel container security architecture, which combines the manageability and agility of standard containers with the strong protection guarantees of hardware-enforced Trusted Execution Environments (TEEs) to enable confidential computing for container workloads. TCX provides significant performance advantages compared to existing approaches while protecting container workloads and the data processed by them. Our implementation, based on AMD Secure Encrypted Virtualization (SEV), ensures integrity and confidentiality of data and services during deployment, and allows secure interaction between protected containers as well as to external entities. Our evaluation shows that our implementation induces a low performance overhead of 5.77% on the standard SPEC2017 benchmark suite."
Unisolvent and minimal physical degrees of freedom for the secondfamily of polynomial differential forms,"Ludovico BruniBruno, EnricoZampa",11 May 2022,Numerical Analysis (math.NA)," The principal aim of this work is to provide a family of unisolvent and minimal physical degrees of freedom, called weights, for Nédélec second family of finite elements. Such elements are thought of as differential forms $ \mathcal{P}_r \Lambda^k (T)$ whose coefficients are polynomials of degree $ r $. We confine ourselves in the two dimensional case $ \mathbb{R}^2 $ since it is easy to visualise and offers a neat and elegant treatment; however, we present techniques that can be extended to $ n  2 $ with some adjustments of technical details. In particular, we use techniques of homological algebra to obtain degrees of freedom for the whole diagram $$ \mathcal{P}_r \Lambda^0 (T) \rightarrow \mathcal{P}_r \Lambda^1 (T) \rightarrow \mathcal{P}_r \Lambda^2 (T), $$ being $ T $ a $2$-simplex of $ \mathbb{R}^2 $. This work pairs its companions recently appeared for Nédélec first family of finite elements."
Surface Representation for Point Clouds,"HaoxiRan, JunLiu, ChengjieWang",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Most prior work represents the shapes of point clouds by coordinates. However, it is insufficient to describe the local geometry directly. In this paper, we present \textbf{RepSurf} (representative surfaces), a novel representation of point clouds to \textbf{explicitly} depict the very local structure. We explore two variants of RepSurf, Triangular RepSurf and Umbrella RepSurf inspired by triangle meshes and umbrella curvature in computer graphics. We compute the representations of RepSurf by predefined geometric priors after surface reconstruction. RepSurf can be a plug-and-play module for most point cloud models thanks to its free collaboration with irregular points. Based on a simple baseline of PointNet++ (SSG version), Umbrella RepSurf surpasses the previous state-of- the-art by a large margin for classification, segmentation and detection on various benchmarks in terms of performance and efficiency. With an increase of around \textbf{0.008M} number of parameters, \textbf{0.04G} FLOPs, and \textbf{1.12ms} inference time, our method achieves \textbf{94.7\%} (+0.5\%) on ModelNet40, and \textbf{84.6\%} (+1.8\%) on ScanObjectNN for classification, while \textbf{74.3\%} (+0.8\%) mIoU on S3DIS 6-fold, and \textbf{70.0\%} (+1.6\%) mIoU on ScanNet for segmentation. For detection, previous state-of-the-art detector with our RepSurf obtains \textbf{71.2\%} (+2.1\%) mAP$\mathit{_{25}}$, \textbf{54.8\%} (+2.0\%) mAP$\mathit{_{50}}$ on ScanNetV2, and \textbf{64.9\%} (+1.9\%) mAP$\mathit{_{25}}$, \textbf{47.7\%} (+2.5\%) mAP$\mathit{_{50}}$ on SUN RGB-D. Our lightweight Triangular RepSurf performs its excellence on these benchmarks as well. The code is publicly available at \url{[this https URL](https://github.com/hancyran/RepSurf)}."
Learning to Retrieve Videos by Asking Questions,"AvinashMadasu, JunierOliva, GedasBertasius",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The majority of traditional text-to-video retrieval systems operate in static environments, i.e., there is no interaction between the user and the agent beyond the initial textual query provided by the user. This can be suboptimal if the initial query has ambiguities, which would lead to many falsely retrieved videos. To overcome this limitation, we propose a novel framework for Video Retrieval using Dialog (ViReD), which enables the user to interact with an AI agent via multiple rounds of dialog. The key contribution of our framework is a novel multimodal question generator that learns to ask questions that maximize the subsequent video retrieval performance. Our multimodal question generator uses (i) the video candidates retrieved during the last round of interaction with the user and (ii) the text-based dialog history documenting all previous interactions, to generate questions that incorporate both visual and linguistic cues relevant to video retrieval. Furthermore, to generate maximally informative questions, we propose an Information-Guided Supervision (IGS), which guides the question generator to ask questions that would boost subsequent video retrieval accuracy. We validate the effectiveness of our interactive ViReD framework on the AVSD dataset, showing that our interactive method performs significantly better than traditional non-interactive video retrieval systems. Furthermore, we also demonstrate that our proposed approach also generalizes to the real-world settings that involve interactions with real humans, thus, demonstrating the robustness and generality of our framework"
DISARM: Detecting the Victims Targeted by Harmful Memes,"ShivamSharma, Md.ShadAkhtar, PreslavNakov, TanmoyChakraborty",11 May 2022,Computation and Language (cs.CL)," Internet memes have emerged as an increasingly popular means of communication on the Web. Although typically intended to elicit humour, they have been increasingly used to spread hatred, trolling, and cyberbullying, as well as to target specific individuals, communities, or society on political, socio-cultural, and psychological grounds. While previous work has focused on detecting harmful, hateful, and offensive memes, identifying whom they attack remains a challenging and underexplored area. Here we aim to bridge this gap. In particular, we create a dataset where we annotate each meme with its victim(s) such as the name of the targeted person(s), organization(s), and community(ies). We then propose DISARM (Detecting vIctimS targeted by hARmful Memes), a framework that uses named entity recognition and person identification to detect all entities a meme is referring to, and then, incorporates a novel contextualized multimodal deep neural network to classify whether the meme intends to harm these entities. We perform several systematic experiments on three test setups, corresponding to entities that are (a) all seen while training, (b) not seen as a harmful target on training, and (c) not seen at all on training. The evaluation results show that DISARM significantly outperforms ten unimodal and multimodal systems. Finally, we show that DISARM is interpretable and comparatively more generalizable and that it can reduce the relative error rate for harmful target identification by up to 9 points absolute over several strong multimodal rivals."
Computational behavior recognition in child and adolescent psychiatry:A statistical and machine learning analysis plan,"Nicole N.Lønfeldt, Flavia D.Frumosu, A.-R. Cecilie Mora-Jensen, Nicklas LeanderLund, SnehaDas, A.KatrinePagsberg, Line K. H.Clemmensen",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Motivation: Behavioral observations are an important resource in the study and evaluation of psychological phenomena, but it is costly, time- consuming, and susceptible to bias. Thus, we aim to automate coding of human behavior for use in psychotherapy and research with the help of artificial intelligence (AI) tools. Here, we present an analysis plan. Methods: Videos of a gold-standard semi-structured diagnostic interview of 25 youth with obsessive-compulsive disorder (OCD) and 12 youth without a psychiatric diagnosis (no-OCD) will be analyzed. Youth were between 8 and 17 years old. Features from the videos will be extracted and used to compute ratings of behavior, which will be compared to ratings of behavior produced by mental health professionals trained to use a specific behavioral coding manual. We will test the effect of OCD diagnosis on the computationally-derived behavior ratings using multivariate analysis of variance (MANOVA). Using the generated features, a binary classification model will be built and used to classify OCD/no-OCD classes. Discussion: Here, we present a pre-defined plan for how data will be pre-processed, analyzed and presented in the publication of results and their interpretation. A challenge for the proposed study is that the AI approach will attempt to derive behavioral ratings based solely on vision, whereas humans use visual, paralinguistic and linguistic cues to rate behavior. Another challenge will be using machine learning models for body and facial movement detection trained primarily on adults and not on children. If the AI tools show promising results, this pre-registered analysis plan may help reduce interpretation bias. Trial registration: [this http URL](http://ClinicalTrials.gov) \- H-18010607"
"Some Grammatical Errors are Frequent, Others are Important","LeshemChoshen, OfirShifman, Omri Abend",11 May 2022,Computation and Language (cs.CL)," In Grammatical Error Correction, systems are evaluated by the number of errors they correct. However, no one has assessed whether all error types are equally important. We provide and apply a method to quantify the importance of different grammatical error types to humans. We show that some rare errors are considered disturbing while other common ones are not. This affects possible directions to improve both systems and their evaluation."
Abductive Reasoning in Intuitionistic Propositional Logic via TheoremSynthesis,PaulTarau,11 May 2022,Logic in Computer Science (cs.LO)," With help of a compact Prolog-based theorem prover for Intuitionistic Propositional Logic, we synthesize minimal assumptions under which a given formula formula becomes a theorem.   After applying our synthesis algorithm to cover basic abductive reasoning mechanisms, we synthesize conjunctions of literals that mimic rows of truth tables in classical or intermediate logics and we abduce conditional hypotheses that turn the theorems of classical or intermediate logics into theorems in intuitionistic logic. One step further, we generalize our abductive reasoning mechanism to synthesize more expressive sequent premises using a minimal set of canonical formulas, to which arbitrary formulas in the calculus can be reduced while preserving their provability.   Organized as a self-contained literate Prolog program, the paper supports interactive exploration of its content and ensures full replicability of our results."
Diverse Video Generation from a Single Video,"NivHaim, BenFeinstein, Niv Granot, AssafShocher, Shai Bagon, Tali Dekel, Michal Irani",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," GANs are able to perform generation and manipulation tasks, trained on a single video. However, these single video GANs require unreasonable amount of time to train on a single video, rendering them almost impractical. In this paper we question the necessity of a GAN for generation from a single video, and introduce a non-parametric baseline for a variety of generation and manipulation tasks. We revive classical space- time patches-nearest-neighbors approaches and adapt them to a scalable unconditional generative model, without any learning. This simple baseline surprisingly outperforms single-video GANs in visual quality and realism (confirmed by quantitative and qualitative evaluations), and is disproportionately faster (runtime reduced from several days to seconds). Our approach is easily scaled to Full-HD videos. We also use the same framework to demonstrate video analogies and spatio-temporal retargeting. These observations show that classical approaches significantly outperform heavy deep learning machinery for these tasks. This sets a new baseline for single-video generation and manipulation tasks, and no less important -- makes diverse generation from a single video practically possible for the first time."
Error Estimates For A Linear Folding Model,"SörenBartels, AndreaBonito, PhilippTscherner",11 May 2022,Numerical Analysis (math.NA), An interior penalty discontinuous Galerkin method is devised to approximate minimizers of a linear folding model by discontinuous isoparametric finite element functions that account for an approximation of a folding arc. The numerical analysis of the discrete model includes an a priori error estimate in case of an accurate representation of the folding curve by the isoparametric mesh. Additional estimates show that geometric consistency errors may be controlled separately if the folding arc is approximated by piecewise polynomial curves. Various numerical experiments are carried out to validate the a priori error estimate for the folding model.
"Structured, flexible, and robust: benchmarking and improving largelanguage models towards more human-like behavior in out-of-distributionreasoning tasks","Katherine M.Collins, CatherineWong, JiahaiFeng, MeganWei, Joshua B.Tenenbaum",11 May 2022,Computation and Language (cs.CL)," Human language offers a powerful window into our thoughts -- we tell stories, give explanations, and express our beliefs and goals through words. Abundant evidence also suggests that language plays a developmental role in structuring our learning. Here, we ask: how much of human-like thinking can be captured by learning statistical patterns in language alone? We first contribute a new challenge benchmark for comparing humans and distributional large language models (LLMs). Our benchmark contains two problem-solving domains (planning and explanation generation) and is designed to require generalization to new, out-of-distribution problems expressed in language. We find that humans are far more robust than LLMs on this benchmark. Next, we propose a hybrid Parse-and-Solve model, which augments distributional LLMs with a structured symbolic reasoning module. We find that this model shows more robust adaptation to out-of-distribution planning problems, demonstrating the promise of hybrid AI models for more human-like reasoning."
Inferential Tasks as an Evaluation Technique for Visualization,"AshleySuh, AbMosca, ShannonRobinson, Quinn Pham, DylanCashman, AlvittaOttley, Remco Chang",11 May 2022,Human-Computer Interaction (cs.HC)," Designing suitable tasks for visualization evaluation remains challenging. Traditional evaluation techniques commonly rely on 'low-level' or 'open-ended' tasks to assess the efficacy of a proposed visualization, however, nontrivial trade-offs exist between the two. Low-level tasks allow for robust quantitative evaluations, but are not indicative of the complex usage of a visualization. Open-ended tasks, while excellent for insight- based evaluations, are typically unstructured and require time-consuming interviews. Bridging this gap, we propose inferential tasks: a complementary task category based on inferential learning in psychology. Inferential tasks produce quantitative evaluation data in which users are prompted to form and validate their own findings with a visualization. We demonstrate the use of inferential tasks through a validation experiment on two well-known visualization tools."
A Deep Learning Approach for Predicting Two-dimensional SoilConsolidation Using Physics-Informed Neural Networks (PINN),"Yue Lu, Gang Mei, FrancescoPiccialli",9 Apr 2022,"Computational Engineering, Finance, and Science (cs.CE)"," Soil consolidation is closely related to seepage, stability, and settlement of geotechnical buildings and foundations, and directly affects the use and safety of superstructures. Nowadays, the unidirectional consolidation theory of soils is widely used in certain conditions and approximate calculations. The multi-directional theory of soil consolidation is more reasonable than the unidirectional theory in practical applications, but it is much more complicated in terms of index determination and solution. To address the above problem, in this paper, we propose a deep learning method using physics-informed neural networks (PINN) to predict the excess pore water pressure of two-dimensional soil consolidation. In the proposed method, (1) a fully connected neural network is constructed, (2) the computational domain, partial differential equation (PDE), and constraints are defined to generate data for model training, and (3) the PDE of two-dimensional soil consolidation and the model of the neural network is connected to reduce the loss of the model. The effectiveness of the proposed method is verified by comparison with the numerical solution of PDE for two- dimensional consolidation. Using this method, the excess pore water pressure could be predicted simply and efficiently. In addition, the method was applied to predict the soil excess pore water pressure in the foundation in a real case at Tianjin port, China. The proposed deep learning approach can be used to investigate the large and complex multi-directional soil consolidation."
Multi-Class 3D Object Detection with Single-Class Supervision,"Mao Ye, Chenxi Liu, Maoqing Yao, Weiyue Wang, Zhaoqi Leng, Charles R.Qi, DragomirAnguelov",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," While multi-class 3D detectors are needed in many robotics applications, training them with fully labeled datasets can be expensive in labeling cost. An alternative approach is to have targeted single-class labels on disjoint data samples. In this paper, we are interested in training a multi-class 3D object detection model, while using these single- class labeled data. We begin by detailing the unique stance of our ""Single- Class Supervision"" (SCS) setting with respect to related concepts such as partial supervision and semi supervision. Then, based on the case study of training the multi-class version of Range Sparse Net (RSN), we adapt a spectrum of algorithms -- from supervised learning to pseudo-labeling -- to fully exploit the properties of our SCS setting, and perform extensive ablation studies to identify the most effective algorithm and practice. Empirical experiments on the Waymo Open Dataset show that proper training under SCS can approach or match full supervision training while saving labeling costs."
Explainable Computational Creativity,"Maria TeresaLlano, Markd'Inverno, Matthew Yee-King, JonMcCormack, Alon Ilsar, AlisonPease, SimonColton",11 May 2022,Human-Computer Interaction (cs.HC)," Human collaboration with systems within the Computational Creativity (CC) field is often restricted to shallow interactions, where the creative processes, of systems and humans alike, are carried out in isolation, without any (or little) intervention from the user, and without any discussion about how the unfolding decisions are taking place. Fruitful co-creation requires a sustained ongoing interaction that can include discussions of ideas, comparisons to previous/other works, incremental improvements and revisions, etc. For these interactions, communication is an intrinsic factor. This means giving a voice to CC systems and enabling two- way communication channels between them and their users so that they can: explain their processes and decisions, support their ideas so that these are given serious consideration by their creative collaborators, and learn from these discussions to further improve their creative processes. For this, we propose a set of design principles for CC systems that aim at supporting greater co-creation and collaboration with their human collaborators."
Graph Fourier transform based on singular value decomposition ofdirected Laplacian,"YangChen, ChengCheng, Qiyu Sun",12 May 2022,Signal Processing (eess.SP)," Graph Fourier transform (GFT) is a fundamental concept in graph signal processing. In this paper, based on singular value decomposition of Laplacian, we introduce a novel definition of GFT on directed graphs, and use singular values of Laplacian to carry the notion of graph frequencies. % of the proposed GFT. The proposed GFT is consistent with the conventional GFT in the undirected graph setting, and on directed circulant graphs, the proposed GFT is the classical discrete Fourier transform, up to some rotation, permutation and phase adjustment. We show that frequencies and frequency components of the proposed GFT can be evaluated by solving some constrained minimization problems with low computational cost. Numerical demonstrations indicate that the proposed GFT could represent graph signals with different modes of variation efficiently."
"The Experimental Multi-Arm Pendulum on a Cart: A Benchmark System forChaos, Learning, and Control","KadierdanKaheman, UrbanFasel, Jason J.Bramburger, BenjaminStrom, J.NathanKutz, Steven L.Brunton",12 May 2022,Chaotic Dynamics (nlin.CD)," The single, double, and triple pendulum has served as an illustrative experimental benchmark system for scientists to study dynamical behavior for more than four centuries. The pendulum system exhibits a wide range of interesting behaviors, from simple harmonic motion in the single pendulum to chaotic dynamics in multi-arm pendulums. Under forcing, even the single pendulum may exhibit chaos, providing a simple example of a damped- driven system. All multi-armed pendulums are characterized by the existence of index-one saddle points, which mediate the transport of trajectories in the system, providing a simple mechanical analog of various complex transport phenomena, from biolocomotion to transport within the solar system. Further, pendulum systems have long been used to design and test both linear and nonlinear control strategies, with the addition of more arms making the problem more challenging. In this work, we provide extensive designs for the construction and operation of a high-performance, multi-link pendulum on a cart system. Although many experimental setups have been built to study the behavior of pendulum systems, such an extensive documentation on the design, construction, and operation is missing from the literature. The resulting experimental system is highly flexible, enabling a wide range of benchmark problems in dynamical systems modeling, system identification and learning, and control. To promote reproducible research, we have made our entire system open-source, including 3D CAD drawings, basic tutorial code, and data. Moreover, we discuss the possibility of extending our system capability to be operated remotely to enable researchers all around the world to use it, thus increasing access."
High frequency tunable grounded and floating incremental/ decrementalmeminductor emulator and its application as Amplitude Modulator,"PratikKumar, Sajal K.Paul",12 May 2022,Signal Processing (eess.SP)," In this paper, a new design has been proposed for the realization of grounded and floating meminductor emulators built with two OTAs and two second-generation current conveyors. The proposed emulators can be configured in both incremental and decremental topology. This paper also proposes the application of meminductor as Amplitude Modulator (AM). The proposed circuits and its application claim that the circuit is much simpler in design and can be utilized in both topologies. The performance of all the proposed circuits has been verified with Cadence Virtuoso Spectre on CMOS 180 nm. Furthermore, post-layout simulations and its comparison along with non-ideal and Monte Carlo analysis have been carried out in detail."
Exploiting symmetry in variational quantum machine learning,"Johannes Jakob Meyer, MarianMularski, Elies Gil-Fuster, Antonio Anna Mele, FrancescoArzani, AlissaWilms, Jens Eisert",12 May 2022,Quantum Physics (quant-ph)," Variational quantum machine learning is an extensively studied application of near-term quantum computers. The success of variational quantum learning models crucially depends on finding a suitable parametrization of the model that encodes an inductive bias relevant to the learning task. However, precious little is known about guiding principles for the construction of suitable parametrizations. In this work, we holistically explore when and how symmetries of the learning problem can be exploited to construct quantum learning models with outcomes invariant under the symmetry of the learning task. Building on tools from representation theory, we show how a standard gateset can be transformed into an equivariant gateset that respects the symmetries of the problem at hand through a process of gate symmetrization. We benchmark the proposed methods on two toy problems that feature a non-trivial symmetry and observe a substantial increase in generalization performance. As our tools can also be applied in a straightforward way to other variational problems with symmetric structure, we show how equivariant gatesets can be used in variational quantum eigensolvers."
MIMO Input-Output Linearization with Applications for LongitudinalFlight Dynamics,"Jhon Manuel PortellaDelgado, Ankit Goel",12 May 2022,Optimization and Control (math.OC)," This paper presents an extension of the input-output linearization method for nonsquare systems with more outputs than inputs. Unlike the square systems and nonsquare systems with fewer outputs than inputs, which can be completely linearized, we consider the problem of linearizing nonsquare systems with more outputs than inputs. In particular, the system is linearized by decomposing the state using a diffeomorphism, which is chosen such that the output of the system is a linear combination of the outputs of integrator chains, and the input of the system is chosen to cancel the nonlinearities using feedback linearization. In the case of nonsquare systems with more outputs than inputs, we observe that the resulting linear system can be stabilized even though it is uncontrollable at all times. This apparent contradiction is due to the switching behavior in the control action. We apply the input-output linearization method to linearize the longitudinal aircraft dynamics and demonstrate asymptotic stability of the closed-loop system despite the switching behavior."
Line Search-Free Methods for Higher-Order Smooth Monotone VariationalInequalities,"DeekshaAdil, BrianBullins, ArunJambulapati, SushantSachdeva",12 May 2022,Optimization and Control (math.OC)," Recent work by Jiang and Mokhtari [2022] has presented $p^{th}$-order methods for solving higher-order smooth monotone variational inequalities which establish a rate of $O(\epsilon^{-2/(p+1)})$. A drawback to their approach, however, is the reliance on a line search scheme when solving a particular set of subproblems. In this note, we provide a simple $p^{th}$-order method that achieves the same $O(\epsilon^{-2/(p+1)})$ rate without depending on any line search routine."
Neural Network-based OFDM Receiver for Resource Constrained IoTDevices,"NasimSoltani, Hai Cheng, MauroBelgiovine, Yanyu Li, Haoqing Li, BaharAzari, SalvatoreD'Oro, TalesImbiriba, TommasoMelodia, PauClosas, YanzhiWang, DenizErdogmus, KaushikChowdhury",12 May 2022,Signal Processing (eess.SP)," Orthogonal Frequency Division Multiplexing (OFDM)-based waveforms are used for communication links in many current and emerging Internet of Things (IoT) applications, including the latest WiFi standards. For such OFDM-based transceivers, many core physical layer functions related to channel estimation, demapping, and decoding are implemented for specific choices of channel types and modulation schemes, among others. To decouple hard-wired choices from the receiver chain and thereby enhance the flexibility of IoT deployment in many novel scenarios without changing the underlying hardware, we explore a novel, modular Machine Learning (ML)-based receiver chain design. Here, ML blocks replace the individual processing blocks of an OFDM receiver, and we specifically describe this swapping for the legacy channel estimation, symbol demapping, and decoding blocks with Neural Networks (NNs). A unique aspect of this modular design is providing flexible allocation of processing functions to the legacy or ML blocks, allowing them to interchangeably coexist. Furthermore, we study the implementation cost-benefits of the proposed NNs in resource-constrained IoT devices through pruning and quantization, as well as emulation of these compressed NNs within Field Programmable Gate Arrays (FPGAs). Our evaluations demonstrate that the proposed modular NN-based receiver improves bit error rate of the traditional non-ML receiver by averagely 61% and 10% for the simulated and over-the-air datasets, respectively. We further show complexity-performance tradeoffs by presenting computational complexity comparisons between the traditional algorithms and the proposed compressed NNs."
Training Strategies for Own Voice Reconstruction in Hearing ProtectionDevices using an In-ear Microphone,"MattesOhlenbusch, ChristianRollwage, SimonDoclo",12 May 2022,Audio and Speech Processing (eess.AS)," In-ear microphones in hearing protection devices can be utilized to capture the own voice speech of the person wearing the devices in noisy environments. Since in-ear recordings of the own voice are typically band- limited, an own voice reconstruction system is required to recover clean broadband speech from the in-ear signals. However, the availability of speech data for this scenario is typically limited due to device-specific transfer characteristics and the need to collect data from in-situ measurements. In this paper, we apply a deep learning-based bandwidth- extension system to the own voice reconstruction task and investigate different training strategies in order to overcome the limited availability of training data. Experimental results indicate that the use of simulated training data based on recordings of several talkers in combination with a fine-tuning approach using real data is advantageous compared to directly training on a small real dataset."
Framework for inferring empirical causal graphs from binary data tosupport multidimensional poverty analysis,"ChainarongAmornbunchornvej, NavapornSurasvadi, AnonPlangprasopchok, SuttipongThajchayapong",12 May 2022,Methodology (stat.ME)," Poverty is one of the fundamental issues that mankind faces. Multidimensional Poverty Index (MPI) is deployed for measuring poverty issues in a population beyond monetary. However, MPI cannot provide information regarding associations and causal relations among poverty factors. Does education cause income inequality in a specific region? Is lacking education a cause of health issues? By not knowing causal relations, policy maker cannot pinpoint root causes of poverty issues of a specific population, which might not be the same across different population. Additionally, MPI requires binary data, which cannot be analyzed by most of causal inference frameworks. In this work, we proposed an exploratory-data- analysis framework for finding possible causal relations with confidence intervals among binary data. The proposed framework provides not only how severe the issue of poverty is, but it also provides the causal relations among poverty factors. Moreover, knowing a confidence interval of degree of causal direction lets us know how strong a causal relation is.   We evaluated the proposed framework with several baseline approaches in simulation datasets as well as using two real-world datasets as case studies 1) Twin births of the United States: the relation between birth weight and mortality of twin, and 2) Thailand population surveys from 378k households of Chiang Mai and 353k households of Khon Kaen provinces. Our framework performed better than baselines in most cases. The first case study reveals almost all mortality cases in twins have issues of low birth weights but not all low-birth-weight twins were died. The second case study reveals that smoking associates with drinking alcohol in both provinces and there is a causal relation of smoking causes drinking alcohol in only Chiang Mai province. The framework can be applied beyond the poverty context."
Addressing Census data problems in race imputation via fully BayesianImproved Surname Geocoding and name supplements,"KosukeImai, SantiagoOlivella, Evan T. R.Rosenman",12 May 2022,Machine Learning (stat.ML)," Prediction of an individual's race and ethnicity plays an important role in social science and public health research. Examples include studies of racial disparity in health and voting. Recently, Bayesian Improved Surname Geocoding (BISG), which uses Bayes' rule to combine information from Census surname files with the geocoding of an individual's residence, has emerged as a leading methodology for this prediction task. Unfortunately, BISG suffers from two Census data problems that contribute to unsatisfactory predictive performance for minorities. First, the decennial Census often contains zero counts for minority racial groups in the Census blocks where some members of those groups reside. Second, because the Census surname files only include frequent names, many surnames -- especially those of minorities -- are missing from the list. To address the zero counts problem, we introduce a fully Bayesian Improved Surname Geocoding (fBISG) methodology that accounts for potential measurement error in Census counts by extending the naïve Bayesian inference of the BISG methodology to full posterior inference. To address the missing surname problem, we supplement the Census surname data with additional data on last, first, and middle names taken from the voter files of six Southern states where self-reported race is available. Our empirical validation shows that the fBISG methodology and name supplements significantly improve the accuracy of race imputation across all racial groups, and especially for Asians. The proposed methodology, together with additional name data, is available via the open- source software package wru."
Stabilizer Inactivation for Message-Passing Decoding of Quantum LDPCCodes,"Julien du Crest, MehdiMhalla, ValentinSavin",12 May 2022,Quantum Physics (quant-ph)," We propose a post-processing method for message-passing (MP) decoding of CSS quantum LDPC codes, called stabilizer-inactivation (SI). It relies on inactivating a set of qubits, supporting a check in the dual code, and then running the MP decoding again. This allows MP decoding to converge outside the inactivated set of qubits, while the error on these is determined by solving a small, constant size, linear system. Compared to the state of the art post-processing method based on ordered statistics decoding (OSD), we show through numerical simulations that MP-SI outperforms MP-OSD for different quantum LDPC code constructions, different MP decoding algorithms, and different MP scheduling strategies, while having a significantly reduced complexity."
Equivariant quantum circuits for learning on weighted graphs,"Andrea Skolik, MicheleCattelan, SheirYarkoni, ThomasBäck, VedranDunjko",12 May 2022,Quantum Physics (quant-ph)," Variational quantum algorithms are the leading candidate for near- term advantage on noisy quantum hardware. When training a parametrized quantum circuit to solve a specific task, the choice of ansatz is one of the most important factors that determines the trainability and performance of the algorithm. Problem-tailored ansatzes have become the standard for tasks in optimization or quantum chemistry, and yield more efficient algorithms with better performance than unstructured approaches. In quantum machine learning (QML), however, the literature on ansatzes that are motivated by the training data structure is scarce. Considering that it is widely known that unstructured ansatzes can become untrainable with increasing system size and circuit depth, it is of key importance to also study problem- tailored circuit architectures in a QML context. In this work, we introduce an ansatz for learning tasks on weighted graphs that respects an important graph symmetry, namely equivariance under node permutations. We evaluate the performance of this ansatz on a complex learning task on weighted graphs, where a ML model is used to implement a heuristic for a combinatorial optimization problem. We analytically study the expressivity of our ansatz at depth one, and numerically compare the performance of our model on instances with up to 20 qubits to ansatzes where the equivariance property is gradually broken. We show that our ansatz outperforms all others even in the small-instance regime. Our results strengthen the notion that symmetry- preserving ansatzes are a key to success in QML and should be an active area of research in order to enable near-term advantages in this field."
Social learning via actions in bandit environments,AroonNarayanan,12 May 2022,Theoretical Economics (econ.TH)," I study a game of strategic exploration with private payoffs and public actions in a Bayesian bandit setting. In particular, I look at cascade equilibria, in which agents switch over time from the risky action to the riskless action only when they become sufficiently pessimistic. I show that these equilibria exist under some conditions and establish their salient properties. Individual exploration in these equilibria can be more or less than the single-agent level depending on whether the agents start out with a common prior or not, but the most optimistic agent always underexplores. I also show that allowing the agents to write enforceable ex- ante contracts will lead to the most ex-ante optimistic agent to buy all payoff streams, providing an explanation to the buying out of smaller start- ups by more established firms."
Faster quantum mixing of Markov chains in non-regular graph with fewerqubits,"Xinyin Li, YunShang",12 May 2022,Quantum Physics (quant-ph)," Sampling from the stationary distribution is one of the fundamental tasks of Markov chain-based algorithms and has important applications in machine learning, combinatorial optimization and network science. For the quantum case, qsampling from Markov chains can be constructed as preparing quantum states with amplitudes arbitrarily close to the square root of a stationary distribution instead of classical sampling from a stationary distribution. In this paper, a new qsampling algorithm for all reversible Markov chains is constructed by discrete-time quantum walks and works without any limit compared with existing results. In detail, we build a qsampling algorithm that not only accelerates non-regular graphs but also keeps the speed-up of existing quantum algorithms for regular graphs. In non-regular graphs, the invocation of the quantum fast-forward algorithm accelerates existing state-of-the-art qsampling algorithms for both discrete-time and continuous-time cases, especially on sparse graphs. Compared to existing algorithms we reduce log n, where n is the number of graph vertices. In regular graphs, our result matches other quantum algorithms, and our reliance on the gap of Markov chains achieves quadratic speedup compared with classical cases. For both cases, we reduce the number of ancilla qubits required compared to the existing results. In some widely used graphs and a series of sparse graphs where stationary distributions are difficult to reach quickly, our algorithm is the first algorithm to achieve complete quadratic acceleration (without log factor) over the classical case without any limit. To enlarge success probability amplitude amplification is introduced. We construct a new reflection on stationary state with fewer ancilla qubits and think it may have independent application."
NeuralTree: A 256-Channel 0.227μJ/class Versatile Neural ActivityClassification and Closed-Loop Neuromodulation SoC,"UisubShin, CongDing, BingzhaoZhu, YashwanthVyza, AlixTrouillet, Emilie C. M.Revol, Stéphanie P.Lacour, MahsaShoaran",12 May 2022,Signal Processing (eess.SP)," Closed-loop neural interfaces with on-chip machine learning can detect and suppress disease symptoms in neurological disorders or restore lost functions in paralyzed patients. While high-density neural recording can provide rich neural activity information for accurate disease-state detection, existing systems have low channel count and poor scalability, which could limit their therapeutic efficacy. This work presents a highly scalable and versatile closed-loop neural interface SoC that can overcome these limitations. A 256-channel time-division multiplexed (TDM) front-end with a two-step fast-settling mixed-signal DC servo loop (DSL) is proposed to record high-spatial-resolution neural activity and perform channel- selective brain-state inference. A tree-structured neural network (NeuralTree) classification processor extracts a rich set of neural biomarkers in a patient- and disease-specific manner. Trained with an energy-aware learning algorithm, the NeuralTree classifier detects the symptoms of underlying disorders at an optimal energy-accuracy trade-off. A 16-channel high-voltage (HV) compliant neurostimulator closes the therapeutic loop by delivering charge-balanced biphasic current pulses to the brain. The proposed SoC was fabricated in 65nm CMOS and achieved a 0.227{\mu}J/class energy efficiency in a compact area of 0.014mm\textsuperscript{2}/channel. The SoC was extensively verified on human electroencephalography (EEG) and intracranial EEG (iEEG) epilepsy datasets, obtaining 95.6\%/94\% sensitivity and 96.8\%/96.9\% specificity, respectively. \emph{In-vivo} neural recordings using soft {\mu}ECoG arrays and multi-domain biomarker extraction were further performed on a rat model of epilepsy. In addition, for the first time in literature, on-chip classification of rest-state tremor in Parkinson's disease from human local field potentials (LFPs) was demonstrated."
On the Lambek embedding and the category of product-preservingpresheaves,"PengFu, KoheiKishida, Neil J.Ross, PeterSelinger",12 May 2022,Category Theory (math.CT)," It is well-known that the category of presheaf functors is complete and cocomplete, and that the Yoneda embedding into the presheaf category preserves products. However, the Yoneda embedding does not preserve coproducts. It is perhaps less well-known that if we restrict the codomain of the Yoneda embedding to the full subcategory of limit-preserving functors, then this embedding preserves colimits, while still enjoying most of the other useful properties of the Yoneda embedding. We call this modified embedding the Lambek embedding. The category of limit-preserving functors is known to be a reflective subcategory of the category of all functors, i.e., there is a left adjoint for the inclusion functor. In the literature, the existence of this left adjoint is often proved non- constructively, e.g., by an application of Freyd's adjoint functor theorem. In this paper, we provide an alternative, more constructive proof of this fact. We first explain the Lambek embedding and why it preserves coproducts. Then we review some concepts from multi-sorted algebras and observe that there is a one-to-one correspondence between product-preserving presheaves and certain multi-sorted term algebras. We provide a construction that freely turns any presheaf functor into a product-preserving one, hence giving an explicit definition of the left adjoint functor of the inclusion. Finally, we sketch how to extend our method to prove that the subcategory of limit-preserving functors is also reflective."
An improved KTNS algorithm for the job sequencing and tool switchingproblem,"MikhailCherniavskii, BorisGoldengorin",12 May 2022,Optimization and Control (math.OC), We outline a new Max Pipe Construction Algorithm (MPCA) with the purpose to reduce the CPU time for the classic Keep Tool Needed Soonest (KTNS) algorithm. The KTNS algorithm is applied to compute the objective function value for the given sequence of jobs in all exact and approximating algorithms for solving the Job Sequencing and Tool Switching Problem (SSP). Our MPCA outperforms the KTNS algorithm by at least an order of magnitude in terms of CPU times. Since all exact and heuristic algorithms for solving the SSP spend most of their CPU time on applying the KTNS algorithm we show that our MPCA solves the entire SSP on average 59 times faster for benchmark instances of D compared to current state of the art heuristics.
Information flow estimation: a study of news on Twitter,"TobinSouth, BridgetSmart, MatthewRoughan, LewisMitchell",12 May 2022,Physics and Society (physics.soc-ph)," News media has long been an ecosystem of creation, reproduction, and critique, where news outlets report on current events and add commentary to ongoing stories. Understanding the dynamics of news information creation and dispersion is important to accurately ascribe credit to influential work and understand how societal narratives develop. These dynamics can be modelled through a combination of information-theoretic natural language processing and networks; and can be parameterised using large quantities of textual data. However, it is challenging to see ""the wood for the trees"", i.e., to detect small but important flows of information in a sea of noise. Here we develop new comparative techniques to estimate temporal information flow between pairs of text producers. Using both simulated and real text data we compare the reliability and sensitivity of methods for estimating textual information flow, showing that a metric that normalises by local neighbourhood structure provides a robust estimate of information flow in large networks. We apply this metric to a large corpus of news organisations on Twitter and demonstrate its usefulness in identifying influence within an information ecosystem, finding that average information contribution to the network is not correlated with the number of followers or the number of tweets. This suggests that small local organisations and right-wing organisations which have lower average follower counts still contribute significant information to the ecosystem. Further, the methods are applied to smaller full-text datasets of specific news events across news sites and Russian troll bots on Twitter. The information flow estimation reveals and quantifies features of how these events develop and the role of groups of bots in setting disinformation narratives."
Low-variance estimation in the Plackett-Luce model via quasi-MonteCarlo sampling,"AlexanderBuchholz, Jan MalteLichtenberg, Giuseppe DiBenedetto, YannikStein, VitoBellini, MatteoRuffini",12 May 2022,Machine Learning (stat.ML)," The Plackett-Luce (PL) model is ubiquitous in learning-to-rank (LTR) because it provides a useful and intuitive probabilistic model for sampling ranked lists. Counterfactual offline evaluation and optimization of ranking metrics are pivotal for using LTR methods in production. When adopting the PL model as a ranking policy, both tasks require the computation of expectations with respect to the model. These are usually approximated via Monte-Carlo (MC) sampling, since the combinatorial scaling in the number of items to be ranked makes their analytical computation intractable. Despite recent advances in improving the computational efficiency of the sampling process via the Gumbel top-k trick, the MC estimates can suffer from high variance. We develop a novel approach to producing more sample-efficient estimators of expectations in the PL model by combining the Gumbel top-k trick with quasi-Monte Carlo (QMC) sampling, a well-established technique for variance reduction. We illustrate our findings both theoretically and empirically using real-world recommendation data from Amazon Music and the Yahoo learning-to-rank challenge."
Modelling the dynamics of cross-border ideological competition,Jose Segovia-Martin,12 May 2022,Physics and Society (physics.soc-ph)," Individuals are increasingly exposed to news and opinion from beyond national borders in a world that is becoming more and more globalised. This news and opinion is often concentrated in clusters of ideological homophily such as political parties, factions or interest groups. But how does exposure to cross-border information affect the diffusion of ideas across national and ideological borders? Here we develop a non-linear mathematical model for the cross-border spread of two ideologies by using an epidemiological approach. The populations of each country are assumed to be a constant and homogeneously mixed. We solve the system of differential equations numerically and show how small changes in the influence of a minority ideology can trigger shifts in the global political equilibrium."
On the influence of the geometry on skin effect in electromagnetism,"GabrielCaloz, MoniqueDauge, Erwan Faou, VictorPéron",12 May 2022,Analysis of PDEs (math.AP)," We consider the equations of electromagnetism set on a domain made of a dielectric and a conductor subdomain in a regime where the conductivity is large. Assuming smoothness for the dielectric--conductor interface, relying on recent works we prove that the solution of the Maxwell equations admits a multiscale asymptotic expansion with profile terms rapidly decaying inside the conductor. This skin effect is measured by introducing a skin depth function that turns out to depend on the mean curvature of the boundary of the conductor. We then confirm these asymptotic results by numerical experiments in various axisymmetric configurations. We also investigate numerically the case of a nonsmooth interface, namely a cylindrical conductor."
Controlling chaotic itinerancy in laser dynamics for reinforcementlearning,"RyugoIwami, TakatomoMihana, KazutakaKanno, SatoshiSunada, MakotoNaruse, AtsushiUchida",12 May 2022,Optics (physics.optics)," Photonic artificial intelligence has attracted considerable interest in accelerating machine learning; however, the unique optical properties have not been fully utilized for achieving higher-order functionalities. Chaotic itinerancy, with its spontaneous transient dynamics among multiple quasi-attractors, can be employed to realize brain-like functionalities. In this paper, we propose a method for controlling the chaotic itinerancy in a multi-mode semiconductor laser to solve a machine learning task, known as the multi-armed bandit problem, which is fundamental to reinforcement learning. The proposed method utilizes ultrafast chaotic itinerant motion in mode competition dynamics controlled via optical injection. We found that the exploration mechanism is completely different from a conventional searching algorithm and is highly scalable, outperforming the conventional approaches for large-scale bandit problems. This study paves the way to utilize chaotic itinerancy for effectively solving complex machine learning tasks as photonic hardware accelerators."
Automated Audio Captioning: an Overview of Recent Progress and NewChallenges,"XinhaoMei, XuboLiu, Mark D.Plumbley, Wenwu Wang",12 May 2022,Audio and Speech Processing (eess.AS)," Automated audio captioning is a cross-modal translation task that aims to generate natural language descriptions for given audio clips. This task has received increasing attention with the release of freely available datasets in recent years. The problem has been addressed predominantly with deep learning techniques. Numerous approaches have been proposed, such as investigating different neural network architectures, exploiting auxiliary information such as keywords or sentence information to guide caption generation, and employing different training strategies, which have greatly facilitated the development of this field. In this paper, we present a comprehensive review of the published contributions in automated audio captioning, from a variety of existing approaches to evaluation metrics and datasets. Moreover, we discuss open challenges and envisage possible future research directions."
Virtual twins of nonlinear vibrating multiphysics microstructures:physics-based versus deep learning-based approaches,"GiorgioGobat, StefaniaFresca, AndreaManzoni, AttilioFrangi",12 May 2022,Dynamical Systems (math.DS)," Micro-Electro-Mechanical-Systems are complex structures, often involving nonlinearites of geometric and multiphysics nature, that are used as sensors and actuators in countless applications. Starting from full-order representations, we apply deep learning techniques to generate accurate, efficient and real-time reduced order models to be used as virtual twin for the simulation and optimization of higher-level complex systems. We extensively test the reliability of the proposed procedures on micromirrors, arches and gyroscopes, also displaying intricate dynamical evolutions like internal resonances. In particular, we discuss the accuracy of the deep learning technique and its ability to replicate and converge to the invariant manifolds predicted using the recently developed direct parametrization approach that allows extracting the nonlinear normal modes of large finite element models. Finally, by addressing an electromechanical gyroscope, we show that the non-intrusive deep learning approach generalizes easily to complex multiphysics problems"
"Comments on: ""Hybrid Semiparametric Bayesian Networks""",MarcoScutari,12 May 2022,Methodology (stat.ME)," Invited discussion on the paper ""Hybrid Semiparametric Bayesian Networks"" by David Atienza, Pedro Larranaga and Concha Bielza (TEST, 2022)."
Pseudo-Label Guided Multi-Contrast Generalization for Non-ContrastOrgan-Aware Segmentation,"Ho HinLee, YuchengTang, Riqiang Gao, Qi Yang, Xin Yu, ShunxingBao, JamesG. Terry, J. JeffreyCarr, Yuankai Huo, Bennett A.Landman",12 May 2022,Image and Video Processing (eess.IV)," Non-contrast computed tomography (NCCT) is commonly acquired for lung cancer screening, assessment of general abdominal pain or suspected renal stones, trauma evaluation, and many other indications. However, the absence of contrast limits distinguishing organ in-between boundaries. In this paper, we propose a novel unsupervised approach that leverages pairwise contrast-enhanced CT (CECT) context to compute non-contrast segmentation without ground-truth label. Unlike generative adversarial approaches, we compute the pairwise morphological context with CECT to provide teacher guidance instead of generating fake anatomical context. Additionally, we further augment the intensity correlations in 'organ-specific' settings and increase the sensitivity to organ-aware boundary. We validate our approach on multi-organ segmentation with paired non-contrast & contrast-enhanced CT scans using five-fold cross-validation. Full external validations are performed on an independent non-contrast cohort for aorta segmentation. Compared with current abdominal organs segmentation state-of-the-art in fully supervised setting, our proposed pipeline achieves a significantly higher Dice by 3.98% (internal multi-organ annotated), and 8.00% (external aorta annotated) for abdominal organs segmentation. The code and pretrained models are publicly available at [this https URL](https://github.com/MASILab/ContrastMix)."
Training Uncertainty-Aware Classifiers with Conformalized DeepLearning,"Bat-ShevaEinbinder, YanivRomano, MatteoSesia, Yanfei Zhou",12 May 2022,Machine Learning (stat.ML)," Deep neural networks are powerful tools to detect hidden patterns in data and leverage them to make predictions, but they are not designed to understand uncertainty and estimate reliable probabilities. In particular, they tend to be overconfident. We address this problem by developing a novel training algorithm that can lead to more dependable uncertainty estimates, without sacrificing predictive power. The idea is to mitigate overconfidence by minimizing a loss function, inspired by advances in conformal inference, that quantifies model uncertainty by carefully leveraging hold-out data. Experiments with synthetic and real data demonstrate this method leads to smaller conformal prediction sets with higher conditional coverage, after exact calibration with hold-out data, compared to state-of-the-art alternatives."
AFFIRM: Affinity Fusion-based Framework for Iteratively Random Motioncorrection of multi-slice fetal brain MRI,"WenShi, HaoanXu, CongSun, JiweiSun, YaminLi, XinyiXu, TianshuZheng, YiZhang, GuangbinWang, DanWu",12 May 2022,Image and Video Processing (eess.IV)," Multi-slice magnetic resonance images of the fetal brain are usually contaminated by severe and arbitrary fetal and maternal motion. Hence, stable and robust motion correction is necessary to reconstruct high- resolution 3D fetal brain volume for clinical diagnosis and quantitative analysis. However, the conventional registration-based correction has a limited capture range and is insufficient for detecting relatively large motions. Here, we present a novel Affinity Fusion-based Framework for Iteratively Random Motion (AFFIRM) correction of the multi-slice fetal brain MRI. It learns the sequential motion from multiple stacks of slices and integrates the features between 2D slices and reconstructed 3D volume using affinity fusion, which resembles the iterations between slice-to-volume registration and volumetric reconstruction in the regular pipeline. The method accurately estimates the motion regardless of brain orientations and outperforms other state-of-the-art learning-based methods on the simulated motion-corrupted data, with a 48.4% reduction of mean absolute error for rotation and 61.3% for displacement. We then incorporated AFFIRM into the multi-resolution slice-to-volume registration and tested it on the real- world fetal MRI scans at different gestation stages. The results indicated that adding AFFIRM to the conventional pipeline improved the success rate of fetal brain super-resolution reconstruction from 77.2% to 91.9%."
A Survey of Risk-Aware Multi-Armed Bandits,"Vincent Y. F.Tan, PrashanthL.A., KrishnaJagannathan",12 May 2022,Machine Learning (stat.ML)," In several applications such as clinical trials and financial portfolio optimization, the expected value (or the average reward) does not satisfactorily capture the merits of a drug or a portfolio. In such applications, risk plays a crucial role, and a risk-aware performance measure is preferable, so as to capture losses in the case of adverse events. This survey aims to consolidate and summarise the existing research on risk measures, specifically in the context of multi-armed bandits. We review various risk measures of interest, and comment on their properties. Next, we review existing concentration inequalities for various risk measures. Then, we proceed to defining risk-aware bandit problems, We consider algorithms for the regret minimization setting, where the exploration-exploitation trade-off manifests, as well as the best-arm identification setting, which is a pure exploration problem -- both in the context of risk-sensitive measures. We conclude by commenting on persisting challenges and fertile areas for future research."
Leveraging Uncertainty for Deep Interpretable Classification andWeakly-Supervised Segmentation of Histology Images,"SoufianeBelharbi, JérômeRony, JoseDolz, Ismail BenAyed, LukeMcCaffrey, EricGranger",12 May 2022,Image and Video Processing (eess.IV)," Trained using only image class label, deep weakly supervised methods allow image classification and ROI segmentation for interpretability. Despite their success on natural images, they face several challenges over histology data where ROI are visually similar to background making models vulnerable to high pixel-wise false positives. These methods lack mechanisms for modeling explicitly non-discriminative regions which raises false-positive rates. We propose novel regularization terms, which enable the model to seek both non-discriminative and discriminative regions, while discouraging unbalanced segmentations and using only image class label. Our method is composed of two networks: a localizer that yields segmentation mask, followed by a classifier. The training loss pushes the localizer to build a segmentation mask that holds most discrimiantive regions while simultaneously modeling background regions. Comprehensive experiments over two histology datasets showed the merits of our method in reducing false positives and accurately segmenting ROI."
Cutting Quantum Circuits to Run on Quantum and Classical Platforms,"Wei Tang, MargaretMartonosi",12 May 2022,Quantum Physics (quant-ph)," Quantum computing (QC) offers a new computing paradigm that has the potential to provide significant speedups over classical computing. Each additional qubit doubles the size of the computational state space available to a quantum algorithm. Such exponentially expanding reach underlies QC's power, but at the same time puts demanding requirements on the quantum processing units (QPU) hardware. On the other hand, purely classical simulations of quantum circuits on either central processing unit (CPU) or graphics processing unit (GPU) scale poorly as they quickly become bottlenecked by runtime and memory. This paper introduces CutQC, a scalable hybrid computing approach that distributes a large quantum circuit onto quantum (QPU) and classical platforms (CPU or GPU) for co-processing. CutQC demonstrates evaluation of quantum circuits that are larger than the limit of QPU or classical simulation, and achieves much higher quantum circuit evaluation fidelity than the large NISQ devices achieve in real-system runs."
Assessment of an energy-based surface tension model for simulation oftwo-phase flows using second-order phase field methods,"ShahabMirjalili, Makrand AKhanwale, Ali Mani",12 May 2022,Fluid Dynamics (physics.flu-dyn)," Second-order phase field models have emerged as an attractive option for capturing the advection of interfaces in two-phase flows. Prior to these, the state of the art models based on the Cahn-Hilliard equation, which is a fourth order equation, allowed for derivation of surface tension models through thermodynamic arguments. In contrast, the second-order phase field models do not follow a known energy law, and deriving a surface tension term for these models using thermodynamic arguments is not straight- forward. In this work, we justify that the energy-based surface tension model from the Cahn-Hilliard context can be adopted for second-order phase field models as well, and assess its performance. We test the surface tension model on three different second-order phase field equations; the conservative diffuse interface model of Chiu and Lin [1], and two models based on the modified Allen-Cahn equation introduced by Sun and Beckermann [2]. Using canonical tests, we illustrate the lower magnitude of spurious currents, better accuracy, and superior convergence properties of the energy-based surface tension model compared to the continuum surface force (CSF) model, which is a popular choice that is used in conjunction with second order phase field methods. Importantly, in terms of computational expense and parallel efficiency, the energy-based model incurs no penalty compared to the CSF model."
Dimension-adaptive machine-learning-based quantum state reconstruction,"Sanjaya Lohani, SangitaRegmi, Joseph M. Lukens, Ryan T.Glasser, Thomas A.Searles, Brian T.Kirby",11 May 2022,Quantum Physics (quant-ph)," We introduce an approach for performing quantum state reconstruction on systems of $n$ qubits using a machine-learning-based reconstruction system trained exclusively on $m$ qubits, where $m\geq n$. This approach removes the necessity of exactly matching the dimensionality of a system under consideration with the dimension of a model used for training. We demonstrate our technique by performing quantum state reconstruction on randomly sampled systems of one, two, and three qubits using machine-learning-based methods trained exclusively on systems containing at least one additional qubit. The reconstruction time required for machine-learning-based methods scales significantly more favorably than the training time; hence this technique can offer an overall savings of resources by leveraging a single neural network for dimension-variable state reconstruction, obviating the need to train dedicated machine-learning systems for each Hilbert space."
Algebraic Machine Learning with an Application to Chemistry,"Ezzeddine ElSai, ParkerGara, Markus J.Pflaum",11 May 2022,Algebraic Geometry (math.AG)," As data used in scientific application become more complex, studying their geometry and topology has become an increasingly prevalent part of the data analysis process. This can be seen for example with the growing interest in topological tools such as persistent homology. However, on the one hand, topological tools are inherently limited to providing only coarse information about the underlying space of the data. On the other hand, more geometric approaches rely predominately on the manifold hypothesis, which asserts that the underlying space is a smooth manifold. This assumption fails for many physical models where the underlying space contains singularities.   In this paper we develop a machine learning pipeline that captures fine- grain geometric information without having to rely on any smoothness assumptions. Our approach involves working within the scope of algebraic geometry and algebraic varieties instead of differential geometry and smooth manifolds. In the setting of the variety hypothesis, the learning problem becomes to find the underlying variety using sample data. We cast this learning problem into a Maximum A Posteriori optimization problem which we solve in terms of an eigenvalue computation. Having found the underlying variety, we explore the use of Gröbner bases and numerical methods to reveal information about its geometry. In particular, we propose a heuristic for numerically detecting points lying near the singular locus of the underlying variety."
RITA: a Study on Scaling Up Generative Protein Sequence Models,"DanielHesslow, NiccolóZanichelli, PascalNotin, IacopoPoli, DeboraMarks",11 May 2022,Quantitative Methods (q-bio.QM)," In this work we introduce RITA: a suite of autoregressive generative models for protein sequences, with up to 1.2 billion parameters, trained on over 280 million protein sequences belonging to the UniRef-100 database. Such generative models hold the promise of greatly accelerating protein design. We conduct the first systematic study of how capabilities evolve with model size for autoregressive transformers in the protein domain: we evaluate RITA models in next amino acid prediction, zero-shot fitness, and enzyme function prediction, showing benefits from increased scale. We release the RITA models openly, to the benefit of the research community."
Real-Time Packet Loss Concealment With Mixed Generative and PredictiveModel,"Jean-MarcValin, AhmedMustafa, ChristopherMontgomery, Timothy B.Terriberry, MichaelKlingbeil, ParisSmaragdis, ArvindhKrishnaswamy",11 May 2022,Audio and Speech Processing (eess.AS)," As deep speech enhancement algorithms have recently demonstrated capabilities greatly surpassing their traditional counterparts for suppressing noise, reverberation and echo, attention is turning to the problem of packet loss concealment (PLC). PLC is a challenging task because it not only involves real-time speech synthesis, but also frequent transitions between the received audio and the synthesized concealment. We propose a hybrid neural PLC architecture where the missing speech is synthesized using a generative model conditioned using a predictive model. The resulting algorithm achieves natural concealment that surpasses the quality of existing conventional PLC algorithms and ranked second in the Interspeech 2022 PLC Challenge. We show that our solution not only works for uncompressed audio, but is also applicable to a modern speech codec."
VyZX : A Vision for Verifying the ZX Calculus,"Adrian Lehmann, BenCaldwell, RobertRand",11 May 2022,Quantum Physics (quant-ph)," Optimizing quantum circuits is a key challenge for quantum computing. The PyZX compiler broke new ground by optimizing circuits via the ZX calculus, a powerful graphical alternative to the quantum circuit model. Still, it carries no guarantee of its correctness. To address this, we developed VyZX, a verified ZX-calculus in the Coq proof assistant. VyZX provides two distinct representations of ZX diagrams for ease of programming and proof: A graph-based representation for writing high-level functions on diagrams and a block-based representation for proving ZX diagrams equivalent. Through these two different views, VyZX provides the tools necessary to verify properties and transformations of ZX diagrams. This paper explores the proofs and design choices underlying VyZX and its application and the challenges of verifying a graphical programming language."
CSI-based Indoor Localization via Attention-Augmented ResidualConvolutional Neural Network,"BowenZhang, HoussemSifaou, Geoffrey YeLi",11 May 2022,Signal Processing (eess.SP)," Deep learning has been widely adopted for channel state information (CSI)-fingerprinting indoor localization systems. These systems usually consist of two main parts, i.e., a positioning network that learns the mapping from high-dimensional CSI to physical locations and a tracking system that utilizes historical CSI to reduce the positioning error. This paper presents a new localization system with high accuracy and generality. On the one hand, the receptive field of the existing convolutional neural network (CNN)-based positioning networks is limited, restricting their performance as useful information in CSI is not explored thoroughly. As a solution, we propose a novel attention-augmented Residual CNN to utilize the local information and global context in CSI exhaustively. On the other hand, considering the generality of a tracking system, we decouple the tracking system from the CSI environments so that one tracking system for all environments becomes possible. Specifically, we remodel the tracking problem as a denoising task and solve it with deep trajectory prior. Furthermore, we investigate how the precision difference of inertial measurement units will adversely affect the tracking performance and adopt plug-and-play to solve the precision difference problem. Experiments show the superiority of our methods over existing approaches in performance and generality improvement."
Desarrollo del software de interfaz de usuario para el espectrógrafoastronómico COLORES instalado en el observatorio de la Mayora,Álvaro Montoro Martínez,10 May 2022,Instrumentation and Methods for Astrophysics (astro-ph.IM)," This thesis project arises from the need to put into operation the spectrograph (COLORES) of the station (BOOTES 2), located in La Mayora and belonging to the network of Burst Observer and Optical Transient Exploring System (BOOTES) telescopes. A robotic telescope such as the one located at BOOTES 2 has, among its many virtues, the ability to perform a multitude of observations with a very low reaction time. This makes it possible to obtain a large amount of data on the positioning and characterization of astronomical bodies. With this tool in operation, it will now be possible to extract a multitude of new parameters from the observations, providing this station with a more complete and versatile instrument with which to obtain more interesting scientific information.   For this task, a series of scripts will be performed. Specifically two, one for the calibration of the spectrograph and another one in charge of the image processing and the extraction of its spectrum. This will be carried out using Spyder software (Python), in which, in addition, numerous tests will be carried out to verify that the software works perfectly. Once these tests have been carried out, it will be implemented in the telescope's Web page for its use.   Several libraries will be used for this purpose, including Astropy, which includes a complete package for handling astronomical data in Python, and Matplotlib, which allows the use of graphics generated from data contained in arrays. In addition, several image acquisition techniques will be used, such as: filtering, Gaussian adjustment, and use of regions of interferences. With all this, the data extracted from the telescope will be optimized to achieve the desired results."
"De-biasing ""bias"" measurement","KristianLum, YunfengZhang, AmandaBower",11 May 2022,Methodology (stat.ME)," When a model's performance differs across socially or culturally relevant groups--like race, gender, or the intersections of many such groups --it is often called ""biased."" While much of the work in algorithmic fairness over the last several years has focused on developing various definitions of model fairness (the absence of group-wise model performance disparities) and eliminating such ""bias,"" much less work has gone into rigorously measuring it. In practice, it important to have high quality, human digestible measures of model performance disparities and associated uncertainty quantification about them that can serve as inputs into multi- faceted decision-making processes. In this paper, we show both mathematically and through simulation that many of the metrics used to measure group-wise model performance disparities are themselves statistically biased estimators of the underlying quantities they purport to represent. We argue that this can cause misleading conclusions about the relative group-wise model performance disparities along different dimensions, especially in cases where some sensitive variables consist of categories with few members. We propose the ""double-corrected"" variance estimator, which provides unbiased estimates and uncertainty quantification of the variance of model performance across groups. It is conceptually simple and easily implementable without statistical software package or numerical optimization. We demonstrate the utility of this approach through simulation and show on a real dataset that while statistically biased estimators of model group-wise model performance disparities indicate statistically significant between-group model performance disparities, when accounting for statistical bias in the estimator, the estimated group-wise disparities in model performance are no longer statistically significant."
"A time-varying study of Chinese investor sentiment, stock marketliquidity and volatility: Based on deep learning BERT model and TVP-VAR model","ChenruiZhang, Xinyi Wu, HailuDeng, HuiweiZhang",11 May 2022,Computational Finance (q-fin.CP)," Based on the commentary data of the Shenzhen Stock Index bar on the EastMoney website from January 1, 2018 to December 31, 2019. This paper extracts the embedded investor sentiment by using a deep learning BERT model and investigates the time-varying linkage between investment sentiment, stock market liquidity and volatility using a TVP-VAR model. The results show that the impact of investor sentiment on stock market liquidity and volatility is stronger. Although the inverse effect is relatively small, it is more pronounced with the state of the stock market. In all cases, the response is more pronounced in the short term than in the medium to long term, and the impact is asymmetric, with shocks stronger when the market is in a downward spiral."
Causal discovery under a confounder blanket,"DavidWatson, RicardoSilva",11 May 2022,Methodology (stat.ME)," Inferring causal relationships from observational data is rarely straightforward, but the problem is especially difficult in high dimensions. For these applications, causal discovery algorithms typically require parametric restrictions or extreme sparsity constraints. We relax these assumptions and focus on an important but more specialized problem, namely recovering a directed acyclic subgraph of variables known to be causally descended from some (possibly large) set of confounding covariates, i.e. a $\textit{confounder blanket}$. This is useful in many settings, for example when studying a dynamic biomolecular subsystem with genetic data providing causally relevant background information. Under a structural assumption that, we argue, must be satisfied in practice if informative answers are to be found, our method accommodates graphs of low or high sparsity while maintaining polynomial time complexity. We derive a sound and complete algorithm for identifying causal relationships under these conditions and implement testing procedures with provable error control for linear and nonlinear systems. We demonstrate our approach on a range of simulation settings."
Concise tensors of minimal border rank,"JoachimJelisiejew, J.M.Landsberg, Arpan Pal",11 May 2022,Algebraic Geometry (math.AG)," We determine defining equations for the set of concise tensors of minimal border rank in $C^m\otimes C^m\otimes C^m$ when $m=5$ and the set of concise minimal border rank $1_*$-generic tensors when $m=5,6$. We solve this classical problem in algebraic complexity theory with the aid of two recent developments: the 111-equations defined by Buczyńska-Buczyński and results of Jelisiejew-Šivic on the variety of commuting matrices. We introduce a new algebraic invariant of a concise tensor, its 111-algebra, and exploit it to give a strengthening of Friedland's normal form for $1$-degenerate tensors satisfying Strassen's equations. We use the 111-algebra to characterize wild minimal border rank tensors and classify them in $C^5\otimes C^5\otimes C^5$."
A Closer Look at Audio-Visual Multi-Person Speech Recognition andActive Speaker Selection,"OtavioBraga, OlivierSiohan",11 May 2022,Audio and Speech Processing (eess.AS)," Audio-visual automatic speech recognition is a promising approach to robust ASR under noisy conditions. However, up until recently it had been traditionally studied in isolation assuming the video of a single speaking face matches the audio, and selecting the active speaker at inference time when multiple people are on screen was put aside as a separate problem. As an alternative, recent work has proposed to address the two problems simultaneously with an attention mechanism, baking the speaker selection problem directly into a fully differentiable model. One interesting finding was that the attention indirectly learns the association between the audio and the speaking face even though this correspondence is never explicitly provided at training time. In the present work we further investigate this connection and examine the interplay between the two problems. With experiments involving over 50 thousand hours of public YouTube videos as training data, we first evaluate the accuracy of the attention layer on an active speaker selection task. Secondly, we show under closer scrutiny that an end-to-end model performs at least as well as a considerably larger two- step system that utilizes a hard decision boundary under various noise conditions and number of parallel face tracks."
Stabilizing a linear system using phone calls: when time isinformation,"Mohammad JavadKhojasteh, MassimoFranceschetti, GireejaRanade","1 Apr 2018 (v1(https://arxiv.org/abs/1804.00351v1)), lastrevised 12 May 2022 (this version, v4)",Systems and Control (eess.SY)," We consider the problem of stabilizing an undisturbed, scalar, linear system over a ""timing"" channel, namely a channel where information is communicated through the timestamps of the transmitted symbols. Each symbol transmitted from a sensor to a controller in a closed-loop system is received subject to some to random delay. The sensor can encode messages in the waiting times between successive transmissions and the controller must decode them from the inter-reception times of successive symbols. This set- up is analogous to a telephone system where a transmitter signals a phone call to a receiver through a ""ring"" and, after the random delay required to establish the connection; the receiver is aware of the ""ring"" being received. Since there is no data payload exchange between the sensor and the controller, this set-up provides an abstraction for performing event- triggering control with zero-payload rate. We show the following requirement for stabilization: for the state of the system to converge to zero in probability, the timing capacity of the channel should be, essentially, at least as large as the entropy rate of the system. Conversely, in the case the symbol delays are exponentially distributed, we show an ""almost"" tight sufficient condition using a coding strategy that refines the estimate of the decoded message every time a new symbol is received. Our results generalize previous zero-payload event-triggering control strategies, revealing a fundamental limit in using timing information for stabilization, independent of any transmission strategy."
RISP: Rendering-Invariant State Predictor with DifferentiableSimulation and Rendering for Cross-Domain Parameter Estimation,"PingchuanMa, TaoDu, Joshua B.Tenenbaum, WojciechMatusik, Chuang Gan",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," This work considers identifying parameters characterizing a physical system's dynamic motion directly from a video whose rendering configurations are inaccessible. Existing solutions require massive training data or lack generalizability to unknown rendering configurations. We propose a novel approach that marries domain randomization and differentiable rendering gradients to address this problem. Our core idea is to train a rendering-invariant state-prediction (RISP) network that transforms image differences into state differences independent of rendering configurations, e.g., lighting, shadows, or material reflectance. To train this predictor, we formulate a new loss on rendering variances using gradients from differentiable rendering. Moreover, we present an efficient, second-order method to compute the gradients of this loss, allowing it to be integrated seamlessly into modern deep learning frameworks. We evaluate our method in rigid-body and deformable-body simulation environments using four tasks: state estimation, system identification, imitation learning, and visuomotor control. We further demonstrate the efficacy of our approach on a real-world example: inferring the state and action sequences of a quadrotor from a video of its motion sequences. Compared with existing methods, our approach achieves significantly lower reconstruction errors and has better generalizability among unknown rendering configurations."
HULC: 3D Human Motion Capture with Pose Manifold Sampling and DenseContact Guidance,"SoshiShimada, VladislavGolyanik, PatrickPérez, Weipeng Xu, ChristianTheobalt",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Marker-less monocular 3D human motion capture (MoCap) with scene interactions is a challenging research topic relevant for extended reality, robotics and virtual avatar generation. Due to the inherent depth ambiguity of monocular settings, 3D motions captured with existing methods often contain severe artefacts such as incorrect body-scene inter-penetrations, jitter and body floating. To tackle these issues, we propose HULC, a new approach for 3D human MoCap which is aware of the scene geometry. HULC estimates 3D poses and dense body-environment surface contacts for improved 3D localisations, as well as the absolute scale of the subject. Furthermore, we introduce a 3D pose trajectory optimisation based on a novel pose manifold sampling that resolves erroneous body-environment inter- penetrations. Although the proposed method requires less structured inputs compared to existing scene-aware monocular MoCap algorithms, it produces more physically-plausible poses: HULC significantly and consistently outperforms the existing approaches in various experiments and on different metrics."
Revisiting Random Channel Pruning for Neural Network Compression,"YaweiLi, KamilAdamczewski, Wen Li, Shuhang Gu, RaduTimofte, Luc VanGool",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Channel (or 3D filter) pruning serves as an effective way to accelerate the inference of neural networks. There has been a flurry of algorithms that try to solve this practical problem, each being claimed effective in some ways. Yet, a benchmark to compare those algorithms directly is lacking, mainly due to the complexity of the algorithms and some custom settings such as the particular network configuration or training procedure. A fair benchmark is important for the further development of channel pruning.   Meanwhile, recent investigations reveal that the channel configurations discovered by pruning algorithms are at least as important as the pre- trained weights. This gives channel pruning a new role, namely searching the optimal channel configuration. In this paper, we try to determine the channel configuration of the pruned models by random search. The proposed approach provides a new way to compare different methods, namely how well they behave compared with random pruning. We show that this simple strategy works quite well compared with other channel pruning methods. We also show that under this setting, there are surprisingly no clear winners among different channel importance evaluation methods, which then may tilt the research efforts into advanced channel configuration searching methods."
NTIRE 2022 Challenge on Efficient Super-Resolution: Methods andResults,"YaweiLi, KaiZhang, RaduTimofte, Luc VanGool, FangyuanKong, MingxiLi, SongweiLiu, ZongcaiDu, DingLiu, ChenhuiZhou, JingyiChen, QingruiHan, ZheyuanLi, YingqiLiu, XiangyuChen, HaomingCai, YuQiao, ChaoDong, LongSun, JinshanPan, YiZhu, ZhikaiZong, Xiaoxiao Liu, Zheng Hui, Tao Yang, Peiran Ren, Xuansong Xie, Xian-ShengHua, YanboWang, Xiaozhong Ji, Chuming Lin, Donghao Luo, Ying Tai, ChengjieWang, ZhizhongZhang, YuanXie, ShenCheng, ZiweiLuo, LeiYu, ZhihongWen, QiWu1, YouweiLi, HaoqiangFan, JianSun, ShuaichengLiu, YuanfeiHuang, Meiguang Jin, Hua Huang, Jing Liu, XinjianZhang, YanWang, LingshunLong, GenLi, YuanfanZhang, Zuowei Cao, Lei Sun, PanaetovAlexander, Yucong Wang, Minjie Cai, Li Wang, LuTian, ZheyuanWang, Hongbing Ma, Jie Liu, ChaoChen, YidongCai, JieTang, Gangshan Wu, Weiran Wang, ShiruiHuang, Honglei Lu, Huan Liu, Keyan Wang, Jun Chen, Shi Chen, Yuchun Miao, Zimo Huang, Lefei Zhang, MustafaAyazoğlu, Wei Xiong, ChengyiXiong, FeiWang, HaoLi, RuimianWen, ZhijingYang, WenbinZou, WeixinZheng, TianYe, YunchengZhang, XiangzhenKong, AdityaArora, SyedWaqasZamir, Salman Khan, MunawarHayat, FahadShahbazKhan, Dandan Gaoand Dengwen Zhouand QianNing, Jingzhu Tang, Han Huang, Yufei Wang, ZhanghengPeng, Haobo Li, Wenxue Guan, ShenghuaGong, XinLi, JunLiu, WanjunWang, DengwenZhou, KunZeng, Hanjiang Lin, Xinyu Chen, Jinsheng Fang, et al. (javascript:toggleAuthorList\('long-author-list''et al. \ You must enableJavaScript to view entire author list.",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," This paper reviews the NTIRE 2022 challenge on efficient single image super-resolution with focus on the proposed solutions and results. The task of the challenge was to super-resolve an input image with a magnification factor of $\times$4 based on pairs of low and corresponding high resolution images. The aim was to design a network for single image super-resolution that achieved improvement of efficiency measured according to several metrics including runtime, parameters, FLOPs, activations, and memory consumption while at least maintaining the PSNR of 29.00dB on DIV2K validation set. IMDN is set as the baseline for efficiency measurement. The challenge had 3 tracks including the main track (runtime), sub-track one (model complexity), and sub-track two (overall performance). In the main track, the practical runtime performance of the submissions was evaluated. The rank of the teams were determined directly by the absolute value of the average runtime on the validation set and test set. In sub-track one, the number of parameters and FLOPs were considered. And the individual rankings of the two metrics were summed up to determine a final ranking in this track. In sub-track two, all of the five metrics mentioned in the description of the challenge including runtime, parameter count, FLOPs, activations, and memory consumption were considered. Similar to sub-track one, the rankings of five metrics were summed up to determine a final ranking. The challenge had 303 registered participants, and 43 teams made valid submissions. They gauge the state-of-the-art in efficient single image super-resolution."
RepSR: Training Efficient VGG-style Super-Resolution Networks withStructural Re-Parameterization and Batch Normalization,"XintaoWang, ChaoDong, YingShan",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," This paper explores training efficient VGG-style super-resolution (SR) networks with the structural re-parameterization technique. The general pipeline of re-parameterization is to train networks with multi-branch topology first, and then merge them into standard 3x3 convolutions for efficient inference. In this work, we revisit those primary designs and investigate essential components for re-parameterizing SR networks. First of all, we find that batch normalization (BN) is important to bring training non-linearity and improve the final performance. However, BN is typically ignored in SR, as it usually degrades the performance and introduces unpleasant artifacts. We carefully analyze the cause of BN issue and then propose a straightforward yet effective solution. In particular, we first train SR networks with mini-batch statistics as usual, and then switch to using population statistics at the later training period. While we have successfully re-introduced BN into SR, we further design a new re- parameterizable block tailored for SR, namely RepSR. It consists of a clean residual path and two expand-and-squeeze convolution paths with the modified BN. Extensive experiments demonstrate that our simple RepSR is capable of achieving superior performance to previous SR re-parameterization methods among different model sizes. In addition, our RepSR can achieve a better trade-off between performance and actual running time (throughput) than previous SR methods. Codes will be available at [this https URL](https://github.com/TencentARC/RepSR)."
Identifying concept libraries from language about object structure,"CatherineWong, WilliamP.McCarthy, GabrielGrand, YoniFriedman, Joshua B.Tenenbaum, JacobAndreas, Robert D.Hawkins, Judith E.Fan",11 May 2022,Computation and Language (cs.CL)," Our understanding of the visual world goes beyond naming objects, encompassing our ability to parse objects into meaningful parts, attributes, and relations. In this work, we leverage natural language descriptions for a diverse set of 2K procedurally generated objects to identify the parts people use and the principles leading these parts to be favored over others. We formalize our problem as search over a space of program libraries that contain different part concepts, using tools from machine translation to evaluate how well programs expressed in each library align to human language. By combining naturalistic language at scale with structured program representations, we discover a fundamental information-theoretic tradeoff governing the part concepts people name: people favor a lexicon that allows concise descriptions of each object, while also minimizing the size of the lexicon itself."
Theory and Implementation of Process and Temperature Scalable Shape-based CMOS Analog Circuits,"PratikKumar, AnkitaNandi, ShantanuChakrabartty, Chetan SinghThakur",11 May 2022,Hardware Architecture (cs.AR)," Analog computing is attractive to its digital counterparts due to its potential for achieving high compute density and energy efficiency. However, the device-to-device variability and challenges in porting existing designs to advance process nodes have posed a major hindrance in harnessing the full potential of analog computations for Machine Learning (ML) applications. This work proposes a novel analog computing framework for designing an analog ML processor similar to that of a digital design - where the designs can be scaled and ported to advanced process nodes without architectural changes. At the core of our work lies shape-based analog computing (S-AC). It utilizes device primitives to yield a robust proto- function through which other non-linear shapes can be derived. S-AC paradigm also allows the user to trade off computational precision with silicon circuit area and power. Thus allowing users to build a truly power-efficient and scalable analog architecture where the same synthesized analog circuit can operate across different biasing regimes of transistors and simultaneously scale across process nodes. As a proof of concept, we show the implementation of commonly used mathematical functions for carrying standard ML tasks in both planar CMOS 180nm and FinFET 7nm process nodes. The synthesized Shape-based ML architecture has been demonstrated for its classification accuracy on standard data sets at different process nodes."
Deep Architecture Connectivity Matters for Its Convergence: A Fine-Grained Analysis,"WuyangChen, WeiHuang, XinyuGong, BorisHanin, ZhangyangWang",11 May 2022,Machine Learning (cs.LG)," Advanced deep neural networks (DNNs), designed by either human or AutoML algorithms, are growing increasingly complex. Diverse operations are connected by complicated connectivity patterns, e.g., various types of skip connections. Those topological compositions are empirically effective and observed to smooth the loss landscape and facilitate the gradient flow in general. However, it remains elusive to derive any principled understanding of their effects on the DNN capacity or trainability, and to understand why or in which aspect one specific connectivity pattern is better than another. In this work, we theoretically characterize the impact of connectivity patterns on the convergence of DNNs under gradient descent training in fine granularity. By analyzing a wide network's Neural Network Gaussian Process (NNGP), we are able to depict how the spectrum of an NNGP kernel propagates through a particular connectivity pattern, and how that affects the bound of convergence rates. As one practical implication of our results, we show that by a simple filtration on ""unpromising"" connectivity patterns, we can trim down the number of models to evaluate, and significantly accelerate the large-scale neural architecture search without any overhead. Codes will be released at [this https URL](https://github.com/chenwydj/architecture_convergence)."
How Platform-User Power Relations Shape Algorithmic Accountability: ACase Study of Instant Loan Platforms and Financially Stressed Users in India,"DivyaRamesh, VaishnavKameswaran, Ding Wang, NithyaSambasivan",11 May 2022,Human-Computer Interaction (cs.HC)," Accountability, a requisite for responsible AI, can be facilitated through transparency mechanisms such as audits and explainability. However, prior work suggests that the success of these mechanisms may be limited to Global North contexts; understanding the limitations of current interventions in varied socio-political conditions is crucial to help policymakers facilitate wider accountability. To do so, we examined the mediation of accountability in the existing interactions between vulnerable users and a 'high-risk' AI system in a Global South setting. We report on a qualitative study with 29 financially-stressed users of instant loan platforms in India. We found that users experienced intense feelings of indebtedness for the 'boon' of instant loans, and perceived huge obligations towards loan platforms. Users fulfilled obligations by accepting harsh terms and conditions, over-sharing sensitive data, and paying high fees to unknown and unverified lenders. Users demonstrated a dependence on loan platforms by persisting with such behaviors despite risks of harms such as abuse, recurring debts, discrimination, privacy harms, and self-harm to them. Instead of being enraged with loan platforms, users assumed responsibility for their negative experiences, thus releasing the high-powered loan platforms from accountability obligations. We argue that accountability is shaped by platform-user power relations, and urge caution to policymakers in adopting a purely technical approach to fostering algorithmic accountability. Instead, we call for situated interventions that enhance agency of users, enable meaningful transparency, reconfigure designer-user relations, and prompt a critical reflection in practitioners towards wider accountability. We conclude with implications for responsibly deploying AI in FinTech applications in India and beyond."
Ranked Prioritization of Groups in Combinatorial Bandit Allocation,"LilyXu, ArpitaBiswas, FeiFang, MilindTambe",11 May 2022,Artificial Intelligence (cs.AI)," Preventing poaching through ranger patrols protects endangered wildlife, directly contributing to the UN Sustainable Development Goal 15 of life on land. Combinatorial bandits have been used to allocate limited patrol resources, but existing approaches overlook the fact that each location is home to multiple species in varying proportions, so a patrol benefits each species to differing degrees. When some species are more vulnerable, we ought to offer more protection to these animals; unfortunately, existing combinatorial bandit approaches do not offer a way to prioritize important species. To bridge this gap, (1) We propose a novel combinatorial bandit objective that trades off between reward maximization and also accounts for prioritization over species, which we call ranked prioritization. We show this objective can be expressed as a weighted linear sum of Lipschitz-continuous reward functions. (2) We provide RankedCUCB, an algorithm to select combinatorial actions that optimize our prioritization- based objective, and prove that it achieves asymptotic no-regret. (3) We demonstrate empirically that RankedCUCB leads to up to 38% improvement in outcomes for endangered species using real-world wildlife conservation data. Along with adapting to other challenges such as preventing illegal logging and overfishing, our no-regret algorithm addresses the general combinatorial bandit problem with a weighted linear objective."
Ontology-Based and Weakly Supervised Rare Disease Phenotyping fromClinical Notes,"HangDong, VíctorSuárez-Paniagua, HuayuZhang, Minhong Wang, ArleneCasey, EmmaDavidson, Jiaoyan Chen, BeatriceAlex, WilliamWhiteley, Honghan Wu",11 May 2022,Computation and Language (cs.CL)," Computational text phenotyping is the practice of identifying patients with certain disorders and traits from clinical notes. Rare diseases are challenging to be identified due to few cases available for machine learning and the need for data annotation from domain experts. We propose a method using ontologies and weak supervision, with recent pre- trained contextual representations from Bi-directional Transformers (e.g. BERT). The ontology-based framework includes two steps: (i) Text-to-UMLS, extracting phenotypes by contextually linking mentions to concepts in Unified Medical Language System (UMLS), with a Named Entity Recognition and Linking (NER+L) tool, SemEHR, and weak supervision with customised rules and contextual mention representation; (ii) UMLS-to-ORDO, matching UMLS concepts to rare diseases in Orphanet Rare Disease Ontology (ORDO). The weakly supervised approach is proposed to learn a phenotype confirmation model to improve Text-to-UMLS linking, without annotated data from domain experts. We evaluated the approach on three clinical datasets of discharge summaries and radiology reports from two institutions in the US and the UK. Our best weakly supervised method achieved 81.4% precision and 91.4% recall on extracting rare disease UMLS phenotypes from MIMIC-III discharge summaries. The overall pipeline processing clinical notes can surface rare disease cases, mostly uncaptured in structured data (manually assigned ICD codes). Results on radiology reports from MIMIC-III and NHS Tayside were consistent with the discharge summaries. We discuss the usefulness of the weak supervision approach and propose directions for future studies."
Any-k Algorithms for Enumerating Ranked Answers to Conjunctive Queries,"NikolaosTziavelis, WolfgangGatterbauer, MirekRiedewald",11 May 2022,Databases (cs.DB)," We study ranked enumeration for Conjunctive Queries (CQs) where the answers are ordered by a given ranking function (e.g., an ORDER BY clause in SQL). We develop ""any-k"" algorithms which, without knowing the number k of desired answers, push the ranking into joins and avoid materializing the join output earlier than necessary. For this to be possible, the ranking function needs to obey a certain kind of monotonicity; the supported ranking functions include the common sum-of-weights case where query answers are compared by sums of input weights, as well as any commutative selective dioid. One core insight of our work is that the problem is closely related to the fundamental task of path enumeration in a weighted DAG. We generalize and improve upon classic research on finding the k'th shortest path and unify into the same framework several solutions from different areas that had been studied in isolation. For the time to the k'th ranked CQ answer (for every value of k), our approach is optimal in data complexity precisely for the same class of queries where unranked enumeration is optimal -- and only slower by a logarithmic factor. In a more careful analysis of combined complexity, we uncover a previously unknown tradeoff between two different any-k algorithms: one has lower complexity when the number of returned results is small, the other when the number is very large. This tradeoff is eliminated under a stricter monotonicity property that we exploit to design a novel algorithm that asymptotically dominates all previously known alternatives, including the well-known algorithm of Eppstein for sum-of-weights path enumeration. We empirically demonstrate the findings of our theoretical analysis in an experimental study that highlights the superiority of our approach over the join-then- rank approach that existing database systems typically follow."
Aggregating Pairwise Semantic Differences for Few-Shot Claim VeracityClassification,"XiaZeng, ArkaitzZubiaga",11 May 2022,Computation and Language (cs.CL)," As part of an automated fact-checking pipeline, the claim veracity classification task consists in determining if a claim is supported by an associated piece of evidence. The complexity of gathering labelled claim- evidence pairs leads to a scarcity of datasets, particularly when dealing with new domains. In this paper, we introduce SEED, a novel vector-based method to few-shot claim veracity classification that aggregates pairwise semantic differences for claim-evidence pairs. We build on the hypothesis that we can simulate class representative vectors that capture average semantic differences for claim-evidence pairs in a class, which can then be used for classification of new instances. We compare the performance of our method with competitive baselines including fine-tuned BERT/RoBERTa models, as well as the state-of-the-art few-shot veracity classification method that leverages language model perplexity. Experiments conducted on the FEVER and SCIFACT datasets show consistent improvements over competitive baselines in few-shot settings. Our code is available."
A New Class of String Transformations for Compressed Text Indexing,"RaffaeleGiancarlo, GiovanniManzini, AntonioRestivo, GiovannaRosone, MarinellaSciortino",11 May 2022,Data Structures and Algorithms (cs.DS)," Introduced about thirty years ago in the field of Data Compression, the Burrows-Wheeler Transform (BWT) is a string transformation that, besides being a booster of the performance of memoryless compressors, plays a fundamental role in the design of efficient self-indexing compressed data structures. Finding other string transformations with the same remarkable properties of BWT has been a challenge for many researchers for a long time. Among the known BWT variants, the only one that has been recently shown to be a valid alternative to BWT is the Alternating BWT (ABWT), another invertible string transformation introduced about ten years ago in connection with a generalization of Lyndon words. In this paper, we introduce a whole class of new string transformations, called local orderings-based transformations, which have all the myriad virtues of BWT. We show that this new family is a special case of a much larger class of transformations, based on context adaptive alphabet orderings, that includes BWT and ABWT. Although all transformations support pattern search, we show that, in the general case, the transformations within our larger class may take quadratic time for inversion and pattern search. As a further result, we show that the local orderings-based transformations can be used for the construction of the recently introduced r-index, which makes them suitable also for highly repetitive collections. In this context, we consider the problem of finding, for a given string, the BWT variant that minimizes the number of runs in the transformed string, and we provide an algorithm solving this problem in linear time."
Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper thanIn-Context Learning,"HaokunLiu, DerekTam, MohammedMuqeeth, Jay Mohta, TenghaoHuang, MohitBansal, ColinRaffel",11 May 2022,Machine Learning (cs.LG)," Few-shot in-context learning (ICL) enables pre-trained language models to perform a previously-unseen task without any gradient-based training by feeding a small number of training examples as part of the input. ICL incurs substantial computational, memory, and storage costs because it involves processing all of the training examples every time a prediction is made. Parameter-efficient fine-tuning (e.g. adapter modules, prompt tuning, sparse update methods, etc.) offers an alternative paradigm where a small set of parameters are trained to enable a model to perform the new task. In this paper, we rigorously compare few-shot ICL and parameter- efficient fine-tuning and demonstrate that the latter offers better accuracy as well as dramatically lower computational costs. Along the way, we introduce a new parameter-efficient fine-tuning method called (IA)$^3$ that scales activations by learned vectors, attaining stronger performance while only introducing a relatively tiny amount of new parameters. We also propose a simple recipe based on the T0 model called T-Few that can be applied to new tasks without task-specific tuning or modifications. We validate the effectiveness of T-Few on completely unseen tasks by applying it to the RAFT benchmark, attaining super-human performance for the first time and outperforming the state-of-the-art by 6% absolute. All of the code used in our experiments is publicly available."
Second-Order Asymptotics of Hoeffding-Like Hypothesis Tests,"K. V.Harsha, Jithin Ravi, Tobias Koch",11 May 2022,Information Theory (cs.IT)," We consider a binary statistical hypothesis testing problem, where $n$ independent and identically distributed random variables $Z^n$ are either distributed according to the null hypothesis $P$ or the alternate hypothesis $Q$, and only $P$ is known. For this problem, a well-known test is the Hoeffding test, which accepts $P$ if the Kullback-Leibler (KL) divergence between the empirical distribution of $Z^n$ and $P$ is below some threshold. In this paper, we consider Hoeffding-like tests, where the KL divergence is replaced by other divergences, and characterize, for a large class of divergences, the first and second-order terms of the type-II error for a fixed type-I error. Since the considered class includes the KL divergence, we obtain the second-order term of the Hoeffiding test as a special case."
Benefits of Feedforward for Model Predictive Airpath Control of DieselEngines,"JiadiZhang, Mohammad RezaAmini, IlyaKolmanovsky, MunechikaTsutsumi, HayatoNakada",11 May 2022,Systems and Control (eess.SY)," This paper investigates options to complement a diesel engine airpath feedback controller with a feedforward. The control objective is to track the intake manifold pressure and exhaust gas recirculation (EGR) rate targets by manipulating the EGR valve and variable geometry turbine (VGT) while satisfying state and input constraints. The feedback controller is based on rate-based Model Predictive Control (MPC) that provides integral action for tracking. Two options for the feedforward are considered one based on a look-up table that specifies the feedforward as a function of engine speed and fuel injection rate, and another one based on a (non-rate- based) MPC that generates dynamic feedforward trajectories. The controllers are designed and verified using a high-fidelity engine model in GT-Power and exploit a low-order rate-based linear parameter-varying (LPV) model for prediction which is identified from transient response data generated by the GT-Power model. It is shown that the combination of feedforward and feedback MPC has the potential to improve the performance and robustness of the control design. In particular, the feedback MPC without feedforward can lose stability at low engine speeds, while MPC-based feedforward results in the best transient response. Mechanisms by which feedforward is able to assist in stabilization and improve performance are discussed."
Extensible Machine Learning for Encrypted Network Traffic ApplicationLabeling via Uncertainty Quantification,"StevenJorgensen, JohnHolodnak, JensenDempsey, Karla deSouza, AnandithaRaghunath, VernonRivet, NoahDeMoes, AndrésAlejos, AllanWollaber",11 May 2022,Cryptography and Security (cs.CR)," With the increasing prevalence of encrypted network traffic, cyber security analysts have been turning to machine learning (ML) techniques to elucidate the traffic on their networks. However, ML models can become stale as known traffic features can shift between networks and as new traffic emerges that is outside of the distribution of the training set. In order to reliably adapt in this dynamic environment, ML models must additionally provide contextualized uncertainty quantification to their predictions, which has received little attention in the cyber security domain. Uncertainty quantification is necessary both to signal when the model is uncertain about which class to choose in its label assignment and when the traffic is not likely to belong to any pre-trained classes.   We present a new, public dataset of network traffic that includes labeled, Virtual Private Network (VPN)-encrypted network traffic generated by 10 applications and corresponding to 5 application categories. We also present an ML framework that is designed to rapidly train with modest data requirements and provide both calibrated, predictive probabilities as well as an interpretable ``out-of-distribution'' (OOD) score to flag novel traffic samples. We describe how to compute a calibrated OOD score from p-values of the so-called relative Mahalanobis distance.   We demonstrate that our framework achieves an F1 score of 0.98 on our dataset and that it can extend to an enterprise network by testing the model: (1) on data from similar applications, (2) on dissimilar application traffic from an existing category, and (3) on application traffic from a new category. The model correctly flags uncertain traffic and, upon retraining, accurately incorporates the new data. We additionally demonstrate good performance (F1 score of 0.97) when packet sizes are made to be uniform, as occurs for certain encryption protocols."
On Upward-Planar L-Drawings of Graphs,"PatrizioAngelini, StevenChaplick, SabineCornelsen, Giordano DaLozzo",11 May 2022,Data Structures and Algorithms (cs.DS)," In an upward-planar L-drawing of a directed acyclic graph (DAG) each edge $e$ is represented as a polyline composed of a vertical segment with its lowest endpoint at the tail of $e$ and of a horizontal segment ending at the head of $e$. Distinct edges may overlap, but not cross. Recently, upward-planar L-drawings have been studied for $st$-graphs, i.e., planar DAGs with a single source $s$ and a single sink $t$ containing an edge directed from $s$ to $t$. It is known that a plane $st$-graph, i.e., an embedded $st$-graph in which the edge $(s,t)$ is incident to the outer face, admits an upward-planar L-drawing if and only if it admits a bitonic $st$-ordering, which can be tested in linear time.   We study upward-planar L-drawings of DAGs that are not necessarily $st$-graphs. On the combinatorial side, we show that a plane DAG admits an upward-planar L-drawing if and only if it is a subgraph of a plane $st$-graph admitting a bitonic $st$-ordering. This allows us to show that not every tree with a fixed bimodal embedding admits an upward-planar L-drawing. Moreover, we prove that any acyclic cactus with a single source (or a single sink) admits an upward-planar L-drawing, which respects a given outerplanar embedding if there are no transitive edges. On the algorithmic side, we consider DAGs with a single source (or a single sink). We give linear-time testing algorithms for these DAGs in two cases: (i) when the drawing must respect a prescribed embedding and (ii) when no restriction is given on the embedding, but each biconnected component is series-parallel."
High-Speed Imaging Receiver Design for 6G Optical WirelessCommunications: A Rate-FOV Trade-Off,"Mohammad DehghaniSoltani, HosseinKazemi, ElhamSarbazi, Taisir E. H. El-Gorashi, Jaafar M. H.Elmirghani, Richard V.Penty, IanH. White, Harald Haas, MajidSafari",11 May 2022,Information Theory (cs.IT)," The design of a compact high-speed and wide field of view (FOV) receiver is challenging due to the presence of two well-known trade-offs. The first one is the area-bandwidth trade-off of photodetectors (PDs) and the second one is the gain-FOV trade-off due to the use of optics. The combined effects of these two trade-offs imply that the achievable data rate of an imaging optical receiver is limited by its FOV, i.e., a rate-FOV trade-off. To control the area-bandwidth trade-off, an array of small PDs can be used instead of a single PD. Moreover, in practice, a large-area lens is required to ensure sufficient power collection, which in turn limits the receiver FOV (i.e., gain-FOV trade-off). We propose an imaging receiver design in the form of an array of arrays. To achieve a reasonable receiver FOV, we use individual focusing lens for each PD array rather than a single collection lens for the whole receiver. The proposed array of arrays structure provides an effective method to control both gain-FOV trade-off (via an array of lenses) and area-bandwidth trade-off (via arrays of PDs). We first derive a tractable analytical model for the SNR of an array of PDs where the maximum ratio combining has been employed. Then, we extend the model for the proposed array of arrays structure and the accuracy of the analytical model is verified based on several Optic Studio-based simulations. Next, we formulate an optimization problem to maximize the achievable data rate of the imaging receiver subject to a minimum required FOV. The optimization problem is solved for two commonly used modulation techniques, namely, OOK and direct current biased optical orthogonal frequency division multiplexing with variable rate quadrature amplitude modulation. It is demonstrated that a data rate of ~ 24 Gbps with a FOV of 15 is achievable using OOK with a total receiver size of 2 cm by 2 cm."
Computing control invariant sets of nonlinear systems: decompositionand distributed computing,"Benjamin Decardi-Nelson, JinfengLiu",11 May 2022,Systems and Control (eess.SY)," In this work, we present a distributed framework based on the graph algorithm for computing control invariant set for nonlinear cascade systems. The proposed algorithm exploits the structure of the interconnections within a process network. First, the overall system is decomposed into several subsystems with overlapping states. Second, the control invariant set for the subsystems are computed in a distributed manner. Finally, an approximation of the control invariant set for the overall system is reconstructed from the subsystem solutions and validated. We demonstrate the efficacy and convergence of the proposed method to the centralized graph-based algorithm using several numerical examples including a six dimensional continuous stirred tank reactor system."
Blockchain-based Secure Client Selection in Federated Learning,"TrucNguyen, Phuc Thai, Tre' R.Jeter, Thang N.Dinh, My T.Thai",11 May 2022,Cryptography and Security (cs.CR)," Despite the great potential of Federated Learning (FL) in large- scale distributed learning, the current system is still subject to several privacy issues due to the fact that local models trained by clients are exposed to the central server. Consequently, secure aggregation protocols for FL have been developed to conceal the local models from the server. However, we show that, by manipulating the client selection process, the server can circumvent the secure aggregation to learn the local models of a victim client, indicating that secure aggregation alone is inadequate for privacy protection. To tackle this issue, we leverage blockchain technology to propose a verifiable client selection protocol. Owing to the immutability and transparency of blockchain, our proposed protocol enforces a random selection of clients, making the server unable to control the selection process at its discretion. We present security proofs showing that our protocol is secure against this attack. Additionally, we conduct several experiments on an Ethereum-like blockchain to demonstrate the feasibility and practicality of our solution."
Video-ReTime: Learning Temporally Varying Speediness for TimeRemapping,"SimonJenni, MarkusWoodson, Fabian CabaHeilbron",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We propose a method for generating a temporally remapped video that matches the desired target duration while maximally preserving natural video dynamics. Our approach trains a neural network through self- supervision to recognize and accurately localize temporally varying changes in the video playback speed. To re-time videos, we 1. use the model to infer the slowness of individual video frames, and 2. optimize the temporal frame sub-sampling to be consistent with the model's slowness predictions. We demonstrate that this model can detect playback speed variations more accurately while also being orders of magnitude more efficient than prior approaches. Furthermore, we propose an optimization for video re-timing that enables precise control over the target duration and performs more robustly on longer videos than prior methods. We evaluate the model quantitatively on artificially speed-up videos, through transfer to action recognition, and qualitatively through user studies."
The Fluctuating Two-Ray Fading Model with Independent SpecularComponents,"MaryamOlyaee, José A.Cortés, F. Javier Lopez-Martinez, José F.Paris, Juan M. Romero-Jerez",11 May 2022,Information Theory (cs.IT)," We introduce and characterize the independent fluctuating two-ray (IFTR) fading model, a class of fading models consisting of two specular components which fluctuate independently, plus a diffuse component modeled as a complex Gaussian random variable. The IFTR model complements the popular fluctuating two-ray (FTR) model, on which the specular components are fully correlated and fluctuate jointly. The chief probability functions of the received SNR in IFTR fading, including the PDF, CDF and MGF, are expressed in closed-form, having a functional form similar to other state- of-the-art fading models. Then, the IFTR model is empirically validated using multiple channels measured in rather diverse scenarios, including line of sight (LOS) millimeter-wave, land mobile satellite (LMS) and underwater acoustic communication (UAC), showing a better fit than the original FTR model and other models previously used in these environments. Additionally, the performance of wireless communication systems operating under IFTR fading is evaluated in closed-form in two scenarios: (i) exact and asymptotic bit error rate for a family of coherent modulations; and (ii) exact and asymptotic outage probability."
Studying Scientific Data Lifecycle in On-demand Distributed StorageCaches,"JulianBellavita, Alex Sim, Kesheng Wu, Inder Monga, Chin Guok, FrankWürthwein, DiegoDavila",11 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," The XRootD system is used to transfer, store, and cache large datasets from high-energy physics (HEP). In this study we focus on its capability as distributed on-demand storage cache. Through exploring a large set of daily log files between 2020 and 2021, we seek to understand the data access patterns that might inform future cache design. Our study begins with a set of summary statistics regarding file read operations, file lifetimes, and file transfers. We observe that the number of read operations on each file remains nearly constant, while the average size of a read operation grows over time. Furthermore, files tend to have a consistent length of time during which they remain open and are in use. Based on this comprehensive study of the cache access statistics, we developed a cache simulator to explore the behavior of caches of different sizes. Within a certain size range, we find that increasing the XRootD cache size improves the cache hit rate, yielding faster overall file access. In particular, we find that increase the cache size from 40TB to 56TB could increase the hit rate from 0.62 to 0.89, which is a significant increase in cache effectiveness for modest cost."
Delay Encryption by Cubing,"IvoMaffei, A.W. Roscoe",11 May 2022,Cryptography and Security (cs.CR), Delay Encryption (often called Timed-Release Encryption) is a scheme in which a message is sent into the future by ensuring its confidentiality only for a given amount of time. We propose a new scheme based on a novel time-lock puzzle. This puzzle relies on the assumption that repeated squaring is an inherently sequential process. We perform an extensive and practical analysis of many classical and quantum attacks on our scheme and conclude that it is secure given some precautions.
Identifying Moments of Change from Longitudinal User Text,"AdamTsakalidis, FedericoNanni, AnthonyHills, JennyChim, JiayuSong, MariaLiakata",11 May 2022,Computation and Language (cs.CL)," Identifying changes in individuals' behaviour and mood, as observed via content shared on online platforms, is increasingly gaining importance. Most research to-date on this topic focuses on either: (a) identifying individuals at risk or with a certain mental health condition given a batch of posts or (b) providing equivalent labels at the post level. A disadvantage of such work is the lack of a strong temporal component and the inability to make longitudinal assessments following an individual's trajectory and allowing timely interventions. Here we define a new task, that of identifying moments of change in individuals on the basis of their shared content online. The changes we consider are sudden shifts in mood (switches) or gradual mood progression (escalations). We have created detailed guidelines for capturing moments of change and a corpus of 500 manually annotated user timelines (18.7K posts). We have developed a variety of baseline models drawing inspiration from related tasks and show that the best performance is obtained through context aware sequential modelling. We also introduce new metrics for capturing rare events in temporal windows."
A neural prosody encoder for end-ro-end dialogue act classification,"KaiWei, DillonKnox, MartinRadfar, Thanh Tran, MarkusMuller, Grant P.Strimel, NathanSusanj, AthanasiosMouchtaris, MaurizioOmologo",11 May 2022,Computation and Language (cs.CL)," Dialogue act classification (DAC) is a critical task for spoken language understanding in dialogue systems. Prosodic features such as energy and pitch have been shown to be useful for DAC. Despite their importance, little research has explored neural approaches to integrate prosodic features into end-to-end (E2E) DAC models which infer dialogue acts directly from audio signals. In this work, we propose an E2E neural architecture that takes into account the need for characterizing prosodic phenomena co- occurring at different levels inside an utterance. A novel part of this architecture is a learnable gating mechanism that assesses the importance of prosodic features and selectively retains core information necessary for E2E DAC. Our proposed model improves DAC accuracy by 1.07% absolute across three publicly available benchmark datasets."
KETOD: Knowledge-Enriched Task-Oriented Dialogue,"ZhiyuChen, BingLiu, SeungwhanMoon, ChinnadhuraiSankar, Paul Crook, William YangWang",11 May 2022,Computation and Language (cs.CL)," Existing studies in dialogue system research mostly treat task- oriented dialogue and chit-chat as separate domains. Towards building a human-like assistant that can converse naturally and seamlessly with users, it is important to build a dialogue system that conducts both types of conversations effectively. In this work, we investigate how task-oriented dialogue and knowledge-grounded chit-chat can be effectively integrated into a single model. To this end, we create a new dataset, KETOD (Knowledge- Enriched Task-Oriented Dialogue), where we naturally enrich task-oriented dialogues with chit-chat based on relevant entity knowledge. We also propose two new models, SimpleToDPlus and Combiner, for the proposed task. Experimental results on both automatic and human evaluations show that the proposed methods can significantly improve the performance in knowledge- enriched response generation while maintaining a competitive task-oriented dialog performance. We believe our new dataset will be a valuable resource for future studies. Our dataset and code are publicly available at \url{[this https URL](https://github.com/facebookresearch/ketod)}."
Characterizing the Action-Generalization Gap in Deep Q-Learning,"ZhiyuanZhou, CameronAllen, KavoshAsadi, GeorgeKonidaris",11 May 2022,Artificial Intelligence (cs.AI)," We study the action generalization ability of deep Q-learning in discrete action spaces. Generalization is crucial for efficient reinforcement learning (RL) because it allows agents to use knowledge learned from past experiences on new tasks. But while function approximation provides deep RL agents with a natural way to generalize over state inputs, the same generalization mechanism does not apply to discrete action outputs. And yet, surprisingly, our experiments indicate that Deep Q-Networks (DQN), which use exactly this type of function approximator, are still able to achieve modest action generalization. Our main contribution is twofold: first, we propose a method of evaluating action generalization using expert knowledge of action similarity, and empirically confirm that action generalization leads to faster learning; second, we characterize the action- generalization gap (the difference in learning performance between DQN and the expert) in different domains. We find that DQN can indeed generalize over actions in several simple domains, but that its ability to do so decreases as the action space grows larger."
TDT: Teaching Detectors to Track without Fully Annotated Videos,"ShuzhiYu, GuanhangWu, ChunhuiGu, Mohammed E.Fathy",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Recently, one-stage trackers that use a joint model to predict both detections and appearance embeddings in one forward pass received much attention and achieved state-of-the-art results on the Multi-Object Tracking (MOT) benchmarks. However, their success depends on the availability of videos that are fully annotated with tracking data, which is expensive and hard to obtain. This can limit the model generalization. In comparison, the two-stage approach, which performs detection and embedding separately, is slower but easier to train as their data are easier to annotate. We propose to combine the best of the two worlds through a data distillation approach. Specifically, we use a teacher embedder, trained on Re-ID datasets, to generate pseudo appearance embedding labels for the detection datasets. Then, we use the augmented dataset to train a detector that is also capable of regressing these pseudo-embeddings in a fully-convolutional fashion. Our proposed one-stage solution matches the two-stage counterpart in quality but is 3 times faster. Even though the teacher embedder has not seen any tracking data during training, our proposed tracker achieves competitive performance with some popular trackers (e.g. JDE) trained with fully labeled tracking data."
Scream Detection in Heavy Metal Music,"VedantKalbag, AlexanderLerch",11 May 2022,Sound (cs.SD)," Harsh vocal effects such as screams or growls are far more common in heavy metal vocals than the traditionally sung vocal. This paper explores the problem of detection and classification of extreme vocal techniques in heavy metal music, specifically the identification of different scream techniques. We investigate the suitability of various feature representations, including cepstral, spectral, and temporal features as input representations for classification. The main contributions of this work are (i) a manually annotated dataset comprised of over 280 minutes of heavy metal songs of various genres with a statistical analysis of occurrences of different extreme vocal techniques in heavy metal music, and (ii) a systematic study of different input feature representations for the classification of heavy metal vocals"
Channel Estimation in RIS-assisted Downlink Massive MIMO: A Learning-Based Approach,"Tung T.Vu, Trinh VanChien, Canh T.Dinh, HienQuoc Ngo, MichailMatthaiou",11 May 2022,Information Theory (cs.IT)," For downlink massive multiple-input multiple-output (MIMO) operating in time-division duplex protocol, users can decode the signals effectively by only utilizing the channel statistics as long as channel hardening holds. However, in a reconfigurable intelligent surface (RIS)-assisted massive MIMO system, the propagation channels may be less hardened due to the extra random fluctuations of the effective channel gains. To address this issue, we propose a learning-based method that trains a neural network to learn a mapping between the received downlink signal and the effective channel gains. The proposed method does not require any downlink pilots and statistical information of interfering users. Numerical results show that, in terms of mean-square error of the channel estimation, our proposed learning-based method outperforms the state-of-the-art methods, especially when the light-of-sight (LoS) paths are dominated by non-LoS paths with a low level of channel hardening, e.g., in the cases of small numbers of RIS elements and/or base station antennas."
DoubleMatch: Improving Semi-Supervised Learning with Self-Supervision,"ErikWallin, LennartSvensson, Fredrik Kahl, LarsHammarstrand",11 May 2022,Machine Learning (cs.LG)," Following the success of supervised learning, semi-supervised learning (SSL) is now becoming increasingly popular. SSL is a family of methods, which in addition to a labeled training set, also use a sizable collection of unlabeled data for fitting a model. Most of the recent successful SSL methods are based on pseudo-labeling approaches: letting confident model predictions act as training labels. While these methods have shown impressive results on many benchmark datasets, a drawback of this approach is that not all unlabeled data are used during training. We propose a new SSL algorithm, DoubleMatch, which combines the pseudo-labeling technique with a self-supervised loss, enabling the model to utilize all unlabeled data in the training process. We show that this method achieves state-of-the-art accuracies on multiple benchmark datasets while also reducing training times compared to existing SSL methods. Code is available at [this https URL](https://github.com/walline/doublematch)."
A Longitudal Study of Cryptographic API -- a Decade of Android Malware,"AdamJanovsky, DavideMaiorca, DominikMacko, VashekMatyas, GiorgioGiacinto",11 May 2022,Cryptography and Security (cs.CR)," Cryptography has been extensively used in Android applications to guarantee secure communications, conceal critical data from reverse engineering, or ensure mobile users' privacy. Various system-based and third-party libraries for Android provide cryptographic functionalities, and previous works mainly explored the misuse of cryptographic API in benign applications. However, the role of cryptographic API has not yet been explored in Android malware. This paper performs a comprehensive, longitudinal analysis of cryptographic API in Android malware. In particular, we analyzed $603\,937$ Android applications (half of them malicious, half benign) released between $2012$ and $2020$, gathering more than 1 million cryptographic API expressions. Our results reveal intriguing trends and insights on how and why cryptography is employed in Android malware. For instance, we point out the widespread use of weak hash functions and the late transition from insecure DES to AES. Additionally, we show that cryptography-related characteristics can help to improve the performance of learning-based systems in detecting malicious applications."
Face Detection on Mobile: Five Implementations and Analysis,KostiantynKhabarlak,"11 May 2022 (v1(https://arxiv.org/abs/2205.05572v1)), lastrevised 12 May 2022 (this version, v2)",Computer Vision and Pattern Recognition (cs.CV)," In many practical cases face detection on smartphones or other highly portable devices is a necessity. Applications include mobile face access control systems, driver status tracking, emotion recognition, etc. Mobile devices have limited processing power and should have long-enough battery life even with face detection application running. Thus, striking the right balance between algorithm quality and complexity is crucial. In this work we adapt 5 algorithms to mobile. These algorithms are based on handcrafted or neural-network-based features and include: Viola-Jones (Haar cascade), LBP, HOG, MTCNN, BlazeFace. We analyze inference time of these algorithms on different devices with different input image resolutions. We provide guidance, which algorithms are the best fit for mobile face access control systems and potentially other mobile applications. Interestingly, we note that cascaded algorithms perform faster on scenes without faces, while BlazeFace is slower on empty scenes. Exploiting this behavior might be useful in practice."
Review on Panoramic Imaging and Its Applications in SceneUnderstanding,"ShaohuaGao, KailunYang, HaoShi, KaiweiWang, JianBai",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," With the rapid development of high-speed communication and artificial intelligence technologies, human perception of real-world scenes is no longer limited to the use of small Field of View (FoV) and low- dimensional scene detection devices. Panoramic imaging emerges as the next generation of innovative intelligent instruments for environmental perception and measurement. However, while satisfying the need for large-FoV photographic imaging, panoramic imaging instruments are expected to have high resolution, no blind area, miniaturization, and multi-dimensional intelligent perception, and can be combined with artificial intelligence methods towards the next generation of intelligent instruments, enabling deeper understanding and more holistic perception of 360-degree real-world surrounding environments. Fortunately, recent advances in freeform surfaces, thin-plate optics, and metasurfaces provide innovative approaches to address human perception of the environment, offering promising ideas beyond conventional optical imaging. In this review, we begin with introducing the basic principles of panoramic imaging systems, and then describe the architectures, features, and functions of various panoramic imaging systems. Afterwards, we discuss in detail the broad application prospects and great design potential of freeform surfaces, thin-plate optics, and metasurfaces in panoramic imaging. We then provide a detailed analysis on how these techniques can help enhance the performance of panoramic imaging systems. We further offer a detailed analysis of applications of panoramic imaging in scene understanding for autonomous driving and robotics, spanning panoramic semantic image segmentation, panoramic depth estimation, panoramic visual localization, and so on. Finally, we cast a perspective on future potential and research directions for panoramic imaging instruments."
Delayed Reinforcement Learning by Imitation,"PierreLiotet, DavideMaran, Lorenzo Bisi, MarcelloRestelli",11 May 2022,Machine Learning (cs.LG)," When the agent's observations or interactions are delayed, classic reinforcement learning tools usually fail. In this paper, we propose a simple yet new and efficient solution to this problem. We assume that, in the undelayed environment, an efficient policy is known or can be easily learned, but the task may suffer from delays in practice and we thus want to take them into account. We present a novel algorithm, Delayed Imitation with Dataset Aggregation (DIDA), which builds upon imitation learning methods to learn how to act in a delayed environment from undelayed demonstrations. We provide a theoretical analysis of the approach that will guide the practical design of DIDA. These results are also of general interest in the delayed reinforcement learning literature by providing bounds on the performance between delayed and undelayed tasks, under smoothness conditions. We show empirically that DIDA obtains high performances with a remarkable sample efficiency on a variety of tasks, including robotic locomotion, classic control, and trading."
Access Trends of In-network Cache for Scientific Data,"RuizeHan, AlexSim, KeshengWu, InderMonga, ChinGuok, FrankWürthwein, DiegoDavila, JustasBalcas, HarveyNewman",11 May 2022,Networking and Internet Architecture (cs.NI)," Scientific collaborations are increasingly relying on large volumes of data for their work and many of them employ tiered systems to replicate the data to their worldwide user communities. Each user in the community often selects a different subset of data for their analysis tasks; however, members of a research group often are working on related research topics that require similar data objects. Thus, there is a significant amount of data sharing possible. In this work, we study the access traces of a federated storage cache known as the Southern California Petabyte Scale Cache. By studying the access patterns and potential for network traffic reduction by this caching system, we aim to explore the predictability of the cache uses and the potential for a more general in-network data caching. Our study shows that this distributed storage cache is able to reduce the network traffic volume by a factor of 2.35 during a part of the study period. We further show that machine learning models could predict cache utilization with an accuracy of 0.88. This demonstrates that such cache usage is predictable, which could be useful for managing complex networking resources such as in-network caching."
NMR: Neural Manifold Representation for Autonomous Driving,"Unnikrishnan R.Nair, SarthakSharma, Midhun S.Menon, SrikanthVidapanakal",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Autonomous driving requires efficient reasoning about the Spatio- temporal nature of the semantics of the scene. Recent approaches have successfully amalgamated the traditional modular architecture of an autonomous driving stack comprising perception, prediction, and planning in an end-to-end trainable system. Such a system calls for a shared latent space embedding with interpretable intermediate trainable projected representation. One such successfully deployed representation is the Bird's-Eye View(BEV) representation of the scene in ego-frame. However, a fundamental assumption for an undistorted BEV is the local coplanarity of the world around the ego-vehicle. This assumption is highly restrictive, as roads, in general, do have gradients. The resulting distortions make path planning inefficient and incorrect. To overcome this limitation, we propose Neural Manifold Representation (NMR), a representation for the task of autonomous driving that learns to infer semantics and predict way-points on a manifold over a finite horizon, centered on the ego-vehicle. We do this using an iterative attention mechanism applied on a latent high dimensional embedding of surround monocular images and partial ego-vehicle state. This representation helps generate motion and behavior plans consistent with and cognizant of the surface geometry. We propose a sampling algorithm based on edge-adaptive coverage loss of BEV occupancy grid and associated guidance flow field to generate the surface manifold while incurring minimal computational overhead. We aim to test the efficacy of our approach on CARLA and SYNTHIA-SF."
An Empirical Study Of Self-supervised Learning Approaches For ObjectDetection With Transformers,"Gokul KarthikKumar, Sahal ShajiMullappilly, Abhishek SinghGehlot",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Self-supervised learning (SSL) methods such as masked language modeling have shown massive performance gains by pretraining transformer models for a variety of natural language processing tasks. The follow-up research adapted similar methods like masked image modeling in vision transformer and demonstrated improvements in the image classification task. Such simple self-supervised methods are not exhaustively studied for object detection transformers (DETR, Deformable DETR) as their transformer encoder modules take input in the convolutional neural network (CNN) extracted feature space rather than the image space as in general vision transformers. However, the CNN feature maps still maintain the spatial relationship and we utilize this property to design self-supervised learning approaches to train the encoder of object detection transformers in pretraining and multi-task learning settings. We explore common self-supervised methods based on image reconstruction, masked image modeling and jigsaw. Preliminary experiments in the iSAID dataset demonstrate faster convergence of DETR in the initial epochs in both pretraining and multi-task learning settings; nonetheless, similar improvement is not observed in the case of multi-task learning with Deformable DETR. The code for our experiments with DETR and Deformable DETR are available at [this https URL](https://github.com/gokulkarthik/detr) and [this https URL](https://github.com/gokulkarthik/Deformable-DETR) respectively."
Clinical Prompt Learning with Frozen Language Models,"NiallTaylor, YiZhang, DanJoyce, AlejoNevado-Holgado, AndreyKormilitzin",11 May 2022,Computation and Language (cs.CL)," Prompt learning is a new paradigm in the Natural Language Processing (NLP) field which has shown impressive performance on a number of natural language tasks with common benchmarking text datasets in full, few- shot, and zero-shot train-evaluation setups. Recently, it has even been observed that large but frozen pre-trained language models (PLMs) with prompt learning outperform smaller but fine-tuned models. However, as with many recent NLP trends, the performance of even the largest PLMs such as GPT-3 do not perform well on specialized domains (e.g. medical text), and the common practice to achieve State of the Art (SoTA) results still consists of pre-training and fine-tuning the PLMs on downstream tasks. The reliance on fine-tuning large PLMs is problematic in clinical settings where data is often held in non-GPU environments, and more resource efficient methods of training specialized domain models is crucial. We investigated the viability of prompt learning on clinically meaningful decision tasks and directly compared with more traditional fine-tuning methods. Results are partially in line with the prompt learning literature, with prompt learning able to match or improve on traditional fine-tuning with substantially fewer trainable parameters and requiring less training data. We argue that prompt learning therefore provides lower computational resource costs applicable to clinical settings, that can serve as an alternative to fine-tuning ever increasing in size PLMs. Complementary code to reproduce experiments presented in this work can be found at: [this https URL](https://github.com/NtaylorOX/Public_Clinical_Prompt)."
"Design, Modeling and Control for a Tilt-rotor VTOL UAV in the Presenceof Actuator Failure","MohammadrezaMousaei, Junyi Geng, AzarakhshKeipour, Dongwei Bai, SebastianScherer",11 May 2022,Robotics (cs.RO)," Providing both the vertical take-off and landing capabilities and the ability to fly long distances to aircraft opens the door to a wide range of new real-world aircraft applications while improving many existing applications. Tiltrotor vertical take-off and landing (VTOL) unmanned aerial vehicles (UAVs) are a better choice than fixed-wing and multirotor aircraft for such applications. Prior work on these aircraft has addressed the aerodynamic performance, design, modeling, and control. However, a less explored area is the study of their potential fault tolerance due to their inherent redundancy, which allows them to sustain some degree of actuator failure. This work introduces tolerance to several types of actuator failures in a tiltrotor VTOL aircraft. We discuss the design and model of a custom tiltrotor VTOL UAV, which is a combination of a fixed-wing aircraft and a quadrotor with tilting rotors, where the four propellers can be rotated individually. Then, we analyze the feasible wrench space the vehicle can generate and design the dynamic control allocation so that the system can adapt to actuator failure, benefiting from the configuration redundancy. The proposed approach is lightweight and is implemented as an extension to an already existing flight control stack. Extensive experiments are performed to validate that the system can maintain the controlled flight under different actuator failures. To the best of our knowledge, this work is the first study of the tiltrotor VTOL's fault-tolerance that exploits the configuration redundancy."
Comparison of Brick and Project Haystack to Support Smart BuildingApplications,CarolineQuinn (1)J.J.McArthur(1) (,11 May 2022,Computers and Society (cs.CY)," Enabling buildings with Smart Building applications will help to achieve the ongoing efficient commissioning of buildings, ultimately attaining peak performance in energy use and improved occupant health and comfort, at minimum cost. For these technologies to be scalable data ontology must be adopted to semantically represent data generated by building mechanical systems, acting as conduit for connection to Smart Building applications. The viability of Brick and Project Haystack ontologies, as found by industry and academia, prompted a quantitative comparison of completeness and expressiveness using a case study with an industry ontology as the baseline. Additionally, a qualitative comparison was completed using key ontology qualities outlined in literature. A recommendation of Brick is made based on results. Brick achieved higher assessment values in completeness and expressiveness achieving 59% and 100% respectively, as compared to Haystacks 43% and 96%. Additionally, Brick exhibited five of six desirable qualities, where Haystack exhibited only three. The recommendation of the appropriate ontology forms the basis for longer-term Smart Building application development, which will support innovative approaches to sustainability in building operations across scale, as well as next-generation building controls and automation strategies."
Query Efficient Prophet Inequality with Unknown I.I.D. Distributions,"Bo Li, Xiaowei Wu, Yutong Wu",11 May 2022,Data Structures and Algorithms (cs.DS)," We study the single-choice prophet inequality problem, where a gambler faces a sequence of $n$ online i.i.d. random variables drawn from an unknown distribution. When a variable reveals its value, the gambler needs to decide irrevocably whether or not to accept it. The goal is to maximize the competitive ratio between the expected gain of the gambler and that of the maximum variable. It is shown by Correa et al. that when the distribution is unknown or only $o(n)$ uniform samples from the distribution are given, the best an algorithm can do is $1/e$-competitive. In contrast, when the distribution is known or $\Omega(n)$ uniform samples are given, the optimal competitive ratio 0.7451 can be achieved. In this paper, we propose a new model in which the algorithm has access to an oracle that answers quantile queries about the distribution, and study the extent to which we can use a small number of queries to achieve good competitive ratios. Naturally, by making queries to the oracle, one can implement the threshold- based blind strategies that use the answers from the queries as thresholds to accept variables. Our first contribution is to prove that the competitive ratio improves gracefully with the number of thresholds. Particularly with two thresholds our algorithm achieves a competitive ratio of 0.6786. Our second contribution, surprisingly, shows that with a single query, we can do strictly better than with a single threshold. The algorithm sets a threshold in the first phase by making a single query and uses the maximum realization from the first phase as the threshold for the second phase. It can be viewed as a natural combination of the single-threshold algorithm and the algorithm for the secretary problem. By properly choosing the quantile to query and the break-point between the two phases, we achieve a competitive ratio of 0.6718."
Building Automation System Data Integration with BIM: Data Structureand Supporting Case Study,CarolineQuinn (1)Ali ZargarShabestari(2) MarinLitoiu (2)J.J.McArthur(1) ((1) Department of Architectural Science Ryerson University AuthorAffiliation ,11 May 2022,Networking and Internet Architecture (cs.NI)," Buildings Automation Systems (BAS) are ubiquitous in contemporary buildings, both monitoring building conditions and managing the building system control points. At present, these controls are prescriptive and pre- determined by the design team, rather than responsive to actual building performance. These are further limited by prescribed logic, possess only rudimentary visualizations, and lack broader system integration capabilities. Advances in machine learning, edge analytics, data management systems, and Facility Management-enabled Building Information Models (FM- BIMs) permit a novel approach: cloud-hosted building management. This paper presents an integration technique for mapping the data from a building Internet of Things (IoT) sensor network to an FM-BIM. The sensor data naming convention and timeseries analysis strategies integrated into the data structure are discussed and presented, including the use of a 3D nested list to permit timeseries data to be mapped to the FM-BIM and readily visualized. The developed approach is presented through a case study of an office living lab consisting of a local sensor network mimicking a BAS, which streams to a cloud server via a virtual private network connection. The resultant data structure and key visualizations are presented to demonstrate the value of this approach, which permits the end-user to select the desired timeframe for visualization and readily step through the spatio-temporal building performance data."
Keep Your Friends Close and Your Counterfactuals Closer: ImprovedLearning From Closest Rather Than Plausible Counterfactual Explanations in anAbstract Setting,"UlrikeKuhl, AndréArtelt, BarbaraHammer",11 May 2022,Artificial Intelligence (cs.AI)," Counterfactual explanations (CFEs) highlight what changes to a model's input would have changed its prediction in a particular way. CFEs have gained considerable traction as a psychologically grounded solution for explainable artificial intelligence (XAI). Recent innovations introduce the notion of computational plausibility for automatically generated CFEs, enhancing their robustness by exclusively creating plausible explanations. However, practical benefits of such a constraint on user experience and behavior is yet unclear. In this study, we evaluate objective and subjective usability of computationally plausible CFEs in an iterative learning design targeting novice users. We rely on a novel, game-like experimental design, revolving around an abstract scenario. Our results show that novice users actually benefit less from receiving computationally plausible rather than closest CFEs that produce minimal changes leading to the desired outcome. Responses in a post-game survey reveal no differences in terms of subjective user experience between both groups. Following the view of psychological plausibility as comparative similarity, this may be explained by the fact that users in the closest condition experience their CFEs as more psychologically plausible than the computationally plausible counterpart. In sum, our work highlights a little-considered divergence of definitions of computational plausibility and psychological plausibility, critically confirming the need to incorporate human behavior, preferences and mental models already at the design stages of XAI approaches. In the interest of reproducible research, all source code, acquired user data, and evaluation scripts of the current study are available: [this https URL](https://github.com/ukuhl/PlausibleAlienZoo)"
Is calibration a fairness requirement? An argument from the point ofview of moral philosophy and decision theory,"MicheleLoi, ChristophHeitz",11 May 2022,Machine Learning (cs.LG)," In this paper, we provide a moral analysis of two criteria of statistical fairness debated in the machine learning literature: 1) calibration between groups and 2) equality of false positive and false negative rates between groups. In our paper, we focus on moral arguments in support of either measure. The conflict between group calibration vs. false positive and false negative rate equality is one of the core issues in the debate about group fairness definitions among practitioners. For any thorough moral analysis, the meaning of the term fairness has to be made explicit and defined properly. For our paper, we equate fairness with (non-)discrimination, which is a legitimate understanding in the discussion about group fairness. More specifically, we equate it with prima facie wrongful discrimination in the sense this is used in Prof. Lippert- Rasmussen's treatment of this definition. In this paper, we argue that a violation of group calibration may be unfair in some cases, but not unfair in others. This is in line with claims already advanced in the literature, that algorithmic fairness should be defined in a way that is sensitive to context. The most important practical implication is that arguments based on examples in which fairness requires between-group calibration, or equality in the false-positive/false-negative rates, do no generalize. For it may be that group calibration is a fairness requirement in one case, but not in another."
Efficient Automated Deep Learning for Time Series Forecasting,"DifanDeng, FlorianKarl, FrankHutter, BerndBischl, MariusLindauer",11 May 2022,Machine Learning (cs.LG)," Recent years have witnessed tremendously improved efficiency of Automated Machine Learning (AutoML), especially Automated Deep Learning (AutoDL) systems, but recent work focuses on tabular, image, or NLP tasks. So far, little attention has been paid to general AutoDL frameworks for time series forecasting, despite the enormous success in applying different novel architectures to such tasks. In this paper, we propose an efficient approach for the joint optimization of neural architecture and hyperparameters of the entire data processing pipeline for time series forecasting. In contrast to common NAS search spaces, we designed a novel neural architecture search space covering various state-of-the-art architectures, allowing for an efficient macro-search over different DL approaches. To efficiently search in such a large configuration space, we use Bayesian optimization with multi-fidelity optimization. We empirically study several different budget types enabling efficient multi-fidelity optimization on different forecasting datasets. Furthermore, we compared our resulting system, dubbed Auto-PyTorch-TS, against several established baselines and show that it significantly outperforms all of them across several datasets."
READ: Large-Scale Neural Scene Rendering for Autonomous Driving,"ZhuopengLi, LuLi, ZeyuMa, PingZhang, JunboChen, JiankeZhu",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Synthesizing free-view photo-realistic images is an important task in multimedia. With the development of advanced driver assistance systems~(ADAS) and their applications in autonomous vehicles, experimenting with different scenarios becomes a challenge. Although the photo-realistic street scenes can be synthesized by image-to-image translation methods, which cannot produce coherent scenes due to the lack of 3D information. In this paper, a large-scale neural rendering method is proposed to synthesize the autonomous driving scene~(READ), which makes it possible to synthesize large-scale driving scenarios on a PC through a variety of sampling schemes. In order to represent driving scenarios, we propose an {\omega} rendering network to learn neural descriptors from sparse point clouds. Our model can not only synthesize realistic driving scenes but also stitch and edit driving scenes. Experiments show that our model performs well in large-scale driving scenarios."
Self-Supervised Antipodal Grasp Learning with Fine-Grained GraspQuality Feedback in Clutter,"YanxuHou, JunLi, I-MingChen",11 May 2022,Robotics (cs.RO)," It is a challenging goal in robotics to make a robot grasp like a human being in a cluttered environment. Self-supervised grasp learning is one of the most promising approaches to human-like robotic grasp. However, due to inadequate feedback on grasp quality, almost the existing self- supervised grasp learning methods are coarse-grained. This paper proposes a fine-grained antipodal grasp learning (FAGL) method with augmented learning feedback. First, an indicator called antipodal degree of a grasp (ADG) is defined by a non-increasing monotonous function. ADG reflecting fine-grained grasp quality is evaluated indirectly by the destructive effect of a grasp on the environment via scene images. Next, we design a restorative sampling strategy to collect the samples of fine-grained antipodal grasps and propose a refined affordance network to generate grasp affordance maps for FAGL to decide grasp policies. Finally, in grasping actual metal workpieces, FAGL outperforms its peers in terms of grasp success rate and ADG in cluttered and adversarial scenarios by reducing the grasp effects on the surroundings. The results of extensive experiments show that our method has great potential for industrial application."
TextMatcher: Cross-Attentional Neural Network to Compare Image andText,"ValentinaArrigoni, LuisaRepele, Dario MarinoSaccavino",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We study a novel multimodal-learning problem, which we call text matching: given an image containing a single-line text and a candidate text transcription, the goal is to assess whether the text represented in the image corresponds to the candidate text. We devise the first machine- learning model specifically designed for this problem. The proposed model, termed TextMatcher, compares the two inputs by applying a cross-attention mechanism over the embedding representations of image and text, and it is trained in an end-to-end fashion. We extensively evaluate the empirical performance of TextMatcher on the popular IAM dataset. Results attest that, compared to a baseline and existing models designed for related problems, TextMatcher achieves higher performance on a variety of configurations, while at the same time running faster at inference time. We also showcase TextMatcher in a real-world application scenario concerning the automatic processing of bank cheques."
Probability Distribution of Hypervolume Improvement in Bi-objectiveBayesian Optimization,"HaoWang, KaifengYang, MichaelAffenzeller, MichaelEmmerich","11 May 2022 (v1(https://arxiv.org/abs/2205.05505v1)), lastrevised 12 May 2022 (this version, v2)",Machine Learning (cs.LG)," This work provides the exact expression of the probability distribution of the hypervolume improvement (HVI) for bi-objective generalization of Bayesian optimization. Here, instead of a single-objective improvement, we consider the improvement of the hypervolume indicator concerning the current best approximation of the Pareto front. Gaussian process regression models are trained independently on both objective functions, resulting in a bi-variate separated Gaussian distribution serving as a predictive model for the vector-valued objective function. Some commonly HVI-based acquisition functions (probability of improvement and upper confidence bound) are also leveraged with the help of the exact distribution of HVI. In addition, we show the superior numerical accuracy and efficiency of the exact distribution compared to the commonly used approximation by Monte-Carlo sampling. Finally, we benchmark distribution- leveraged acquisition functions on the widely applied ZDT problem set, demonstrating a significant advantage of using the exact distribution of HVI in multi-objective Bayesian optimization."
Towards Run-Time Search for Real-World Multi-Agent Systems,"Abigail C.Diller, Erik M.Fredericks",11 May 2022,Software Engineering (cs.SE)," Multi-agent systems (MAS) may encounter uncertainties in the form of unexpected environmental conditions, sub-optimal system configurations, and unplanned interactions between autonomous agents. The number of combinations of such uncertainties may be innumerable, however run-time testing may reduce the issues impacting such a system. We posit that search heuristics can augment a run-time testing process, in-situ, for a MAS. To support our position we discuss our in-progress experimental testbed to realize this goal and highlight challenges we anticipate for this domain."
Towards Self-Adaptive Game Logic,"Erik M.Fredericks, ByronDeVries, Jared M.Moore",11 May 2022,Software Engineering (cs.SE)," Self-adaptive systems (SAS) can reconfigure at run time in response to changing situations to express acceptable behaviors in the face of uncertainty. With respect to game design, such situations may include user input, emergent behaviors, performance concerns, and combinations thereof. Typically an SAS is modeled as a feedback loop that functions within an existing system, with operations including monitoring, analyzing, planning, and executing (i.e., MAPE-K) to enable online reconfiguration. This paper presents a conceptual approach for extending software engineering artifacts to be self-adaptive within the context of game design. We have modified a game developed for creative coding education to include a MAPE-K self-adaptive feedback loop, comprising run-time adaptation capabilities and the software artifacts required to support adaptation."
Deep Learning and Computer Vision Techniques for MicrocirculationAnalysis: A Review,"Maged Abdalla Helmy MohamedAbdou, Trung TuyenTruong, Eric Jul, PauloFerreira",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The analysis of microcirculation images has the potential to reveal early signs of life-threatening diseases like sepsis. Quantifying the capillary density and the capillary distribution in microcirculation images can be used as a biological marker to assist critically ill patients. The quantification of these biological markers is labor-intensive, time- consuming, and subject to interobserver variability. Several computer vision techniques with varying performance can be used to automate the analysis of these microcirculation images in light of the stated challenges. In this paper, we present a survey of over 50 research papers and present the most relevant and promising computer vision algorithms to automate the analysis of microcirculation images. Furthermore, we present a survey of the methods currently used by other researchers to automate the analysis of microcirculation images. This survey is of high clinical relevance because it acts as a guidebook of techniques for other researchers to develop their microcirculation analysis systems and algorithms."
"Two ways to make your robot proactive: reasoning about humanintentions, or reasoning about possible futures","SeraBuyukgoz, JasminGrosinger, MohamedChetouani, AlessandroSaffiotti",11 May 2022,Artificial Intelligence (cs.AI)," Robots sharing their space with humans need to be proactive in order to be helpful. Proactive robots are able to act on their own initiative in an anticipatory way to benefit humans. In this work, we investigate two ways to make robots proactive. One way is to recognize humans' intentions and to act to fulfill them, like opening the door that you are about to cross. The other way is to reason about possible future threats or opportunities and to act to prevent or to foster them, like recommending you to take an umbrella since rain has been forecasted. In this paper, we present approaches to realize these two types of proactive behavior. We then present an integrated system that can generate proactive robot behavior by reasoning on both factors: intentions and predictions. We illustrate our system on a sample use case including a domestic robot and a human. We first run this use case with the two separate proactive systems, intention-based and prediction-based, and then run it with our integrated system. The results show that the integrated system is able to take into account a broader variety of aspects that are needed for proactivity."
"DNA data storage, sequencing data-carrying DNA","JasmineQuah, OmerSella, ThomasHeinis",11 May 2022,Emerging Technologies (cs.ET)," DNA is a leading candidate as the next archival storage media due to its density, durability and sustainability. To read (and write) data DNA storage exploits technology that has been developed over decades to sequence naturally occurring DNA in the life sciences. To achieve higher accuracy for previously unseen, biological DNA, sequencing relies on extending and training deep machine learning models known as basecallers. This growth in model complexity requires substantial resources, both computational and data sets. It also eliminates the possibility of a compact read head for DNA as a storage medium.   We argue that we need to depart from blindly using sequencing models from the life sciences for DNA data storage. The difference is striking: for life science applications we have no control over the DNA, however, in the case of DNA data storage, we control how it is written, as well as the particular write head. More specifically, data-carrying DNA can be modulated and embedded with alignment markers and error correcting codes to guarantee higher fidelity and to carry out some of the work that the machine learning models perform.   In this paper, we study accuracy trade-offs between deep model size and error correcting codes. We show that, starting with a model size of 107MB, the reduced accuracy from model compression can be compensated by using simple error correcting codes in the DNA sequences. In our experiments, we show that a substantial reduction in the size of the model does not incur an undue penalty for the error correcting codes used, therefore paving the way for portable data-carrying DNA read head. Crucially, we show that through the joint use of model compression and error correcting codes, we achieve a higher read accuracy than without compression and error correction codes."
Scene Consistency Representation Learning for Video Scene Segmentation,"HaoqianWu, KeyuChen, YananLuo, RuizhiQiao, BoRen, HaozheLiu, WeichengXie, LinlinShen",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," A long-term video, such as a movie or TV show, is composed of various scenes, each of which represents a series of shots sharing the same semantic story. Spotting the correct scene boundary from the long-term video is a challenging task, since a model must understand the storyline of the video to figure out where a scene starts and ends. To this end, we propose an effective Self-Supervised Learning (SSL) framework to learn better shot representations from unlabeled long-term videos. More specifically, we present an SSL scheme to achieve scene consistency, while exploring considerable data augmentation and shuffling methods to boost the model generalizability. Instead of explicitly learning the scene boundary features as in the previous methods, we introduce a vanilla temporal model with less inductive bias to verify the quality of the shot features. Our method achieves the state-of-the-art performance on the task of Video Scene Segmentation. Additionally, we suggest a more fair and reasonable benchmark to evaluate the performance of Video Scene Segmentation methods. The code is made available."
Who won? Winner Determination and Robustness in Liquid Democracy,"MatthiasBentert, NiclasBoehmer, MaciejRymar, HenriTannenberg","11 May 2022 (v1(https://arxiv.org/abs/2205.05482v1)), lastrevised 12 May 2022 (this version, v2)",Computer Science and Game Theory (cs.GT)," Liquid democracy is a decision-making paradigm in which each agent can either vote directly for some alternative or (transitively) delegate its vote to another agent. To mitigate the issue of delegation cycles or the concentration of power, delegating agents might be allowed to specify multiple delegation options. Then, a (cycle-free) delegation is selected in which each delegating agent has exactly one representative. We study the winner determination problem for this setting, i.e., whether we can select a delegation such that a given alternative wins (or does not win). Moreover, we study the robustness of winning alternatives in two ways: First, we consider whether we can make a limited number of changes to the preferences cast by the delegating or directly voting agents such that a given alternative becomes a winner in one/in all delegations, and second, whether we can make a limited number of changes to a selected delegation to make a given alternative a winner."
Automatic Tuberculosis and COVID-19 cough classification using deeplearning,"MadhuranandaPahar, MarisaKlopper, Byron Reeve, Rob Warren, GrantTheron, AndreasDiacon, ThomasNiesler",11 May 2022,Machine Learning (cs.LG)," We present a deep learning based automatic cough classifier which can discriminate tuberculosis (TB) coughs from COVID-19 coughs and healthy coughs. Both TB and COVID-19 are respiratory disease, have cough as a predominant symptom and claim thousands of lives each year. The cough audio recordings were collected at both indoor and outdoor settings and also uploaded using smartphones from subjects around the globe, thus contain various levels of noise. This cough data include 1.68 hours of TB coughs, 18.54 minutes of COVID-19 coughs and 1.69 hours of healthy coughs from 47 TB patients, 229 COVID-19 patients and 1498 healthy patients and were used to train and evaluate a CNN, LSTM and Resnet50. These three deep architectures were also pre-trained on 2.14 hours of sneeze, 2.91 hours of speech and 2.79 hours of noise for improved performance. The class-imbalance in our dataset was addressed by using SMOTE data balancing technique and using performance metrics such as F1-score and AUC. Our study shows that the highest F1-scores of 0.9259 and 0.8631 have been achieved from a pre-trained Resnet50 for two- class (TB vs COVID-19) and three-class (TB vs COVID-19 vs healthy) cough classification tasks, respectively. The application of deep transfer learning has improved the classifiers' performance and makes them more robust as they generalise better over the cross-validation folds. Their performances exceed the TB triage test requirements set by the world health organisation (WHO). The features producing the best performance contain higher order of MFCCs suggesting that the differences between TB and COVID-19 coughs are not perceivable by the human ear. This type of cough audio classification is non-contact, cost-effective and can easily be deployed on a smartphone, thus it can be an excellent tool for both TB and COVID-19 screening."
Marsupial Walking-and-Flying Robotic Deployment for CollaborativeExploration of Unknown Environments,"Paolo DePetris, ShehryarKhattak, MihirDharmadhikari, GabrielWaibel, HuanNguyen, MarkusMontenegro, NikhilKhedekar, KostasAlexis, MarcoHutter",11 May 2022,Robotics (cs.RO)," This work contributes a marsupial robotic system-of-systems involving a legged and an aerial robot capable of collaborative mapping and exploration path planning that exploits the heterogeneous properties of the two systems and the ability to selectively deploy the aerial system from the ground robot. Exploiting the dexterous locomotion capabilities and long endurance of quadruped robots, the marsupial combination can explore within large-scale and confined environments involving rough terrain. However, as certain types of terrain or vertical geometries can render any ground system unable to continue its exploration, the marsupial system can - when needed - deploy the flying robot which, by exploiting its 3D navigation capabilities, can undertake a focused exploration task within its endurance limitations. Focusing on autonomy, the two systems can co-localize and map together by sharing LiDAR-based maps and plan exploration paths individually, while a tailored graph search onboard the legged robot allows it to identify where and when the ferried aerial platform should be deployed. The system is verified within multiple experimental studies demonstrating the expanded exploration capabilities of the marsupial system-of-systems and facilitating the exploration of otherwise individually unreachable areas."
Contrastive Supervised Distillation for Continual RepresentationLearning,"TommasoBarletti, Niccolo'Biondi, FedericoPernici, MatteoBruni, Alberto DelBimbo",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In this paper, we propose a novel training procedure for the continual representation learning problem in which a neural network model is sequentially learned to alleviate catastrophic forgetting in visual search tasks. Our method, called Contrastive Supervised Distillation (CSD), reduces feature forgetting while learning discriminative features. This is achieved by leveraging labels information in a distillation setting in which the student model is contrastively learned from the teacher model. Extensive experiments show that CSD performs favorably in mitigating catastrophic forgetting by outperforming current state-of-the-art methods. Our results also provide further evidence that feature forgetting evaluated in visual retrieval tasks is not as catastrophic as in classification tasks. Code at: [this https URL](https://github.com/NiccoBiondi/ContrastiveSupervisedDistillation)."
The Hijackers Guide To The Galaxy: Off-Path Taking Over InternetResources,"TianxiangDai, PhilippJeitner, HayaShulman, MichaelWaidner",11 May 2022,Cryptography and Security (cs.CR)," Internet resources form the basic fabric of the digital society. They provide the fundamental platform for digital services and assets, e.g., for critical infrastructures, financial services, government. Whoever controls that fabric effectively controls the digital society.   In this work we demonstrate that the current practices of Internet resources management, of IP addresses, domains, certificates and virtual platforms are insecure. Over long periods of time adversaries can maintain control over Internet resources which they do not own and perform stealthy manipulations, leading to devastating attacks. We show that network adversaries can take over and manipulate at least 68% of the assigned IPv4 address space as well as 31% of the top Alexa domains. We demonstrate such attacks by hijacking the accounts associated with the digital resources.   For hijacking the accounts we launch off-path DNS cache poisoning attacks, to redirect the password recovery link to the adversarial hosts. We then demonstrate that the adversaries can manipulate the resources associated with these accounts. We find all the tested providers vulnerable to our attacks.   We recommend mitigations for blocking the attacks that we present in this work. Nevertheless, the countermeasures cannot solve the fundamental problem - the management of the Internet resources should be revised to ensure that applying transactions cannot be done so easily and stealthily as is currently possible."
Generation of non-stationary stochastic fields using GenerativeAdversarial Networks with limited training data,"AlhasanAbdellatif, Ahmed H.Elsheikh, DanielBusby, PhilippeBerthet",11 May 2022,Machine Learning (cs.LG)," In the context of generating geological facies conditioned on observed data, samples corresponding to all possible conditions are not generally available in the training set and hence the generation of these realizations depends primary on the generalization capability of the trained generative model. The problem becomes more complex when applied on non- stationary fields. In this work, we investigate the problem of training Generative Adversarial Networks (GANs) models against a dataset of geological channelized patterns that has a few non-stationary spatial modes and examine the training and self-conditioning settings that improve the generalization capability at new spatial modes that were never seen in the given training set. The developed training method allowed for effective learning of the correlation between the spatial conditions (i.e. non- stationary maps) and the realizations implicitly without using additional loss terms or solving a costly optimization problem at the realization generation phase. Our models, trained on real and artificial datasets were able to generate geologically-plausible realizations beyond the training samples with a strong correlation with the target maps."
Utilizing coarse-grained data in low-data settings for eventextraction,OsmanMutlu,11 May 2022,Computation and Language (cs.CL)," Annotating text data for event information extraction systems is hard, expensive, and error-prone. We investigate the feasibility of integrating coarse-grained data (document or sentence labels), which is far more feasible to obtain, instead of annotating more documents. We utilize a multi-task model with two auxiliary tasks, document and sentence binary classification, in addition to the main task of token classification. We perform a series of experiments with varying data regimes for the aforementioned integration. Results show that while introducing extra coarse-grained data offers greater improvement and robustness, a gain is still possible with only the addition of negative documents that have no information on any event."
"A Continual Deepfake Detection Benchmark: Dataset, Methods, andEssentials","ChuqiaoLi, ZhiwuHuang, DandaPaniPaudel, Yabin Wang, MohamadShahbazi, XiaopengHong, Luc VanGool",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," There have been emerging a number of benchmarks and techniques for the detection of deepfakes. However, very few works study the detection of incrementally appearing deepfakes in the real-world scenarios. To simulate the wild scenes, this paper suggests a continual deepfake detection benchmark (CDDB) over a new collection of deepfakes from both known and unknown generative models. The suggested CDDB designs multiple evaluations on the detection over easy, hard, and long sequence of deepfake tasks, with a set of appropriate measures. In addition, we exploit multiple approaches to adapt multiclass incremental learning methods, commonly used in the continual visual recognition, to the continual deepfake detection problem. We evaluate several methods, including the adapted ones, on the proposed CDDB. Within the proposed benchmark, we explore some commonly known essentials of standard continual learning. Our study provides new insights on these essentials in the context of continual deepfake detection. The suggested CDDB is clearly more challenging than the existing benchmarks, which thus offers a suitable evaluation avenue to the future research. Our benchmark dataset and the source code will be made publicly available."
Raw Filtering of JSON Data on FPGAs,"TobiasHahn, AndreasBecher, StefanWildermann, Jürgen Teich",11 May 2022,Databases (cs.DB)," Many Big Data applications include the processing of data streams on semi-structured data formats such as JSON. A disadvantage of such formats is that an application may spend a significant amount of processing time just on unselectively parsing all data. To relax this issue, the concept of raw filtering is proposed with the idea to remove data from a stream prior to the costly parsing stage. However, as accurate filtering of raw data is often only possible after the data has been parsed, raw filters are designed to be approximate in the sense of allowing false-positives in order to be implemented efficiently.   Contrary to previously proposed CPU-based raw filtering techniques that are restricted to string matching, we present FPGA-based primitives for filtering strings, numbers and also number ranges. In addition, a primitive respecting the basic structure of JSON data is proposed that can be used to further increase the accuracy of introduced raw filters.   The proposed raw filter primitives are designed to allow for their composition according to a given filter expression of a query. Thus, complex raw filters can be created for FPGAs which enable a drastical decrease in the amount of generated false-positives, particularly for IoT workload.   As there exists a trade-off between accuracy and resource consumption, we evaluate primitives as well as composed raw filters using different queries from the RiotBench benchmark. Our results show that up to 94.3% of the raw data can be filtered without producing any observed false-positives using only a few hundred LUTs."
Making Pre-trained Language Models Good Long-tailed Learners,"ChenZhang, LeiRen, JingangWang, WeiWu, DaweiSong",11 May 2022,Computation and Language (cs.CL)," Prompt-tuning has shown appealing performance in few-shot classification by virtue of its capability in effectively exploiting pre- trained knowledge. This motivates us to check the hypothesis that prompt- tuning is also a promising choice for long-tailed classification, since the tail classes are intuitively few-shot ones. To achieve this aim, we conduct empirical studies to examine the hypothesis. The results demonstrate that prompt-tuning exactly makes pre-trained language models at least good long- tailed learners. For intuitions on why prompt-tuning can achieve good performance in long-tailed classification, we carry out an in-depth analysis by progressively bridging the gap between prompt-tuning and commonly used fine-tuning. The summary is that the classifier structure and parameterization form the key to making good long-tailed learners, in comparison with the less important input structure. Finally, we verify the applicability of our finding to few-shot classification."
Comparison of PAM-6 Modulations for Short-Reach Fiber-Optic Links withIntensity Modulation and Direct Detection,"TobiasPrinz, ThomasWiegart, DanielPlabst, TalhaRahman, MdSabbir-BinHossain, NebojšaStojanović, StefanoCalabrò, NorbertHanik, GerhardKramer",11 May 2022,Information Theory (cs.IT), PAM-6 transmission is considered for short-reach fiber-optic links with intensity modulation and direct detection. Experiments show that probabilistically-shaped PAM-6 and a framed-cross QAM-32 constellation outperform conventional cross QAM-32 under a peak power constraint.
Finite-Time Analysis of Constant Step-Size Q-Learning : SwitchingSystem Approach Revisited,DonghwnaLee,"11 May 2022 (v1(https://arxiv.org/abs/2205.05455v1)), lastrevised 12 May 2022 (this version, v2)",Systems and Control (eess.SY)," This technical note revisits the novel switching system framework in [1] for analyzing the finite-time convergence of Q-learning, where the dynamics of asynchronous Q-learning with a constant step-size is formulated as a discrete-time stochastic switching system model, and a bound on the average iteration is established based on Lyapunov functions. We improve the analysis in the previous paper by replacing the average iteration with the final iteration, which is simpler and more common in the literature. The proposed analysis relies on propagations of the autocorrelation matrix of the state instead of the Lyapunov function analysis. Moreover, we provide comparative analysis of the proposed method and existing approaches, and prove that the proposed approach improves the previous sample complexities in terms of the effective horizon. Besides, the proposed analysis offers additional insights on analysis of Q-learning and reinforcement learning, and complements existing approaches."
Experiments on Bipolar Transmission with Direct Detection,"ThomasWiegart, DanielPlabst, TobiasPrinz, TalhaRahman, MaximilianSchädler, NebojšaStojanović, StefanoCalabrò, NorbertHanik, GerhardKramer",11 May 2022,Information Theory (cs.IT), Achievable information rates of bipolar 4- and 8-ary constellations are experimentally compared to those of intensity modulation (IM) when using an oversampled direct detection receiver. The bipolar constellations gain up to 1.8 dB over their IM counterparts.
Detecting Emerging Technologies and their Evolution using DeepLearning and Weak Signal Analysis,"AshkanEbadi, AlainAuger, YvanGauthier",11 May 2022,Artificial Intelligence (cs.AI)," Emerging technologies can have major economic impacts and affect strategic stability. Yet, early identification of emerging technologies remains challenging. In order to identify emerging technologies in a timely and reliable manner, a comprehensive examination of relevant scientific and technological (S&T) trends and their related references is required. This examination is generally done by domain experts and requires significant amounts of time and effort to gain insights. The use of domain experts to identify emerging technologies from S&T trends may limit the capacity to analyse large volumes of information and introduce subjectivity in the assessments. Decision support systems are required to provide accurate and reliable evidence-based indicators through constant and continuous monitoring of the environment and help identify signals of emerging technologies that could alter security and economic prosperity. For example, the research field of hypersonics has recently witnessed several advancements having profound technological, commercial, and national security implications. In this work, we present a multi-layer quantitative approach able to identify future signs from scientific publications on hypersonics by leveraging deep learning and weak signal analysis. The proposed framework can help strategic planners and domain experts better identify and monitor emerging technology trends."
Symphony Generation with Permutation Invariant Language Model,"JiafengLiu, YuanliangDong, ZehuaCheng, XinranZhang, Xiaobing Li, Feng Yu, Maosong Sun",10 May 2022,Sound (cs.SD)," In this work, we present a symbolic symphony music generation solution, SymphonyNet, based on a permutation invariant language model. To bridge the gap between text generation and symphony generation task, we propose a novel Multi-track Multi-instrument Repeatable (MMR) representation with particular 3-D positional embedding and a modified Byte Pair Encoding algorithm (Music BPE) for music tokens. A novel linear transformer decoder architecture is introduced as a backbone for modeling extra-long sequences of symphony tokens. Meanwhile, we train the decoder to learn automatic orchestration as a joint task by masking instrument information from the input. We also introduce a large-scale symbolic symphony dataset for the advance of symphony generation research. Our empirical results show that our proposed approach can generate coherent, novel, complex and harmonious symphony compared to human composition, which is the pioneer solution for multi-track multi-instrument symbolic music generation."
"Predictive Compliance Monitoring in Process-Aware Information Systems:State of the Art, Functionalities, Research Directions","Stefanie Rinderle-Ma, KarolinWinter",10 May 2022,Software Engineering (cs.SE)," Business process compliance is a key area of business process management and aims at ensuring that processes obey to compliance constraints such as regulatory constraints or business rules imposed on them. Process compliance can be checked during process design time based on verification of process models and at runtime based on monitoring the compliance states of running process instances. For existing compliance monitoring approaches it remains unclear whether and how compliance violations can be predicted, although predictions are crucial in order to prepare and take countermeasures in time. This work, hence, analyzes existing literature from compliance and SLA monitoring as well as predictive process monitoring and provides an updated framework of compliance monitoring functionalities. For each compliance monitoring functionality we elicit prediction requirements and analyze their coverage by existing approaches. Based on this analysis, open challenges and research directions for predictive compliance and process monitoring are elaborated."
Injection Attacks Reloaded: Tunnelling Malicious Payloads over DNS,"PhilippJeitner, HayaShulman",11 May 2022,Cryptography and Security (cs.CR)," The traditional design principle for Internet protocols indicates: ""Be strict when sending and tolerant when receiving"" [RFC1958], and DNS is no exception to this. The transparency of DNS in handling the DNS records, also standardised specifically for DNS [RFC3597], is one of the key features that made it such a popular platform facilitating a constantly increasing number of new applications. An application simply creates a new DNS record and can instantly start distributing it over DNS without requiring any changes to the DNS servers and platforms. Our Internet wide study confirms that more than 1.3M (96% of tested) open DNS resolvers are standard compliant and treat DNS records transparently.   In this work we show that this `transparency' introduces a severe vulnerability in the Internet: we demonstrate a new method to launch string injection attacks by encoding malicious payloads into DNS records. We show how to weaponise such DNS records to attack popular applications. For instance, we apply string injection to launch a new type of DNS cache poisoning attack, which we evaluated against a population of open resolvers and found 105K to be vulnerable. Such cache poisoning cannot be prevented with common setups of DNSSEC. Our attacks apply to internal as well as to public services, for instance, we reveal that all eduroam services are vulnerable to our injection attacks, allowing us to launch exploits ranging from unauthorised access to eduroam networks to resource starvation. Depending on the application, our attacks cause system crashes, data corruption and leakage, degradation of security, and can introduce remote code execution and arbitrary errors.   In our evaluation of the attacks in the Internet we find that all the standard compliant open DNS resolvers we tested allow our injection attacks against applications and users on their networks."
Building for Tomorrow: Assessing the Temporal Persistence of TextClassifiers,"RababAlkhalifa, ElenaKochkina, ArkaitzZubiaga",11 May 2022,Computation and Language (cs.CL)," Performance of text classification models can drop over time when new data to be classified is more distant in time from the data used for training, due to naturally occurring changes in the data, such as vocabulary change. A solution to this is to continually label new data to retrain the model, which is, however, often unaffordable to be performed regularly due to its associated cost. This raises important research questions on the design of text classification models that are intended to persist over time: do all embedding models and classification algorithms exhibit similar performance drops over time and is the performance drop more prominent in some tasks or datasets than others? With the aim of answering these research questions, we perform longitudinal classification experiments on three datasets spanning between 6 and 19 years. Findings from these experiments inform the design of text classification models with the aim of preserving performance over time, discussing the extent to which one can rely on classification models trained from temporally distant training data, as well as how the characteristics of the dataset impact this."
A polynomial time algorithm for local testability and its level,A.N.Trahtman,11 May 2022,Formal Languages and Automata Theory (cs.FL)," A locally testable semigroup S is a semigroup with the property that for some nonnegative integer k, called the order or level of local testability, two words u and v in some set of generators for semigroup S are equal in the semigroup if (1) the prefix and suffix of the words of length k coincide, and (2) the set of intermediate substrings of length k of the words coincide. The local testability problem for semigroups is, given a finite semigroup, to decide, if the semigroup is locally testable or not. Recently, we introduced a polynomial time algorithm for the local testability problem and to find the level of local testability for semigroups based on our previous description of identities of $k$-testable semigroups and the structure of locally testable semigroups. The first part of the algorithm we introduce solves the local testability problem. The second part of the algorithm finds the order of local testability of a semigroup. The algorithm is of quadratic order where n is the order of the semigroup."
"ALIGNMEET: A Comprehensive Tool for Meeting Annotation, Alignment, andEvaluation","PeterPolák, MuskaanSingh, AnnaNedoluzhko, Ondřej Bojar",11 May 2022,Computation and Language (cs.CL)," Summarization is a challenging problem, and even more challenging is to manually create, correct, and evaluate the summaries. The severity of the problem grows when the inputs are multi-party dialogues in a meeting setup. To facilitate the research in this area, we present ALIGNMEET, a comprehensive tool for meeting annotation, alignment, and evaluation. The tool aims to provide an efficient and clear interface for fast annotation while mitigating the risk of introducing errors. Moreover, we add an evaluation mode that enables a comprehensive quality evaluation of meeting minutes. To the best of our knowledge, there is no such tool available. We release the tool as open source. It is also directly installable from PyPI."
Learning a Better Control Barrier Function,"BolunDai, PrashanthKrishnamurthy, FarshadKhorrami",11 May 2022,Systems and Control (eess.SY)," Control barrier functions (CBF) are widely used in safety-critical controllers. However, the construction of valid CBFs is well known to be challenging, especially for nonlinear or non-convex constraints and high relative degree systems. On the other hand, finding a conservative CBF that only recovers a portion of the true safe set is usually possible. In this work, starting from a ""conservative"" handcrafted control barrier function (HCBF), we develop a method to find a control barrier function that recovers a reasonably larger portion of the safe set. Using a different approach, by incorporating the hard constraints into an optimal control problem, e.g., MPC, we can safely generate solutions within the true safe set. Nevertheless, such an approach is usually computationally expensive and may not lend itself to real-time implementations. We propose to combine the two methods. During training, we utilize MPC to collect safe trajectory data. Thereafter, we train a neural network to estimate the difference between the HCBF and the CBF that recovers a closer solution to the true safe set. Using the proposed approach, we can generate a safe controller that is less conservative and computationally efficient. We validate our approach on three systems: a second-order integrator, ball-on-beam, and unicycle."
RustSEG -- Automated segmentation of corrosion using deep learning,"B.Burton, W.T. Nash, N.Birbilis",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The inspection of infrastructure for corrosion remains a task that is typically performed manually by qualified engineers or inspectors. This task of inspection is laborious, slow, and often requires complex access. Recently, deep learning based algorithms have revealed promise and performance in the automatic detection of corrosion. However, to date, research regarding the segmentation of images for automated corrosion detection has been limited, due to the lack of availability of per-pixel labelled data sets which are required for model training. Herein, a novel deep learning approach (termed RustSEG) is presented, that can accurately segment images for automated corrosion detection, without the requirement of per-pixel labelled data sets for training. The RustSEG method will first, using deep learning techniques, determine if corrosion is present in an image (i.e. a classification task), and then if corrosion is present, the model will examine what pixels in the original image contributed to that classification decision. Finally, the method can refine its predictions into a pixel-level segmentation mask. In ideal cases, the method is able to generate precise masks of corrosion in images, demonstrating that the automated segmentation of corrosion without per-pixel training data is possible, addressing a significant hurdle in automated infrastructure inspection."
"""If it didn't happen, why would I change my decision?"": How JudgesRespond to Counterfactual Explanations for the Public Safety Assessment","YanivYacoby, BenGreen, Christopher L.Griffin, Finale DoshiVelez",11 May 2022,Human-Computer Interaction (cs.HC)," Researchers and policymakers are interested in algorithmic explanations as a mechanism for enabling more fair and responsible decision- making. In this study, we shed light on how judges interpret and respond to algorithmic explanations in the context of pretrial risk assessment instruments (PRAI). We found that, at first, all judges misinterpreted the counterfactuals in the explanations as real -- rather than hypothetical -- changes to defendants' criminal history profiles. Once judges understood the counterfactuals, they ignored them, preferring to make decisions based solely on the actual details of the defendant in question. Our findings suggest that using (at least this kind of) explanations to improve human and AI collaboration is not straightforward."
Multi-Label Logo Recognition and Retrieval based on Weighted Fusion ofNeural Features,"MarisaBernabeu, Antonio JavierGallego, AntonioPertusa",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Logo classification is a particular case of image classification, since these may contain only text, images, or a combination of both. In this work, we propose a system for the multi-label classification and similarity search of logo images. The method allows obtaining the most similar logos on the basis of their shape, color, business sector, semantics, general characteristics, or a combination of such features established by the user. This is done by employing a set of multi-label networks specialized in certain characteristics of logos. The features extracted from these networks are combined to perform the similarity search according to the search criteria established. Since the text of logos is sometimes irrelevant for the classification, a preprocessing stage is carried out to remove it, thus improving the overall performance. The proposed approach is evaluated using the European Union Trademark (EUTM) dataset, structured with the hierarchical Vienna classification system, which includes a series of metadata with which to index trademarks. We also make a comparison between well known logo topologies and Vienna in order to help designers understand their correspondences. The experimentation carried out attained reliable performance results, both quantitatively and qualitatively, which outperformed the state-of-the-art results. In addition, since the semantics and classification of brands can often be subjective, we also surveyed graphic design students and professionals in order to assess the reliability of the proposed method."
Recommending Research Papers to Chemists: A Specialized Interface forChemical Entity Exploration,"CorinnaBreitinger, KayHerklotz, TimFlegelskamp, NormanMeuschke",11 May 2022,Information Retrieval (cs.IR)," Researchers and scientists increasingly rely on specialized information retrieval (IR) or recommendation systems (RS) to support them in their daily research tasks. Paper recommender systems are one such tool scientists use to stay on top of the ever-increasing number of academic publications in their field. Improving research paper recommender systems is an active research field. However, less research has focused on how the interfaces of research paper recommender systems can be tailored to suit the needs of different research domains. For example, in the field of biomedicine and chemistry, researchers are not only interested in textual relevance but may also want to discover or compare the contained chemical entity information found in a paper's full text. Existing recommender systems for academic literature do not support the discovery of this non- textual, but semantically valuable, chemical entity data. We present the first implementation of a specialized chemistry paper recommender system capable of visualizing the contained chemical structures, chemical formulae, and synonyms for chemical compounds within the document's full text. We review existing tools and related research in this field before describing the implementation of our ChemVis system. With the help of chemists, we are expanding the functionality of ChemVis, and will perform an evaluation of recommendation performance and usability in future work."
Compact and Efficient NTRU-based KEM with Scalable CiphertextCompression,"ZhichuangLiang, BoyueFang, JieyuZheng, Yunlei Zhao",11 May 2022,Cryptography and Security (cs.CR)," The NTRU lattice is a promising candidate to construct practical cryptosystems resistant to quantum computing attacks, and particularly plays a leading role in the ongoing NIST post-quantum cryptography standardization. On the one hand, it is benefited from a strong security guarantee since it has essentially not been broken over 24 years. On the other hand, all the known patent threats against NTRU have expired, which is deemed a critical factor for consideration when deploying PQC algorithms in reality. Nevertheless, there are still some obstacles to the computational efficiency and bandwidth complexity of NTRU-based constructions of key encapsulation mechanisms (KEM). To address these issues, we propose a compact and efficient KEM based on the NTRU lattice, called CTRU, by introducing a scalable ciphertext compression technique. It demonstrates a new approach to decrypting NTRU ciphertext, where the plaintext message is recovered with the aid of our decoding algorithm in the scalable ${E}_8$ lattice. The instantiation of CTRU is over the NTT-friendly rings of the form $\mathbb{Z}_q[x]/(x^{n}-x^{n/2}+1)$. To our knowledge, our CTRU is the most bandwidth efficient KEM based on the NTRU lattice up to now. In addition, compared to other NTRU-based KEM schemes, CTRU has stronger security against known attacks, enjoys more robust CCA security reduction (starting from IND-CPA rather than OW-CPA), and its encapsulation and decapsulation processes are also among the most efficient. When compared to the NIST Round 3 finalist NTRU-HRSS, our CTRU-768 has $15\%$ smaller ciphertext size and its security is strengthened by $(45,40)$ bits for classical and quantum security respectively. When compared to the NIST Round 3 finalist Kyber that is based on the Module-LWE assumption, CTRU has both smaller bandwidth and lower error probabilities at about the same security level."
An Objective Method for Pedestrian Occlusion Level Classification,"ShaneGilroy, MartinGlavin, EdwardJones, DarraghMullins",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Pedestrian detection is among the most safety-critical features of driver assistance systems for autonomous vehicles. One of the most complex detection challenges is that of partial occlusion, where a target object is only partially available to the sensor due to obstruction by another foreground object. A number of current pedestrian detection benchmarks provide annotation for partial occlusion to assess algorithm performance in these scenarios, however each benchmark varies greatly in their definition of the occurrence and severity of occlusion. In addition, current occlusion level annotation methods contain a high degree of subjectivity by the human annotator. This can lead to inaccurate or inconsistent reporting of an algorithm's detection performance for partially occluded pedestrians, depending on which benchmark is used. This research presents a novel, objective method for pedestrian occlusion level classification for ground truth annotation. Occlusion level classification is achieved through the identification of visible pedestrian keypoints and through the use of a novel, effective method of 2D body surface area estimation. Experimental results demonstrate that the proposed method reflects the pixel-wise occlusion level of pedestrians in images and is effective for all forms of occlusion, including challenging edge cases such as self-occlusion, truncation and inter-occluding pedestrians."
Knowledge-powered Explainable Artificial Intelligence (XAI) forNetwork Automation Towards 6G,"YuleiWu, GuozhiLin, JingguoGe",11 May 2022,Networking and Internet Architecture (cs.NI)," Communication networks are becoming increasingly complex towards 6G. Manual management is no longer an option for network operators. Network automation has been widely discussed in the networking community, and it is a sensible means to manage the complex communication network. Deep learning models developed to enable network automation for given operation practices have the limitations of 1) lack of explainability and 2) inapplicable across different networks and/or network settings. To tackle the above issues, in this article we propose a new knowledge-powered framework that provides a human-understandable explainable artificial intelligence (XAI) agent for network automation. A case study of path selection is developed to demonstrate the feasibility of the proposed framework. Research on network automation is still in its infancy. Therefore, at the end of this article, we provide a list of challenges and open issues that can guide further research in this important area."
Recurrent Encoder-Decoder Networks for Vessel Trajectory Predictionwith Uncertainty Estimation,"SamueleCapobianco, NicolaForti, Leonardo M.Millefiori, Paolo Braca, PeterWillett",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Recent deep learning methods for vessel trajectory prediction are able to learn complex maritime patterns from historical Automatic Identification System (AIS) data and accurately predict sequences of future vessel positions with a prediction horizon of several hours. However, in maritime surveillance applications, reliably quantifying the prediction uncertainty can be as important as obtaining high accuracy. This paper extends deep learning frameworks for trajectory prediction tasks by exploring how recurrent encoder-decoder neural networks can be tasked not only to predict but also to yield a corresponding prediction uncertainty via Bayesian modeling of epistemic and aleatoric uncertainties. We compare the prediction performance of two different models based on labeled or unlabeled input data to highlight how uncertainty quantification and accuracy can be improved by using, if available, additional information on the intention of the ship (e.g., its planned destination)."
Uptime-Optimized Cloud Architecture as a Brokered Service,"SreekrishnanVenkateswaran, SantonuSarkar",11 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Enterprise workloads usually call for an uptime service level agreement (SLA) at the pain of contractual penalty in the event of slippage. Often, the strategy is to introduce ad-hoc HA (High Availability) mechanisms in response. Implemented solutions that we surveyed do not mathematically map their availability model to the required uptime SLA and to any expected penalty payout. In most client cases that we observed, this either resulted in an over-engineered solution that had more redundancies than was required, or in an inadequate solution that could potentially slip on the system uptime SLA stipulated in the contract. In this paper, we propose a framework backed by a model, to automatically determine the HA-enabled solution with the least TCO (total cost of ownership) for a given uptime SLA and slippage penalty. We attempt to establish that our work is best implemented as a brokered service that recommends an uptime-optimized cloud architecture."
Stochastic Variational Smoothed Model Checking,"LucaBortolussi, FrancescaCairoli, GinevraCarbone, PaoloPulcini",11 May 2022,Machine Learning (cs.LG)," Model-checking for parametric stochastic models can be expressed as checking the satisfaction probability of a certain property as a function of the parameters of the model. Smoothed model checking (smMC) leverages Gaussian Processes (GP) to infer the satisfaction function over the entire parameter space from a limited set of observations obtained via simulation. This approach provides accurate reconstructions with statistically sound quantification of the uncertainty. However, it inherits the scalability issues of GP. In this paper, we exploit recent advances in probabilistic machine learning to push this limitation forward, making Bayesian inference of smMC scalable to larger datasets, enabling its application to larger models in terms of the dimension of the parameter set. We propose Stochastic Variational Smoothed Model Checking (SV-smMC), a solution that exploits stochastic variational inference (SVI) to approximate the posterior distribution of the smMC problem. The strength and flexibility of SVI make SV-smMC applicable to two alternative probabilistic models: Gaussian Processes (GP) and Bayesian Neural Networks (BNN). Moreover, SVI makes inference easily parallelizable and it enables GPU acceleration. In this paper, we compare the performances of smMC against those of SV-smMC by looking at the scalability, the computational efficiency and at the accuracy of the reconstructed satisfaction function."
A Survey on Fairness for Machine Learning on Graphs,"ManviChoudhary, CharlotteLaclau, ChristineLargeron",11 May 2022,Machine Learning (cs.LG)," Nowadays, the analysis of complex phenomena modeled by graphs plays a crucial role in many real-world application domains where decisions can have a strong societal impact. However, numerous studies and papers have recently revealed that machine learning models could lead to potential disparate treatment between individuals and unfair outcomes. In that context, algorithmic contributions for graph mining are not spared by the problem of fairness and present some specific challenges related to the intrinsic nature of graphs: (1) graph data is non-IID, and this assumption may invalidate many existing studies in fair machine learning, (2) suited metric definitions to assess the different types of fairness with relational data and (3) algorithmic challenge on the difficulty of finding a good trade-off between model accuracy and fairness. This survey is the first one dedicated to fairness for relational data. It aims to present a comprehensive review of state-of-the-art techniques in fairness on graph mining and identify the open challenges and future trends. In particular, we start by presenting several sensible application domains and the associated graph mining tasks with a focus on edge prediction and node classification in the sequel. We also recall the different metrics proposed to evaluate potential bias at different levels of the graph mining process; then we provide a comprehensive overview of recent contributions in the domain of fair machine learning for graphs, that we classify into pre-processing, in- processing and post-processing models. We also propose to describe existing graph data, synthetic and real-world benchmarks. Finally, we present in detail five potential promising directions to advance research in studying algorithmic fairness on graphs."
CVTT: Cross-Validation Through Time,"SergeyKolesnikov, MikhailAndronov",11 May 2022,Machine Learning (cs.LG)," The practical aspects of evaluating recommender systems is an actively discussed topic in the research community. While many current evaluation techniques bring performance down to a single-value metric as a straightforward approach for model comparison, it is based on a strong assumption of the methods' stable performance over time. In this paper, we argue that leaving out a method's continuous performance can lead to losing valuable insight into joint data-method effects. We propose the Cross- Validation Thought Time (CVTT) technique to perform more detailed evaluations, which focus on model cross-validation performance over time. Using the proposed technique, we conduct a detailed analysis of popular RecSys algorithms' performance against various metrics and datasets. We also compare several data preparation and evaluation strategies to analyze their impact on model performance. Our results show that model performance can vary significantly over time, and both data and evaluation setup can have a marked effect on it."
Algebraic Presentation of Semifree Monads,"AloïsRosset, Helle HvidHansen, JörgEndrullis",11 May 2022,Logic in Computer Science (cs.LO)," Monads and their composition via distributive laws have many applications in program semantics and functional programming. For many interesting monads, distributive laws fail to exist, and this has motivated investigations into weaker notions. In this line of research, Petrişan and Sarkis recently introduced a construction called the semifree monad in order to study semialgebras for a monad and weak distributive laws. In this paper, we prove that an algebraic presentation of the semifree monad M^s on a monad M can be obtained uniformly from an algebraic presentation of M. This result was conjectured by Petrişan and Sarkis. We also show that semifree monads are ideal monads, that the semifree construction is not a monad transformer, and that the semifree construction is a comonad on the category of monads."
Query-Based Keyphrase Extraction from Long Documents,"MartinDocekal, Pavel Smrz",11 May 2022,Computation and Language (cs.CL)," Transformer-based architectures in natural language processing force input size limits that can be problematic when long documents need to be processed. This paper overcomes this issue for keyphrase extraction by chunking the long documents while keeping a global context as a query defining the topic for which relevant keyphrases should be extracted. The developed system employs a pre-trained BERT model and adapts it to estimate the probability that a given text span forms a keyphrase. We experimented using various context sizes on two popular datasets, Inspec and SemEval, and a large novel dataset. The presented results show that a shorter context with a query overcomes a longer one without the query on long documents."
AutoKE: An automatic knowledge embedding framework for scientificmachine learning,"MenggeDu, YuntianChen, DongxiaoZhang",11 May 2022,Machine Learning (cs.LG)," Imposing physical constraints on neural networks as a method of knowledge embedding has achieved great progress in solving physical problems described by governing equations. However, for many engineering problems, governing equations often have complex forms, including complex partial derivatives or stochastic physical fields, which results in significant inconveniences from the perspective of implementation. In this paper, a scientific machine learning framework, called AutoKE, is proposed, and a reservoir flow problem is taken as an instance to demonstrate that this framework can effectively automate the process of embedding physical knowledge. In AutoKE, an emulator comprised of deep neural networks (DNNs) is built for predicting the physical variables of interest. An arbitrarily complex equation can be parsed and automatically converted into a computational graph through the equation parser module, and the fitness of the emulator to the governing equation is evaluated via automatic differentiation. Furthermore, the fixed weights in the loss function are substituted with adaptive weights by incorporating the Lagrangian dual method. Neural architecture search (NAS) is also introduced into the AutoKE to select an optimal network architecture of the emulator according to the specific problem. Finally, we apply transfer learning to enhance the scalability of the emulator. In experiments, the framework is verified by a series of physical problems in which it can automatically embed physical knowledge into an emulator without heavy hand-coding. The results demonstrate that the emulator can not only make accurate predictions, but also be applied to similar problems with high efficiency via transfer learning."
Machine Learning to Support Triage of Children at Risk for EpilepticSeizures in the Pediatric Intensive Care Unit,"RaphaelAzriel, Cecil D.Hahn, Thomas DeCooman, Sabine VanHuffel, Eric T.Payne, Kristin L.McBain, Danny Eytan, Joachim A.Behar",11 May 2022,Machine Learning (cs.LG)," Objective: Epileptic seizures are relatively common in critically- ill children admitted to the pediatric intensive care unit (PICU) and thus serve as an important target for identification and treatment. Most of these seizures have no discernible clinical manifestation but still have a significant impact on morbidity and mortality. Children that are deemed at risk for seizures within the PICU are monitored using continuous- electroencephalogram (cEEG). cEEG monitoring cost is considerable and as the number of available machines is always limited, clinicians need to resort to triaging patients according to perceived risk in order to allocate resources. This research aims to develop a computer aided tool to improve seizures risk assessment in critically-ill children, using an ubiquitously recorded signal in the PICU, namely the electrocardiogram (ECG). Approach: A novel data-driven model was developed at a patient-level approach, based on features extracted from the first hour of ECG recording and the clinical data of the patient. Main results: The most predictive features were the age of the patient, the brain injury as coma etiology and the QRS area. For patients without any prior clinical data, using one hour of ECG recording, the classification performance of the random forest classifier reached an area under the receiver operating characteristic curve (AUROC) score of 0.84. When combining ECG features with the patients clinical history, the AUROC reached 0.87. Significance: Taking a real clinical scenario, we estimated that our clinical decision support triage tool can improve the positive predictive value by more than 59% over the clinical standard."
A game comonadic account of Courcelle and Feferman-Vaught-Mostowskitheorems,"TomášJakl, DanMarsden, Nihil Shah",11 May 2022,Logic in Computer Science (cs.LO)," Game comonads, introduced by Abramsky, Dawar and Wang, and developed by Abramsky and Shah, give a categorical semantics for model comparison games. We present an axiomatic account of Feferman-Vaught- Mostowski (FVM) composition theorems within the game comonad framework, parameterized by the model comparison game. In a uniform way, we produce compositionality results for the logic in question, and its positive existential and counting quantifier variants.   Secondly, we extend game comonads to the second order setting, specifically in the case of Monadic Second Order (MSO) logic. We then generalize our FVM theorems to the second order case. We conclude with an abstract formulation of Courcelle's algorithmic meta-theorem, exploiting our earlier developments. This is instantiated to recover well-known bounded tree-width and bounded clique-width Courcelle theorems for MSO on graphs."
Automated differential equation solver based on the parametricapproximation optimization,"AlexanderHvatov, TatianaTikhonova",11 May 2022,Numerical Analysis (math.NA)," The numerical methods for differential equation solution allow obtaining a discrete field that converges towards the solution if the method is applied to the correct problem. Nevertheless, the numerical methods have the restricted class of the equations, on which the convergence with a given parameter set or range is proved. Only a few ""cheap and dirty"" numerical methods converge on a wide class of equations without parameter tuning with the lower approximation order price. The article presents a method that uses an optimization algorithm to obtain a solution using the parameterized approximation. The result may not be as precise as an expert one. However, it allows solving the wide class of equations in an automated manner without the algorithm's parameters change."
AutoLC: Search Lightweight and Top-Performing Architecture for RemoteSensing Image Land-Cover Classification,"ChenyuZheng, Junjue Wang, Ailong Ma, Yanfei Zhong",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Land-cover classification has long been a hot and difficult challenge in remote sensing community. With massive High-resolution Remote Sensing (HRS) images available, manually and automatically designed Convolutional Neural Networks (CNNs) have already shown their great latent capacity on HRS land-cover classification in recent years. Especially, the former can achieve better performance while the latter is able to generate lightweight architecture. Unfortunately, they both have shortcomings. On the one hand, because manual CNNs are almost proposed for natural image processing, it becomes very redundant and inefficient to process HRS images. On the other hand, nascent Neural Architecture Search (NAS) techniques for dense prediction tasks are mainly based on encoder-decoder architecture, and just focus on the automatic design of the encoder, which makes it still difficult to recover the refined mapping when confronting complicated HRS scenes.   To overcome their defects and tackle the HRS land-cover classification problems better, we propose AutoLC which combines the advantages of two methods. First, we devise a hierarchical search space and gain the lightweight encoder underlying gradient-based search strategy. Second, we meticulously design a lightweight but top-performing decoder that is adaptive to the searched encoder of itself. Finally, experimental results on the LoveDA land-cover dataset demonstrate that our AutoLC method outperforms the state-of-art manual and automatic methods with much less computational consumption."
Pre-trained Language Models as Re-Annotators,ChangShu,11 May 2022,Computation and Language (cs.CL)," Annotation noise is widespread in datasets, but manually revising a flawed corpus is time-consuming and error-prone. Hence, given the prior knowledge in Pre-trained Language Models and the expected uniformity across all annotations, we attempt to reduce annotation noise in the corpus through two tasks automatically: (1) Annotation Inconsistency Detection that indicates the credibility of annotations, and (2) Annotation Error Correction that rectifies the abnormal annotations.   We investigate how to acquire semantic sensitive annotation representations from Pre-trained Language Models, expecting to embed the examples with identical annotations to the mutually adjacent positions even without fine- tuning. We proposed a novel credibility score to reveal the likelihood of annotation inconsistencies based on the neighbouring consistency. Then, we fine-tune the Pre-trained Language Models based classifier with cross- validation for annotation correction. The annotation corrector is further elaborated with two approaches: (1) soft labelling by Kernel Density Estimation and (2) a novel distant-peer contrastive loss.   We study the re-annotation in relation extraction and create a new manually revised dataset, Re-DocRED, for evaluating document-level re-annotation. The proposed credibility scores show promising agreement with human revisions, achieving a Binary F1 of 93.4 and 72.5 in detecting inconsistencies on TACRED and DocRED respectively. Moreover, the neighbour-aware classifiers based on distant-peer contrastive learning and uncertain labels achieve Macro F1 up to 66.2 and 57.8 in correcting annotations on TACRED and DocRED respectively. These improvements are not merely theoretical: Rather, automatically denoised training sets demonstrate up to 3.6% performance improvement for state-of-the-art relation extraction models."
Improved maximin fair allocation of indivisible items to three agents,"UrielFeige, AlexeyNorkin",11 May 2022,Computer Science and Game Theory (cs.GT)," We consider the problem of approximate maximin share (MMS) allocation of indivisible items among three agents with additive valuation functions. For goods, we show that an $\frac{11}{12}$ - MMS allocation always exists, improving over the previously known bound of $\frac{8}{9}$ . Moreover, in our allocation, we can prespecify an agent that is to receive her full proportional share (PS); we also present examples showing that for such allocations the ratio of $\frac{11}{12}$ is best possible. For chores, we show that a $\frac{19}{18}$-MMS allocation always exists. Also in this case, we can prespecify an agent that is to receive no more than her PS, and we present examples showing that for such allocations the ratio of $\frac{19}{18}$ is best possible."
Reducing a complex two-sided smartwatch examination for Parkinson'sDisease to an efficient one-sided examination preserving machine learningaccuracy,"AlexanderBrenner, MichaelFujarski, TobiasWarnecke, JulianVarghese",11 May 2022,Machine Learning (cs.LG)," Sensors from smart consumer devices have demonstrated high potential to serve as digital biomarkers in the identification of movement disorders in recent years. With the usage of broadly available smartwatches we have recorded participants performing technology-based assessments in a prospective study to research Parkinson's Disease (PD). In total, 504 participants, including PD patients, differential diagnoses (DD) and healthy controls (HC), were captured with a comprehensive system utilizing two smartwatches and two smartphones. To the best of our knowledge, this study provided the largest PD sample size of two-hand synchronous smartwatch measurements. To establish a future easy-to use home-based assessment system in PD screening, we systematically evaluated the performance of the system based on a significantly reduced set of assessments with only one-sided measures and assessed, whether we can maintain classification accuracy."
A Comprehensive Survey of Automated Audio Captioning,"XuenanXu, MengyueWu, KaiYu",11 May 2022,Sound (cs.SD)," Automated audio captioning, a task that mimics human perception as well as innovatively links audio processing and natural language processing, has overseen much progress over the last few years. Audio captioning requires recognizing the acoustic scene, primary audio events and sometimes the spatial and temporal relationship between events in an audio clip. It also requires describing these elements by a fluent and vivid sentence. Deep learning-based approaches are widely adopted to tackle this problem. This current paper situates itself as a comprehensive review covering the benchmark datasets, existing deep learning techniques and the evaluation metrics in automated audio captioning."
Human-Robot Interface to Operate Robotic Systems via Muscle Synergy-Based Kinodynamic Information Transfer,"JanghyeonKim, Dae HanSim, Ho-JinJung, Ji-Hyeon Yoo, Changjae Lee, Han Ul Yoon",11 May 2022,Robotics (cs.RO)," When a human performs a given specific task, it has been known that the central nervous system controls modularized muscle group, which is called muscle synergy. For human-robot interface design problem, therefore, the muscle synergy can be utilized to reduce the dimensionality of control signal as well as the complexity of classifying human posture and motion. In this paper, we propose an approach to design a human-robot interface which enables a human operator to transfer a kinodynamic control command to robotic systems. A key feature of the proposed approach is that the muscle synergy and corresponding activation curve are employed to calculate a force generated by a tool at the robot end effector. A test bed for experiments consisted of two armband type surface electromyography sensors, an RGB-d camera, and a Kinova Gen2 robotic manipulator to verify the proposed approach. The result showed that both force and position commands could be successfully transferred to the robotic manipulator via our muscle synergy- based kinodynamic interface."
NDGGNET-A Node Independent Gate based Graph Neural Networks,"YeTang, XuesongYang, XinruiLiu, XiweiZhao, Zhangang Lin, ChangpingPeng",11 May 2022,Machine Learning (cs.LG)," Graph Neural Networks (GNNs) is an architecture for structural data, and has been adopted in a mass of tasks and achieved fabulous results, such as link prediction, node classification, graph classification and so on. Generally, for a certain node in a given graph, a traditional GNN layer can be regarded as an aggregation from one-hop neighbors, thus a set of stacked layers are able to fetch and update node status within multi-hops. For nodes with sparse connectivity, it is difficult to obtain enough information through a single GNN layer as not only there are only few nodes directly connected to them but also can not propagate the high-order neighbor information. However, as the number of layer increases, the GNN model is prone to over-smooth for nodes with the dense connectivity, which resulting in the decrease of accuracy. To tackle this issue, in this thesis, we define a novel framework that allows the normal GNN model to accommodate more layers. Specifically, a node-degree based gate is employed to adjust weight of layers dynamically, that try to enhance the information aggregation ability and reduce the probability of over-smoothing. Experimental results show that our proposed model can effectively increase the model depth and perform well on several datasets."
"An Efficient Summation Algorithm for the Accuracy, Convergence andReproducibility of Parallel Numerical Methods","FarahBenmouhoub, Pierre-LoïcGaroche, MatthieuMartel",11 May 2022,Computation and Language (cs.CL)," Nowadays, parallel computing is ubiquitous in several application fields, both in engineering and science. The computations rely on the floating-point arithmetic specified by the IEEE754 Standard. In this context, an elementary brick of computation, used everywhere, is the sum of a sequence of numbers. This sum is subject to many numerical errors in floating-point arithmetic. To alleviate this issue, we have introduced a new parallel algorithm for summing a sequence of floating-point numbers. This algorithm which scales up easily with the number of processors, adds numbers of the same exponents first. In this article, our main contribution is an extensive analysis of its efficiency with respect to several properties: accuracy, convergence and reproducibility. In order to show the usefulness of our algorithm, we have chosen a set of representative numerical methods which are Simpson, Jacobi, LU factorization and the Iterated power method."
Deep Depth Completion: A Survey,"JunjieHu, ChenyuBao, MeteOzay, ChenyouFan, QingGao, HonghaiLiu, Tin LunLam",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Depth completion aims at predicting dense pixel-wise depth from a sparse map captured from a depth sensor. It plays an essential role in various applications such as autonomous driving, 3D reconstruction, augmented reality, and robot navigation. Recent successes on the task have been demonstrated and dominated by deep learning based solutions. In this article, for the first time, we provide a comprehensive literature review that helps readers better grasp the research trends and clearly understand the current advances. We investigate the related studies from the design aspects of network architectures, loss functions, benchmark datasets, and learning strategies with a proposal of a novel taxonomy that categorizes existing methods. Besides, we present a quantitative comparison of model performance on two widely used benchmark datasets, including an indoor and an outdoor dataset. Finally, we discuss the challenges of prior works and provide readers with some insights for future research directions."
Collaborative Multi-Radars Tracking by Distributed Auctions,"PierreLarrenie, Cédric Buron, FrédéricBarbaresco",11 May 2022,Multiagent Systems (cs.MA)," In this paper, we present an algorithm which lies in the domain of task allocation for a set of static autonomous radars with rotating antennas. It allows a set of radars to allocate in a fully decentralized way a set of active tracking tasks according to their location, considering that a target can be tracked by several radars, in order to improve accuracy with which the target is tracked. The allocation algorithm proceeds through a collaborative and fully decentralized auction protocol, using a collaborative auction protocol (Consensus Based Bundle Auction algorithm). Our algorithm is based on a double use of our allocation protocol among the radars. The latter begin by allocating targets, then launch a second round of allocation if theyhave resources left, in order to improve accuracy on targets already tracked. Our algorithm is also able to adapt to dynamism, i.e. to take into account the fact that the targets are moving and that the radar(s) most suitable for Tracking them changes as the mission progresses. To do this, the algorithm is restarted on a regular basis, to ensure that a bid made by a radar can decrease when the target moves away from it. Since our algorithm is based on collaborative auctions, it does not plan the following rounds, assuming that the targets are not predictable enough for this. Our algorithm is however based on radars capable of anticipating the positions of short-term targets, thanks to a Kalman filter. The algorithm will be illustrated based on a multi-radar tracking scenario where the radars, autonomous, must follow a set of targets in order to reduce the position uncertainty of the targets. Standby aspects will not be considered in this scenario. It is assumed that the radars can pick up targets in active pursuit, with an area ofuncertainty corresponding to their distance."
Implementation and Empirical Evaluation of a Quantum Machine LearningPipeline for Local Classification,"EnricoZardini, EnricoBlanzieri, DavidePastorello",11 May 2022,Emerging Technologies (cs.ET)," In the current era, quantum resources are extremely limited, and this makes difficult the usage of quantum machine learning (QML) models. Concerning the supervised tasks, a viable approach is the introduction of a quantum locality technique, which allows the models to focus only on the neighborhood of the considered element. A well-known locality technique is the k-nearest neighbors (k-NN) algorithm, of which several quantum variants have been proposed. Nevertheless, they have not been employed yet as a preliminary step of other QML models, whereas the classical counterpart has already proven successful. In this paper, we present (i) an implementation in Python of a QML pipeline for local classification, and (ii) its extensive empirical evaluation. Specifically, the quantum pipeline, developed using Qiskit, consists of a quantum k-NN and a quantum binary classifier. The results have shown the quantum pipeline's equivalence (in terms of accuracy) to its classical counterpart in the ideal case, the validity of locality's application to the QML realm, but also the strong sensitivity of the chosen quantum k-NN to probability fluctuations and the better performance of classical baseline methods like the random forest."
Generalized Fast Multichannel Nonnegative Matrix Factorization Basedon Gaussian Scale Mixtures for Blind Source Separation,"MathieuFontaine, KouheiSekiguchi, AdityaNugraha, YoshiakiBando, KazuyoshiYoshii",11 May 2022,Sound (cs.SD)," This paper describes heavy-tailed extensions of a state-of-the-art versatile blind source separation method called fast multichannel nonnegative matrix factorization (FastMNMF) from a unified point of view. The common way of deriving such an extension is to replace the multivariate complex Gaussian distribution in the likelihood function with its heavy- tailed generalization, e.g., the multivariate complex Student's t and leptokurtic generalized Gaussian distributions, and tailor-make the corresponding parameter optimization algorithm. Using a wider class of heavy-tailed distributions called a Gaussian scale mixture (GSM), i.e., a mixture of Gaussian distributions whose variances are perturbed by positive random scalars called impulse variables, we propose GSM-FastMNMF and develop an expectationmaximization algorithm that works even when the probability density function of the impulse variables have no analytical expressions. We show that existing heavy-tailed FastMNMF extensions are instances of GSM- FastMNMF and derive a new instance based on the generalized hyperbolic distribution that include the normal-inverse Gaussian, Student's t, and Gaussian distributions as the special cases. Our experiments show that the normalinverse Gaussian FastMNMF outperforms the state-of-the-art FastMNMF extensions and ILRMA model in speech enhancement and separation in terms of the signal-to-distortion ratio."
Generalized Modeling and Fundamental Limits for Multiple-AccessIntegrated Sensing and Communication Systems,"YaoLiu, MinLi, AnLiu, JianminLu, RuiDu, Tony XiaoHan","11 May 2022 (v1(https://arxiv.org/abs/2205.05328v1)), lastrevised 12 May 2022 (this version, v2)",Information Theory (cs.IT)," In this paper, we propose a generalized state-dependent channel modeling and present fundamental limits for multiple-access integrated sensing and communication (ISAC) systems. The model proposed extends the latest studies by Kobayashi et al. and Ahmadipour et al., which explicitly accounts for more practical scenarios with correlated sensing and channel states, and imperfect channel state information at the receiver (CSIR). For the model considered, we devise an achievable scheme that combines message cooperation and joint compression of past transmitted codeword and echo signals (a form of strictly causal feedback) via distributed Wyner-Ziv coding at each user to realize ""simultaneously cooperative communication and sensing"". The corresponding achievable rate-distortion region is derived and a numerical example is constructed to illustrate the potential gain of the proposed scheme. It is found that the compressed information sent is not only useful for further enhancing communication (particularly in the case without CSIR), but also helpful in improving the sensing performance of the transmitters."
Open Problems in Fuzzing RESTful APIs: A Comparison of Tools,"ManZhang, AndreaArcuri",11 May 2022,Software Engineering (cs.SE)," RESTful APIs are a type of web services that are widely used in industry. In the last few years, a lot of effort in the research community has been spent in designing novel techniques to automatically fuzz those APIs to find faults in them. Many real faults were automatically found in a large variety of RESTful APIs. However, usually the analyzed fuzzers treat the APIs as black-box, and no analysis of what is actually covered in these systems is done. Therefore, although these fuzzers are clearly useful for practitioners, we do not know what are their current limitations and actual effectiveness. Solving this is a necessary step to be able to design better, more efficient and effective techniques. To address this issue, in this paper we compare 6 state-of-the-art fuzzers on 10 RESTful APIs. We then analyzed the source code of which parts of these APIs the fuzzers fail to generate tests for. This analysis points to clear limitations of these current fuzzers, listing concrete challenges for the research community to follow up on."
A Survey on Cache-Aided NOMA for 6G Networks,"DipenBepari, SoumenMondal, AniruddhaChandra, RajeevShukla, Yuanwei Liu, MohsenGuizani, ArumugamNallanathan",11 May 2022,Information Theory (cs.IT)," Contrary to orthogonal multiple-access (OMA), non-orthogonal multiple-access (NOMA) schemes can serve a pool of users without exploiting the scarce frequency or time domain resources. This is useful in meeting the sixth generation (6G) network requirements, such as, low latency, massive connectivity, users fairness, and high spectral efficiency. On the other hand, content caching restricts duplicate data transmission by storing popular contents in advance at the network edge which reduces 6G data traffic. In this survey, we focus on cache-aided NOMA-based wireless networks which can reap the benefits of both cache and NOMA; switching to NOMA from OMA enables cache-aided networks to push additional files to content servers in parallel and improve the cache hit probability. Beginning with fundamentals of cache-aided NOMA technology, we summarize the performance goals of cache-aided NOMA systems, present the associated design challenges, and categorize related recent literature based on their application verticals. Concomitant standardization activities and open research challenges are highlighted as well."
Arbitrary Shape Text Detection via Boundary Transformer,"Shi-XueZhang, Xiaobin Zhu, Chun Yang, Xu-Cheng Yin",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Arbitrary shape text detection is a challenging task due to its complexity and variety, e.g, various scales, random rotations, and curve shapes. In this paper, we propose an arbitrary shape text detector with a boundary transformer, which can accurately and directly locate text boundaries without any post-processing. Our method mainly consists of a boundary proposal module and an iteratively optimized boundary transformer module. The boundary proposal module consisting of multi-layer dilated convolutions will compute important prior information (including classification map, distance field, and direction field) for generating coarse boundary proposals meanwhile guiding the optimization of boundary transformer. The boundary transformer module adopts an encoder-decoder structure, in which the encoder is constructed by multi-layer transformer blocks with residual connection while the decoder is a simple multi-layer perceptron network (MLP). Under the guidance of prior information, the boundary transformer module will gradually refine the coarse boundary proposals via boundary deformation in an iterative manner. Furthermore, we propose a novel boundary energy loss (BEL) which introduces an energy minimization constraint and an energy monotonically decreasing constraint for every boundary optimization step. Extensive experiments on publicly available and challenging datasets demonstrate the state-of-the-art performance and promising efficiency of our method."
Statistical Characterization of Closed-Loop Latency at the Mobile Edge,"SurajSuman, FedericoChiariotti, CedomirStefanovic, StrahinjaDosen, PetarPopovski",11 May 2022,Networking and Internet Architecture (cs.NI)," The stringent timing and reliability requirements in mission- critical applications require a detailed statistical characterization of the latency. Teleoperation is a representative use case, in which a human operator (HO) remotely controls a robot by exchanging command and feedback signals. We present a framework to analyze the latency of a closed-loop teleoperation system consisting of three entities: HO, robot located in remote environment, and a Base Station (BS) with Mobile edge Computing (MEC) capabilities. A model of each component of the system is used to analyze the closed-loop latency and decide upon the optimal compression strategy. The closed-form expression of the distribution of the closed-loop latency is difficult to estimate, such that suitable upper and lower bounds are obtained. We formulate a non-convex optimization problem to minimize the closed-loop latency. Using the obtained upper and lower bound on the closed- loop latency, a computationally efficient procedure to optimize the closed- loop latency is presented. The simulation results reveal that compression of sensing data is not always beneficial, while system design based on average performance leads to under-provisioning and may cause performance degradation. The applicability of the proposed analysis is much wider than teleoperation, for systems whose latency budget consists of many components."
Towards Unified Prompt Tuning for Few-shot Text Classification,"JianingWang, ChengyuWang, FuliLuo, ChuanqiTan, MinghuiQiu, FeiYang, QiuhuiShi, SongfangHuang, MingGao",11 May 2022,Computation and Language (cs.CL)," Prompt-based fine-tuning has boosted the performance of Pre- trained Language Models (PLMs) on few-shot text classification by employing task-specific prompts. Yet, PLMs are unfamiliar with prompt-style expressions during pre-training, which limits the few-shot learning performance on downstream tasks. It would be desirable if the models can acquire some prompting knowledge before adaptation to specific NLP tasks. We present the Unified Prompt Tuning (UPT) framework, leading to better few- shot text classification for BERT-style models by explicitly capturing prompting semantics from non-target NLP datasets. In UPT, a novel paradigm Prompt-Options-Verbalizer is proposed for joint prompt learning across different NLP tasks, forcing PLMs to capture task-invariant prompting knowledge. We further design a self-supervised task named Knowledge-enhanced Selective Masked Language Modeling to improve the PLM's generalization abilities for accurate adaptation to previously unseen tasks. After multi- task learning across multiple tasks, the PLM can be better prompt-tuned towards any dissimilar target tasks in low-resourced settings. Experiments over a variety of NLP tasks show that UPT consistently outperforms state-of- the-arts for prompt-based fine-tuning."
The Conflict Between Explainable and Accountable Decision-MakingAlgorithms,"GabrielLima, NinaGrgić-Hlača, Jin KeunJeong, Meeyoung Cha",11 May 2022,Computers and Society (cs.CY)," Decision-making algorithms are being used in important decisions, such as who should be enrolled in health care programs and be hired. Even though these systems are currently deployed in high-stakes scenarios, many of them cannot explain their decisions. This limitation has prompted the Explainable Artificial Intelligence (XAI) initiative, which aims to make algorithms explainable to comply with legal requirements, promote trust, and maintain accountability. This paper questions whether and to what extent explainability can help solve the responsibility issues posed by autonomous AI systems. We suggest that XAI systems that provide post-hoc explanations could be seen as blameworthy agents, obscuring the responsibility of developers in the decision-making process. Furthermore, we argue that XAI could result in incorrect attributions of responsibility to vulnerable stakeholders, such as those who are subjected to algorithmic decisions (i.e., patients), due to a misguided perception that they have control over explainable algorithms. This conflict between explainability and accountability can be exacerbated if designers choose to use algorithms and patients as moral and legal scapegoats. We conclude with a set of recommendations for how to approach this tension in the socio-technical process of algorithmic decision-making and a defense of hard regulation to prevent designers from escaping responsibility."
Error Rate Analysis for Grant-free Massive Random Access with Short-Packet Transmission,"XinyuBian, YuyiMao, JunZhang",11 May 2022,Information Theory (cs.IT)," Grant-free massive random access (RA) is a promising protocol to support the massive machine-type communications (mMTC) scenario in 5G and beyond networks. In this paper, we focus on the error rate analysis in grant-free massive RA, which is critical for practical deployment but has not been well studied. We consider a two-phase frame structure, with a pilot transmission phase for activity detection and channel estimation, followed by a data transmission phase with coded data symbols. Considering the characteristics of short-packet transmission, we analyze the block error rate (BLER) in the finite blocklength regime to characterize the data transmission performance. The analysis involves characterizing the activity detection and channel estimation errors as well as applying the random matrix theory (RMT) to analyze the distribution of the post-processing signal-to-noise ratio (SNR). As a case study, the derived BLER expression is further simplified to optimize the pilot length. Simulation results verify our analysis and demonstrate its effectiveness in pilot length optimization."
Weak Supervision with Incremental Source Accuracy Estimation,Richard GreshamCorrero,11 May 2022,Machine Learning (cs.LG), Motivated by the desire to generate labels for real-time data we develop a method to estimate the dependency structure and accuracy of weak supervision sources incrementally. Our method first estimates the dependency structure associated with the supervision sources and then uses this to iteratively update the estimated source accuracies as new data is received. Using both off-the-shelf classification models trained using publicly- available datasets and heuristic functions as supervision sources we show that our method generates probabilistic labels with an accuracy matching that of existing off-line methods.
User Guide for KOTE: Korean Online Comments Emotions Dataset,"DuyoungJeon, JunhoLee, CheongtagKim",11 May 2022,Computation and Language (cs.CL)," Sentiment analysis that classifies data into positive or negative has been dominantly used to recognize emotional aspects of texts, despite the deficit of thorough examination of emotional meanings. Recently, corpora labeled with more than just valence are built to exceed this limit. However, most Korean emotion corpora are small in the number of instances and cover a limited range of emotions. We introduce KOTE dataset. KOTE contains 50k (250k cases) Korean online comments, each of which is manually labeled for 43 emotion labels or one special label (NO EMOTION) by crowdsourcing (Ps = 3,048). The emotion taxonomy of the 43 emotions is systematically established by cluster analysis of Korean emotion concepts expressed on word embedding space. After explaining how KOTE is developed, we also discuss the results of finetuning and analysis for social discrimination in the corpus."
Subspace Learning Machine (SLM): Methodology and Performance,"HongyuFu, YijingYang, VinodK. Mishra, C.-C. JayKuo",11 May 2022,Machine Learning (cs.LG)," Inspired by the feedforward multilayer perceptron (FF-MLP), decision tree (DT) and extreme learning machine (ELM), a new classification model, called the subspace learning machine (SLM), is proposed in this work. SLM first identifies a discriminant subspace, $S^0$, by examining the discriminant power of each input feature. Then, it uses probabilistic projections of features in $S^0$ to yield 1D subspaces and finds the optimal partition for each of them. This is equivalent to partitioning $S^0$ with hyperplanes. A criterion is developed to choose the best $q$ partitions that yield $2q$ partitioned subspaces among them. We assign $S^0$ to the root node of a decision tree and the intersections of $2q$ subspaces to its child nodes of depth one. The partitioning process is recursively applied at each child node to build an SLM tree. When the samples at a child node are sufficiently pure, the partitioning process stops and each leaf node makes a prediction. The idea can be generalized to regression, leading to the subspace learning regressor (SLR). Furthermore, ensembles of SLM/SLR trees can yield a stronger predictor. Extensive experiments are conducted for performance benchmarking among SLM/SLR trees, ensembles and classical classifiers/regressors."
Invisible-to-Visible: Privacy-Aware Human Segmentation using AirborneUltrasound via Collaborative Learning Probabilistic U-Net,"RisakoTanigawa, YasunoriIshii, KazukiKozuka, TakayoshiYamashita",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Color images are easy to understand visually and can acquire a great deal of information, such as color and texture. They are highly and widely used in tasks such as segmentation. On the other hand, in indoor person segmentation, it is necessary to collect person data considering privacy. We propose a new task for human segmentation from invisible information, especially airborne ultrasound. We first convert ultrasound waves to reflected ultrasound directional images (ultrasound images) to perform segmentation from invisible information. Although ultrasound images can roughly identify a person's location, the detailed shape is ambiguous. To address this problem, we propose a collaborative learning probabilistic U-Net that uses ultrasound and segmentation images simultaneously during training, closing the probabilistic distributions between ultrasound and segmentation images by comparing the parameters of the latent spaces. In inference, only ultrasound images can be used to obtain segmentation results. As a result of performance verification, the proposed method could estimate human segmentations more accurately than conventional probabilistic U-Net and other variational autoencoder models."
ReFine: Re-randomization before Fine-tuning for Cross-domain Few-shotLearning,"JaehoonOh, SungnyunKim, NamgyuHo, Jin-HwaKim, HwanjunSong, Se-Young Yun",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Cross-domain few-shot learning (CD-FSL), where there are few target samples under extreme differences between source and target domains, has recently attracted huge attention. For CD-FSL, recent studies generally have developed transfer learning based approaches that pre-train a neural network on popular labeled source domain datasets and then transfer it to target domain data. Although the labeled datasets may provide suitable initial parameters for the target data, the domain difference between the source and target might hinder the fine-tuning on the target domain. This paper proposes a simple yet powerful method that re-randomizes the parameters fitted on the source domain before adapting to the target data. The re-randomization resets source-specific parameters of the source pre- trained model and thus facilitates fine-tuning on the target domain, improving few-shot performance."
Poisson Integrators based on splitting method for Poisson systems,"BeibeiZhu, LunJi, AiqingZhu, YifaTang",11 May 2022,Numerical Analysis (math.NA)," We propose Poisson integrators for the numerical integration of separable Poisson systems. We analyze three situations in which the Poisson systems are separated in three ways and the Poisson integrators can be constructed by using the splitting method. Numerical results show that the Poisson integrators outperform the higher order non-Poisson integrators in phase orbit tracking, long-term energy conservation and efficiency."
Unsupervised machine learning for physical concepts,RuyuYang,11 May 2022,Machine Learning (cs.LG)," In recent years, machine learning methods have been used to assist scientists in scientific research. Human scientific theories are based on a series of concepts. How machine learns the concepts from experimental data will be an important first step. We propose a hybrid method to extract interpretable physical concepts through unsupervised machine learning. This method consists of two stages. At first, we need to find the Betti numbers of experimental data. Secondly, given the Betti numbers, we use a variational autoencoder network to extract meaningful physical variables. We test our protocol on toy models and show how it works."
AggPose: Deep Aggregation Vision Transformer for Infant PoseEstimation,"XuCao, XiaoyeLi, LiyaMa, YiHuang, XuanFeng, ZeningChen, HongwuZeng, JianguoCao",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Movement and pose assessment of newborns lets experienced pediatricians predict neurodevelopmental disorders, allowing early intervention for related diseases. However, most of the newest AI approaches for human pose estimation methods focus on adults, lacking publicly benchmark for infant pose estimation. In this paper, we fill this gap by proposing infant pose dataset and Deep Aggregation Vision Transformer for human pose estimation, which introduces a fast trained full transformer framework without using convolution operations to extract features in the early stages. It generalizes Transformer + MLP to high-resolution deep layer aggregation within feature maps, thus enabling information fusion between different vision levels. We pre-train AggPose on COCO pose dataset and apply it on our newly released large-scale infant pose estimation dataset. The results show that AggPose could effectively learn the multi-scale features among different resolutions and significantly improve the performance of infant pose estimation. We show that AggPose outperforms hybrid model HRFormer and TokenPose in the infant pose estimation dataset. Moreover, our AggPose outperforms HRFormer by 0.7% AP on COCO val pose estimation on average. Our code is available at [this http URL](http://github.com/SZAR- LAB/AggPose)."
Strong Sign Controllability of Diffusively-Coupled Networks,"Nam-JinPark, Seong-HoKwon, Yoo-Bin Bae, Byeong-YeonKim, KevinL. Moore, Hyo-Sung Ahn",11 May 2022,Systems and Control (eess.SY)," This paper presents several conditions to determine strong sign controllability for diffusively-coupled undirected networks. The strong sign controllability is determined by the sign patterns (positive, negative, zero) of the edges. We first provide the necessary and sufficient conditions for strong sign controllability of basic components, such as path, cycle, and tree. Next, we propose a merging process to extend the basic componenets to a larger graph based on the conditions of the strong sign controllability. Furthermore, we develop an algorithm of polynomial complexity to find the minimum number of external input nodes while maintaining the strong sign controllability of a network."
Hierarchical Collaborative Hyper-parameter Tuning,"AhmadEsmaeili, ZahraGhorrati, Eric Matson",11 May 2022,Machine Learning (cs.LG)," Hyper-parameter Tuning is among the most critical stages in building machine learning solutions. This paper demonstrates how multi-agent systems can be utilized to develop a distributed technique for determining near-optimal values for any arbitrary set of hyper-parameters in a machine learning model. The proposed method employs a distributedly formed hierarchical agent-based architecture for the cooperative searching procedure of tuning hyper-parameter values. The presented generic model is used to develop a guided randomized agent-based tuning technique, and its behavior is investigated in both machine learning and global function optimization applications. According the empirical results, the proposed model outperformed both of its underlying randomized tuning strategies in terms of classification error and function evaluations, notably in higher number of dimensions."
Relational Triple Extraction: One Step is Enough,"Yu-MingShang, HeyanHuang, XinSun, WeiWei, Xian-LingMao",11 May 2022,Computation and Language (cs.CL)," Extracting relational triples from unstructured text is an essential task in natural language processing and knowledge graph construction. Existing approaches usually contain two fundamental steps: (1) finding the boundary positions of head and tail entities; (2) concatenating specific tokens to form triples. However, nearly all previous methods suffer from the problem of error accumulation, i.e., the boundary recognition error of each entity in step (1) will be accumulated into the final combined triples. To solve the problem, in this paper, we introduce a fresh perspective to revisit the triple extraction task, and propose a simple but effective model, named DirectRel. Specifically, the proposed model first generates candidate entities through enumerating token sequences in a sentence, and then transforms the triple extraction task into a linking problem on a ""head $\rightarrow$ tail"" bipartite graph. By doing so, all triples can be directly extracted in only one step. Extensive experimental results on two widely used datasets demonstrate that the proposed model performs better than the state-of-the-art baselines."
The Meta-Turing Test,TobyWalsh,11 May 2022,Artificial Intelligence (cs.AI)," We propose an alternative to the Turing test that removes the inherent asymmetry between humans and machines in Turing's original imitation game. In this new test, both humans and machines judge each other. We argue that this makes the test more robust against simple deceptions. We also propose a small number of refinements to improve further the test. These refinements could be applied also to Turing's original imitation game."
What is Proxy Discrimination?,Michael CarlTschantz,11 May 2022,Machine Learning (cs.LG)," The near universal condemnation of proxy discrimination hides a disagreement over what it is. This work surveys various notions of proxy and proxy discrimination found in prior work and represents them in a common framework. These notions variously turn on statistical dependencies, causal effects, and intentions. It discusses the limitations and uses of each notation and of the concept as a whole."
Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution via Cycle-Projected Mutual Learning,"MengshunHu, KuiJiang, LiangLiao, JingXiao, JunjunJiang, ZhengWang",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Spatial-Temporal Video Super-Resolution (ST-VSR) aims to generate super-resolved videos with higher resolution(HR) and higher frame rate (HFR). Quite intuitively, pioneering two-stage based methods complete ST-VSR by directly combining two sub-tasks: Spatial Video Super-Resolution (S-VSR) and Temporal Video Super-Resolution(T-VSR) but ignore the reciprocal relations among them. Specifically, 1) T-VSR to S-VSR: temporal correlations help accurate spatial detail representation with more clues; 2) S-VSR to T-VSR: abundant spatial information contributes to the refinement of temporal prediction. To this end, we propose a one-stage based Cycle- projected Mutual learning network (CycMu-Net) for ST-VSR, which makes full use of spatial-temporal correlations via the mutual learning between S-VSR and T-VSR. Specifically, we propose to exploit the mutual information among them via iterative up-and-down projections, where the spatial and temporal features are fully fused and distilled, helping the high-quality video reconstruction. Besides extensive experiments on benchmark datasets, we also compare our proposed CycMu-Net with S-VSR and T-VSR tasks, demonstrating that our method significantly outperforms state-of-the-art methods."
Evaluation Gaps in Machine Learning Practice,"BenHutchinson, NegarRostamzadeh, ChristinaGreer, KatherineHeller, VinodkumarPrabhakaran",11 May 2022,Machine Learning (cs.LG)," Forming a reliable judgement of a machine learning (ML) model's appropriateness for an application ecosystem is critical for its responsible use, and requires considering a broad range of factors including harms, benefits, and responsibilities. In practice, however, evaluations of ML models frequently focus on only a narrow range of decontextualized predictive behaviours. We examine the evaluation gaps between the idealized breadth of evaluation concerns and the observed narrow focus of actual evaluations. Through an empirical study of papers from recent high-profile conferences in the Computer Vision and Natural Language Processing communities, we demonstrate a general focus on a handful of evaluation methods. By considering the metrics and test data distributions used in these methods, we draw attention to which properties of models are centered in the field, revealing the properties that are frequently neglected or sidelined during evaluation. By studying these properties, we demonstrate the machine learning discipline's implicit assumption of a range of commitments which have normative impacts; these include commitments to consequentialism, abstractability from context, the quantifiability of impacts, the limited role of model inputs in evaluation, and the equivalence of different failure modes. Shedding light on these assumptions enables us to question their appropriateness for ML system contexts, pointing the way towards more contextualized evaluation methodologies for robustly examining the trustworthiness of ML models"
Spatial-temporal associations representation and application forprocess monitoring using graph convolution neural network,"HaoRen, ChunhuaYang, XiaojunLiang, Zhiwen Chen, Weihua Gui",11 May 2022,Machine Learning (cs.LG)," Industrial process data reflects the dynamic changes of operation conditions, which mainly refer to the irregular changes in the dynamic associations between different variables in different time. And this related associations knowledge for process monitoring is often implicit in these dynamic monitoring data which always have richer operation condition information and have not been paid enough attention in current research. To this end, a new process monitoring method based on spatial-based graph convolution neural network (SGCN) is proposed to describe the characteristics of the dynamic associations which can be used to represent the operation status over time. Spatia-temporal graphs are firstly defined, which can be used to represent the characteristics of node attributes (dynamic edge features) dynamically changing with time. Then, the associations between monitoring variables at a certain time can be considered as the node attributes to define a snapshot of the static graph network at the certain time. Finally, the snapshot containing graph structure and node attributes is used as model inputs which are processed to implement graph classification by spatial-based convolution graph neural network with aggregate and readout steps. The feasibility and applicability of this proposed method are demonstrated by our experimental results of benchmark and practical case application."
Secure Federated Learning for Neuroimaging,"DimitrisStripelis, Umang Gupta, HamzaSaleem, NikhilDhinagar, Tanmay Ghai, RafaelSanchez, ChrysovalantisAnastasiou, ArmaghanAsghar, Greg VerSteeg, SrivatsanRavi, MuhammadNaveed, Paul M.Thompson, Jose LuisAmbite",11 May 2022,Machine Learning (cs.LG)," The amount of biomedical data continues to grow rapidly. However, the ability to collect data from multiple sites for joint analysis remains challenging due to security, privacy, and regulatory concerns. We present a Secure Federated Learning architecture, MetisFL, which enables distributed training of neural networks over multiple data sources without sharing data. Each site trains the neural network over its private data for some time, then shares the neural network parameters (i.e., weights, gradients) with a Federation Controller, which in turn aggregates the local models, sends the resulting community model back to each site, and the process repeats. Our architecture provides strong security and privacy. First, sample data never leaves a site. Second, neural parameters are encrypted before transmission and the community model is computed under fully-homomorphic encryption. Finally, we use information-theoretic methods to limit information leakage from the neural model to prevent a curious site from performing membership attacks. We demonstrate this architecture in neuroimaging. Specifically, we investigate training neural models to classify Alzheimer's disease, and estimate Brain Age, from magnetic resonance imaging datasets distributed across multiple sites, including heterogeneous environments where sites have different amounts of data, statistical distributions, and computational capabilities."
Efficient Distributed Framework for Collaborative Multi-AgentReinforcement Learning,"ShuhanQi, ShuhaoZhang, Xiaohan Hou, JiajiaZhang, XuanWang, JingXiao",11 May 2022,Artificial Intelligence (cs.AI)," Multi-agent reinforcement learning for incomplete information environments has attracted extensive attention from researchers. However, due to the slow sample collection and poor sample exploration, there are still some problems in multi-agent reinforcement learning, such as unstable model iteration and low training efficiency. Moreover, most of the existing distributed framework are proposed for single-agent reinforcement learning and not suitable for multi-agent. In this paper, we design an distributed MARL framework based on the actor-work-learner architecture. In this framework, multiple asynchronous environment interaction modules can be deployed simultaneously, which greatly improves the sample collection speed and sample diversity. Meanwhile, to make full use of computing resources, we decouple the model iteration from environment interaction, and thus accelerate the policy iteration. Finally, we verified the effectiveness of propose framework in MaCA military simulation environment and the SMAC 3D realtime strategy gaming environment with imcomplete information characteristics."
Salient Object Detection via Bounding-box Supervision,"MengqiHe, JingZhang, Wenxin Yu",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The success of fully supervised saliency detection models depends on a large number of pixel-wise labeling. In this paper, we work on bounding-box based weakly-supervised saliency detection to relieve the labeling effort. Given the bounding box annotation, we observe that pixels inside the bounding box may contain extensive labeling noise. However, as a large amount of background is excluded, the foreground bounding box region contains a less complex background, making it possible to perform handcrafted features-based saliency detection with only the cropped foreground region. As the conventional handcrafted features are not representative enough, leading to noisy saliency maps, we further introduce structure-aware self-supervised loss to regularize the structure of the prediction. Further, we claim that pixels outside the bounding box should be background, thus partial cross-entropy loss function can be used to accurately localize the accurate background region. Experimental results on six benchmark RGB saliency datasets illustrate the effectiveness of our model."
Libra: In-network Gradient Aggregation for Speeding up DistributedSparse Deep Training,"HengPan, PenglaiCui, Zhenyuli, RuJia, PenghaoZhang, LeileiZhang, YeYang, JiahaoWu, JianboDong, ZhengCao, QiangLi, HongqiangHarry Liu, MathyLaurent, Gaogang Xie",11 May 2022,Networking and Internet Architecture (cs.NI)," Distributed sparse deep learning has been widely used in many internet-scale applications. Network communication is one of the major hurdles for the training performance. In-network gradient aggregation on programmable switches is a promising solution to speed up the performance. Nevertheless,existing in-network aggregation solutions are designed for the distributed dense deep training, and fall short when used for the sparse deep [this http URL](http://training.To) address this gap, we present Libra based on our key observation of the extremely biased update frequency of parameters in distributed deep sparse training. Specifically, Libra offloads only the aggregation for ""hot"" parameters that are updated frequently onto programmable switches. To enable this offloading and achieve high aggregation throughput, we propose solutions to address the challenges related to hot parameter identification, parameter orchestration, floating- point summation on switches as well as system reliability. We implemented Libra on Intel Tofino switches and integrated it with PS-lite. Finally, we evaluate Libra's performance through extensive experiments and show that Libra can speed up the gradient aggregation by 1.5~4 times."
Reconnecting the Estranged Relationships: Optimizing the InfluencePropagation in Evolving Networks,"TaotaoCai, QiLei, Quan Z.Sheng, ShuiqiaoYang, JianYang, WeiEmma Zhang",11 May 2022,Social and Information Networks (cs.SI)," Influence Maximization (IM), which aims to select a set of users from a social network to maximize the expected number of influenced users, has recently received significant attention for mass communication and commercial marketing. Existing research efforts dedicated to the IM problem depend on a strong assumption: the selected seed users are willing to spread the information after receiving benefits from a company or organization. In reality, however, some seed users may be reluctant to spread the information, or need to be paid higher to be motivated. Furthermore, the existing IM works pay little attention to capture user's influence propagation in the future period as well. In this paper, we target a new research problem, named Reconnecting Top-l Relationships (RTlR) query, which aims to find l number of previous existing relationships but being stranged later, such that reconnecting these relationships will maximize the expected benefit of influenced users by the given group in a future period. We prove that the RTlR problem is NP-hard. An efficient greedy algorithm is proposed to answer the RTlR queries with the influence estimation technique and the well-chosen link prediction method to predict the near future network structure. We also design a pruning method to reduce unnecessary probing from candidate edges. Further, a carefully designed order-based algorithm is proposed to accelerate the RTlR queries. Finally, we conduct extensive experiments on real-world datasets to demonstrate the effectiveness and efficiency of our proposed methods."
Developing cooperative policies for multi-stage reinforcement learningtasks,"JordanErskine, ChrisLehnert",11 May 2022,Machine Learning (cs.LG)," Many hierarchical reinforcement learning algorithms utilise a series of independent skills as a basis to solve tasks at a higher level of reasoning. These algorithms don't consider the value of using skills that are cooperative instead of independent. This paper proposes the Cooperative Consecutive Policies (CCP) method of enabling consecutive agents to cooperatively solve long time horizon multi-stage tasks. This method is achieved by modifying the policy of each agent to maximise both the current and next agent's critic. Cooperatively maximising critics allows each agent to take actions that are beneficial for its task as well as subsequent tasks. Using this method in a multi-room maze domain and a peg in hole manipulation domain, the cooperative policies were able to outperform a set of naive policies, a single agent trained across the entire domain, as well as another sequential HRL algorithm."
Hierarchical Constrained Stochastic Shortest Path Planning via CostBudget Allocation,"SungkweonHong, BrianC.Williams",11 May 2022,Artificial Intelligence (cs.AI)," Stochastic sequential decision making often requires hierarchical structure in the problem where each high-level action should be further planned with primitive states and actions. In addition, many real-world applications require a plan that satisfies constraints on the secondary costs such as risk measure or fuel consumption. In this paper, we propose a hierarchical constrained stochastic shortest path problem (HC-SSP) that meets those two crucial requirements in a single framework. Although HC-SSP provides a useful framework to model such planning requirements in many real-world applications, the resulting problem has high complexity and makes it difficult to find an optimal solution fast which prevents user from applying it to real-time and risk-sensitive applications. To address this problem, we present an algorithm that iteratively allocates cost budget to lower level planning problems based on branch-and-bound scheme to find a feasible solution fast and incrementally update the incumbent solution. We demonstrate the proposed algorithm in an evacuation scenario and prove the advantage over a state-of-the-art mathematical programming based approach."
DcnnGrasp: Towards Accurate Grasp Pattern Recognition with AdaptiveRegularizer Learning,"XiaoqinZhang, ZiweiHuang, JingjingZheng, ShuoWang, XiantaJiang",11 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The task of grasp pattern recognition aims to derive the applicable grasp types of an object according to the visual information. Current state-of-the-art methods ignore category information of objects which is crucial for grasp pattern recognition. This paper presents a novel dual-branch convolutional neural network (DcnnGrasp) to achieve joint learning of object category classification and grasp pattern recognition. DcnnGrasp takes object category classification as an auxiliary task to improve the effectiveness of grasp pattern recognition. Meanwhile, a new loss function called joint cross-entropy with an adaptive regularizer is derived through maximizing a posterior, which significantly improves the model performance. Besides, based on the new loss function, a training strategy is proposed to maximize the collaborative learning of the two tasks. The experiment was performed on five household objects datasets including the RGB-D Object dataset, Hit-GPRec dataset, Amsterdam library of object images (ALOI), Columbia University Image Library (COIL-100), and MeganePro dataset 1. The experimental results demonstrated that the proposed method can achieve competitive performance on grasp pattern recognition with several state-of-the-art methods. Specifically, our method even outperformed the second-best one by nearly 15% in terms of global accuracy for the case of testing a novel object on the RGB-D Object dataset."
A State-Distribution Matching Approach to Non-Episodic ReinforcementLearning,"ArchitSharma, RehaanAhmad, Chelsea Finn",11 May 2022,Machine Learning (cs.LG)," While reinforcement learning (RL) provides a framework for learning through trial and error, translating RL algorithms into the real world has remained challenging. A major hurdle to real-world application arises from the development of algorithms in an episodic setting where the environment is reset after every trial, in contrast with the continual and non-episodic nature of the real-world encountered by embodied agents such as humans and robots. Prior works have considered an alternating approach where a forward policy learns to solve the task and the backward policy learns to reset the environment, but what initial state distribution should the backward policy reset the agent to? Assuming access to a few demonstrations, we propose a new method, MEDAL, that trains the backward policy to match the state distribution in the provided demonstrations. This keeps the agent close to the task-relevant states, allowing for a mix of easy and difficult starting states for the forward policy. Our experiments show that MEDAL matches or outperforms prior methods on three sparse-reward continuous control tasks from the EARL benchmark, with 40% gains on the hardest task, while making fewer assumptions than prior works."
Ancestral Colorings of Perfect Binary Trees With Applications inPrivate Retrieval of Merkle Proofs,"QuangCao, RinaldoGagiano, Duy Huynh, Xun Yi, SonHoang Dau, Phuc Lu Le, Quang-HungLuu, EmanueleViterbo, Yu-ChihHuang, Jingge Zhu, Mohammad M.Jalalzai, Chen Feng",11 May 2022,Data Structures and Algorithms (cs.DS)," We introduce a novel tree coloring problem in which each node of a rooted tree of height $h$ is assigned one of the $h$ colors under the condition that any two nodes that are ancestor and descendant of each other must have different colors and moreover, the numbers of nodes in any two distinct color classes differ by at most one. We refer to such a coloring as a balanced ancestral coloring. Our key contribution is to characterize, based on majorizations, all color sequences (not only the balanced ones) for which there exists an ancestral coloring for perfect binary trees. We then develop an almost linear time (in the number of tree nodes) divide-and- conquer algorithm to generate such a coloring for every perfect binary tree of height $h\geq 1$. The existence of a balanced ancestral coloring reveals an interesting fact about combinatorial batch code: when the batch follows a special pattern (consisting of nodes along a root-to-leaf path in a tree), the total storage capacity required can be reduced by a factor of $\Theta(h)$ compared to when the batch is arbitrary while keeping a balanced storage capacity across $h$ servers. Furthermore, our result also identifies an infinite family of graphs for which the equitable chromatic number can be explicitly determined. As far as we know, this family has not been discovered before in the literature. As a practical application, we show that a balanced ancestral coloring can be employed to speed up the private retrieval of a Merkle proof in a Merkle tree by a factor of $\Theta(h/2)$ compared to a straightforward parallel implementation of SealPIR, a state- of-the-art private information retrieval scheme."
Bayesian Prior Learning via Neural Networks for Next-itemRecommendation,"Manoj ReddyDareddy, Zijun Xue, Nicholas Lin, Junghoo Cho",10 May 2022,Information Retrieval (cs.IR)," Next-item prediction is a a popular problem in the recommender systems domain. As the name suggests, the task is to recommend subsequent items that a user would be interested in given contextual information and historical interaction data. In our paper, we model a general notion of context via a sequence of item interactions. We model the next item prediction problem using the Bayesian framework and capture the probability of appearance of a sequence through the posterior mean of the Beta distribution. We train two neural networks to accurately predict the alpha & beta parameter values of the Beta distribution. Our novel approach of combining black-box style neural networks, known to be suitable for function approximation with Bayesian estimation methods have resulted in an innovative method that outperforms various state-of-the-art baselines. We demonstrate the effectiveness of our method in two real world datasets. Our framework is an important step towards the goal of building privacy preserving recommender systems."
Optimal screening contests,SumitGoel,10 May 2022,Computer Science and Game Theory (cs.GT)," We study the optimal design of contests as screening devices. In an incomplete information environment, contest results reveal information about the quality of the participating agents at the cost of potentially wasteful effort put in by these agents. We are interested in finding contests that maximize the information revealed per unit of expected effort put in by the agents. In a model with linear costs of effort and privately known marginal costs, we find the Bayes-Nash equilibrium strategy for arbitrary prize structures ($1=v_1 \geq v_2 \dots \geq v_n=0$) and show that the equilibrium strategy mapping marginal costs to effort is always a density function. It follows then that the expected effort under the uniform prior on marginal costs is independent of the prize structure. Restricting attention to a simple class of uniform prizes contests (top $k$ agents get $1$ and others get $0$), we find that the optimal screening contest under the uniform prior awards half as many prizes as there are agents. For the power distribution $F(\theta)=\theta^p$ with $p\geq 1$, we conjecture that the number of prizes in the optimal screening contest is decreasing in $p$. In addition, we also show that a uniform prize structure is generally optimal for the standard objectives of maximizing expected effort of an arbitrary agent, most efficient agent and least efficient agent."
Deep Learning-based Channel Estimation for Wideband Hybrid MmWaveMassive MIMO,"JiabaoGao, CaijunZhong, Geoffrey YeLi, Joseph B.Soriaga, ArashBehboodi",10 May 2022,Information Theory (cs.IT)," Hybrid analog-digital (HAD) architecture is widely adopted in practical millimeter wave (mmWave) massive multiple-input multiple-output (MIMO) systems to reduce hardware cost and energy consumption. However, channel estimation in the context of HAD is challenging due to only limited radio frequency (RF) chains at transceivers. Although various compressive sensing (CS) algorithms have been developed to solve this problem by exploiting inherent channel sparsity and sparsity structures, practical effects, such as power leakage and beam squint, can still make the real channel features deviate from the assumed models and result in performance degradation. Also, the high complexity of CS algorithms caused by a large number of iterations hinders their applications in practice. To tackle these issues, we develop a deep learning (DL)-based channel estimation approach where the sparse Bayesian learning (SBL) algorithm is unfolded into a deep neural network (DNN). In each SBL layer, Gaussian variance parameters of the sparse angular domain channel are updated by a tailored DNN, which is able to effectively capture complicated channel sparsity structures in various domains. Besides, the measurement matrix is jointly optimized for performance improvement. Then, the proposed approach is extended to the multi-block case where channel correlation in time is further exploited to adaptively predict the measurement matrix and facilitate the update of Gaussian variance parameters. Based on simulation results, the proposed approaches significantly outperform existing approaches but with reduced complexity."
Reducing Activation Recomputation in Large Transformer Models,"VijayKorthikanti, JaredCasper, Sangkug Lym, LawrenceMcAfee, MichaelAndersch, MohammadShoeybi, BryanCatanzaro",10 May 2022,Machine Learning (cs.LG)," Training large transformer models is one of the most important computational challenges of modern AI. In this paper, we show how to significantly accelerate training of large transformer models by reducing activation recomputation. Activation recomputation is commonly used to work around memory capacity constraints. Rather than storing activations for backpropagation, they are traditionally recomputed, which saves memory but adds redundant compute. In this work, we show most of this redundant compute is unnecessary because we can reduce memory consumption sufficiently without it. We present two novel yet very simple techniques: sequence parallelism and selective activation recomputation. In conjunction with tensor parallelism, these techniques almost eliminate the need to recompute activations. We evaluate our approach on language models up to one trillion parameters in scale and show that our method reduces activation memory by 5x, while reducing execution time overhead from activation recomputation by over 90%. For example, when training a 530B parameter GPT-3 style model on 2240 NVIDIA A100 GPUs, we achieve a Model Flops Utilization of 54.2%, which is 29% faster than the 42.1% we achieve using recomputation. Our implementation will be available in both Megatron-LM and NeMo-Megatron."
Incident duration prediction using a bi-level machine learningframework with outlier removal and intra-extra joint optimisation,"ArturGrigorev, Adriana-SimonaMihaita, SeunghyeonLee, FangChen",10 May 2022,Machine Learning (cs.LG)," Predicting the duration of traffic incidents is a challenging task due to the stochastic nature of events. The ability to accurately predict how long accidents will last can provide significant benefits to both end- users in their route choice and traffic operation managers in handling of non-recurrent traffic congestion. This paper presents a novel bi-level machine learning framework enhanced with outlier removal and intra-extra joint optimisation for predicting the incident duration on three heterogeneous data sets collected for both arterial roads and motorways from Sydney, Australia and San-Francisco, U.S.A. Firstly, we use incident data logs to develop a binary classification prediction approach, which allows us to classify traffic incidents as short-term or long-term. We find the optimal threshold between short-term versus long-term traffic incident duration, targeting both class balance and prediction performance while also comparing the binary versus multi-class classification approaches. Secondly, for more granularity of the incident duration prediction to the minute level, we propose a new Intra-Extra Joint Optimisation algorithm (IEO-ML) which extends multiple baseline ML models tested against several regression scenarios across the data sets. Final results indicate that: a) 40-45 min is the best split threshold for identifying short versus long-term incidents and that these incidents should be modelled separately, b) our proposed IEO- ML approach significantly outperforms baseline ML models in $66\%$ of all cases showcasing its great potential for accurate incident duration prediction. Lastly, we evaluate the feature importance and show that time, location, incident type, incident reporting source and weather at among the top 10 critical factors which influence how long incidents will last."
Student Collaboration Improves Self-Supervised Learning: Dual-LossAdaptive Masked Autoencoder for Brain Cell Image Analysis,"Son T.Ly, BaiLin, Hung Q.Vo, DraganMaric, BadriRoysam, Hien V.Nguyen",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Self-supervised learning leverages the underlying data structure as the source of the supervisory signal without the need for human annotation effort. This approach offers a practical solution to learning with a large amount of biomedical data and limited annotation. Unlike other studies exploiting data via multi-view (e.g., augmented images), this study presents a self-supervised Dual-Loss Adaptive Masked Autoencoder (DAMA) algorithm established from the viewpoint of the information theory. Specifically, our objective function maximizes the mutual information by minimizing the conditional entropy in pixel-level reconstruction and feature-level regression. We further introduce an adaptive mask sampling strategy to maximize mutual information. We conduct extensive experiments on brain cell images to validate the proposed method. DAMA significantly outperforms both state-of-the-art self-supervised and supervised methods on brain cells data and demonstrates competitive result on ImageNet-1k. Code: [this https URL](https://github.com/hula-ai/DAMA)"
Social Inclusion in Curated Contexts: Insights from Museum Practices,"Han-YinHuang, Cynthia C. S.Liem",10 May 2022,Machine Learning (cs.LG)," Artificial intelligence literature suggests that minority and fragile communities in society can be negatively impacted by machine learning algorithms due to inherent biases in the design process, which lead to socially exclusive decisions and policies. Faced with similar challenges in dealing with an increasingly diversified audience, the museum sector has seen changes in theory and practice, particularly in the areas of representation and meaning-making. While rarity and grandeur used to be at the centre stage of the early museum practices, folk life and museums' relationships with the diverse communities they serve become a widely integrated part of the contemporary practices. These changes address issues of diversity and accessibility in order to offer more socially inclusive services. Drawing on these changes and reflecting back on the AI world, we argue that the museum experience provides useful lessons for building AI with socially inclusive approaches, especially in situations in which both a collection and access to it will need to be curated or filtered, as frequently happens in search engines, recommender systems and digital libraries. We highlight three principles: (1) Instead of upholding the value of neutrality, practitioners are aware of the influences of their own backgrounds and those of others on their work. By not claiming to be neutral but practising cultural humility, the chances of addressing potential biases can be increased. (2) There should be room for situational interpretation beyond the stages of data collection and machine learning. Before applying models and predictions, the contexts in which relevant parties exist should be taken into account. (3) Community participation serves the needs of communities and has the added benefit of bringing practitioners and communities together."
"On Scale Space Radon Transform, Properties and Image Reconstruction","NafaaNacereddine, Djemel Ziou, Aicha BayaGoumeidane",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Aware of the importance of the good behavior in the scale space that a mathematical transform must have, we depict, in this paper, the basic properties and the inverse transform of the Scale Space Radon Transform (SSRT). To reconstruct the image from SSRT sinogram, the Filtered backprojection (FBP) technique is used in two different ways: (1) Deconvolve SSRT to obtain the estimated Radon transform (RT) and then, reconstruct image using classical FBP or (2) Adapt FBP technique to SSRT so that the Radon projections spectrum used in classical FBP is replaced by SSRT and Wiener filtering, expressed in the frequency domain. Comparison of image reconstruction techniques using SSRT and RT are performed on Shepp-Logan head phantom image. Using the Mean Absolute Error (MAE) as image reconstruction quality measure, the preliminary results present an outstanding performance for SSRT-based image reconstruction techniques compared to the RT-based one. Furthermore, the method (2) outperforms the method (1) in terms of computation time and adaptability for high level of noise when fairly large Gaussian kernel is used."
Multifidelity data fusion in convolutional encoder/decoder networks,"LaurenPartin, GianlucaGeraci, AhmadRushdi, Michael S.Eldred, Daniele E.Schiavazzi",10 May 2022,Machine Learning (cs.LG)," We analyze the regression accuracy of convolutional neural networks assembled from encoders, decoders and skip connections and trained with multifidelity data. Besides requiring significantly less trainable parameters than equivalent fully connected networks, encoder, decoder, encoder-decoder or decoder-encoder architectures can learn the mapping between inputs to outputs of arbitrary dimensionality. We demonstrate their accuracy when trained on a few high-fidelity and many low-fidelity data generated from models ranging from one-dimensional functions to Poisson equation solvers in two-dimensions. We finally discuss a number of implementation choices that improve the reliability of the uncertainty estimates generated by Monte Carlo DropBlocks, and compare uncertainty estimates among low-, high- and multifidelity approaches."
All-to-All Encode in Synchronous Systems,"CanranWang, NetanelRaviv",10 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," We define all-to-all encode, a collective communication operation serving as a primitive in decentralized computation and storage systems. Consider a scenario where every processor initially has a data packet and requires a linear combination of all data packets; the linear combinations are distinct from one processor to another, and are specified by a generator matrix of an error correcting code. We use a linear network model, in which processors transmit linear combinations of their data and previously received packets, and adopt a standard synchronous system setting to analyze its communication cost. We provide a universal algorithm which computes any matrix in this model by only varying intermediate coefficients, and prove its optimality. When the generator matrix is of the Vandermonde or Lagrange type, we further optimize the communication efficiency of the proposed algorithm."
A Gödel Calculus for Linear Temporal Logic,"Juan PabloAguilera, MartínDiéguez, David Fernández-Duque, BrettMcLean",10 May 2022,Logic in Computer Science (cs.LO)," We consider Gödel temporal logic ($\sf GTL$), a variant of linear temporal logic based on Gödel--Dummett propositional logic. In recent work, we have shown this logic to enjoy natural semantics both as a fuzzy logic and as a superintuitionistic logic. Using semantical methods, the logic was shown to be {\sc pspace}-complete. In this paper we provide a deductive calculus for $\sf GTL$, and show this calculus to be sound and complete for the above-mentioned semantics."
The Move Borrow Checker,"SamBlackshear, JohnMitchell, ToddNowacki, Shaz Qadeer",10 May 2022,Programming Languages (cs.PL)," The Move language provides abstractions for programming with digital assets via a mix of value semantics and reference semantics. Ensuring memory safety in programs with references that access a shared, mutable global ledger is difficult, yet essential for the use-cases targeted by Move. The language meets this challenge with a novel memory model and a modular, intraprocedural static reference safety analysis that leverages key properties of the memory. The analysis ensures the absence of memory safety violations in all Move programs (including ones that link against untrusted code) by running as part of a load-time bytecode verification pass similar to the JVM [12] and CLR [15]. We formalize the static analysis and prove that it enjoys three desirable properties: absence of dangling references, referential transparency for immutable references, and absence of memory leaks."
Massively Digitized Power Grid: Opportunities and Challenges of Use-inspired AI,"LeXie, XiangtianZheng, Yannan Sun, TongHuang, TonyBruton",10 May 2022,Systems and Control (eess.SY)," This article presents a use-inspired perspective of the opportunities and challenges in a massively digitized power grid. It argues that the intricate interplay of data availability, computing capability, and artificial intelligence (AI) algorithm development are the three key factors driving the adoption of digitized solutions in the power grid. The impact of these three factors on critical functions of power system operation and planning practices are reviewed and illustrated with industrial practice case studies. Open challenges and research opportunities for data, computing, and AI algorithms are articulated within the context of the power industry's tremendous decarbonization efforts."
ConfLab: A Rich Multimodal Multisensor Dataset of Free-Standing SocialInteractions In-the-Wild,"ChiragRaman, JoseVargas-Quiros, StephanieTan, EkinGedik, AshrafulIslam, Hayley Hung",10 May 2022,Multimedia (cs.MM)," We describe an instantiation of a new concept for multimodal multisensor data collection of real life in-the-wild free standing social interactions in the form of a Conference Living Lab (ConfLab). ConfLab contains high fidelity data of 49 people during a real-life professional networking event capturing a diverse mix of status, acquaintanceship, and networking motivations at an international conference. Recording such a dataset is challenging due to the delicate trade-off between participant privacy and fidelity of the data, and the technical and logistic challenges involved. We improve upon prior datasets in the fidelity of most of our modalities: 8-camera overhead setup, personal wearable sensors recording body motion (9-axis IMU), Bluetooth-based proximity, and low-frequency audio. Additionally, we use a state-of-the-art hardware synchronization solution and time-efficient continuous technique for annotating body keypoints and actions at high frequencies. We argue that our improvements are essential for a deeper study of interaction dynamics at finer time scales. Our research tasks showcase some of the open challenges related to in-the-wild privacy-preserving social data analysis: keypoints detection from overhead camera views, skeleton based no-audio speaker detection, and F-formation detection. With the ConfLab dataset, we aim to bridge the gap between traditional computer vision tasks and in-the-wild ecologically valid socially-motivated tasks."
Self-Supervised Anomaly Detection: A Survey and Outlook,"HadiHojjati, Thi Kieu KhanhHo, NargesArmanfard","10 May 2022 (v1(https://arxiv.org/abs/2205.05173v1)), lastrevised 12 May 2022 (this version, v2)",Machine Learning (cs.LG)," Over the past few years, anomaly detection, a subfield of machine learning that is mainly concerned with the detection of rare events, witnessed an immense improvement following the unprecedented growth of deep learning models. Recently, the emergence of self-supervised learning has sparked the development of new anomaly detection algorithms that surpassed state-of-the-art accuracy by a significant margin. This paper aims to review the current approaches in self-supervised anomaly detection. We present technical details of the common approaches and discuss their strengths and drawbacks. We also compare the performance of these models against each other and other state-of-the-art anomaly detection models. Finally, we discuss a variety of new directions for improving the existing algorithms."
Deep Graph Clustering via Mutual Information Maximization and MixtureModel,"MaedehAhmadi, MehranSafayani, AbdolrezaMirzaei",10 May 2022,Machine Learning (cs.LG)," Attributed graph clustering or community detection which learns to cluster the nodes of a graph is a challenging task in graph analysis. In this paper, we introduce a contrastive learning framework for learning clustering-friendly node embedding. Although graph contrastive learning has shown outstanding performance in self-supervised graph learning, using it for graph clustering is not well explored. We propose Gaussian mixture information maximization (GMIM) which utilizes a mutual information maximization approach for node embedding. Meanwhile, it assumes that the representation space follows a Mixture of Gaussians (MoG) distribution. The clustering part of our objective tries to fit a Gaussian distribution to each community. The node embedding is jointly optimized with the parameters of MoG in a unified framework. Experiments on real-world datasets demonstrate the effectiveness of our method in community detection."
Robustness of Humans and Machines on Object Recognition with ExtremeImage Transformations,"DakaraiCrowder, Girik Malik",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Recent neural network architectures have claimed to explain data from the human visual cortex. Their demonstrated performance is however still limited by the dependence on exploiting low-level features for solving visual tasks. This strategy limits their performance in case of out-of- distribution/adversarial data. Humans, meanwhile learn abstract concepts and are mostly unaffected by even extreme image distortions. Humans and networks employ strikingly different strategies to solve visual tasks. To probe this, we introduce a novel set of image transforms and evaluate humans and networks on an object recognition task. We found performance for a few common networks quickly decreases while humans are able to recognize objects with a high accuracy."
Soft Robotic Mannequin: Design and Algorithm for Deformation Control,"YingjunTian, GuoxinFang, JustasPetrulis, AndrewWeightman, Charlie C.L.Wang",10 May 2022,Robotics (cs.RO)," This paper presents a novel soft robotic system for a deformable mannequin that can be employed to physically realize the 3D geometry of different human bodies. The soft membrane on a mannequin is deformed by inflating several curved chambers using pneumatic actuation. Controlling the freeform surface of a soft membrane by adjusting the pneumatic actuation in different chambers is challenging as the membrane's shape is commonly determined by interaction between all chambers. Using vision feedback provided by a structured-light based 3D scanner, we developed an efficient algorithm to compute the optimized actuation of all chambers which could drive the soft membrane to deform into the best approximation of different target shapes. Our algorithm converges quickly by including the step of pose estimation in the loop of optimization, and the time-consuming step for evaluating derivatives on the deformable membrane is avoided by using the Broyden update when possible. The effectiveness of our soft robotic mannequin with controlled deformation has been verified in experiments."
Numerical Solution of the Savage-Hutter Equations for GranularAvalanche Flow using the Discontinuous Galerkin Method,"AbdullahShah, Muhammad NaveedZafar, Yulong Du, Li Yuan",29 Apr 2022,Numerical Analysis (math.NA)," The Savage-Hutter (SH) equations are a hyperbolic system of nonlinear partial differential equations describing the temporal evolution of the depth and depth averaged velocity for modelling the avalanche of a shallow layer of granular materials on an inclined surface. These equations admit the occurrence of shock waves and vacuum fronts as in the shallow- water equations while possessing the special reposing state of granular material. In this paper, we develop a third-order Runge-Kutta discontinuous Galerkin (RKDG) method for the numerical solution of the one-dimensional SH equations. We adopt a TVD slope limiter to suppress numerical oscillations near discontinuities. And we give numerical treatments for the avalanche front and for the bed friction to achieve the well-balanced reposing property of granular materials. Numerical results of the avalanche of cohesionless dry granular materials down an inclined and smoothly transitioned to horizontal plane under various internal and bed friction angles and slope angles are given to show the performance of the present numerical scheme."
Improved long time accuracy for projection methods for Navier-Stokesequations using EMAC formulation,"SeanIngimarson, MonikaNeda, LeoRebholz, JorgeReyes, AnVu",10 May 2022,Numerical Analysis (math.NA)," We consider a pressure correction temporal discretization for the incompressible Navier-Stokes equations in EMAC form. We prove stability and error estimates for the case of mixed finite element spatial discretization, and in particular that the Gronwall constant's exponential dependence on the Reynolds number is removed (for sufficiently smooth true solutions) or at least significantly reduced compared to the commonly used skew-symmetric formulation. We also show the method preserves momentum and angular momentum, and while it does not preserve energy it does admit an energy inequality. Several numerical tests show the advantages EMAC can have over other commonly used formulations of the nonlinearity. Additionally, we discuss extensions of the results to the usual Crank-Nicolson temporal discretization."
Few-Shot Image Classification Benchmarks are Too Far From Reality:Build Back Better with Semantic Task Sampling,"EtienneBennequin, Myriam Tami, AntoineToubhans, CelineHudelot",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Every day, a new method is published to tackle Few-Shot Image Classification, showing better and better performances on academic benchmarks. Nevertheless, we observe that these current benchmarks do not accurately represent the real industrial use cases that we encountered. In this work, through both qualitative and quantitative studies, we expose that the widely used benchmark tieredImageNet is strongly biased towards tasks composed of very semantically dissimilar classes e.g. bathtub, cabbage, pizza, schipperke, and cardoon. This makes tieredImageNet (and similar benchmarks) irrelevant to evaluate the ability of a model to solve real-life use cases usually involving more fine-grained classification. We mitigate this bias using semantic information about the classes of tieredImageNet and generate an improved, balanced benchmark. Going further, we also introduce a new benchmark for Few-Shot Image Classification using the Danish Fungi 2020 dataset. This benchmark proposes a wide variety of evaluation tasks with various fine-graininess. Moreover, this benchmark includes many-way tasks (e.g. composed of 100 classes), which is a challenging setting yet very common in industrial applications. Our experiments bring out the correlation between the difficulty of a task and the semantic similarity between its classes, as well as a heavy performance drop of state-of-the-art methods on many-way few-shot classification, raising questions about the scaling abilities of these methods. We hope that our work will encourage the community to further question the quality of standard evaluation processes and their relevance to real-life applications."
Bounds on the Coupling Strengths of Communication Channels and TheirInformation Capacities,"ZeyuKuang, DavidA. B.Miller, Owen D.Miller",10 May 2022,Information Theory (cs.IT)," The concept of optimal communication channels shapes our understanding of wave-based communication. Its analysis, however, always pertains to specific communication-domain geometries, without a general theory of scaling laws or fundamental limits. In this article, we derive shape-independent bounds on the coupling strengths and information capacities of optimal communication channels for any two domains that can be separated by a spherical surface. Previous computational experiments have always observed rapid, exponential decay of coupling strengths, but our bounds predict a much slower, sub-exponential optimal decay, and specific source/receiver distributions that can achieve such performance. Our bounds show that domain sizes and configurations, and not domain shapes, are the keys to maximizing the number of non-trivial communication channels and total information capacities. Applicable to general wireless and optical communication systems, our bounds reveal fundamental limits to what is possible through engineering the communication domains of electromagnetic waves."
RotorTM: A Flexible Simulator for Aerial Transportation andManipulation,"GuanruiLi, XinyangLiu, GiuseppeLoianno",10 May 2022,Robotics (cs.RO)," Low-cost autonomous Micro Aerial Vehicles (MAVs) have the potential to help humans by simplifying and speeding up complex tasks that require their interaction with the environment such as construction, package delivery, and search and rescue. These systems, composed of single or multiple vehicles, can be endowed with passive connection mechanisms such as rigid links or cables to perform transportation and manipulation tasks. However, they are inherently complex since they are often underactuated, and evolve on nonlinear manifold configuration spaces. In addition, the complexity of systems with cable-suspended load is further increased by the hybrid dynamics depending on the cables' varying tension conditions. In this paper, we present the first aerial transportation and manipulation simulator incorporating different payloads and passive connection mechanisms with full system dynamics as well as planning and control algorithms. Furthermore, it includes a novel model accounting for the transient hybrid dynamics for aerial systems with cable-suspended load to closely mimic real-world systems. The availability of a flexible and intuitive interface further contributes to its usability and versatility. Comparisons between simulations and real-world experiments with different vehicles' configurations show the fidelity of the simulator results with respect to real-world settings and its benefit for rapid prototyping and transitioning of aerial transportation and manipulation systems to real-world deployment."
Efficient Risk-Averse Reinforcement Learning,"IdoGreenberg, Yinlam Chow, MohammadGhavamzadeh, Shie Mannor",10 May 2022,Machine Learning (cs.LG)," In risk-averse reinforcement learning (RL), the goal is to optimize some risk measure of the returns. A risk measure often focuses on the worst returns out of the agent's experience. As a result, standard methods for risk-averse RL often ignore high-return strategies. We prove that under certain conditions this inevitably leads to a local-optimum barrier, and propose a soft risk mechanism to bypass it. We also devise a novel Cross Entropy module for risk sampling, which (1) preserves risk aversion despite the soft risk; (2) independently improves sample efficiency. By separating the risk aversion of the sampler and the optimizer, we can sample episodes with poor conditions, yet optimize with respect to successful strategies. We combine these two concepts in CeSoR - Cross-entropy Soft-Risk optimization algorithm - which can be applied on top of any risk-averse policy gradient (PG) method. We demonstrate improved risk aversion in maze navigation, autonomous driving, and resource allocation benchmarks, including in scenarios where standard risk-averse PG completely fails."
Sibylvariant Transformations for Robust Text Classification,"Fabrice Harel-Canada, Muhammad AliGulzar, Nanyun Peng, Miryung Kim",10 May 2022,Computation and Language (cs.CL)," The vast majority of text transformation techniques in NLP are inherently limited in their ability to expand input space coverage due to an implicit constraint to preserve the original class label. In this work, we propose the notion of sibylvariance (SIB) to describe the broader set of transforms that relax the label-preserving constraint, knowably vary the expected class, and lead to significantly more diverse input distributions. We offer a unified framework to organize all data transformations, including two types of SIB: (1) Transmutations convert one discrete kind into another, (2) Mixture Mutations blend two or more classes together. To explore the role of sibylvariance within NLP, we implemented 41 text transformations, including several novel techniques like Concept2Sentence and SentMix. Sibylvariance also enables a unique form of adaptive training that generates new input mixtures for the most confused class pairs, challenging the learner to differentiate with greater nuance. Our experiments on six benchmark datasets strongly support the efficacy of sibylvariance for generalization performance, defect detection, and adversarial robustness."
A matrix-free high-order solver for the numerical solution of cardiacelectrophysiology,"Pasquale ClaudioAfrica, MatteoSalvador, PaolaGervasio, LucaDede', AlfioQuarteroni","10 May 2022 (v1(https://arxiv.org/abs/2205.05136v1)), lastrevised 12 May 2022 (this version, v2)",Numerical Analysis (math.NA)," We propose a matrix-free solver for the numerical solution of the cardiac electrophysiology model consisting of the monodomain nonlinear reaction-diffusion equation coupled with a system of ordinary differential equations for the ionic species. Our numerical approximation is based on the high-order Spectral Element Method (SEM) to achieve accurate numerical discretization while employing a much smaller number of Degrees of Freedom than first-order Finite Elements. We combine sum-factorization with vectorization, thus allowing for a very efficient use of high-order polynomials in a high performance computing framework. We validate the effectiveness of our matrix-free solver in a variety of applications and perform different electrophysiological simulations ranging from a simple slab of cardiac tissue to a realistic four-chamber heart geometry. We compare SEM to SEM with Numerical Integration (SEM-NI), showing that they provide comparable results in terms of accuracy and efficiency. In both cases, increasing the local polynomial degree $p$ leads to better numerical results and smaller computational times than reducing the mesh size $h$. We also implement a matrix-free Geometric Multigrid preconditioner that entails better performance in terms of linear solver iterations than state-of-the- art matrix-based Algebraic Multigrid preconditioners. As a matter of fact, the matrix-free solver here proposed yields up to 50$\times$ speed-up with respect to a conventional matrix-based solver."
Unifying Language Learning Paradigms,"YiTay, MostafaDehghani, Vinh Q.Tran, XavierGarcia, Dara Bahri, TalSchuster, Huaixiu StevenZheng, NeilHoulsby, DonaldMetzler",10 May 2022,Computation and Language (cs.CL)," Existing pre-trained models are generally geared towards a particular class of problems. To date, there seems to be still no consensus on what the right architecture and pre-training setup should be. This paper presents a unified framework for pre-training models that are universally effective across datasets and setups. We begin by disentangling architectural archetypes with pre-training objectives -- two concepts that are commonly conflated. Next, we present a generalized and unified perspective for self-supervision in NLP and show how different pre-training objectives can be cast as one another and how interpolating between different objectives can be effective. We then propose Mixture-of-Denoisers (MoD), a pre-training objective that combines diverse pre-training paradigms together. We furthermore introduce a notion of mode switching, wherein downstream fine-tuning is associated with specific pre-training schemes. We conduct extensive ablative experiments to compare multiple pre-training objectives and find that our method pushes the Pareto-frontier by outperforming T5 and/or GPT-like models across multiple diverse setups. Finally, by scaling our model up to 20B parameters, we achieve SOTA performance on 50 well-established supervised NLP tasks ranging from language generation (with automated and human evaluation), language understanding, text classification, question answering, commonsense reasoning, long text reasoning, structured knowledge grounding and information retrieval. Our model also achieve strong results at in-context learning, outperforming 175B GPT-3 on zero-shot SuperGLUE and tripling the performance of T5-XXL on one-shot summarization. We release Flax-based T5X model checkpoints for the 20B model at \url{[this https URL](https://github.com/google-research/google-research/tree/master/ul2)}."
Human Language Modeling,"NikitaSoni, MatthewMatero, NiranjanBalasubramanian, H. AndrewSchwartz",10 May 2022,Computation and Language (cs.CL)," Natural language is generated by people, yet traditional language modeling views words or documents as if generated independently. Here, we propose human language modeling (HuLM), a hierarchical extension to the language modeling problem whereby a human-level exists to connect sequences of documents (e.g. social media messages) and capture the notion that human language is moderated by changing human states. We introduce, HaRT, a large- scale transformer model for the HuLM task, pre-trained on approximately 100,000 social media users, and demonstrate its effectiveness in terms of both language modeling (perplexity) for social media and fine-tuning for 4 downstream tasks spanning document- and user-levels: stance detection, sentiment classification, age estimation, and personality assessment. Results on all tasks meet or surpass the current state-of-the-art."
A Meta-Analysis on the Utility of Explainable Artificial Intelligencein Human-AI Decision-Making,"MaxSchemmer, PatrickHemmer, MaximilianNitsche, NiklasKühl, MichaelVössing",10 May 2022,Human-Computer Interaction (cs.HC)," Research in Artificial Intelligence (AI)-assisted decision-making is experiencing tremendous growth with a constantly rising number of studies evaluating the effect of AI with and without techniques from the field of explainable AI (XAI) on human decision-making performance. However, as tasks and experimental setups vary due to different objectives, some studies report improved user decision-making performance through XAI, while others report only negligible effects. Therefore, in this article, we present an initial synthesis of existing research on XAI studies using a statistical meta-analysis to derive implications across existing research. We observe a statistically positive impact of XAI on users' performance. Additionally, first results might indicate that human-AI decision-making yields better task performance on text data. However, we find no effect of explanations on users' performance compared to sole AI predictions. Our initial synthesis gives rise to future research to investigate the underlying causes as well as contribute to further development of algorithms that effectively benefit human decision-makers in the form of explanations."
Extracting Latent Steering Vectors from Pretrained Language Models,"NishantSubramani, NiveditaSuresh, Matthew E.Peters",10 May 2022,Computation and Language (cs.CL)," Prior work on controllable text generation has focused on learning how to control language models through trainable decoding, smart-prompt design, or fine-tuning based on a desired objective. We hypothesize that the information needed to steer the model to generate a target sentence is already encoded within the model. Accordingly, we explore a different approach altogether: extracting latent vectors directly from pretrained language model decoders without fine-tuning. Experiments show that there exist steering vectors, which, when added to the hidden states of the language model, generate a target sentence nearly perfectly ( 99 BLEU) for English sentences from a variety of domains. We show that vector arithmetic can be used for unsupervised sentiment transfer on the Yelp sentiment benchmark, with performance comparable to models tailored to this task. We find that distances between steering vectors reflect sentence similarity when evaluated on a textual similarity benchmark (STS-B), outperforming pooled hidden states of models. Finally, we present an analysis of the intrinsic properties of the steering vectors. Taken together, our results suggest that frozen LMs can be effectively controlled through their latent steering space."
Multichannel Optimal Tree-Decodable Codes are Not Always OptimalPrefix Codes,"Hoover H. F.Yin, HarryW. H.Wong, MehrdadTahernia, Russell W. F.Lai",10 May 2022,Information Theory (cs.IT)," The theory of multichannel prefix codes aims to generalize the classical theory of prefix codes. Although single- and two-channel prefix codes always have decoding trees, the same cannot be said when there are more than two channels. One question is of theoretical interest: Do there exist optimal tree-decodable codes that are not optimal prefix codes? Existing literature, which focused on generalizing single-channel results, covered little about non-tree-decodable prefix codes since they have no single-channel counterparts. In this work, we study the fundamental reason behind the non-tree-decodability of prefix codes. By investigating the simplest non-tree-decodable structure, we obtain a general sufficient condition on the channel alphabets for the existence of optimal tree- decodable codes that are not optimal prefix codes."
Detecting Phishing sites Without Visiting them,KalaharshaPagadala,3 May 2022,Cryptography and Security (cs.CR)," Now-a-days, cyberattacks are increasing at an unprecedented rate. Phishing is a social engineering attack which has a massive global impact, destroying the financial and economic value of corporations, government sectors and individuals. In phishing, attackers steal users personal information such as username, passwords, debit card information and so on. In order to detect zero-hour attacks and protect end-users from these attacks, various anti-phishing techniques are developed, but the end-users have to visit the websites to know whether they are safe or not, which may lead to infecting their system. In this paper, we propose a method where end-users can detect the genuineness of the sites without visiting them. The proposed method collects legitimate and phishing URLs and extract features from them. The extracted features are given as input to six different classifiers for training and constructing the model. The classifiers used are Naive-Bayes, Logistic Regression, Random Forest,CatBoost, XGBoost and Multilayer perceptron. The method is tested by developing into an extension so that the end-users can use it when browsing. In the browser extension when the user takes the cursor over any link, a pop-up appears showing the nature of the website i.e., safe site or deceptive site and then a confirm box shows up asking the user whether they want to visit or not. The performance of the approach is tested using a dataset consisting of 2000 phishing and legitimate website URLs and the method is able to detect the sites correctly in very little time. Random-Forest is chosen for constructing the model as it gives the highest accuracy of 95%."
Robust Data-Driven Output Feedback Control via BootstrappedMultiplicative Noise,"BenjaminGravell, ImanShames, TylerSummers",10 May 2022,Systems and Control (eess.SY)," We propose a robust data-driven output feedback control algorithm that explicitly incorporates inherent finite-sample model estimate uncertainties into the control design. The algorithm has three components: (1) a subspace identification nominal model estimator; (2) a bootstrap resampling method that quantifies non-asymptotic variance of the nominal model estimate; and (3) a non-conventional robust control design method comprising a coupled optimal dynamic output feedback filter and controller with multiplicative noise. A key advantage of the proposed approach is that the system identification and robust control design procedures both use stochastic uncertainty representations, so that the actual inherent statistical estimation uncertainty directly aligns with the uncertainty the robust controller is being designed against. Moreover, the control design method accommodates a highly structured uncertainty representation that can capture uncertainty shape more effectively than existing approaches. We show through numerical experiments that the proposed robust data-driven output feedback controller can significantly outperform a certainty equivalent controller on various measures of sample complexity and stability robustness."
Vibration-Based Bridge Health Monitoring using TelecommunicationCables,"JingxiaoLiu, SiyuanYuan, BinLuo, BiondoBiondi, Hae YoungNoh",10 May 2022,Systems and Control (eess.SY)," Bridge Health Monitoring (BHM) enables early damage detection of bridges and is thus critical for avoiding more severe damages that might result in major financial and human losses. However, conventional BHM systems require dedicated sensors on bridges, which is costly to install and maintain and hard to scale up. To overcome this challenge, we introduce a new system that uses existing telecommunication cables for Distributed Acoustic Sensing (DAS) to collect bridge dynamic strain responses. In addition, we develop a two-module physics-guided system identification method to extract bridge damage-sensitive information (e.g., natural frequencies and mode shapes) from noisy DAS data by constraining strain and displacement mode shapes by bridge dynamics. This approach does not require installation and maintenance of dedicated sensors on bridges. We evaluate our system with field experiments on a concrete bridge with fiber cable running in a conduit under the deck. Our system successfully identified modal frequencies and reconstructed meter-scale mode shapes."
Data-driven Tensor Train Gradient Cross Approximation for Hamilton-Jacobi-Bellman Equations,"SergeyDolgov, DanteKalise, LucaSaluzzi",10 May 2022,Numerical Analysis (math.NA)," A gradient-enhanced functional tensor train cross approximation method for the resolution of the Hamilton-Jacobi-Bellman (HJB) equations associated to optimal feedback control of nonlinear dynamics is presented. The procedure uses samples of both the solution of the HJB equation and its gradient to obtain a tensor train approximation of the value function. The collection of the data for the algorithm is based on two possible techniques: Pontryagin Maximum Principle and State Dependent Riccati Equations. Several numerical tests are presented in low and high dimension showing the effectiveness of the proposed method and its robustness with respect to inexact data evaluations, provided by the gradient information. The resulting tensor train approximation paves the way towards fast synthesis of the control signal in real-time applications."
Design and Implementation of a Secure RISC-V Microprocessor,"KleberStangherlin, ManojSachdev",10 May 2022,Cryptography and Security (cs.CR)," Secret keys can be extracted from the power consumption or electromagnetic emanations of unprotected devices. Traditional counter- measures have limited scope of protection, and impose several restrictions on how sensitive data must be manipulated. We demonstrate a bit-serial RISC-V microprocessor implementation with no plain-text data. All values are protected using Boolean masking. Software can run with little to no counter- measures, reducing code size and performance overheads. Unlike previous literature, our methodology is fully automated and can be applied to designs of arbitrary size or complexity. We also provide details on other key components such as clock randomizer, memory protection, and random number generator. The microprocessor was implemented in 65 nm CMOS technology. Its implementation was evaluated using NIST tests as well as side channel attacks. Random numbers generated with our RNG pass on all NIST tests. Side- channel analysis on the baseline implementation extracted the AES key using only 375 traces, while our secure microprocessor was able to withstand attacks using 20 M traces."
Richer Countries and Richer Representations,"KaitlynZhou, KawinEthayarajh, DanJurafsky",10 May 2022,Computation and Language (cs.CL)," We examine whether some countries are more richly represented in embedding space than others. We find that countries whose names occur with low frequency in training corpora are more likely to be tokenized into subwords, are less semantically distinct in embedding space, and are less likely to be correctly predicted: e.g., Ghana (the correct answer and in- vocabulary) is not predicted for, ""The country producing the most cocoa is [MASK]."". Although these performance discrepancies and representational harms are due to frequency, we find that frequency is highly correlated with a country's GDP; thus perpetuating historic power and wealth inequalities. We analyze the effectiveness of mitigation strategies; recommend that researchers report training word frequencies; and recommend future work for the community to define and design representational guarantees."
Problems with Cosine as a Measure of Embedding Similarity for HighFrequency Words,"KaitlynZhou, KawinEthayarajh, Dallas Card, DanJurafsky",10 May 2022,Computation and Language (cs.CL)," Cosine similarity of contextual embeddings is used in many NLP tasks (e.g., QA, IR, MT) and metrics (e.g., BERTScore). Here, we uncover systematic ways in which word similarities estimated by cosine over BERT embeddings are understated and trace this effect to training data frequency. We find that relative to human judgements, cosine similarity underestimates the similarity of frequent words with other instances of the same word or other words across contexts, even after controlling for polysemy and other factors. We conjecture that this underestimation of similarity for high frequency words is due to differences in the representational geometry of high and low frequency words and provide a formal argument for the two- dimensional case."
Modeling Operational Fairness of Hybrid Cloud Brokerage,"SreekrishnanVenkateswaran, SantonuSarkar",7 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Cloud service brokerage is an emerging technology that attempts to simplify the consumption and operation of hybrid clouds. Today's cloud brokers attempt to insulate consumers from the vagaries of multiple clouds. To achieve the insulation, the modern cloud broker needs to disguise itself as the end-provider to consumers by creating and operating a virtual data center construct that we call a meta-cloud, which is assembled on top of a set of participating supplier clouds. It is crucial for such a cloud broker to be considered a trusted partner both by cloud consumers and by the underpinning cloud suppliers. A fundamental tenet of brokerage trust is vendor neutrality. On the one hand, cloud consumers will be comfortable if a cloud broker guarantees that they will not be led through a preferred path. And on the other hand, cloud suppliers would be more interested in partnering with a cloud broker who promises a fair apportioning of client provisioning requests. Because consumer and supplier trust on a meta-cloud broker stems from the assumption of being agnostic to supplier clouds, there is a need for a test strategy that verifies the fairness of cloud brokerage. In this paper, we propose a calculus of fairness that defines the rules to determine the operational behavior of a cloud broker. The calculus uses temporal logic to model the fact that fairness is a trait that has to be ascertained over time; it is not a characteristic that can be judged at a per-request fulfillment level. Using our temporal calculus of fairness as the basis, we propose an algorithm to determine the fairness of a broker probabilistically, based on its observed request apportioning policies. Our model for the fairness of cloud broker behavior also factors in inter- provider variables such as cost divergence and capacity variance."
Unconditional Stability Of A Two-Step Fourth-Order Modified ExplicitEuler/Crank-Nicolson Approach For Solving Time-Variable Fractional Mobile-Immobile Advection-Dispersion Equation,EricNgondiep,6 May 2022,Numerical Analysis (math.NA)," This paper considers a two-step fourth-order modified explicit Euler/Crank-Nicolson numerical method for solving the time-variable fractional mobile-immobile advection-dispersion model subjects to suitable initial and boundary conditions. Both stability and error estimates of the new approach are deeply analyzed in the $L^{\infty}(0,T;L^{2})$-norm. The theoretical studies show that the proposed technique is unconditionally stable with convergence of order $O(k+h^{4})$, where $h$ and $k$ are space step and time step, respectively. This result indicate that the two-step fourth-order formulation is more efficient than a broad range of numerical schemes widely studied in the literature for the considered problem. Numerical experiments are performed to verify the unconditional stability and convergence rate of the developed algorithm."
The First Optimal Algorithm for Smooth and Strongly-Convex-Strongly-Concave Minimax Optimization,"DmitryKovalev, AlexanderGasnikov",11 May 2022,Optimization and Control (math.OC)," In this paper, we revisit the smooth and strongly-convex-strongly- concave minimax optimization problem. Zhang et al. (2021) and Ibrahim et al. (2020) established the lower bound $\Omega\left(\sqrt{\kappa_x\kappa_y} \log \frac{1}{\epsilon}\right)$ on the number of gradient evaluations required to find an $\epsilon$-accurate solution, where $\kappa_x$ and $\kappa_y$ are condition numbers for the strong convexity and strong concavity assumptions. However, the existing state-of-the-art methods do not match this lower bound: algorithms of Lin et al. (2020) and Wang and Li (2020) have gradient evaluation complexity $\mathcal{O}\left( \sqrt{\kappa_x\kappa_y}\log^3\frac{1}{\epsilon}\right)$ and $\mathcal{O}\left( \sqrt{\kappa_x\kappa_y}\log^3 (\kappa_x\kappa_y)\log\frac{1}{\epsilon}\right)$, respectively. We fix this fundamental issue by providing the first algorithm with $\mathcal{O}\left(\sqrt{\kappa_x\kappa_y}\log\frac{1}{\epsilon}\right)$ gradient evaluation complexity. We design our algorithm in three steps: (i) we reformulate the original problem as a minimization problem via the pointwise conjugate function; (ii) we apply a specific variant of the proximal point algorithm to the reformulated problem; (iii) we compute the proximal operator inexactly using the optimal algorithm for operator norm reduction in monotone inclusions."
On Distributed Adaptive Optimization with Gradient Compression,"XiaoyunLi, BelhalKarimi, Ping Li",11 May 2022,Machine Learning (stat.ML)," We study COMP-AMS, a distributed optimization framework based on gradient averaging and adaptive AMSGrad algorithm. Gradient compression with error feedback is applied to reduce the communication cost in the gradient transmission process. Our convergence analysis of COMP-AMS shows that such compressed gradient averaging strategy yields same convergence rate as standard AMSGrad, and also exhibits the linear speedup effect w.r.t. the number of local workers. Compared with recently proposed protocols on distributed adaptive methods, COMP-AMS is simple and convenient. Numerical experiments are conducted to justify the theoretical findings, and demonstrate that the proposed method can achieve same test accuracy as the full-gradient AMSGrad with substantial communication savings. With its simplicity and efficiency, COMP-AMS can serve as a useful distributed training framework for adaptive gradient methods."
Quantum Self-Attention Neural Networks for Text Classification,"Guangxi Li, XuanqiangZhao, Xin Wang",11 May 2022,Quantum Physics (quant-ph)," An emerging direction of quantum computing is to establish meaningful quantum applications in various fields of artificial intelligence, including natural language processing (NLP). Although some efforts based on syntactic analysis have opened the door to research in Quantum NLP (QNLP), limitations such as heavy syntactic preprocessing and syntax-dependent network architecture make them impracticable on larger and real-world data sets. In this paper, we propose a new simple network architecture, called the quantum self-attention neural network (QSANN), which can make up for these limitations. Specifically, we introduce the self-attention mechanism into quantum neural networks and then utilize a Gaussian projected quantum self-attention serving as a sensible quantum version of self-attention. As a result, QSANN is effective and scalable on larger data sets and has the desirable property of being implementable on near-term quantum devices. In particular, our QSANN outperforms the best existing QNLP model based on syntactic analysis as well as a simple classical self-attention neural network in numerical experiments of text classification tasks on public data sets. We further show that our method exhibits robustness to low-level quantum noises."
Rational sets in virtually abelian groups: languages and growth,"LauraCiobanu, AlexEvetts",11 May 2022,Group Theory (math.GR)," In this paper we generalise and unify the results and methods used by Benson, Liardet, Evetts, and Evetts & Levine, to show that rational sets in a virtually abelian group G have rational (relative) growth series with respect to any generating set for G. We prove equivalences between the structures used in the literature, and establish the rationality of important classes of sets in G: definable sets, algebraic sets, conjugacy representatives and coset representatives (of any fixed subgroup), among others. Furthermore, we show that any rational set, when written as words over the generating set of G, has several EDT0L representations."
Gamma and Vega Hedging Using Deep Distributional ReinforcementLearning,"JayCao, JackyChen, SoroushFarghadani, John Hull, ZissisPoulos, Zeyu Wang, Jun Yuan",10 May 2022,Computational Finance (q-fin.CP)," We use deep distributional reinforcement learning (RL) to develop hedging strategies for a trader responsible for derivatives dependent on a particular underlying asset. The transaction costs associated with trading the underlying asset are usually quite small. Traders therefore tend to carry out delta hedging daily, or even more frequently, to ensure that the portfolio is almost completely insensitive to small movements in the asset's price. Hedging the portfolio's exposure to large asset price movements and volatility changes (gamma and vega hedging) is more expensive because this requires trades in derivatives, for which transaction costs are quite large. Our analysis takes account of these transaction cost differences. It shows how RL can be used to develop a strategy for using options to manage gamma and vega risk with three different objective functions. These objective functions involve a mean-variance trade-off, value at risk, and conditional value at risk. We illustrate how the optimal hedging strategy depends on the asset price process, the trader's objective function, the level of transaction costs when options are traded, and the maturity of the options used for hedging."
A simple framework for contrastive learning phases of matter,"Xiao-Qi Han, Sheng-SongXu, ZhenFeng, Rong-Qiang He, Zhong-YiLu",11 May 2022,Disordered Systems and Neural Networks (cond-mat.dis-nn)," A main task in condensed-matter physics is to recognize, classify, and characterize phases of matter and the corresponding phase transitions, for which machine learning provides a new class of research tools due to the remarkable development in computing power and algorithms. Despite much exploration in this new field, usually different methods and techniques are needed for different scenarios. Here, we present SimCLP: a simple framework for contrastive learning phases of matter, which is inspired by the recent development in contrastive learning of visual representations. We demonstrate the success of this framework on several representative systems, including classical and quantum, single-particle and many-body, conventional and topological. SimCLP is flexible and free of usual burdens such as manual feature engineering and prior knowledge. The only prerequisite is to prepare enough state configurations. Furthermore, it can generate representation vectors and labels and hence help tackle other problems. SimCLP therefore paves an alternative way to the development of a generic tool for identifying unexplored phase transitions."
RLOP: RL Methods in Option Pricing from a Mathematical Perspective,ZihengChen,11 May 2022,Pricing of Securities (q-fin.PR)," Abstract In this work, we build two environments, namely the modified QLBS and RLOP models, from a mathematics perspective which enables RL methods in option pricing through replicating by portfolio. We implement the environment specifications (the source code can be found at [this https URL](https://github.com/owen8877/RLOP)), the learning algorithm, and agent parametrization by a neural network. The learned optimal hedging strategy is compared against the BS prediction. The effect of various factors is considered and studied based on how they affect the optimal price and position."
Predicting hot electrons free energies from ground-state data,"Chiheb Ben Mahmoud, FedericoGrasselli, MicheleCeriotti",11 May 2022,Materials Science (cond-mat.mtrl-sci)," Machine-learning potentials are usually trained on the ground- state, Born-Oppenheimer energy surface, which depends exclusively on the atomic positions and not on the simulation temperature. This disregards the effect of thermally-excited electrons, that is important in metals, and essential to the description of warm dense matter. An accurate physical description of these effects requires that the nuclei move on a temperature- dependent electronic free energy. We propose a method to obtain machine- learning predictions of this free energy at an arbitrary electron temperature using exclusively training data from ground-state calculations, avoiding the need to train temperature-dependent potentials. We benchmark our method on metallic liquid hydrogen at the conditions of the core of gas giants and brown dwarfs."
Choice of training label matters: how to best use deep learning forquantitative MRI parameter estimation,"Sean C.Epstein, Timothy J. P.Bray, Margaret Hall-Craggs, HuiZhang",11 May 2022,Medical Physics (physics.med-ph)," Deep learning (DL) is gaining popularity as a parameter estimation method for quantitative MRI. A range of competing implementations have been proposed, relying on either supervised or self-supervised learning. Self- supervised approaches, sometimes referred to as unsupervised, have been loosely based on auto-encoders, whereas supervised methods have, to date, been trained on groundtruth labels. These two learning paradigms have been shown to have distinct strengths. Notably, self-supervised approaches have offered lower-bias parameter estimates than their supervised alternatives. This result is counterintuitive - incorporating prior knowledge with supervised labels should, in theory, lead to improved accuracy. In this work, we show that this apparent limitation of supervised approaches stems from the naive choice of groundtruth training labels. By training on labels which are deliberately not groundtruth, we show that the low-bias parameter estimation previously associated with self-supervised methods can be replicated - and improved on - within a supervised learning framework. This approach sets the stage for a single, unifying, deep learning parameter estimation framework, based on supervised learning, where trade-offs between bias and variance are made by careful adjustment of training label."
End-to-End Multi-Person Audio/Visual Automatic Speech Recognition,"OtavioBraga, TakakiMakino, OlivierSiohan, Hank Liao",11 May 2022,Audio and Speech Processing (eess.AS)," Traditionally, audio-visual automatic speech recognition has been studied under the assumption that the speaking face on the visual signal is the face matching the audio. However, in a more realistic setting, when multiple faces are potentially on screen one needs to decide which face to feed to the A/V ASR system. The present work takes the recent progress of A/V ASR one step further and considers the scenario where multiple people are simultaneously on screen (multi-person A/V ASR). We propose a fully differentiable A/V ASR model that is able to handle multiple face tracks in a video. Instead of relying on two separate models for speaker face selection and audio-visual ASR on a single face track, we introduce an attention layer to the ASR encoder that is able to soft-select the appropriate face video track. Experiments carried out on an A/V system trained on over 30k hours of YouTube videos illustrate that the proposed approach can automatically select the proper face tracks with minor WER degradation compared to an oracle selection of the speaking face while still showing benefits of employing the visual signal instead of the audio alone."
A deep representation learning speech enhancement method using $β$-VAE,"YangXiang, Jesper LisbyHøjvang, Morten HøjfeldtRasmussen, Mads GræsbøllChristensen",11 May 2022,Audio and Speech Processing (eess.AS)," In previous work, we proposed a variational autoencoder-based (VAE) Bayesian permutation training speech enhancement (SE) method (PVAE) which indicated that the SE performance of the traditional deep neural network-based (DNN) method could be improved by deep representation learning (DRL). Based on our previous work, we in this paper propose to use $\beta$-VAE to further improve PVAE's ability of representation learning. More specifically, our $\beta$-VAE can improve PVAE's capacity of disentangling different latent variables from the observed signal without the trade-off problem between disentanglement and signal reconstruction. This trade-off problem widely exists in previous $\beta$-VAE algorithms. Unlike the previous $\beta$-VAE algorithms, the proposed $\beta$-VAE strategy can also be used to optimize the DNN's structure. This means that the proposed method can not only improve PVAE's SE performance but also reduce the number of PVAE training parameters. The experimental results show that the proposed method can acquire better speech and noise latent representation than PVAE. Meanwhile, it also obtains a higher scale- invariant signal-to-distortion ratio, speech quality, and speech intelligibility."
Components and Cycles of Random Mappings,StevenFinch,11 May 2022,Combinatorics (math.CO)," Each connected component of a mapping $\\{1,2,...,n\\}\rightarrow\\{1,2,...,n\\}$ contains a unique cycle. The largest such component can be studied probabilistically via either a delay differential equation or an inverse Laplace transform. The longest such cycle likewise admits two approaches: we find an (apparently new) density formula for its length. Implications of a constraint -- that exactly one component exists -- are also examined. For instance, the mean length of the longest cycle is $(0.7824...)\sqrt n$ in general, but for the special case, it is $(0.7978...)\sqrt n$, a difference of less than $2\%$."
Performance of a deep learning system for detection of referablediabetic retinopathy in real clinical settings,"Verónica Sánchez-Gutiérrez, Paula Hernández-Martínez, Francisco J. Muñoz-Negrete, JonneEngelberts, Allison M.Luger, Mark J.J.P. vanGrinsven",11 May 2022,Image and Video Processing (eess.IV)," Background: To determine the ability of a commercially available deep learning system, RetCAD v.1.3.1 (Thirona, Nijmegen, The Netherlands) for the automatic detection of referable diabetic retinopathy (DR) on a dataset of colour fundus images acquired during routine clinical practice in a tertiary hospital screening program, analyzing the reduction of workload that can be released incorporating this artificial intelligence-based technology. Methods: Evaluation of the software was performed on a dataset of 7195 nonmydriatic fundus images from 6325 eyes of 3189 diabetic patients attending our screening program between February to December of 2019. The software generated a DR severity score for each colour fundus image which was combined into an eye-level score. This score was then compared with a reference standard as set by a human expert using receiver operating characteristic (ROC) curve analysis. Results: The artificial intelligence (AI) software achieved an area under the ROC curve (AUC) value of 0.988 [0.981:0.993] for the detection of referable DR. At the proposed operating point, the sensitivity of the RetCAD software for DR is 90.53% and specificity is 97.13%. A workload reduction of 96% could be achieved at the cost of only 6 false negatives. Conclusions: The AI software correctly identified the vast majority of referable DR cases, with a workload reduction of 96% of the cases that would need to be checked, while missing almost no true cases, so it may therefore be used as an instrument for triage."
CNN-LSTM Based Multimodal MRI and Clinical Data Fusion for PredictingFunctional Outcome in Stroke Patients,"NimaHatami, Tae-Hee Cho, LauraMechtouff, Omer FarukEker, DavidRousseau, CaroleFrindel",11 May 2022,Image and Video Processing (eess.IV)," Clinical outcome prediction plays an important role in stroke patient management. From a machine learning point-of-view, one of the main challenges is dealing with heterogeneous data at patient admission, i.e. the image data which are multidimensional and the clinical data which are scalars. In this paper, a multimodal convolutional neural network - long short-term memory (CNN-LSTM) based ensemble model is proposed. For each MR image module, a dedicated network provides preliminary prediction of the clinical outcome using the modified Rankin scale (mRS). The final mRS score is obtained by merging the preliminary probabilities of each module dedicated to a specific type of MR image weighted by the clinical metadata, here age or the National Institutes of Health Stroke Scale (NIHSS). The experimental results demonstrate that the proposed model surpasses the baselines and offers an original way to automatically encode the spatio- temporal context of MR images in a deep learning architecture. The highest AUC (0.77) was achieved for the proposed model with NIHSS."
Private Hypothesis Testing for Social Sciences,"Ajinkya KMulay, Sean Lane, ErinHennes",7 May 2022,Methodology (stat.ME)," While running any experiment, we often have to consider the statistical power to ensure an effective study. Statistical power or power ensures that we can observe an effect with high probability if such a true effect exists. However, several studies lack the appropriate planning for determining the optimal sample size to ensure adequate power. Thus, careful planning ensures that the power remains high even under high measurement errors while keeping the type 1 error constrained. We study the impact of differential privacy on experiments and theoretically analyze the change in sample size required due to the Gaussian mechanisms. Further, we provide an empirical method to improve the accuracy of private statistics with simple bootstrapping."
Analysis of convolutional neural network image classifiers in arotationally symmetric model,"MichaelKohler, BenjaminWalter",11 May 2022,Machine Learning (stat.ML)," Convolutional neural network image classifiers are defined and the rate of convergence of the misclassification risk of the estimates towards the optimal misclassification risk is analyzed. Here we consider images as random variables with values in some functional space, where we only observe discrete samples as function values on some finite grid. Under suitable structural and smoothness assumptions on the functional a posteriori probability, which includes some kind of symmetry against rotation of subparts of the input image, it is shown that least squares plug-in classifiers based on convolutional neural networks are able to circumvent the curse of dimensionality in binary image classification if we neglect a resolution-dependent error term. The finite sample size behavior of the classifier is analyzed by applying it to simulated and real data."
Beyond Griffin-Lim: Improved Iterative Phase Retrieval for Speech,"TalPeer, SimonWelker, TimoGerkmann",11 May 2022,Audio and Speech Processing (eess.AS)," Phase retrieval is a problem encountered not only in speech and audio processing, but in many other fields such as optics. Iterative algorithms based on non-convex set projections are effective and frequently used for retrieving the phase when only STFT magnitudes are available. While the basic Griffin-Lim algorithm and its variants have been the prevalent method for decades, more recent advances, e.g. in optics, raise the question: Can we do better than Griffin-Lim for speech signals, using the same principle of iterative projection?   In this paper we compare the classical algorithms in the speech domain with two modern methods from optics with respect to reconstruction quality and convergence rate. Based on this study, we propose to combine Griffin-Lim with the Difference Map algorithm in a hybrid approach which shows superior results, in terms of both convergence and quality of the final reconstruction."
DeepFilterNet2: Towards Real-Time Speech Enhancement on EmbeddedDevices for Full-Band Audio,"HendrikSchröter, Alberto N.Escalante-B., TobiasRosenkranz, AndreasMaier",11 May 2022,Audio and Speech Processing (eess.AS)," Deep learning-based speech enhancement has seen huge improvements and recently also expanded to full band audio (48 kHz). However, many approaches have a rather high computational complexity and require big temporal buffers for real time usage e.g. due to temporal convolutions or attention. Both make those approaches not feasible on embedded devices. This work further extends DeepFilterNet, which exploits harmonic structure of speech allowing for efficient speech enhancement (SE). Several optimizations in the training procedure, data augmentation, and network structure result in state-of-the-art SE performance while reducing the real-time factor to 0.04 on a notebook Core-i5 CPU. This makes the algorithm applicable to run on embedded devices in real-time. The DeepFilterNet framework can be obtained under an open source license."
Effective submodularity of influence maximization on temporal networks,"SiragErkol, DarioMazzilli, FilippoRadicchi",11 May 2022,Physics and Society (physics.soc-ph)," We study influence maximization on temporal networks. This is a special setting where the influence function is not submodular, and there is no optimality guarantee for solutions achieved via greedy optimization. We perform an exhaustive analysis on both real and synthetic networks. We show that the influence function of randomly sampled sets of seeds often violates the necessary conditions for submodularity. However, when sets of seeds are selected according to the greedy optimization strategy, the influence function behaves effectively as a submodular function. Specifically, violations of the necessary conditions for submodularity are never observed in real networks, and only rarely in synthetic ones. The direct comparison with exact solutions obtained via brute-force search indicate that the greedy strategy provides approximate solutions that are well within the optimality gap guaranteed for strictly submodular functions. Greedy optimization appears therefore an effective strategy for the maximization of influence on temporal networks."
An Inexact Augmented Lagrangian Algorithm for Training Leaky ReLUNeural Network with Group Sparsity,"WeiLiu, XinLiu, XiaojunChen",11 May 2022,Optimization and Control (math.OC)," The leaky ReLU network with a group sparse regularization term has been widely used in the recent years. However, training such a network yields a nonsmooth nonconvex optimization problem and there exists a lack of approaches to compute a stationary point deterministically. In this paper, we first resolve the multi-layer composite term in the original optimization problem by introducing auxiliary variables and additional constraints. We show the new model has a nonempty and bounded solution set and its feasible set satisfies the Mangasarian-Fromovitz constraint qualification. Moreover, we show the relationship between the new model and the original problem. Remarkably, we propose an inexact augmented Lagrangian algorithm for solving the new model and show the convergence of the algorithm to a KKT point. Numerical experiments demonstrate that our algorithm is more efficient for training sparse leaky ReLU neural networks than some well-known algorithms."
Exploring Local Explanations of Nonlinear Models Using Animated LinearProjections,"NicholasSpyrison, Dianne Cook",11 May 2022,Machine Learning (stat.ML)," The increased predictive power of nonlinear models comes at the cost of interpretability of its terms. This trade-off has led to the emergence of eXplainable AI (XAI). XAI attempts to shed light on how models use predictors to arrive at a prediction with local explanations, a point estimate of the linear feature importance in the vicinity of one instance. These can be considered linear projections and can be further explored to understand better the interactions between features used to make predictions across the predictive model surface. Here we describe interactive linear interpolation used for exploration at any instance and illustrate with examples with categorical (penguin species, chocolate types) and quantitative (soccer/football salaries, house prices) output. The methods are implemented in the R package cheem, available on CRAN."
Learning Multitask Gaussian Bayesian Networks,"ShuaiLiu, YixuanQiu, BaojuanLi, HuaningWang, XiangyuChang",11 May 2022,Machine Learning (stat.ML)," Major depressive disorder (MDD) requires study of brain functional connectivity alterations for patients, which can be uncovered by resting- state functional magnetic resonance imaging (rs-fMRI) data. We consider the problem of identifying alterations of brain functional connectivity for a single MDD patient. This is particularly difficult since the amount of data collected during an fMRI scan is too limited to provide sufficient information for individual analysis. Additionally, rs-fMRI data usually has the characteristics of incompleteness, sparsity, variability, high dimensionality and high noise. To address these problems, we proposed a multitask Gaussian Bayesian network (MTGBN) framework capable for identifying individual disease-induced alterations for MDD patients. We assume that such disease-induced alterations show some degrees of similarity with the tool to learn such network structures from observations to understanding of how system are structured jointly from related tasks. First, we treat each patient in a class of observation as a task and then learn the Gaussian Bayesian networks (GBNs) of this data class by learning from all tasks that share a default covariance matrix that encodes prior knowledge. This setting can help us to learn more information from limited data. Next, we derive a closed-form formula of the complete likelihood function and use the Monte-Carlo Expectation-Maximization(MCEM) algorithm to search for the approximately best Bayesian network structures efficiently. Finally, we assess the performance of our methods with simulated and real- world rs-fMRI data."
Numerical method for approximately optimal solutions of two-stagedistributionally robust optimization with marginal constraints,"ArielNeufeld, QikunXiang","11 May 2022 (v1(https://arxiv.org/abs/2205.05315v1)), lastrevised 12 May 2022 (this version, v2)",Optimization and Control (math.OC)," We consider a general class of two-stage distributionally robust optimization (DRO) problems which includes prominent instances such as task scheduling, the assemble-to-order system, and supply chain network design. The ambiguity set is constrained by fixed marginal distributions that are not necessarily discrete. We develop a numerical algorithm for computing approximately optimal solutions of such problems. Through replacing the marginal constraints by a finite collection of linear constraints, we derive a relaxation of the DRO problem which serves as its upper bound. We can control the relaxation error to be arbitrarily close to 0. We develop duality results and transform the inf-sup problem into an inf-inf problem. This leads to a numerical algorithm for two-stage DRO problems with marginal constraints which solves a linear semi-infinite optimization problem. Besides an approximately optimal solution, the algorithm computes both an upper bound and a lower bound for the optimal value of the problem. The difference between the computed bounds provides a direct sub-optimality estimate of the computed solution. Most importantly, one can choose the inputs of the algorithm such that the sub-optimality is controlled to be arbitrarily small. In our numerical examples, we apply the proposed algorithm to task scheduling, the assemble-to-order system, and supply chain network design. The ambiguity sets in these problems involve a large number of marginals, which include both discrete and continuous distributions. The numerical results showcase that the proposed algorithm computes high-quality robust decisions along with their corresponding sub-optimality estimates with practically reasonable magnitudes that are not over-conservative."
A globally convergent fast iterative shrinkage-thresholding algorithmwith a new momentum factor for single and multi-objective convex optimization,"HirokiTanabe, Ellen H.Fukuda, NobuoYamashita",11 May 2022,Optimization and Control (math.OC)," Convex-composite optimization, which minimizes an objective function represented by the sum of a differentiable function and a convex one, is widely used in machine learning and signal/image processing. Fast Iterative Shrinkage Thresholding Algorithm (FISTA) is a typical method for solving this problem and has a global convergence rate of $O(1 / k^2)$. Recently, this has been extended to multi-objective optimization, together with the proof of the $O(1 / k^2)$ global convergence rate. However, its momentum factor is classical, and the convergence of its iterates has not been proven. In this work, introducing some additional hyperparameters $(a, b)$, we propose another accelerated proximal gradient method with a general momentum factor, which is new even for the single-objective cases. We show that our proposed method also has a global convergence rate of $O(1/k^2)$ for any $(a,b)$, and further that the generated sequence of iterates converges to a weak Pareto solution when $a$ is positive, an essential property for the finite-time manifold identification. Moreover, we report numerical results with various $(a,b)$, showing that some of these choices give better results than the classical momentum factors."
Linear average-case complexity of algorithmic problems in groups,"AlexanderOlshanskii, VladimirShpilrain",11 May 2022,Group Theory (math.GR)," The worst-case complexity of group-theoretic algorithms has been studied for a long time. Generic-case complexity, or complexity on random inputs, was introduced and studied relatively recently. In this paper, we address the average-case time complexity of the word problem in several classes of groups and show that it is often the case that the average-case complexity is linear with respect to the length of an input word. The classes of groups that we consider include groups of matrices over rationals (in particular, polycyclic groups), some classes of solvable groups, as well as free products. For free products, we also address the average-case complexity of the subgroup membership problem and show that it is often linear, too. Finally, we discuss the identity problem that has not been considered before."
A new approach for the fractional Laplacian via deep neural networks,NicolásValenzuela,11 May 2022,Analysis of PDEs (math.AP)," The fractional Laplacian has been strongly studied during past decades. In this paper we present a different approach for the associated Dirichlet problem, using recent deep learning techniques. In fact, recently certain parabolic PDEs with a stochastic representation have been understood via neural networks, overcoming the so-called curse of dimensionality. Among these equations one can find parabolic ones in $\mathbb{R}^d$ and elliptic in a bounded domain $D \subset \mathbb{R}^d$. In this paper we consider the Dirichlet problem for the fractional Laplacian with exponent $\alpha \in (1,2)$. We show that its solution, represented in a stochastic fashion can be approximated using deep neural networks. We also check that this approximation does not suffer from the curse of dimensionality."
Towards Improved Zero-shot Voice Conversion with Conditional DSVAE,"JiachenLian, ChunleiZhang, Gopala KrishnaAnumanchipalli, Dong Yu",11 May 2022,Audio and Speech Processing (eess.AS)," Disentangling content and speaking style information is essential for zero-shot non-parallel voice conversion (VC). Our previous study investigated a novel framework with disentangled sequential variational autoencoder (DSVAE) as the backbone for information decomposition. We have demonstrated that simultaneous disentangling content embedding and speaker embedding from one utterance is feasible for zero-shot VC. In this study, we continue the direction by raising one concern about the prior distribution of content branch in the DSVAE baseline. We find the random initialized prior distribution will force the content embedding to reduce the phonetic- structure information during the learning process, which is not a desired property. Here, we seek to achieve a better content embedding with more phonetic information preserved. We propose conditional DSVAE, a new model that enables content bias as a condition to the prior modeling and reshapes the content embedding sampled from the posterior distribution. In our experiment on the VCTK dataset, we demonstrate that content embeddings derived from the conditional DSVAE overcome the randomness and achieve a much better phoneme classification accuracy, a stabilized vocalization and a better zero-shot VC performance compared with the competitive DSVAE baseline."
A Unified f-divergence Framework Generalizing VAE and GAN,"Jaime RoqueroGimenez, James Zou",11 May 2022,Machine Learning (stat.ML)," Developing deep generative models that flexibly incorporate diverse measures of probability distance is an important area of research. Here we develop an unified mathematical framework of f-divergence generative model, f-GM, that incorporates both VAE and f-GAN, and enables tractable learning with general f-divergences. f-GM allows the experimenter to flexibly design the f-divergence function without changing the structure of the networks or the learning procedure. f-GM jointly models three components: a generator, a inference network and a density estimator. Therefore it simultaneously enables sampling, posterior inference of the latent variable as well as evaluation of the likelihood of an arbitrary datum. f-GM belongs to the class of encoder-decoder GANs: our density estimator can be interpreted as playing the role of a discriminator between samples in the joint space of latent code and observed space. We prove that f-GM naturally simplifies to the standard VAE and to f-GAN as special cases, and illustrates the connections between different encoder-decoder GAN architectures. f-GM is compatible with general network architecture and optimizer. We leverage it to experimentally explore the effects -- e.g. mode collapse and image sharpness -- of different choices of f-divergence."
Best of Both Worlds: Multi-task Audio-Visual Automatic SpeechRecognition and Active Speaker Detection,"OtavioBraga, OlivierSiohan",10 May 2022,Audio and Speech Processing (eess.AS)," Under noisy conditions, automatic speech recognition (ASR) can greatly benefit from the addition of visual signals coming from a video of the speaker's face. However, when multiple candidate speakers are visible this traditionally requires solving a separate problem, namely active speaker detection (ASD), which entails selecting at each moment in time which of the visible faces corresponds to the audio. Recent work has shown that we can solve both problems simultaneously by employing an attention mechanism over the competing video tracks of the speakers' faces, at the cost of sacrificing some accuracy on active speaker detection. This work closes this gap in active speaker detection accuracy by presenting a single model that can be jointly trained with a multi-task loss. By combining the two tasks during training we reduce the ASD classification accuracy by approximately 25%, while simultaneously improving the ASR performance when compared to the multi-person baseline trained exclusively for ASR."
Separator-Transducer-Segmenter: Streaming Recognition and Segmentationof Multi-party Speech,"IlyaSklyar, AnnaPiunova, ChristianOsendorfer",10 May 2022,Audio and Speech Processing (eess.AS)," Streaming recognition and segmentation of multi-party conversations with overlapping speech is crucial for the next generation of voice assistant applications. In this work we address its challenges discovered in the previous work on multi-turn recurrent neural network transducer (MT-RNN-T) with a novel approach, separator-transducer-segmenter (STS), that enables tighter integration of speech separation, recognition and segmentation in a single model. First, we propose a new segmentation modeling strategy through start-of-turn and end-of-turn tokens that improves segmentation without recognition accuracy degradation. Second, we further improve both speech recognition and segmentation accuracy through an emission regularization method, FastEmit, and multi-task training with speech activity information as an additional training signal. Third, we experiment with end-of-turn emission latency penalty to improve end-point detection for each speaker turn. Finally, we establish a novel framework for segmentation analysis of multi-party conversations through emission latency metrics. With our best model, we report 4.6% abs. turn counting accuracy improvement and 17% rel. word error rate (WER) improvement on LibriCSS dataset compared to the previously published work."
Magnitude and topological entropy of digraphs,SteveHuntsman,10 May 2022,Category Theory (math.CT)," Magnitude and (co)weightings are quite general constructions in enriched categories, yet they have been developed almost exclusively in the context of Lawvere metric spaces. We construct a meaningful notion of magnitude for flow graphs based on the observation that topological entropy provides a suitable map into the max-plus semiring, and we outline its utility. Subsequently, we identify a separate point of contact between magnitude and topological entropy in digraphs that yields an analogue of volume entropy for geodesic flows. Finally, we sketch the utility of this construction for feature engineering in downstream applications with generic digraphs."
Simplifying the axiomatization for the order affine geometry,DafaLi,24 Apr 2022,Logic (math.LO)," Based on an ordering with directed lines and using constructions instead of existential axioms, von Plato proposed a constructive axiomatization of ordered affine geometry. There are 22 axioms for the ordered affine geometry, of which the axiom I.7 is about the convergence of three lines (ignoring their directions). In this paper, we indicate that the axiom I.7 includes much redundancy, and demonstrate that the complicated axiom I.7 can be replaced with a simpler and more intuitive new axiom (called ODO) which describes the properties of oppositely and equally directed lines. We also investigate a possibility to replace the axiom I.6 with ODO."
Sparsity Based Non-Contact Vital Signs Monitoring of Multiple PeopleVia FMCW Radar,"YonathanEder, Yonina C.Eldar",10 May 2022,Signal Processing (eess.SP)," Non-contact technology for monitoring multiple people's vital signs, such as respiration and heartbeat, has been investigated in recent years due to the rising cardiopulmonary morbidity, the risk of transmitting diseases, and the heavy burden on the medical staff. Frequency modulated continuous wave (FMCW) radars have shown great promise in meeting these needs. However, contemporary techniques for non-contact vital signs monitoring (NCVSM) via FMCW radars, are based on simplistic models, and present difficulties coping with noisy environments containing multiple objects. In this work, we develop an extended model of FMCW radar signals in a noisy setting containing multiple people and clutter. By utilizing the sparse nature of the modeled signals in conjunction with human-typical cardiopulmonary features, we can accurately localize humans and reliably monitor their vital signs, using only a single channel and a single-input- single-output setup. To this end, we first show that spatial sparsity allows for both accurate detection of multiple people and computationally efficient extraction of their Doppler samples, using a joint sparse recovery approach. Given the extracted samples, we develop a method named Vital Signs based Dictionary Recovery (VSDR), which uses a dictionary-based approach to search for the desired rates of respiration and heartbeat over high-resolution grids corresponding to normal cardiopulmonary activity. The advantages of the proposed method are illustrated through examples that combine the proposed model with real data of $30$ monitored individuals. We demonstrate accurate human localization in a clutter-rich scenario that includes both static and vibrating objects, and show that our VSDR approach outperforms existing techniques, based on several statistical metrics. The findings support the widespread use of FMCW radars with the proposed algorithms in healthcare."
Deep fusion of gray level co-occurrence matrices for lung noduleclassification,"AhmedSaihood, HosseinKarshenas, AhmadReza NaghshNilchi",10 May 2022,Image and Video Processing (eess.IV)," Lung cancer is a severe menace to human health, due to which millions of people die because of late diagnoses of cancer; thus, it is vital to detect the disease as early as possible. The Computerized chest analysis Tomography of scan is assumed to be one of the efficient solutions for detecting and classifying lung nodules. The necessity of high accuracy of analyzing C.T. scan images of the lung is considered as one of the crucial challenges in detecting and classifying lung cancer. A new long- short-term-memory (LSTM) based deep fusion structure, is introduced, where, the texture features computed from lung nodules through new volumetric grey- level-co-occurrence-matrices (GLCM) computations are applied to classify the nodules into: benign, malignant and ambiguous. An improved Otsu segmentation method combined with the water strider optimization algorithm (WSA) is proposed to detect the lung nodules. Otsu-WSA thresholding can overcome the restrictions present in previous thresholding methods. Extended experiments are run to assess this fusion structure by considering 2D-GLCM computations based 2D-slices fusion, and an approximation of this 3D-GLCM with volumetric 2.5D-GLCM computations-based LSTM fusion structure. The proposed methods are trained and assessed through the LIDC-IDRI dataset, where 94.4%, 91.6%, and 95.8% Accuracy, sensitivity, and specificity are obtained, respectively for 2D-GLCM fusion and 97.33%, 96%, and 98%, accuracy, sensitivity, and specificity, respectively, for 2.5D-GLCM fusion. The yield of the same are 98.7%, 98%, and 99%, for the 3D-GLCM fusion. The obtained results and analysis indicate that the WSA-Otsu method requires less execution time and yields a more accurate thresholding process. It is found that 3D-GLCM based LSTM outperforms its counterparts."
An Efficient Calculation of Quaternion Correlation of Signals andColor Images,"Artyom M.Grigoryan, Sos S.Agaian",10 May 2022,Commutative Algebra (math.AC)," Over the past century, a correlation has been an essential mathematical technique utilized in engineering sciences, including practically every signal/image processing field. This paper describes an effective method of calculating the correlation function of signals and color images in quaternion algebra. We propose using the quaternions with a commutative multiplication operation and defining the corresponding correlation function in this arithmetic. The correlation between quaternion signals and images can be calculated by multiplying two quaternion DFTs of signals and images. The complexity of the correlation of color images is three times higher than in complex algebra."
On equipathenergetic graphs and new bounds on path energy,"Amol P.Narke, Prashant P.Malavadkar",10 May 2022,Combinatorics (math.CO)," The path energy of a simple connected graph G is equal to the sum of the absolute values of the path eigenvalues of the graph G . (S. Shikare et. al, 2018), where the path eigenvalues of a graph G is the path eigenvalues of its path matrix. In this paper we define equipathenergetic and n -equipathenergetic graphs, their properties and several ways to construct the equipathenergetic and n -equipathenergetic graphs. We have found new upper bounds for path energy in terms of the maximum degree of a graph. A relation between energy of a graph and path energy of a graph is also provided."
Posterior predictive model checking using formal methods in a spatio-temporal model,"LauraVana, EnnioVisconti, LauraNenzi, AnnalisaCadonna, GregorKastner",4 Oct 2021,Computation (stat.CO)," We propose an interdisciplinary framework, Bayesian formal predictive model checking (Bayes FPMC), which combines Bayesian predictive inference, a well established tool in statistics, with formal verification methods rooting in the computer science community.   Bayesian predictive inference allows for coherently incorporating uncertainty about unknown quantities by making use of methods or models that produce predictive distributions which in turn inform decision problems. By formalizing these problems and the corresponding properties, we can use spatio-temporal reach and escape logic to probabilistically assess their satisfaction. This way, competing models can directly be ranked according to how well they solve the actual problem at hand.   The approach is illustrated on an urban mobility application, where the crowdedness in the center of Milan is proxied by aggregated mobile phone traffic data. We specify several desirable spatio-temporal properties related to city crowdedness such as a fault tolerant network or the reachability of hospitals. After verifying these properties on draws from the posterior predictive distributions, we compare several spatio-temporal Bayesian models based on their overall and property-based predictive performance."
A Sublinear Bound on the Page Number of Upward Planar Graphs,"PaulJungeblut, LauraMerker, TorstenUeckerdt","12 Jul 2021 (v1(https://arxiv.org/abs/2107.05227v1)), lastrevised 9 May 2022 (this version, v3)",Combinatorics (math.CO)," The page number of a directed acyclic graph $G$ is the minimum $k$ for which there is a topological ordering of $G$ and a $k$-coloring of the edges such that no two edges of the same color cross, i.e., have alternating endpoints along the topological ordering. We address the long-standing open problem asking for the largest page number among all upward planar graphs. We improve the best known lower bound to $5$ and present the first asymptotic improvement over the trivial $O(n)$ upper bound, where $n$ denotes the number of vertices in $G$. Specifically, we first prove that the page number of every upward planar graph is bounded in terms of its width, as well as its height. We then combine both approaches to show that every $n$-vertex upward planar graph has page number $O(n^{2/3} \log(n)^{2/3})$."
Reduce Information Loss in Transformers for Pluralistic ImageInpainting,"QiankunLiu, ZhentaoTan, DongdongChen, QiChu, XiyangDai, YinpengChen, Mengchen Liu, Lu Yuan, Nenghai Yu",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Transformers have achieved great success in pluralistic image inpainting recently. However, we find existing transformer based solutions regard each pixel as a token, thus suffer from information loss issue from two aspects: 1) They downsample the input image into much lower resolutions for efficiency consideration, incurring information loss and extra misalignment for the boundaries of masked regions. 2) They quantize $256^3$ RGB pixels to a small number (such as 512) of quantized pixels. The indices of quantized pixels are used as tokens for the inputs and prediction targets of transformer. Although an extra CNN network is used to upsample and refine the low-resolution results, it is difficult to retrieve the lost information [this http URL](http://back.To) keep input information as much as possible, we propose a new transformer based framework ""PUT"". Specifically, to avoid input downsampling while maintaining the computation efficiency, we design a patch-based auto-encoder P-VQVAE, where the encoder converts the masked image into non-overlapped patch tokens and the decoder recovers the masked regions from inpainted tokens while keeping the unmasked regions unchanged. To eliminate the information loss caused by quantization, an Un-Quantized Transformer (UQ-Transformer) is applied, which directly takes the features from P-VQVAE encoder as input without quantization and regards the quantized tokens only as prediction targets. Extensive experiments show that PUT greatly outperforms state-of-the-art methods on image fidelity, especially for large masked regions and complex large-scale datasets."
Learning Visual Styles from Audio-Visual Associations,"TingleLi, YichenLiu, AndrewOwens, HangZhao",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," From the patter of rain to the crunch of snow, the sounds we hear often convey the visual textures that appear within a scene. In this paper, we present a method for learning visual styles from unlabeled audio-visual data. Our model learns to manipulate the texture of a scene to match a sound, a problem we term audio-driven image stylization. Given a dataset of paired audio-visual data, we learn to modify input images such that, after manipulation, they are more likely to co-occur with a given input sound. In quantitative and qualitative evaluations, our sound-based model outperforms label-based approaches. We also show that audio can be an intuitive representation for manipulating images, as adjusting a sound's volume or mixing two sounds together results in predictable changes to visual style. Project webpage: https://tinglok.netlify.app/files/avstyle"
Towards Climate Awareness in NLP Research,"DanielHershcovich, NicolasWebersinke, MathiasKraus, JuliaAnnaBingler, MarkusLeippold","10 May 2022 (v1(https://arxiv.org/abs/2205.05071v1)), lastrevised 11 May 2022 (this version, v2)",Computation and Language (cs.CL)," The climate impact of AI, and NLP research in particular, has become a serious issue given the enormous amount of energy that is increasingly being used for training and running computational models. Consequently, increasing focus is placed on efficient NLP. However, this important initiative lacks simple guidelines that would allow for systematic climate reporting of NLP research. We argue that this deficiency is one of the reasons why very few publications in NLP report key figures that would allow a more thorough examination of environmental impact. As a remedy, we propose a climate performance model card with the primary purpose of being practically usable with only limited information about experiments and the underlying computer hardware. We describe why this step is essential to increase awareness about the environmental impact of NLP research and, thereby, paving the way for more thorough discussions."
Tensor-based Collaborative Filtering With Smooth Ratings Scale,"NikitaMarin, ElizavetaMakhneva, MariaLysyuk, VladimirChernyy, IvanOseledets, EvgenyFrolov",10 May 2022,Information Retrieval (cs.IR)," Conventional collaborative filtering techniques don't take into consideration the effect of discrepancy in users' rating perception. Some users may rarely give 5 stars to items while others almost always assign 5 stars to the chosen item. Even if they had experience with the same items this systematic discrepancy in their evaluation style will lead to the systematic errors in the ability of recommender system to effectively extract right patterns from data. To mitigate this problem we introduce the ratings' similarity matrix which represents the dependency between different values of ratings on the population level. Hence, if on average the correlations between ratings exist, it is possible to improve the quality of proposed recommendations by off-setting the effect of either shifted down or shifted up users' rates."
Accelerating the Training of Video Super-Resolution,"LijianLin, XintaoWang, Zhongang Qi, Ying Shan",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Despite that convolution neural networks (CNN) have recently demonstrated high-quality reconstruction for video super-resolution (VSR), efficiently training competitive VSR models remains a challenging problem. It usually takes an order of magnitude more time than training their counterpart image models, leading to long research cycles. Existing VSR methods typically train models with fixed spatial and temporal sizes from beginning to end. The fixed sizes are usually set to large values for good performance, resulting to slow training. However, is such a rigid training strategy necessary for VSR? In this work, we show that it is possible to gradually train video models from small to large spatial/temporal sizes, i.e., in an easy-to-hard manner. In particular, the whole training is divided into several stages and the earlier stage has smaller training spatial shape. Inside each stage, the temporal size also varies from short to long while the spatial size remains unchanged. Training is accelerated by such a multigrid training strategy, as most of computation is performed on smaller spatial and shorter temporal shapes. For further acceleration with GPU parallelization, we also investigate the large minibatch training without the loss in accuracy. Extensive experiments demonstrate that our method is capable of largely speeding up training (up to $6.2\times$ speedup in wall-clock training time) without performance drop for various VSR models. The code is available at [this https URL](https://github.com/TencentARC/Efficient-VSR-Training)."
Secure and Private Source Coding with Private Key and Decoder SideInformation,"OnurGünlü, Rafael F.Schaefer, HolgerBoche, H.Vincent Poor",10 May 2022,Information Theory (cs.IT)," The problem of secure source coding with multiple terminals is extended by considering a remote source whose noisy measurements are the correlated random variables used for secure source reconstruction. The main additions to the problem include 1) all terminals noncausally observe a noisy measurement of the remote source; 2) a private key is available to all legitimate terminals; 3) the public communication link between the encoder and decoder is rate-limited; 4) the secrecy leakage to the eavesdropper is measured with respect to the encoder input, whereas the privacy leakage is measured with respect to the remote source. Exact rate regions are characterized for a lossy source coding problem with a private key, remote source, and decoder side information under security, privacy, communication, and distortion constraints. By replacing the distortion constraint with a reliability constraint, we obtain the exact rate region also for the lossless case. Furthermore, the lossy rate region for scalar discrete-time Gaussian sources and measurement channels is established."
Metric Learning based Interactive Modulation for Real-World Super-Resolution,"ChongMou, YanzeWu, XintaoWang, ChaoDong, JianZhang, YingShan",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Interactive image restoration aims to restore images by adjusting several controlling coefficients, which determine the restoration strength. Existing methods are restricted in learning the controllable functions under the supervision of known degradation types and levels. They usually suffer from a severe performance drop when the real degradation is different from their assumptions. Such a limitation is due to the complexity of real-world degradations, which can not provide explicit supervision to the interactive modulation during training. However, how to realize the interactive modulation in real-world super-resolution has not yet been studied. In this work, we present a Metric Learning based Interactive Modulation for Real- World Super-Resolution (MM-RealSR). Specifically, we propose an unsupervised degradation estimation strategy to estimate the degradation level in real- world scenarios. Instead of using known degradation levels as explicit supervision to the interactive mechanism, we propose a metric learning strategy to map the unquantifiable degradation levels in real-world scenarios to a metric space, which is trained in an unsupervised manner. Moreover, we introduce an anchor point strategy in the metric learning process to normalize the distribution of metric space. Extensive experiments demonstrate that the proposed MM-RealSR achieves excellent modulation and restoration performance in real-world super-resolution. Codes are available at [this https URL](https://github.com/TencentARC/MM-RealSR)."
On the Verge of Solving Rocket League using Deep ReinforcementLearning and Sim-to-sim Transfer,"MarcoPleines, KonstantinRamthun, YannikWegener, HendrikMeyer, MatthiasPallasch, SebastianPrior, JannikDrögemüller, LeonBüttinghaus, ThiloRöthemeyer, AlexanderKaschwig, OliverChmurzynski, FrederikRohkrähmer, RomanKalkreuth, FrankZimmer, Mike Preuss",10 May 2022,Machine Learning (cs.LG)," Autonomously trained agents that are supposed to play video games reasonably well rely either on fast simulation speeds or heavy parallelization across thousands of machines running concurrently. This work explores a third way that is established in robotics, namely sim-to-real transfer, or if the game is considered a simulation itself, sim-to-sim transfer. In the case of Rocket League, we demonstrate that single behaviors of goalies and strikers can be successfully learned using Deep Reinforcement Learning in the simulation environment and transferred back to the original game. Although the implemented training simulation is to some extent inaccurate, the goalkeeping agent saves nearly 100% of its faced shots once transferred, while the striking agent scores in about 75% of cases. Therefore, the trained agent is robust enough and able to generalize to the target domain of Rocket League."
A Note on the Shape Regularity of Worsey-Farin Splits,"SiningGong, JohnnyGuzmán, MichaelNeilan",10 May 2022,Numerical Analysis (math.NA), We prove Worsey-Farin refinements inherit their parent triangulations' shape-regularity.
Sensible AI: Re-imagining Interpretability and Explainability usingSensemaking Theory,"HarmanpreetKaur, EytanAdar, EricGilbert, Cliff Lampe",10 May 2022,Human-Computer Interaction (cs.HC)," Understanding how ML models work is a prerequisite for responsibly designing, deploying, and using ML-based systems. With interpretability approaches, ML can now offer explanations for its outputs to aid human understanding. Though these approaches rely on guidelines for how humans explain things to each other, they ultimately solve for improving the artifact -- an explanation. In this paper, we propose an alternate framework for interpretability grounded in Weick's sensemaking theory, which focuses on who the explanation is intended for. Recent work has advocated for the importance of understanding stakeholders' needs -- we build on this by providing concrete properties (e.g., identity, social context, environmental cues, etc.) that shape human understanding. We use an application of sensemaking in organizations as a template for discussing design guidelines for Sensible AI, AI that factors in the nuances of human cognition when trying to explain itself."
Data Distributional Properties Drive Emergent Few-Shot Learning inTransformers,"Stephanie C.Y.Chan, AdamSantoro, Andrew K.Lampinen, Jane X.Wang, AadityaSingh, Pierre H.Richemond, JayMcClelland, Felix Hill","22 Apr 2022 (v1(https://arxiv.org/abs/2205.05055v1)), lastrevised 12 May 2022 (this version, v2)",Artificial Intelligence (cs.AI)," Large transformer-based language models are able to perform few- shot learning (also known as in-context learning), without having been explicitly trained for it. We hypothesized that specific distributional properties of natural language might drive this emergent phenomenon, as these characteristics might lead to a kind of interpolation between few-shot meta-training (designed to elicit rapid few-shot learning) and standard supervised training (designed to elicit gradual in-weights learning). We also hypothesized that these distributional properties could lead to emergent few-shot learning in domains outside of language. Inspired by this idea, we ran a series of experiments on a standard image-based few-shot dataset. We discovered that a number of data properties did indeed promote the emergence of few-shot learning in transformer models. All of these properties are present in natural language -- burstiness, long-tailedness, and many-to-one or one-to-many label mappings. The data influenced whether models were biased towards either few-shot learning vs. memorizing information in their weights; models could generally perform well at only one or the other. However, we discovered that an additional distributional property could allow the two capabilities to co-exist in the same model -- a skewed, Zipfian distribution over classes -- which occurs in language as well. Notably, training data that could elicit few-shot learning in transformers were unable to elicit few-shot learning in recurrent models. In sum, we find that few-shot learning emerges only from applying the right architecture to the right data distribution; neither component is sufficient on its own."
A High Throughput Generative Vector Autoregression Model forStochastic Synapses,"T.Hennen, A.Elias, J. F.Nodin, G.Molas, R.Waser, D. J.Wouters, D. Bedau",10 May 2022,Neural and Evolutionary Computing (cs.NE)," By imitating the synaptic connectivity and plasticity of the brain, emerging electronic nanodevices offer new opportunities as the building blocks of neuromorphic systems. One challenge for largescale simulations of computational architectures based on emerging devices is to accurately capture device response, hysteresis, noise, and the covariance structure in the temporal domain as well as between the different device parameters. We address this challenge with a high throughput generative model for synaptic arrays that is based on a recently available type of electrical measurement data for resistive memory cells. We map this real world data onto a vector autoregressive stochastic process to accurately reproduce the device parameters and their cross-correlation structure. While closely matching the measured data, our model is still very fast; we provide parallelized implementations for both CPUs and GPUs and demonstrate array sizes above one billion cells and throughputs exceeding one hundred million weight updates per second, above the pixel rate of a 30 frames/s 4K video stream."
Matric pencils with the numerical range equal to the whole complexplane,"VadymKoval, PatrykPagacz",10 May 2022,Numerical Analysis (math.NA)," The main purpose of this article is to show that the numerical range of a linear pencil $\lambda A + B$ is equal to $\mathbb{C}$ if and only if $0$ belongs to the joint numerical range of $A$ and $B$. We also prove that if the numerical range of a linear pencil $\lambda A + B$ is equal to $\mathbb{C}$ and $A + A^*, B + B^* \geq 0$, then $A$ and $B$ have a common isotropic vector. Moreover, we improve the classical result which describes Hermitian linear pencils."
White-box Testing of NLP models with Mask Neuron Coverage,"ArshdeepSekhon, Yangfeng Ji, Matthew B.Dwyer, Yanjun Qi",10 May 2022,Computation and Language (cs.CL)," Recent literature has seen growing interest in using black-box strategies like CheckList for testing the behavior of NLP models. Research on white-box testing has developed a number of methods for evaluating how thoroughly the internal behavior of deep models is tested, but they are not applicable to NLP models. We propose a set of white-box testing methods that are customized for transformer-based NLP models. These include Mask Neuron Coverage (MNCOVER) that measures how thoroughly the attention layers in models are exercised during testing. We show that MNCOVER can refine testing suites generated by CheckList by substantially reduce them in size, for more than 60\% on average, while retaining failing tests -- thereby concentrating the fault detection power of the test suite. Further we show how MNCOVER can be used to guide CheckList input generation, evaluate alternative NLP testing methods, and drive data augmentation to improve accuracy."
Classification and mapping of low-statured 'shrubland' cover types inpost-agricultural landscapes of the US Northeast,"Michael JMahoney, Lucas KJohnson, Colin MBeier",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Context: Novel plant communities reshape landscapes and pose challenges for land cover classification and mapping that can constrain research and stewardship efforts. In the US Northeast, emergence of low- statured woody vegetation, or 'shrublands', instead of secondary forests in post-agricultural landscapes is well-documented by field studies, but poorly understood from a landscape perspective, which limits the ability to systematically study and manage these lands. Objectives: To address gaps in classification/mapping of low-statured cover types where they have been historically rare, we developed models to predict 'shrubland' distributions at 30m resolution across New York State (NYS), using machine learning and model ensembling techniques to integrate remote sensing of structural (airborne LIDAR) and optical (satellite imagery) properties of vegetation cover. We first classified a 1m canopy height model (CHM), derived from a ""patchwork"" of available LIDAR coverages, to define shrubland presence/absence. Next, these non-contiguous maps were used to train a model ensemble based on temporally-segmented imagery to predict 'shrubland' probability for the entire study landscape (NYS). Results: Approximately 2.5% of the CHM coverage area was classified as shrubland. Models using Landsat predictors trained on the classified CHM were effective at identifying shrubland (test set AUC=0.893, real-world AUC=0.904), in discriminating between shrub/young forest and other cover classes, and produced qualitatively sensible maps, even when extending beyond the original training data. Conclusions: After ground-truthing, we expect these shrubland maps and models will have many research and stewardship applications including wildlife conservation, invasive species mitigation and natural climate solutions."
Decisions in Continuous Integration and Delivery: An Exploratory Study,"YajingLuo, PengLiang, MojtabaShahin, Zengyang Li, Chen Yang",10 May 2022,Software Engineering (cs.SE)," In recent years, Continuous Integration (CI) and Continuous Delivery (CD) has been heatedly discussed and widely used in part or all of the software development life cycle as the practices and pipeline to deliver software products in an efficient way. There are many tools, such as Travis CI, that offer various features to support the CI/CD pipeline, but there is a lack of understanding about what decisions are frequently made in CI/CD. In this work, we explored one popular open-source project on GitHub, Budibase, to provide insights on the types of decisions made in CI/CD from a practitioners' perspective. We first explored the GitHub Trending page, conducted a pilot repository extraction, and identified the Budibase repository as the case for our study. We then crawled all the closed issues from the repository and got 1,168 closed issues. Irrelevant issues were filtered out based on certain criteria, and 370 candidate issues that contain decisions were obtained for data extraction. We analyzed the issues using a hybrid approach combining pre-defined types and the Constant Comparison method to get the categories of decisions. The results show that the major type of decisions in the Budibase closed issues is Functional Requirement Decision (67.6%), followed by Architecture Decision (11.1%). Our findings encourage developers to put more effort on the issues and making decisions related to CI/CD, and provide researchers with a reference of decision classification made in CI/CD."
A Communication-Efficient Distributed Gradient Clipping Algorithm forTraining Deep Neural Networks,"MingruiLiu, ZhenxunZhuang, Yunwei Lei, Chunyang Liao",10 May 2022,Machine Learning (cs.LG)," In distributed training of deep neural networks or Federated Learning (FL), people usually run Stochastic Gradient Descent (SGD) or its variants on each machine and communicate with other machines periodically. However, SGD might converge slowly in training some deep neural networks (e.g., RNN, LSTM) because of the exploding gradient issue. Gradient clipping is usually employed to address this issue in the single machine setting, but exploring this technique in the FL setting is still in its infancy: it remains mysterious whether the gradient clipping scheme can take advantage of multiple machines to enjoy parallel speedup. The main technical difficulty lies in dealing with nonconvex loss function, non-Lipschitz continuous gradient, and skipping communication rounds simultaneously. In this paper, we explore a relaxed-smoothness assumption of the loss landscape which LSTM was shown to satisfy in previous works and design a communication-efficient gradient clipping algorithm. This algorithm can be run on multiple machines, where each machine employs a gradient clipping scheme and communicate with other machines after multiple steps of gradient- based updates. Our algorithm is proved to have $O\left(\frac{1}{N\epsilon^4}\right)$ iteration complexity for finding an $\epsilon$-stationary point, where $N$ is the number of machines. This indicates that our algorithm enjoys linear speedup. We prove this result by introducing novel analysis techniques of estimating truncated random variables, which we believe are of independent interest. Our experiments on several benchmark datasets and various scenarios demonstrate that our algorithm indeed exhibits fast convergence speed in practice and thus validates our theory."
On the Capacity of Gaussian MIMO Channels with Memory,"SergeyLoyka, Charalambos D.Charalambous",10 May 2022,Information Theory (cs.IT)," The operational capacity of Gaussian MIMO channels with memory was obtained by Brandenburg and Wyner in [9] under certain mild assumptions on the channel impulse response and its noise covariance matrix, which essentuially require channel memory to be not too strong. This channel was also considered by Tsybakov in [10] and its information capacity was obtained in some cases. It was further conjectured, based on numerical evidence, that these capacities are the same in all cases. This conjecture is proved here. An explicit closed-form expression for the optimal input power spectral density matrix is also given. The obtained result is further extended to the case of joint constraints, including per-antenna and interference power constraints as well as energy harvesting constraints. These results imply the information-theoretic optimality of OFDM-type transmission systems for such channels with memory."
Multi-agent Reinforcement Learning for Dynamic Resource Management in6G in-X Subnetworks,"XiaoDu, TingWang, QiangFeng, ChenhuiYe, TaoTao, YuanmingShi, MingsongChen",10 May 2022,Networking and Internet Architecture (cs.NI)," The 6G network enables a subnetwork-wide evolution, resulting in a ""network of subnetworks"". However, due to the dynamic mobility of wireless subnetworks, the data transmission of intra-subnetwork and inter-subnetwork will inevitably interfere with each other, which poses a great challenge to radio resource management. Moreover, most of the existing approaches require the instantaneous channel gain between subnetworks, which are usually difficult to be collected. To tackle these issues, in this paper we propose a novel effective intelligent radio resource management method using multi- agent deep reinforcement learning (MARL), which only needs the sum of received power, named received signal strength indicator (RSSI), on each channel instead of channel gains. However, to directly separate individual interference from RSSI is an almost impossible thing. To this end, we further propose a novel MARL architecture, named GA-Net, which integrates a hard attention layer to model the importance distribution of inter- subnetwork relationships based on RSSI and exclude the impact of unrelated subnetworks, and employs a graph attention network with a multi-head attention layer to exact the features and calculate their weights that will impact individual throughput. Experimental results prove that our proposed framework significantly outperforms both traditional and MARL-based methods in various aspects."
Environmental Sensing Options for Robot Teams: A ComputationalComplexity Perspective,"ToddWareham, Andrew Vardy",10 May 2022,Multiagent Systems (cs.MA)," Visual and scalar-field (e.g., chemical) sensing are two of the options robot teams can use to perceive their environments when performing tasks. We give the first comparison of the computational characteristic of visual and scalar-field sensing, phrased in terms of the computational complexities of verifying and designing teams of robots to efficiently and robustly perform distributed construction tasks. This is done relative a basic model in which teams of robots with deterministic finite-state controllers operate in a synchronous error-free manner in 2D grid-based environments. Our results show that for both types of sensing, all of our problems are polynomial-time intractable in general and remain intractable under a variety of restrictions on parameters characterizing robot controllers, teams, and environments. That being said, these results also include restricted situations for each of our problems in which those problems are effectively polynomial-time tractable. Though there are some differences, our results suggest that (at least in this stage of our investigation) verification and design problems relative to visual and scalar-field sensing have roughly the same patterns and types of tractability and intractability results."
Brazilian COVID-19 data streaming,"Nívea B. daSilva, Luis Iván O.Valencia, Fábio M. H. S.Filho, Andressa C. S.Ferreira, Felipe A. C.Pereira, Guilherme L. deOliveira, Paloma F.Oliveira, Moreno S.Rodrigues, Pablo I. P.Ramos, Juliane F.Oliveira",10 May 2022,Databases (cs.DB)," We collected individualized (unidentifiable) and aggregated openly available data from various sources related to suspected/confirmed SARS- CoV-2 infections, vaccinations, non-pharmaceutical government interventions, human mobility, and levels of population inequality in Brazil. In addition, a data structure allowing real-time data collection, curation, integration, and extract-transform-load processes for different objectives was developed. The granularity of this dataset (state- and municipality-wide) enables its application to individualized and ecological epidemiological studies, statistical, mathematical, and computational modeling, data visualization as well as the scientific dissemination of information on the COVID-19 pandemic in Brazil."
A Quantitative Symbolic Approach to Individual Human Reasoning,"EmmanuelleDietz, Johannes K.Fichte, FlorimHamiti",10 May 2022,Artificial Intelligence (cs.AI)," Cognitive theories for reasoning are about understanding how humans come to conclusions from a set of premises. Starting from hypothetical thoughts, we are interested which are the implications behind basic everyday language and how do we reason with them. A widely studied topic is whether cognitive theories can account for typical reasoning tasks and be confirmed by own empirical experiments. This paper takes a different view and we do not propose a theory, but instead take findings from the literature and show how these, formalized as cognitive principles within a logical framework, can establish a quantitative notion of reasoning, which we call plausibility. For this purpose, we employ techniques from non- monotonic reasoning and computer science, namely, a solving paradigm called answer set programming (ASP). Finally, we can fruitfully use plausibility reasoning in ASP to test the effects of an existing experiment and explain different majority responses."
Hybrid Reinforcement Learning for STAR-RISs: A Coupled Phase-ShiftModel Based Beamformer,"RuikangZhong, Yuanwei Liu, Xidong Mu, Yue Chen, XianbinWang, LajosHanzo",10 May 2022,Systems and Control (eess.SY)," A simultaneous transmitting and reflecting reconfigurable intelligent surface (STAR-RIS) assisted multi-user downlink multiple-input single-output (MISO) communication system is investigated. In contrast to the existing ideal STAR-RIS model assuming an independent transmission and reflection phase-shift control, a practical coupled phase-shift model is considered. Then, a joint active and passive beamforming optimization problem is formulated for minimizing the long-term transmission power consumption, subject to the coupled phase-shift constraint and the minimum data rate constraint. Despite the coupled nature of the phase-shift model, the formulated problem is solved by invoking a hybrid continuous and discrete phase-shift control policy. Inspired by this observation, a pair of hybrid reinforcement learning (RL) algorithms, namely the hybrid deep deterministic policy gradient (hybrid DDPG) algorithm and the joint DDPG & deep-Q network (DDPG-DQN) based algorithm are proposed. The hybrid DDPG algorithm controls the associated high-dimensional continuous and discrete actions by relying on the hybrid action mapping. By contrast, the joint DDPG-DQN algorithm constructs two Markov decision processes (MDPs) relying on an inner and an outer environment, thereby amalgamating the two agents to accomplish a joint hybrid control. Simulation results demonstrate that the STAR-RIS has superiority over other conventional RISs in terms of its energy consumption. Furthermore, both the proposed algorithms outperform the baseline DDPG algorithm, and the joint DDPG-DQN algorithm achieves a superior performance, albeit at an increased computational complexity."
A Tale of Two Markets: Investigating the Ransomware Payments Economy,"KrisOosthoek, Jack Cable, GeorgiosSmaragdakis",10 May 2022,Cryptography and Security (cs.CR)," Ransomware attacks are among the most severe cyber threats. They have made headlines in recent years by threatening the operation of governments, critical infrastructure, and corporations. Collecting and analyzing ransomware data is an important step towards understanding the spread of ransomware and designing effective defense and mitigation mechanisms. We report on our experience operating Ransomwhere, an open crowdsourced ransomware payment tracker to collect information from victims of ransomware attacks. With Ransomwhere, we have gathered 13.5k ransom payments to more than 87 ransomware criminal actors with total payments of more than $101 million. Leveraging the transparent nature of Bitcoin, the cryptocurrency used for most ransomware payments, we characterize the evolving ransomware criminal structure and ransom laundering strategies. Our analysis shows that there are two parallel ransomware criminal markets: commodity ransomware and Ransomware as a Service (RaaS). We notice that there are striking differences between the two markets in the way that cryptocurrency resources are utilized, revenue per transaction, and ransom laundering efficiency. Although it is relatively easy to identify choke points in commodity ransomware payment activity, it is more difficult to do the same for RaaS."
Bridging the gap: symplecticity and low regularity on the example ofthe KdV equation,"GeorgMaierhofer, KatharinaSchratz",10 May 2022,Numerical Analysis (math.NA)," Recent years have seen an increasing amount of research devoted to the development of so-called resonance-based methods for dispersive nonlinear partial differential equations. In many situations, this new class of methods allows for approximations in a much more general setting (e.g. for rough data) than, for instance, classical splitting or exponential integrator methods. However, they lack one important property: the preservation of geometric structures. This is particularly drastic in the case of the Korteweg--de Vries (KdV) equation which is a fundamental model in the broad field of dispersive equations that is completely integrable, possessing infinitely many conserved quantities, an important property which we wish to capture -- at least up to some degree -- also on the discrete level. A revolutionary step in this direction was set by the theory of geometric numerical integration resulting in the development of a wide range of structure-preserving algorithms for Hamiltonian systems. However, in general, these methods rely heavily on highly regular solutions. State-of- the-art low-regularity integrators, on the other hand, poorly preserve the geometric structure of the underlying PDE. This work makes a first step towards bridging the gap between low regularity and structure preservation. We introduce a novel symplectic (in the Hamiltonian picture) resonance-based method on the example of the KdV equation that allows for low-regularity approximations to the solution while preserving the underlying geometric structure of the continuous problem on the discrete level."
A Finite-Range Search Formulation of Maximum Likelihood MIMO Detectionfor Coherent Ising Machines,"Abhishek KumarSingh, DavideVenturelli, KyleJamieson",10 May 2022,Networking and Internet Architecture (cs.NI)," The last couple of years have seen an emergence of physics- inspired computing for maximum likelihood MIMO detection. These methods involve transforming the MIMO detection problem into an Ising minimization problem, which can then be solved on an Ising Machine. Recent works have shown promising projections for MIMO wireless detection using Quantum Annealing optimizers and Coherent Ising Machines. While these methods perform very well for BPSK and 4-QAM, they struggle to provide good BER for 16-QAM and higher modulations. In this paper, we explore an enhanced CIM model, and propose a novel Ising formulation, which together are shown to be the first Ising solver that provides significant gains in the BER performance of large and massive MIMO systems, like $16\times16$ and $16\times32$, and sustain its performance gain even at 256-QAM modulation. We further perform a spectral efficiency analysis and show that, for a $16\times16$ MIMO with Adaptive Modulation and Coding, our method can provide substantial throughput gains over MMSE, achieving $2\times$ throughput for SNR $\leq25$ dB, and up to $1.5\times$ throughput for SNR $\geq 30$ dB."
Learning to Answer Visual Questions from Web Videos,"AntoineYang, AntoineMiech, JosefSivic, IvanLaptev, CordeliaSchmid","10 May 2022 (v1(https://arxiv.org/abs/2205.05019v1)), lastrevised 11 May 2022 (this version, v2)",Computer Vision and Pattern Recognition (cs.CV)," Recent methods for visual question answering rely on large-scale annotated datasets. Manual annotation of questions and answers for videos, however, is tedious, expensive and prevents scalability. In this work, we propose to avoid manual annotation and generate a large-scale training dataset for video question answering making use of automatic cross-modal supervision. We leverage a question generation transformer trained on text data and use it to generate question-answer pairs from transcribed video narrations. Given narrated videos, we then automatically generate the HowToVQA69M dataset with 69M video-question-answer triplets. To handle the open vocabulary of diverse answers in this dataset, we propose a training procedure based on a contrastive loss between a video-question multi-modal transformer and an answer transformer. We introduce the zero-shot VideoQA task and the VideoQA feature probe evaluation setting and show excellent results, in particular for rare answers. Furthermore, our method achieves competitive results on MSRVTT-QA, ActivityNet-QA, MSVD-QA and How2QA datasets. We also show that our VideoQA dataset generation approach generalizes to another source of web video and text data. We use our method to generate the WebVidVQA3M dataset from the WebVid dataset, i.e., videos with alt-text annotations, and show its benefits for training VideoQA models. Finally, for a detailed evaluation we introduce iVQA, a new VideoQA dataset with reduced language bias and high-quality manual annotations. Code, datasets and trained models are available at [this https URL](https://antoyang.github.io/just-ask.html)"
Robust Optimization for Local Differential Privacy,"JasperGoseling, Milan Lopuhaä-Zwakenberg",10 May 2022,Information Theory (cs.IT), We consider the setting of publishing data without leaking sensitive information. We do so in the framework of Robust Local Differential Privacy (RLDP). This ensures privacy for all distributions of the data in an uncertainty set. We formulate the problem of finding the optimal data release protocol as a robust optimization problem. By deriving closed-form expressions for the duals of the constraints involved we obtain a convex optimization problem. We compare the performance of four possible optimization problems depending on whether or not we require robustness in i) utility and ii) privacy.
Neuromimetic Linear Systems -- Resilience and Learning,"ZexinSun, JohnBaillieul",10 May 2022,Systems and Control (eess.SY)," Building on our recent work on {\em neuromimetic control theory}, new results on resilience and neuro-inspired quantization are reported. The term neuromimetic refers to the models having features that are characteristic of the neurobiology of biological motor control. As in previous work, the focus is on what we call {\em overcomplete} linear systems that are characterized by larger numbers of input and output channels than the dimensions of the state. The specific contributions of the present paper include a proposed {\em resilient} observer whose operation tolerates output channel intermittency and even complete dropouts. Tying these ideas together with our previous work on resilient stability, a resilient separation principle is established. We also propose a {\em principled quantization} in which control signals are encoded as simple discrete inputs which act collectively through the many channels of input that are the hallmarks of the overcomplete models. Aligned with the neuromimetic paradigm, an {\em emulation} problem is proposed and this in turn defines an optimal quantization problem. Several possible solutions are discussed including direct combinatorial optimization, a Hebbian-like iterative learning algorithm, and a deep Q-learning (DQN) approach. For the problems being considered, machine learning approaches to optimization provide valuable insights regarding comparisons between optimal and nearby suboptimal solutions. These are useful in understanding the kinds of resilience to intermittency and channel dropouts that were earlier demonstrated for continuous systems."
Exploring Viable Algorithmic Options for Automatically Creating andReconfiguring Component-based Software Systems: A Computational ComplexityApproach (Full Version),"ToddWareham, MariekeSweers",10 May 2022,Software Engineering (cs.SE)," Component-Based Development (CBD) is a popular approach to mitigating the costs of creating software systems. However, it is not clear to what extent the core component selection and adaptation activities of CBD can be implemented to operate automatically in an efficient and reliable manner or in what situations (if any) CBD is preferable to other approaches to software development. In this paper, we use computational complexity analysis to determine and compare the computational characteristics of fully automatic component-based software system creation and reconfiguration by de novo design, component selection, and component selection with adaptation. Our results show that none of these approaches can be implemented to operate both efficiently and reliably in a fully automatic manner either in general or relative to a number of restrictions on software systems, system requirements, components, and component adaptation. We also give restrictions under which all of these approaches can be implemented to operate both efficiently and reliably. As such, this paper illustrates how different types of computational complexity analysis (in particular, parameterized complexity analysis) can be used to systematically explore the algorithmic options for implementing automatic activities in software engineering."
Metamorphic Testing and Debugging of Tax Preparation Software,"Saeid Tizpaz-Niari, MorganWagner, ShivaDarian, Krystia Reed, AshutoshTrivedi",10 May 2022,Software Engineering (cs.SE)," This paper presents a data-driven debugging framework to improve the trustworthiness of US tax preparation software. As the US tax law evolves to adapt to ever-changing politico-economic realities, tax preparation software plays a significant role in helping taxpayers navigate these complexities. Given the legal implications of bugs in such software on its users, ensuring the compliance and trustworthiness of tax preparation software is of paramount importance. The key obstacles in developing debugging aids for tax preparation systems, however, are the unavailability of explicit specifications and the difficulty of obtaining oracles. We posit that, since the US tax law adheres to the legal doctrine of precedent, the specifications about the outcome of tax preparation software for an individual taxpayer must be viewed in comparison with individuals that are deemed similar. Consequently, these specifications are naturally available as properties on the software requiring similar inputs provide similar outputs. Inspired by metamorphic testing framework from software engineering, we dub these relations metamorphic relations. We explicated metamorphic relations for a set of properties by carefully studying the US Form 1040 as implemented in an open-source tax preparation software. We developed a randomized search strategy to explore the space of metamorphic relations and explain the behaviors of software with a classification tree algorithm. Our tool revealed $4$ types of failures in the software and provided intuitive explanations to understand the failures."
Improving Emergency Training for Earthquakes Through Immersive VirtualEnvironments and Anxiety Tests: A Case Study,"Mohammad SadraRajabi, HoseinTaghaddos, MehdiZahrai",10 May 2022,Human-Computer Interaction (cs.HC)," Because of the occurrence of severe and large magnitude earthquakes each year, earthquake-prone countries suffer considerable financial damage and loss of life. Teaching essential safety measures will lead to a generation that can perform basic procedures during an earthquake, which is an important and effective solution in preventing the loss of life in this natural disaster. In recent years, virtual reality technology is a tool that has been used to educate people on safety matters. This paper evaluates the effect of education and premonition on the incorrect decision- making of residents under the stressful conditions of an earthquake. For this purpose, a virtual model has been designed and built from a proposed classroom in a school of the city of Tehran. Accordingly, two educational scenarios, presented in reality and the virtual model respectively, were conducted on a statistical sample of 20 students within the range of 20 to 25 years of age. Within the mentioned sample, the first group of 10 students were taught safety measures in a traditional classroom. The second group of 10 students participated in a virtual classroom. Evaluation tests on safety measures against earthquakes were distributed after two weeks. Furthermore, two self-reporting tests of Depression, anxiety, stress test (DASS), and Beck Anxiety Inventory (BAI) were assigned to the second group to evaluate the effect of foresight under two different scenarios. The results show that educating through virtual reality technology yields a higher performance level relative to the traditional approach to education. Additionally, the ability to detect earthquakes ahead of time is an influential factor in controlling stress and determining the right decisions should the event occur."
KeypointNeRF: Generalizing Image-based Volumetric Avatars usingRelative Spatial Encoding of Keypoints,"MarkoMihajlovic, AayushBansal, MichaelZollhoefer, Siyu Tang, ShunsukeSaito",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Image-based volumetric avatars using pixel-aligned features promise generalization to unseen poses and identities. Prior work leverages global spatial encodings and multi-view geometric consistency to reduce spatial ambiguity. However, global encodings often suffer from overfitting to the distribution of the training data, and it is difficult to learn multi-view consistent reconstruction from sparse views. In this work, we investigate common issues with existing spatial encodings and propose a simple yet highly effective approach to modeling high-fidelity volumetric avatars from sparse views. One of the key ideas is to encode relative spatial 3D information via sparse 3D keypoints. This approach is robust to the sparsity of viewpoints and cross-dataset domain gap. Our approach outperforms state-of-the-art methods for head reconstruction. On human body reconstruction for unseen subjects, we also achieve performance comparable to prior work that uses a parametric human body model and temporal feature aggregation. Our experiments show that a majority of errors in prior work stem from an inappropriate choice of spatial encoding and thus we suggest a new direction for high-fidelity image-based avatar modeling. [this https URL](https://markomih.github.io/KeypointNeRF)"
Exploring Viable Algorithmic Options for Learning from Demonstration(LfD): A Parameterized Complexity Approach,ToddWareham,10 May 2022,Machine Learning (cs.LG)," The key to reconciling the polynomial-time intractability of many machine learning tasks in the worst case with the surprising solvability of these tasks by heuristic algorithms in practice seems to be exploiting restrictions on real-world data sets. One approach to investigating such restrictions is to analyze why heuristics perform well under restrictions. A complementary approach would be to systematically determine under which sets of restrictions efficient and reliable machine learning algorithms do and do not exist. In this paper, we show how such a systematic exploration of algorithmic options can be done using parameterized complexity analysis, As an illustrative example, we give the first parameterized complexity analysis of batch and incremental policy inference under Learning from Demonstration (LfD). Relative to a basic model of LfD, we show that none of our problems can be solved efficiently either in general or relative to a number of (often simultaneous) restrictions on environments, demonstrations, and policies. We also give the first known restrictions under which efficient solvability is possible and discuss the implications of our solvability and unsolvability results for both our basic model of LfD and more complex models of LfD used in practice."
On the Value of Project Productivity for Early Effort Estimation,"MohammadAzzeh, AliBouNassif, YousefElsheikh, LefterisAngelis",10 May 2022,Software Engineering (cs.SE)," In general, estimating software effort using a Use Case Point (UCP) size requires the use of productivity as a second prediction factor. However, there are three drawbacks to this approach: (1) there is no clear procedure for predicting productivity in the early stages, (2) the use of fixed or limited productivity ratios does not allow research to reflect the realities of the software industry, and (3) productivity from historical data is often challenging. The new UCP datasets now available allow us to perform further empirical investigations of the productivity variable in order to estimate the UCP effort. Accordingly, four different prediction models based on productivity were used. The results showed that learning productivity from historical data is more efficient than using classical approaches that rely on default or limited productivity values. In addition, predicting productivity from historical environmental factors is not often accurate. From here we conclude that productivity is an effective factor for estimating the software effort based on the UCP in the presence and absence of previous historical data. Moreover, productivity measurement should be flexible and adjustable when historical data is available"
Homophilic and Heterophilic Characteristics Shaping CommunityFormation in Human Mobility Networks During Extreme Weather Response,"Cheng-ChunLee, SiriNamburi, Xin Xiao, AliMostafavi",10 May 2022,Social and Information Networks (cs.SI)," Community formation in socio-spatial human networks is one of the important mechanisms for ameliorating hazard impacts of extreme weather events. Research is scarce regarding latent network characteristics shaping community formation in human mobility networks during natural disasters. We examined human mobility networks in Harris County, Texas, in the context of the managed power outage forced by Winter Storm Uri to detect communities and to evaluate latent characteristics in those communities. We examined three characteristics in the communities formed within human mobility networks: hazard-exposure heterophily, socio-demographic homophily, and social connectedness strength. The analysis results show that population movements were shaped by socio-demographic homophily, heterophilic hazard exposure, and social connectedness strength. The results also indicate that a community encompassing more high-impact areas would motivate population movements to areas with weaker social connectedness. Hence, the findings reveal important characteristics shaping community formation in human mobility networks in hazard response. Specific to managed power outages, formed communities are spatially co-located, underscoring a best management practice to avoid prolonged power outages among areas within communities, thus improving hazard-exposure heterophily. The findings have implications for power utility operators to account for the characteristics of socio- spatial human networks when determining the patterns of managed power outages."
ALLSH: Active Learning Guided by Local Sensitivity and Hardness,"ShujianZhang, ChengyueGong, Xingchao Liu, Pengcheng He, Weizhu Chen, Mingyuan Zhou",10 May 2022,Computation and Language (cs.CL)," Active learning, which effectively collects informative unlabeled data for annotation, reduces the demand for labeled data. In this work, we propose to retrieve unlabeled samples with a local sensitivity and hardness- aware acquisition function. The proposed method generates data copies through local perturbations and selects data points whose predictive likelihoods diverge the most from their copies. We further empower our acquisition function by injecting the select-worst case perturbation. Our method achieves consistent gains over the commonly used active learning strategies in various classification tasks. Furthermore, we observe consistent improvements over the baselines on the study of prompt selection in prompt-based few-shot learning. These experiments demonstrate that our acquisition guided by local sensitivity and hardness can be effective and beneficial for many NLP tasks."
NeRF-Editing: Geometry Editing of Neural Radiance Fields,"Yu-JieYuan, Yang-Tian Sun, Yu-Kun Lai, Yuewen Ma, Rongfei Jia, Lin Gao",10 May 2022,Graphics (cs.GR)," Implicit neural rendering, especially Neural Radiance Field (NeRF), has shown great potential in novel view synthesis of a scene. However, current NeRF-based methods cannot enable users to perform user- controlled shape deformation in the scene. While existing works have proposed some approaches to modify the radiance field according to the user's constraints, the modification is limited to color editing or object translation and rotation. In this paper, we propose a method that allows users to perform controllable shape deformation on the implicit representation of the scene, and synthesizes the novel view images of the edited scene without re-training the network. Specifically, we establish a correspondence between the extracted explicit mesh representation and the implicit neural representation of the target scene. Users can first utilize well-developed mesh-based deformation methods to deform the mesh representation of the scene. Our method then utilizes user edits from the mesh representation to bend the camera rays by introducing a tetrahedra mesh as a proxy, obtaining the rendering results of the edited scene. Extensive experiments demonstrate that our framework can achieve ideal editing results not only on synthetic data, but also on real scenes captured by users."
The Future of Hybrid Meetings,"MariosConstantinides, DanieleQuercia",10 May 2022,Human-Computer Interaction (cs.HC)," Meetings are typically considered to be the fuel of an organization's productivity -- a place where employees discuss ideas and make collective decisions. However, it is no secret that meetings are also often perceived as wasteful vacuums, depleting employee morale and productivity, likely due to the fact that current technologies fall short in fully supporting physical or virtual meeting experience. In this position paper, we discuss the three key elements that make a meeting successful (i.e., execution, psychological safety, and physical comfort), and present new tools for hybrid meetings that incorporate those elements. As past research has focused on supporting meeting execution (the first element), we set the roadmap for future research on the two other elements: on psychological safety by articulating how new technologies could make meeting useful for all participants, ensure all participants give and receive appropriate levels of attention, and enable all participants to feel and make others feel comfortable; and on physical comfort by dwelling on how new technologies could make the meeting experience comfortable by integrating all human senses. We also discuss the potential danger of these technologies inadvertently becoming surveillance tools."
How Game Jams and Hackathons Accelerate Design Processes,JeanetteFalk,"10 May 2022 (v1(https://arxiv.org/abs/2205.04966v1)), lastrevised 11 May 2022 (this version, v2)",Human-Computer Interaction (cs.HC)," This dissertation presents three years of research on how design processes in game jams and hackathons can be understood as accelerated. Hackathons and game jams can both be described as formats where participants engage in designing and developing prototypes during an intentionally short time frame, such as 48 hours, which is meant to facilitate creativity, and encourage fast decision making and rapid prototyping. Game jams and hackathons are organised in many different contexts and for many different purposes as well, such as: internally in companies to spark new ideas; for fostering citizen innovation for municipalities; in cultural and governmental agencies; integral parts of education; entry points for developers wanting to enter especially the game industry (Olesen, 2020; Kultima, 2015). During the recent decade, game jams and hackathons have been introduced to academia as well, as formats for teaching and learning, and as research platforms as well. Only few research contributions engage with understanding how accelerated design processes in game jams and hackathons unfold, or how the organisation of game jam and hackathon formats influence these accelerated design processes.   The main contributions of my PhD project are: 1) Descriptive process-level knowledge, which contextualise and solidify how accelerated design processes unfold under the circumstances of a game jam and a hackathon. 2) Overviews of how game jams have been organised for supporting participants' creativity and of how hackathons have been used as means and as research focus within academia. 3) Exploring how game jam and hackathon formats may be organised in order to support knowledge generation such as within academia, and in order to support creativity."
Privadome: Protecting Citizen Privacy from Delivery Drones,"GokulnathPillai, EikanshGupta, AjithSuresh, VinodGanapathy, Arpita Patra",10 May 2022,Cryptography and Security (cs.CR)," As e-commerce companies begin to consider using delivery drones for customer fulfillment, there are growing concerns around citizen privacy. Drones are equipped with cameras, and the video feed from these cameras is often required as part of routine navigation, be it for semi autonomous or fully-autonomous drones. Footage of ground-based citizens may be captured in this video feed, thereby leading to privacy concerns.   This paper presents Privadome, a system that implements the vision of a virtual privacy dome centered around the citizen. Privadome is designed to be integrated with city-scale regulatory authorities that oversee delivery drone operations and realizes this vision through two components, PD-MPC and PD-ROS. PD-MPC allows citizens equipped with a mobile device to identify drones that have captured their footage. It uses secure two-party computation to achieve this goal without compromising the privacy of the citizen's location.   PD-ROS allows the citizen to communicate with such drones and obtain an audit trail showing how the drone uses their footage and determine if privacy-preserving steps are taken to sanitize the footage. An experimental evaluation of Privadome using our prototype implementations of PD-MPC and PD-ROS shows that the system scales to near-term city-scale delivery drone deployments (hundreds of drones). We show that with PD-MPC the mobile data usage on the citizen's mobile device is comparable to that of routine activities on the device, such as streaming videos. We also show that the workflow of PD-ROS consumes a modest amount of additional CPU resources and power on our experimental platform."
Parallel Batch-Dynamic Minimum Spanning Forest and the Efficiency ofDynamic Agglomerative Graph Clustering,"TomTseng, LaxmanDhulipala, Julian Shun",10 May 2022,Data Structures and Algorithms (cs.DS)," Hierarchical agglomerative clustering (HAC) is a popular algorithm for clustering data, but despite its importance, no dynamic algorithms for HAC with good theoretical guarantees exist. In this paper, we study dynamic HAC on edge-weighted graphs. As single-linkage HAC reduces to computing a minimum spanning forest (MSF), our first result is to develop a parallel batch-dynamic algorithm for maintaining MSFs. On a batch of $k$ edge insertions or deletions, our batch-dynamic MSF algorithm runs in $O(k\log^6 n)$ expected amortized work and $O(\log^4 n)$ span with high probability. It is the first fully dynamic MSF algorithm handling batches of edge updates with polylogarithmic work per update and polylogarithmic span. Using MSF, we obtain a parallel batch-dynamic algorithm that can answer queries about single-linkage graph HAC clusters.   Our second result is that dynamic graph HAC is significantly harder for other common linkage functions. Assuming the strong exponential time hypothesis, dynamic graph HAC requires $\Omega(n^{1-o(1)})$ work per update or query on a graph with $n$ vertices for complete linkage, weighted average linkage, and average linkage. For complete linkage and weighted average linkage, this bound still holds even for incremental or decremental algorithms and even if we allow $\operatorname{poly}(n)$-approximation. For average linkage, the bound weakens to $\Omega(n^{1/2 - o(1)})$ for incremental and decremental algorithms, and the bounds still hold if we allow $O(n^{o(1)})$-approximation."
Read the Room: Adapting a Robot's Voice to Ambient and Social Contexts,"EmmaHughson, PaigeTuttosi, AkihiroMatsufuji, Angelica Lim",10 May 2022,Robotics (cs.RO)," Adapting one's voice to different ambient environments and social interactions is required for human social interaction. In robotics, the ability to recognize speech in noisy and quiet environments has received significant attention, but considering ambient cues in the production of social speech features has been little explored. Our research aims to modify a robot's speech to maximize acceptability in various social and acoustic contexts, starting with a use case for service robots in varying restaurants. We created an original dataset collected over Zoom with participants conversing in scripted and unscripted tasks given 7 different ambient sounds and background images. Voice conversion methods, in addition to altered Text-to-Speech that matched ambient specific data, were used for speech synthesis tasks. We conducted a subjective perception study that showed humans prefer synthetic speech that matches ambience and social context, ultimately preferring more human-like voices. This work provides three solutions to ambient and socially appropriate synthetic voices: (1) a novel protocol to collect real contextual audio voice data, (2) tools and directions to manipulate robot speech for appropriate social and ambient specific interactions, and (3) insight into voice conversion's role in flexibly altering robot speech to match different ambient environments."
Transformer-based Cross-Modal Recipe Embeddings with Large BatchTraining,"JingYang, JunwenChen, KeijiYanai",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In this paper, we present a cross-modal recipe retrieval framework, Transformer-based Network for Large Batch Training (TNLBT), which is inspired by ACME~(Adversarial Cross-Modal Embedding) and H-T~(Hierarchical Transformer). TNLBT aims to accomplish retrieval tasks while generating images from recipe embeddings. We apply the Hierarchical Transformer-based recipe text encoder, the Vision Transformer~(ViT)-based recipe image encoder, and an adversarial network architecture to enable better cross-modal embedding learning for recipe texts and images. In addition, we use self-supervised learning to exploit the rich information in the recipe texts having no corresponding images. Since contrastive learning could benefit from a larger batch size according to the recent literature on self-supervised learning, we adopt a large batch size during training and have validated its effectiveness. In the experiments, the proposed framework significantly outperformed the current state-of-the-art frameworks in both cross-modal recipe retrieval and image generation tasks on the benchmark Recipe1M. This is the first work which confirmed the effectiveness of large batch training on cross-modal recipe embeddings."
Fast Performance Evaluation of Linear Block Codes over MemorylessContinuous Channels,"JinzhePan, Wai HoMow","10 May 2022 (v1(https://arxiv.org/abs/2205.04943v1)), lastrevised 11 May 2022 (this version, v2)",Information Theory (cs.IT)," There are rising scenarios in communication systems, where the noises exhibit impulsive behavior and are not adequate to be modeled as the Gaussian distribution. The generalized Gaussian distribution instead is an effective model to describe real-world systems with impulsive noises. In this paper, the problem of efficiently evaluating the error performance of linear block codes over an additive white generalized Gaussian noise (AWGGN) channel is considered. The Monte Carlo (MC) simulation is a widely used but inefficient performance evaluation method, especially in the low error probability regime. As a variance-reduction technique, importance sampling (IS) can significantly reduce the sample size needed for reliable estimation based on a well-designed IS distribution. By deriving the optimal IS distribution on the one-dimensional space mapped from the observation space, we present a general framework to designing IS estimators for memoryless continuous channels. Specifically, for the AWGGN channel, we propose an $L_p$-norm-based minimum-variance IS estimator. As an efficiency measure, the asymptotic IS gain of the proposed estimator is derived in a multiple integral form as the signal-to-noise ratio tends to infinity. Specifically, for the Laplace and Gaussian noises, the gains can be derived in a one- dimensional integral form, which makes the numerical calculation affordable. In addition, by limiting the use of the union bound to an optimized $L_1$-norm sphere, we derive the sphere bound for the additive white Laplace noise channel. Simulation results verify the accuracy of the derived IS gain in predicting the efficiency of the proposed IS estimator."
Proactive Traffic Offloading in Dynamic Integrated Multi-SatelliteTerrestrial Networks,"WiemAbderrahim, Osama Amin, Mohamed-SlimAlouini, BasemShihada",10 May 2022,Networking and Internet Architecture (cs.NI)," The integration between the satellite network and the terrestrial network will play a key role in the upcoming sixth-generation (6G) of mobile cellular networks thanks to the wide coverage and bandwidth offered by satellite networks. To leverage this integration, we propose a proactive traffic offloading scheme in an integrated multi-satellite terrestrial network (IMSTN) that considers the future networks' heterogeneity and predicts their variability. Our proposed offloading scheme hinges on traffic prediction to answer the stringent requirements of data-rate, latency and reliability imposed by heterogeneous and coexisting services and traffic namely enhanced mobile broadband (eMBB), massive machine-type communications (mMTC) and ultra-reliable low latency communication (URLLC). However, the fulfilment of these requirements during offloading in dynamic IMSTN comes at the expense of significant energy consumption and introduces inherently supplementary latency. Therefore, our offloading scheme aims to balance the fundamental trade-offs first between energy consumption and the achievable data-rate and second between energy consumption and latency while meeting the respective needs of the present traffic. Our findings prove the importance of the cooperation between the multi-satellite network and the terrestrial network conditioned by traffic prediction to enhance the performance of IMTSN in terms of latency and energy consumption."
Pointwise Maximal Leakage,SaraSaeidian(1) GiuliaCervia (2)Tobias J.Oechtering(1) MikaelSkoglund(1) ((1) KTH Royal Institute of Technology ,10 May 2022,Information Theory (cs.IT)," We introduce a privacy measure called pointwise maximal leakage, defined based on the pre-existing notion of maximal leakage, which quantifies the amount of information leaking about a secret $X$ by disclosing a single outcome of a (randomized) function calculated on $X$. Pointwise maximal leakage is a robust and operationally meaningful privacy measure that captures the largest amount of information leaking about $X$ to adversaries seeking to guess arbitrary (possibly randomized) functions of $X$, or equivalently, aiming to maximize arbitrary gain functions. We study several properties of pointwise maximal leakage, e.g., how it composes over multiple outcomes, how it is affected by pre- and post-processing, etc. Furthermore, we propose to view privacy leakage as a random variable which, in turn, allows us to regard privacy guarantees as requirements imposed on different statistical properties of the privacy leakage random variable. We define several privacy guarantees and study how they behave under pre- processing, post-processing and composition. Finally, we examine the relationship between pointwise maximal leakage and other privacy notions such as local differential privacy, local information privacy, $f$-information, and so on."
The spatial computer: A model for energy-efficient parallelcomputation,"LukasGianinazzi, Tal Ben-Nun, SalehAshkboos, YvesBaumann, PiotrLuczynski, TorstenHoefler",10 May 2022,Data Structures and Algorithms (cs.DS)," We present a new parallel model of computation suitable for spatial architectures, for which the energy used for communication heavily depends on the distance of the communicating processors. In our model, processors have locations on a conceptual two-dimensional grid, and their distance therein determines their communication cost. In particular, we introduce the energy cost of a spatial computation, which measures the total distance traveled by all messages, and study the depth of communication, which measures the largest number of hops of a chain of messages. We show matching energy lower and upper bounds for many foundational problems, including sorting, median selection, and matrix multiplication. Our model does not depend on any parameters other than the input shape and size, simplifying algorithm analysis. We also show how to simulate PRAM algorithms in our model and how to obtain results for a more complex model that introduces the size of the local memories of the processors as a parameter."
QUANTAS: Quantitative User-friendly Adaptable Networked ThingsAbstract Simulator,"JosephOglio, Kendric Hood, MikhailNesterenko, SebastienTixeuil","10 May 2022 (v1(https://arxiv.org/abs/2205.04930v1)), lastrevised 12 May 2022 (this version, v2)","Distributed, Parallel, and Cluster Computing (cs.DC)"," We present QUANTAS: a simulator that enables quantitative performance analysis of distributed algorithms. It has a number of attractive features. QUANTAS is an abstract simulator, therefore, the obtained results are not affected by the specifics of a particular network or operating system architecture. QUANTAS allows distributed algorithms researchers to quickly investigate a potential solution and collect data about its performance. QUANTAS programming is relatively straightforward and is accessible to theoretical researchers. To demonstrate QUANTAS capabilities, we implement and compare the behavior of two representative examples from four major classes of distributed algorithms: blockchains, distributed hash tables, consensus, and reliable data link message transmission."
Fast Obstacle Avoidance Based on Real-Time Sensing,"LukasHuber, AudeBillard, Jean-JacquesSlotine",10 May 2022,Robotics (cs.RO)," Humans are remarkable at navigating and moving through dynamic and complex spaces, such as crowded streets. For robots to do the same, it is crucial that they are endowed with highly reactive obstacle avoidance robust to partial and poor sensing. We address the issue of enabling obstacle avoidance based on sparse and asynchronous perception. The proposed control scheme combines a high-level input command provided by either a planner or a human operator with fast reactive obstacle avoidance. The sampling-based sensor data can be combined with an analytical reconstruction of the obstacles for real-time collision avoidance. We can ensure that the agent does not get stuck when a feasible path exists between obstacles. The algorithm was evaluated experimentally on static laser data from cluttered, indoor office environments. Additionally, it was used in a shared control mode in a dynamic and complex outdoor environment in the center of Lausanne. The proposed control scheme successfully avoided collisions in both scenarios. During the experiments, the controller on the onboard computer took 1 millisecond to evaluate over 30000 data points."
Gamified Speaker Comparison by Listening,"SandipGhimire, TomiKinnunen, Rosa GonzalezHautamäki",10 May 2022,Sound (cs.SD)," We address speaker comparison by listening in a game-like environment, hypothesized to make the task more motivating for naive listeners. We present the same 30 trials selected with the help of an x-vector speaker recognition system from VoxCeleb to a total of 150 crowdworkers recruited through Amazon's Mechanical Turk. They are divided into cohorts of 50, each using one of three alternative interface designs: (i) a traditional (nongamified) design; (ii) a gamified design with feedback on decisions, along with points, game level indications, and possibility for interface customization; (iii) another gamified design with an additional constraint of maximum of 5 'lives' consumed by wrong answers. We analyze the impact of these interface designs to listener error rates (both misses and false alarms), probability calibration, time of quitting, along with survey questionnaire. The results indicate improved performance from (i) to (ii) and (iii), particularly in terms of balancing the two types of detection errors."
Iterative models for complex networks formed by extending cliques,"AnthonyBonato, RyanCushman, Trent G.Marbach, ZhiyuanZhang",10 May 2022,Discrete Mathematics (cs.DM)," We consider a new model for complex networks whose underlying mechanism is extending dense subgraphs. In the frustum model, we iteratively extend cliques over discrete-time steps. For many choices of the underlying parameters, graphs generated by the model densify over time. In the special case of the cone model, generated graphs provably satisfy properties observed in real-world complex networks such as the small world property and bad spectral expansion. We finish with a set of open problems and next steps for the frustum model."
Rich Screen Reader Experiences for Accessible Data Visualization,"JonathanZong, CrystalLee, AlanLundgard, JiWoong Jang, DanielHajas, ArvindSatyanarayan",10 May 2022,Human-Computer Interaction (cs.HC)," Current web accessibility guidelines ask visualization designers to support screen readers via basic non-visual alternatives like textual descriptions and access to raw data tables. But charts do more than summarize data or reproduce tables; they afford interactive data exploration at varying levels of granularity -- from fine-grained datum-by-datum reading to skimming and surfacing high-level trends. In response to the lack of comparable non-visual affordances, we present a set of rich screen reader experiences for accessible data visualization and exploration. Through an iterative co-design process, we identify three key design dimensions for expressive screen reader accessibility: structure, or how chart entities should be organized for a screen reader to traverse; navigation, or the structural, spatial, and targeted operations a user might perform to step through the structure; and, description, or the semantic content, composition, and verbosity of the screen reader's narration. We operationalize these dimensions to prototype screen-reader-accessible visualizations that cover a diverse range of chart types and combinations of our design dimensions. We evaluate a subset of these prototypes in a mixed- methods study with 13 blind and low vision readers. Our findings demonstrate that these designs help users conceptualize data spatially, selectively attend to data of interest at different levels of granularity, and experience control and agency over their data analysis process. An accessible HTML version of this paper is available at: [this http URL](http://vis.csail.mit.edu/pubs/rich-screen-reader-vis-experiences)."
Understanding the Capability of PD Control for Uncertain StochasticSystems,"ChengZhao, YanbinZhang",10 May 2022,Systems and Control (eess.SY)," In this article, we focus on the global stabilizability problem for a class of second order uncertain stochastic control systems, where both the drift term and the diffusion term are nonlinear functions of the state variables and the control variables. We will show that the widely applied proportional-derivative(PD) control in engineering practice has the ability to globally stabilize such systems in the mean square sense, provided that the upper bounds of the partial derivatives of the nonlinear functions satisfy a certain algebraic inequality. It will also be proved that the stabilizing PD parameters can only be selected from a two dimensional bounded convex set, which is a significant difference from the existing literature on PD controlled uncertain stochastic systems. Moreover, a particular polynomial on these bounds is introduced, which can be used to determine under what conditions the system is not stabilizable by the PD control, and thus demonstrating the fundamental limitations of PD control."
Cross-Language Source Code Clone Detection Using Deep Learning withInferCode,"Mohammad A.Yahya, Dae-Kyoo Kim",10 May 2022,Software Engineering (cs.SE)," Software clones are beneficial to detect security gaps and software maintenance in one programming language or across multiple languages. The existing work on source clone detection performs well but in a single programming language. However, if a piece of code with the same functionality is written in different programming languages, detecting it is harder as different programming languages have a different lexical structure. Moreover, most existing work rely on manual feature engineering. In this paper, we propose a deep neural network model based on source code AST embeddings to detect cross-language clones in an end-to-end fashion of the source code without the need of the manual process to pinpoint similar features across different programming languages. To overcome data shortage and reduce overfitting, a Siamese architecture is employed. The design methodology of our model is twofold -- (a) it accepts AST embeddings as input for two different programming languages, and (b) it uses a deep neural network to learn abstract features from these embeddings to improve the accuracy of cross-language clone detection. The early evaluation of the model observes an average precision, recall and F-measure score of $0.99$, $0.59$ and $0.80$ respectively, which indicates that our model outperforms all available models in cross-language clone detection."
Reasoning in the Description Logic ALC under Category Semantics,"LudovicBrieulle, Chan Le Duc, PascalVaillant",10 May 2022,Logic in Computer Science (cs.LO)," We present in this paper a reformulation of the usual set- theoretical semantics of the description logic $\mathcal{ALC}$ with general TBoxes by using categorical language. In this setting, $\mathcal{ALC}$ concepts are represented as objects, concept subsumptions as arrows, and memberships as logical quantifiers over objects and arrows of categories. Such a category-based semantics provides a more modular representation of the semantics of $\mathcal{ALC}$. This feature allows us to define a sublogic of $\mathcal{ALC}$ by dropping the interaction between existential and universal restrictions, which would be responsible for an exponential complexity in space. Such a sublogic is undefinable in the usual set- theoretical semantics, We show that this sublogic is {\sc{PSPACE}} by proposing a deterministic algorithm for checking concept satisfiability which runs in polynomial space."
Shadow-Aware Dynamic Convolution for Shadow Removal,"YiminXu, MingbaoLin, HongYang, KeLi, YunhangShen, FeiChao, Rongrong Ji",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," With a wide range of shadows in many collected images, shadow removal has aroused increasing attention since uncontaminated images are of vital importance for many downstream multimedia tasks. Current methods consider the same convolution operations for both shadow and non-shadow regions while ignoring the large gap between the color mappings for the shadow region and the non-shadow region, leading to poor quality of reconstructed images and a heavy computation burden. To solve this problem, this paper introduces a novel plug-and-play Shadow-Aware Dynamic Convolution (SADC) module to decouple the interdependence between the shadow region and the non-shadow region. Inspired by the fact that the color mapping of the non-shadow region is easier to learn, our SADC processes the non-shadow region with a lightweight convolution module in a computationally cheap manner and recovers the shadow region with a more complicated convolution module to ensure the quality of image reconstruction. Given that the non- shadow region often contains more background color information, we further develop a novel intra-convolution distillation loss to strengthen the information flow from the non-shadow region to the shadow region. Extensive experiments on the ISTD and SRD datasets show our method achieves better performance in shadow removal over many state-of-the-arts. Our code is available at [this https URL](https://github.com/xuyimin0926/SADC)."
Evaluating the Impact of Tiled User-Adaptive Real-Time Point CloudStreaming on VR Remote Communication,"ShishirSubramanyam, Irene Viola, JackJansen, EvangelosAlexiou, AlanHanjalic, Pablo Cesar",10 May 2022,Multimedia (cs.MM)," Remote communication has rapidly become a part of everyday life in both professional and personal contexts. However, popular video conferencing applications present limitations in terms of quality of communication, immersion and social meaning. VR remote communication applications offer a greater sense of co-presence and mutual sensing of emotions between remote users. Previous research on these applications has shown that realistic point cloud user reconstructions offer better immersion and communication as compared to synthetic user avatars. However, photorealistic point clouds require a large volume of data per frame and are challenging to transmit over bandwidth-limited networks. Recent research has demonstrated significant improvements to perceived quality by optimizing the usage of bandwidth based on the position and orientation of the user's viewport with user-adaptive streaming. In this work, we developed a real-time VR communication application with an adaptation engine that features tiled user-adaptive streaming based on user behaviour. The application also supports traditional network adaptive streaming. The contribution of this work is to evaluate the impact of tiled user-adaptive streaming on quality of communication, visual quality, system performance and task completion in a functional live VR remote communication system. We perform a subjective evaluation with 33 users to compare the different streaming conditions with a neck exercise training task. As a baseline, we use uncompressed streaming requiring ca. 300Mbps and our solution achieves similar visual quality with tiled adaptive streaming at 14Mbps. We also demonstrate statistically significant gains to the quality of interaction and improvements to system performance and CPU consumption with tiled adaptive streaming as compared to the more traditional network adaptive streaming."
Learning Non-target Knowledge for Few-shot Semantic Segmentation,"YuanweiLiu, NianLiu, QinglongCao, XiwenYao, JunweiHan, LingShao",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Existing studies in few-shot semantic segmentation only focus on mining the target object information, however, often are hard to tell ambiguous regions, especially in non-target regions, which include background (BG) and Distracting Objects (DOs). To alleviate this problem, we propose a novel framework, namely Non-Target Region Eliminating (NTRE) network, to explicitly mine and eliminate BG and DO regions in the query. First, a BG Mining Module (BGMM) is proposed to extract the BG region via learning a general BG prototype. To this end, we design a BG loss to supervise the learning of BGMM only using the known target object segmentation ground truth. Then, a BG Eliminating Module and a DO Eliminating Module are proposed to successively filter out the BG and DO information from the query feature, based on which we can obtain a BG and DO-free target object segmentation result. Furthermore, we propose a prototypical contrastive learning algorithm to improve the model ability of distinguishing the target object from DOs. Extensive experiments on both PASCAL-5i and COCO-20i datasets show that our approach is effective despite its simplicity."
Adjusted Expected Improvement for Cumulative Regret Minimization inNoisy Bayesian Optimization,"ShouriHu, HaoweiWang, ZhongxiangDai, BryanKian HsiangLow, SzuHui Ng",10 May 2022,Machine Learning (cs.LG)," The expected improvement (EI) is one of the most popular acquisition functions for Bayesian optimization (BO) and has demonstrated good empirical performances in many applications for the minimization of simple regret. However, under the evaluation metric of cumulative regret, the performance of EI may not be competitive, and its existing theoretical regret upper bound still has room for improvement. To adapt the EI for better performance under cumulative regret, we introduce a novel quantity called the evaluation cost which is compared against the acquisition function, and with this, develop the expected improvement-cost (EIC) algorithm. In each iteration of EIC, a new point with the largest acquisition function value is sampled, only if that value exceeds its evaluation cost. If none meets this criteria, the current best point is resampled.This evaluation cost quantifies the potential downside of sampling a point, which is important under the cumulative regret metric as the objective function value in every iteration affects the performance measure. We further establish in theory a near-optimal regret upper bound of EIC for the squared-exponential covariance kernel under mild regularity conditions, and perform experiments to illustrate the improvement of EIC over several popular BO algorithms."
From Trade-only to Zero-Value NFTs: The Asset Proxy NFT Paradigm inWeb3,"DenisAvrilionis, ThomasHardjono","6 May 2022 (v1(https://arxiv.org/abs/2205.04899v1)), lastrevised 11 May 2022 (this version, v2)",Software Engineering (cs.SE)," Many implementations of smart contracts available in NFT marketplaces today allow the modification of NFT token attributes, without any specific mechanism to control the consistency with off-chain metadata. We believe this is a weakness in overall design of NFTs today. We propose a computation model called the Asset Proxy NFT that guarantees the consistency between the NFT token (on-chain) and its corresponding asset metadata (off- chain). In general, the proposed model can be applied to any type of NFT that requires immutability or controlled mutability of metadata. A second contribution of this paper is the notion of the NFT design patterns which recognizes that a coherent framework for dealing with hybrid assets is required, and that for specific hybrid-asset deployments, suitable technological components must be utilized under the framework."
The Drift of #MyBodyMyChoice Discourse on Twitter,"CristinaMenghini, Justin Uhr, ShahrzadHaddadan, AshleyChampagne, BjornSandstede, SohiniRamachandran",10 May 2022,Computers and Society (cs.CY)," #MyBodyMyChoice is a well-known hashtag originally created to advocate for women's rights, often used in discourse about abortion and bodily autonomy. The Covid-19 outbreak prompted governments to take containment measures such as vaccination campaigns and mask mandates. Population groups opposed to such measures started to use the slogan ""My Body My Choice"" to claim their bodily autonomy. In this paper, we investigate whether the discourse around the hashtag #MyBodyMyChoice on Twitter changed its usage after the Covid-19 outbreak. We observe that the conversation around the hashtag changed in two ways. First, semantically, the hashtag #MyBodyMyChoice drifted towards conversations around Covid-19, especially in messages opposed to containment measures. Second, while before the pandemic users used to share content produced by experts and authorities, after Covid-19 the users' attention has shifted towards individuals."
GRU-TV: Time- and velocity-aware GRU for patient representation onmultivariate clinical time-series data,"NingtaoLiu, RuoxiGao, JingYuan, CalirePark, ShuweiXing, Shuiping Gou",4 May 2022,Machine Learning (cs.LG)," Electronic health records (EHRs) provide a rich repository to track a patient's health status. EHRs seek to fully document the patient's physiological status, and include data that is is high dimensional, heterogeneous, and multimodal. The significant differences in the sampling frequency of clinical variables can result in high missing rates and uneven time intervals between adjacent records in the multivariate clinical time- series data extracted from EHRs. Current studies using clinical time-series data for patient characterization view the patient's physiological status as a discrete process described by sporadically collected values, while the dynamics in patient's physiological status are time-continuous. In addition, recurrent neural networks (RNNs) models widely used for patient representation learning lack the perception of time intervals and velocity, which limits the ability of the model to represent the physiological status of the patient.   In this paper, we propose an improved gated recurrent unit (GRU), namely time- and velocity-aware GRU (GRU-TV), for patient representation learning of clinical multivariate time-series data in a time-continuous manner. In proposed GRU-TV, the neural ordinary differential equations (ODEs) and velocity perception mechanism are used to perceive the time interval between records in the time-series data and changing rate of the patient's physiological status, respectively. Experimental results on two real-world clinical EHR datasets(PhysioNet2012, MIMIC-III) show that GRU-TV achieve state-of-the-art performance in computer aided diagnosis (CAD) tasks, and is more advantageous in processing sampled data."
Search-Based Testing of Reinforcement Learning,"MartinTappler, Filip CanoCórdoba, Bernhard K.Aichernig, BettinaKönighofer",7 May 2022,Machine Learning (cs.LG)," Evaluation of deep reinforcement learning (RL) is inherently challenging. Especially the opaqueness of learned policies and the stochastic nature of both agents and environments make testing the behavior of deep RL agents difficult. We present a search-based testing framework that enables a wide range of novel analysis capabilities for evaluating the safety and performance of deep RL agents. For safety testing, our framework utilizes a search algorithm that searches for a reference trace that solves the RL task. The backtracking states of the search, called boundary states, pose safety-critical situations. We create safety test-suites that evaluate how well the RL agent escapes safety-critical situations near these boundary states. For robust performance testing, we create a diverse set of traces via fuzz testing. These fuzz traces are used to bring the agent into a wide variety of potentially unknown states from which the average performance of the agent is compared to the average performance of the fuzz traces. We apply our search-based testing approach on RL for Nintendo's Super Mario Bros."
Impact of L1 Batch Normalization on Analog Noise Resistant Property ofDeep Learning Models,"OmobayodeFagbohungbe, Lijun Qian",7 May 2022,Machine Learning (cs.LG)," Analog hardware has become a popular choice for machine learning on resource-constrained devices recently due to its fast execution and energy efficiency. However, the inherent presence of noise in analog hardware and the negative impact of the noise on deployed deep neural network (DNN) models limit their usage. The degradation in performance due to the noise calls for the novel design of DNN models that have excellent noiseresistant property, leveraging the properties of the fundamental building block of DNN models. In this work, the use of L1 or TopK BatchNorm type, a fundamental DNN model building block, in designing DNN models with excellent noise-resistant property is proposed. Specifically, a systematic study has been carried out by training DNN models with L1/TopK BatchNorm type, and the performance is compared with DNN models with L2 BatchNorm types. The resulting model noise-resistant property is tested by injecting additive noise to the model weights and evaluating the new model inference accuracy due to the noise. The results show that L1 and TopK BatchNorm type has excellent noise-resistant property, and there is no sacrifice in performance due to the change in the BatchNorm type from L2 to L1/TopK BatchNorm type."
Adaptive Graph Convolutional Network Framework for MultidimensionalTime Series Prediction,NingWang,8 May 2022,Machine Learning (cs.LG)," In the real world, long sequence time-series forecasting (LSTF) is needed in many cases, such as power consumption prediction and air quality prediction.Multi-dimensional long time series model has more strict requirements on the model, which not only needs to effectively capture the accurate long-term dependence between input and output, but also needs to capture the relationship between data of different dimensions.Recent research shows that the Informer model based on Transformer has achieved excellent performance in long time series prediction.However, this model still has some deficiencies in multidimensional prediction,it cannot capture the relationship between different dimensions well. We improved Informer to address its shortcomings in multidimensional forecasting. First,we introduce an adaptive graph neural network to capture hidden dimension dependencies in mostly time series prediction. Secondly,we integrate adaptive graph convolutional networks into various spatio-temporal series prediction models to solve the defect that they cannot capture the relationship between different dimensions. Thirdly,After experimental testing with multiple data sets, the accuracy of our framework improved by about 10\% after being introduced into the model."
Identical Image Retrieval using Deep Learning,"SayanNath, NikhilNayak",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In recent years, we know that the interaction with images has increased. Image similarity involves fetching similar-looking images abiding by a given reference image. The target is to find out whether the image searched as a query can result in similar pictures. We are using the BigTransfer Model, which is a state-of-art model itself. BigTransfer(BiT) is essentially a ResNet but pre-trained on a larger dataset like ImageNet and ImageNet-21k with additional modifications. Using the fine-tuned pre-trained Convolution Neural Network Model, we extract the key features and train on the K-Nearest Neighbor model to obtain the nearest neighbor. The application of our model is to find similar images, which are hard to achieve through text queries within a low inference time. We analyse the benchmark of our model based on this application."
Strong Equivalence of Logic Programs with Ordered Disjunction: aLogical Perspective,"AngelosCharalambidis, ChristosNomikos, PanosRondogiannis",10 May 2022,Logic in Computer Science (cs.LO)," Logic Programs with Ordered Disjunction (LPODs) extend classical logic programs with the capability of expressing preferential disjunctions in the heads of program rules. The initial semantics of LPODs, although simple and quite intuitive, is not purely model-theoretic. A consequence of this is that certain properties of programs appear non-trivial to formalize in purely logical terms. An example of this state of affairs is the characterization of the notion of strong equivalence for LPODs. Although the results of Faber et al. (2008) are accurately developed, they fall short of characterizing strong equivalence of LPODs as logical equivalence in some specific logic. This comes in sharp contrast with the well-known characterization of strong equivalence for classical logic programs, which, as proved by Lifschitz et al. (2001), coincides with logical equivalence in the logic of here-and-there. In this paper we obtain a purely logical characterization of strong equivalence of LPODs as logical equivalence in a four-valued logic. Moreover, we provide a new proof of the coNP-completeness of strong equivalence for LPODs, which has an interest in its own right since it relies on the special structure of such programs. Our results are based on the recent logical semantics of LPODs introduced by Charalambidis et al. (2021), a fact which we believe indicates that this new semantics may prove to be a useful tool in the further study of LPODs."
Bounds for Privacy-Utility Trade-off with Per-letter PrivacyConstraints and Non-zero Leakage,"AmirrezaZamani, Tobias J.Oechtering, MikaelSkoglund",10 May 2022,Information Theory (cs.IT)," An information theoretic privacy mechanism design problem for two scenarios is studied where the private data is either hidden or observable. In each scenario, privacy leakage constraints are considered using two different measures. In these scenarios the private data is hidden or observable. In the first scenario, an agent observes useful data $Y$ that is correlated with private data $X$, and wishes to disclose the useful information to a user. A privacy mechanism is designed to generate disclosed data $U$ which maximizes the revealed information about $Y$ while satisfying a per-letter privacy constraint. In the second scenario, the agent has additionally access to the private data. First, the Functional Representation Lemma and Strong Functional Representation Lemma are extended by relaxing the independence condition to find a lower bound considering the second scenario. Next, lower bounds as well as upper bounds on privacy- utility trade-off are derived for both scenarios. In particular, for the case where $X$ is deterministic function of $Y$, we show that our upper and lower bounds are asymptotically optimal considering the first scenario."
Reaching Agreement Among $k$ out of $n$ Processes,GadiTaubenfeld,10 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," In agreement problems, each process has an input value and must choose the input of some process (possibly itself) as a decision value. Given $n\geq 2$ processes and $m \geq 2$ possible different input values, we want to design an agreement algorithm that enables as many processes as possible to decide on the same value in the presence of $t$ crash failures. Without communication, when each process simply decides on its input value, at least $\lceil (n-t)/m \rceil$ of the processes are guaranteed to always decide on the same value. Can we do better with communication? For some cases, for example when $m=2$, even in the presence of a single crash failure, the answer is negative in a deterministic asynchronous system where communication is either by using atomic read/write registers or by sending and receiving messages. The answer is positive in other cases."
THOR: Threshold-Based Ranking Loss for Ordinal Regression,"Tzeviya SylviaFuchs, JosephKeshet",10 May 2022,Machine Learning (cs.LG)," In this work, we present a regression-based ordinal regression algorithm for supervised classification of instances into ordinal categories. In contrast to previous methods, in this work the decision boundaries between categories are predefined, and the algorithm learns to project the input examples onto their appropriate scores according to these predefined boundaries. This is achieved by adding a novel threshold-based pairwise loss function that aims at minimizing the regression error, which in turn minimizes the Mean Absolute Error (MAE) measure. We implemented our proposed architecture-agnostic method using the CNN-framework for feature extraction. Experimental results on five real-world benchmarks demonstrate that the proposed algorithm achieves the best MAE results compared to state- of-the-art ordinal regression algorithms."
Universal Caching,"AtivJoshi, AbhishekSinha",10 May 2022,Information Theory (cs.IT)," In the learning literature, the performance of an online policy is commonly measured in terms of the static regret metric, which compares the cumulative loss of an online policy to that of an optimal benchmark in hindsight. In the definition of static regret, the benchmark policy remains fixed throughout the time horizon. Naturally, the resulting regret bounds become loose in non-stationary settings where fixed benchmarks often suffer from poor performance. In this paper, we investigate a stronger notion of regret minimization in the context of an online caching problem. In particular, we allow the action of the offline benchmark at any round to be decided by a finite state predictor containing arbitrarily many states. Using ideas from the universal prediction literature in information theory, we propose an efficient online caching policy with an adaptive sub-linear regret bound. To the best of our knowledge, this is the first data-dependent regret bound known for the universal caching problem. We establish this result by combining a recently-proposed online caching policy with an incremental parsing algorithm, e.g., Lempel-Ziv '78. Our methods also yield a simpler learning-theoretic proof of the improved regret bound as opposed to the more involved and problem-specific combinatorial arguments used in the earlier works."
Safety-guaranteed trajectory planning and control based on GPestimation for unmanned surface vessels,"ShuhaoZhang, YujiaYang, SethSiriya, YePu",10 May 2022,Robotics (cs.RO)," We propose a safety-guaranteed planning and control framework for unmanned surface vessels (USVs), using Gaussian processes (GPs) to learn uncertainties. The uncertainties encountered by USVs, including external disturbances and model mismatches, are potentially state-dependent, time- varying, and hard to capture with constant models. GP is a powerful learning-based tool that can be integrated with a model-based planning and control framework, which employs a Hamilton-Jacobi differential game formulation. Such a combination yields less conservative trajectories and safety-guaranteeing control strategies. We demonstrate the proposed framework in simulations and experiments on a CLEARPATH Heron USV."
Secure Distributed/Federated Learning: Prediction-Privacy Trade-Offfor Multi-Agent System,"Mohamed RidhaZnaidi, GauravGupta, PaulBogdan",24 Apr 2022,Multiagent Systems (cs.MA)," Decentralized learning is an efficient emerging paradigm for boosting the computing capability of multiple bounded computing agents. In the big data era, performing inference within the distributed and federated learning (DL and FL) frameworks, the central server needs to process a large amount of data while relying on various agents to perform multiple distributed training tasks. Considering the decentralized computing topology, privacy has become a first-class concern. Moreover, assuming limited information processing capability for the agents calls for a sophisticated \textit{privacy-preserving decentralization} that ensures efficient computation. Towards this end, we study the \textit{privacy-aware server to multi-agent assignment} problem subject to information processing constraints associated with each agent, while maintaining the privacy and assuring learning informative messages received by agents about a global terminal through the distributed private federated learning (DPFL) approach. To find a decentralized scheme for a two-agent system, we formulate an optimization problem that balances privacy and accuracy, taking into account the quality of compression constraints associated with each agent. We propose an iterative converging algorithm by alternating over self- consistent equations. We also numerically evaluate the proposed solution to show the privacy-prediction trade-off and demonstrate the efficacy of the novel approach in ensuring privacy in DL and FL."
Scaling-up Generalized Planning as Heuristic Search with Landmarks,"Javier Segovia-Aguas, SergioJiménez, AndersJonsson, LauraSebastiá",10 May 2022,Artificial Intelligence (cs.AI)," Landmarks are one of the most effective search heuristics for classical planning, but largely ignored in generalized planning. Generalized planning (GP) is usually addressed as a combinatorial search in a given space of algorithmic solutions, where candidate solutions are evaluated w.r.t.~the instances they solve. This type of solution evaluation ignores any sub-goal information that is not explicit in the representation of the planning instances, causing plateaus in the space of candidate generalized plans. Furthermore, node expansion in GP is a run-time bottleneck since it requires evaluating every child node over the entire batch of classical planning instances in a GP problem. In this paper we define a landmark counting heuristic for GP (that considers sub-goal information that is not explicitly represented in the planning instances), and a novel heuristic search algorithm for GP (that we call PGP) and that progressively processes subsets of the planning instances of a GP problem. Our two orthogonal contributions are analyzed in an ablation study, showing that both improve the state-of-the-art in GP as heuristic search, and that both benefit from each other when used in combination."
Multi-Tree Guided Efficient Robot Motion Planning,"ZhiruiSun, JiankunWang, MaxQ.-H. Meng",10 May 2022,Robotics (cs.RO)," Motion Planning is necessary for robots to complete different tasks. Rapidly-exploring Random Tree (RRT) and its variants have been widely used in robot motion planning due to their fast search in state space. However, they perform not well in many complex environments since the motion planning needs to simultaneously consider the geometry constraints and differential constraints. In this article, we propose a novel robot motion planning algorithm that utilizes multi-tree to guide the exploration and exploitation. The proposed algorithm maintains more than two trees to search the state space at first. Each tree will explore the local environment. The tree starts from the root will gradually collect information from other trees and grow towards the goal state. This simultaneous exploration and exploitation method can quickly find a feasible trajectory. We compare the proposed algorithm with other popular motion planning algorithms. The experiment results demonstrate that our algorithm achieves the best performance on different evaluation metrics."
"Revisiting the Scheme of Walking-in-Place by Introducing Step-HeightControl, Elastic Input and Pseudo-Haptic Feedback","YutaroHirao, TakujiNarumi, FerranArgelaguet, AnatoleLécuyer",10 May 2022,Human-Computer Interaction (cs.HC)," Walking-in-place (WIP) is a locomotion technique that enables users to walk infinitely through vast virtual environments using walking- like gestures within a limited physical space. This paper investigates alternative interaction schemes for WIP, addressing successively the control, input, and output of WIP. First, we introduce a novel height-based control to increase advance speed. Second, we introduce a novel input system for WIP based on elastic and passive strips. Third, we introduce the use of pseudo-haptic feedback as a novel output for WIP meant to alter walking sensations. The results of a series of user studies show that height and frequency based control of WIP can facilitate higher virtual speed with greater efficacy and ease than in frequency-based WIP. Second, using an upward elastic input system can result in a stable virtual speed control, although excessively strong elastic forces may impact the usability and user experience. Finally, using a pseudo-haptic approach can improve the perceived realism of virtual slopes. Taken together, our results promote the investigation and use of alternative interaction WIP schemes in future virtual reality applications."
Assessing Streamline Plausibility Through Randomized IterativeSpherical-Deconvolution Informed Tractogram Filtering,"AntoniaHain (1)DanielJörgens, RodrigoMoreno (3)((1) Saarland University Faculty of Mathematics and Computer ScienceSaarbrücken Germany (2) Division of Brain Imaging and Behaviour KrembilResearch Institute Toronto Western Hospital University Health NetworkToronto Canada ",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Tractography has become an indispensable part of brain connectivity studies. However, it is currently facing problems with reliability. In particular, a substantial amount of nerve fiber reconstructions (streamlines) in tractograms produced by state-of-the-art tractography methods are anatomically implausible. To address this problem, tractogram filtering methods have been developed to remove faulty connections in a postprocessing step. This study takes a closer look at one such method, \textit{Spherical-deconvolution Informed Filtering of Tractograms} (SIFT), which uses a global optimization approach to improve the agreement between the remaining streamlines after filtering and the underlying diffusion magnetic resonance imaging data. SIFT is not suitable to judge the plausibility of individual streamlines since its results depend on the size and composition of the surrounding tractogram. To tackle this problem, we propose applying SIFT to randomly selected tractogram subsets in order to retrieve multiple assessments for each streamline. This approach makes it possible to identify streamlines with very consistent filtering results, which were used as pseudo ground truths for training classifiers. The trained classifier is able to distinguish the obtained groups of plausible and implausible streamlines with accuracy above 80%. The software code used in the paper and pretrained weights of the classifier are distributed freely via the Github repository [this https URL](https://github.com/djoerch/randomised_filtering)."
Spectral Galerkin method for solving elastic wave scattering problemswith multiple open arcs,"Carlos Jerez-Hanckes, JosePinto, TaoYin",10 May 2022,Numerical Analysis (math.NA)," We study the elastic time-harmonic wave scattering problems on unbounded domains with boundaries composed of finite collections of disjoints finite open arcs (or cracks) in two dimensions. Specifically, we present a fast spectral Galerkin method for solving the associated weakly- and hyper-singular boundary integral equations (BIEs) arising from Dirichlet and Neumann boundary conditions, respectively. Discretization bases of the resulting BIEs employ weighted Chebyshev polynomials that capture the solutions' edge behavior. We show that these bases guarantee exponential convergence in the polynomial degree when assuming analyticity of sources and arcs geometries. Numerical examples demonstrate the accuracy and robustness of the proposed method with respect to number of arcs and wavenumber."
Object Detection in Indian Food Platters using Transfer Learning withYOLOv4,"DeepanshuPandey, PurvaParmar, GauriToshniwal, Mansi Goel, VisheshAgrawal, ShivangiDhiman, LavanyaGupta, GaneshBagler",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Object detection is a well-known problem in computer vision. Despite this, its usage and pervasiveness in the traditional Indian food dishes has been limited. Particularly, recognizing Indian food dishes present in a single photo is challenging due to three reasons: 1. Lack of annotated Indian food datasets 2\. Non-distinct boundaries between the dishes 3. High intra-class variation. We solve these issues by providing a comprehensively labelled Indian food dataset- IndianFood10, which contains 10 food classes that appear frequently in a staple Indian meal and using transfer learning with YOLOv4 object detector model. Our model is able to achieve an overall mAP score of 91.8% and f1-score of 0.90 for our 10 class dataset. We also provide an extension of our 10 class dataset- IndianFood20, which contains 10 more traditional Indian food classes."
Programming Data Structures for Large-Scale Desktop Simulations ofComplex Systems,PatrikChristen,10 May 2022,Data Structures and Algorithms (cs.DS)," Studying complex systems requires running large-scale simulations over many iterations in time. It is therefore important to provide efficient implementations. The present study borrows philosophical concepts from Gilbert Simondon to identify data structures and algorithms that have the biggest impact on running time and memory usage. These are the entity $e$-tuple $\mathcal{E}$ and the intertwined update function $\phi$. Focusing on implementing data structures in C#, $\mathcal{E}$ is implemented as a list of objects according to current software engineering practice and as an array of pointers according to theoretical considerations. Cellular automata simulation with $10^9$ entities over one iteration reveal that object-list with dynamic typing and multi-state readiness has a drastic effect on running time and memory usage, especially dynamic as it has a big impact on the evolution time. Pointer-arrays are possible to implement in C# and are more running time and memory efficient as compared to the object-list implementation, however, they are cumbersome to implement. In conclusion, avoiding dynamic typing in object-list based implementations or using pointer-arrays gives evolution times that are acceptable in practice, even on desktop computers."
Cognitive Visual-learning Environment for PostgreSQL,"Manuela NayantaraJeyaraj, SenuriSucharitharathna, ChathurikaSenarath, YasanthyKanagaraj, IndrakaUdayakumara",10 May 2022,Machine Learning (cs.LG)," PostgreSQL is an object-relational database (ORDBMS) that was introduced into the database community and has been avidly used for a variety of information extraction use cases. It is also known to be an advanced SQL-compliant open source Object RDBMS. However, users have not yet resolved to PostgreSQL due to the fact that it is still under the layers and the complexity of its persistent textual environment for an amateur user. Hence, there is a dire need to provide an easy environment for users to comprehend the procedure and standards with which databases are created, tables and the relationships among them, manipulating queries and their flow based on conditions in PostgreSQL. As such, this project identifies the dominant features offered by Postgresql, analyzes the constraints that exist in the database user community in migrating to PostgreSQL and based on the scope and constraints identified, develop a system that will serve as a query generation platform as well as a learning tool that will provide an interactive environment to cognitively learn PostgreSQL query building. This is achieved using a visual editor incorporating a textual editor for a well- versed user. By providing visually-draggable query components to work with, this research aims to offer a cognitive, visual and tactile environment where users can interactively learn PostgreSQL query generation."
Envelopes and Waves: Safe Multivehicle Collision Avoidance forHorizontal Non-deterministic Turns,"YanniKouskoulas, T. J.Machado, DanielGenin, AuroraSchmidt, IvanPapusha, JoshuaBrulé",10 May 2022,Logic in Computer Science (cs.LO)," We present an approach to analyzing the safety of asynchronous, independent, non-deterministic, turn-to-bearing horizontal maneuvers for two vehicles. Future turn rates, final bearings, and continuously varying ground speeds throughout the encounter are unknown but restricted to known ranges. We develop a library of formal proofs about turning kinematics, and apply the library to create a formally verified timing computation. Additionally, we create a technique that evaluates future collision possibilities that is based on waves of position possibilities and relies on the timing computation. The result either determines that the encounter will be collision-free, or computes a safe overapproximation for when and where collisions may occur."
An Engineer's Nightmare: 102 Years of Critical Robotics,ChristopherCsíkszentmihályi,9 May 2022,Human-Computer Interaction (cs.HC)," A critical and re-configured HRI might look to the arts, where another history of robots has been unfolding since the Czech artist Karel Capek's critical robotic labor parable of 1921, in which the word robot was coined in its modern usage. This paper explores several vectors by which artist-created robots, both physical and imaginary, have offered pronounced contrasts to robots-as-usual, and offers directions as to how these more emancipated cousins might be useful to the field of HRI."
Political Propagation of Social Botnets: Policy Consequences,ShashankYadav,10 May 2022,Computers and Society (cs.CY)," The 2016 US election was a watershed event where an electoral intervention by an adversarial state made extensive use of networks of software robots and data driven communications which transformed the interference into a goal driven functionality of man-machine collaboration. Reviewing the debates post the debacle, we reflect upon the policy consequences of the use of Social Botnets and understand the impact of their adversarial operation in terms of catalysing institutional decay, growing infrastructural anxieties, increased industry regulations, more vulnerable Individuals and more distorted ideas, and most importantly, the emergence of an unintended constituency in form of the bot agency itself. The article first briefly introduces the nature and evolution of Social Botnets, and then moves over to discussing the policy consequences. For future work, it is important to understand the agency and collective properties of these software robots, in order to design the institutional and socio-technical mechanisms which mitigate the risk of adversarial social engineering using these bots from interfering into democratic processes."
Probabilistic and Non-Deterministic Event Data in Process Mining:Embedding Uncertainty in Process Analysis Techniques,MarcoPegoraro,"10 May 2022 (v1(https://arxiv.org/abs/2205.04827v1)), lastrevised 11 May 2022 (this version, v2)",Artificial Intelligence (cs.AI)," Process mining is a subfield of process science that analyzes event data collected in databases called event logs. Recently, novel types of event data have become of interest due to the wide industrial application of process mining analyses. In this paper, we examine uncertain event data. Such data contain meta-attributes describing the amount of imprecision tied with attributes recorded in an event log. We provide examples of uncertain event data, present the state of the art in regard of uncertainty in process mining, and illustrate open challenges related to this research direction."
A Specification Logic for Programs in the Probabilistic GuardedCommand Language (Extended Version),"RaúlPardo, EinarBrochJohnsen, InaSchaefer, AndrzejWąsowski",10 May 2022,Logic in Computer Science (cs.LO)," The semantics of probabilistic languages has been extensively studied, but specification languages for their properties have received little attention. This paper introduces the probabilistic dynamic logic pDL, a specification logic for programs in the probabilistic guarded command language (pGCL) of McIver and Morgan. The proposed logic pDL can express both first-order state properties and probabilistic reachability properties, addressing both the non-deterministic and probabilistic choice operators of pGCL. In order to precisely explain the meaning of specifications, we formally define the satisfaction relation for pDL. Since pDL embeds pGCL programs in its box-modality operator, we first provide a formal MDP semantics for pGCL programs. The satisfaction relation is modeled after PCTL, but extended from propositional to first-order setting of dynamic logic, so also embedding program fragments. We study basic properties of this specification language, such as weakening and distribution, that can support reasoning systems. Finally, we demonstrate the use of pDL to reason about program behavior."
Bridging the prosody GAP: Genetic Algorithm with People to efficientlysample emotional prosody,"Pol vanRijn, Harin Lee, Nori Jacoby",10 May 2022,Computation and Language (cs.CL)," The human voice effectively communicates a range of emotions with nuanced variations in acoustics. Existing emotional speech corpora are limited in that they are either (a) highly curated to induce specific emotions with predefined categories that may not capture the full extent of emotional experiences, or (b) entangled in their semantic and prosodic cues, limiting the ability to study these cues separately. To overcome this challenge, we propose a new approach called 'Genetic Algorithm with People' (GAP), which integrates human decision and production into a genetic algorithm. In our design, we allow creators and raters to jointly optimize the emotional prosody over generations. We demonstrate that GAP can efficiently sample from the emotional speech space and capture a broad range of emotions, and show comparable results to state-of-the-art emotional speech corpora. GAP is language-independent and supports large crowd- sourcing, thus can support future large-scale cross-cultural research."
Massive Enhanced Extracted Email Features Tailored for Cosine Distance,FarshadBarahimi,"10 May 2022 (v1(https://arxiv.org/abs/2205.04819v1)), lastrevised 11 May 2022 (this version, v2)",Information Retrieval (cs.IR)," In this paper, the process of converting the Enron email dataset (the version cited in the preprint) to thousands of features per email for a selected set of 2400 labelled emails is explained and evaluated. The final features are tailored for Cosine distance so that the Cosine distance invertly reflect the number of top indicative words of each email that are common between the two emails in an explainable normalized fashion. The labelling is based on the leaf folder name in the Enron email dataset (the version cited in the preprint) folders tree and the 2400 emails selected consist 300 emails for each of the 8 labels. The evaluation is based on the accuracy of a k nearest neighbours majority voting classification using Cosine distance. In addition to KNN majority voting classification accuracy and confusion matrix, some statistics for the process is reported. The KNN majority voting classification accuracy using Cosine distance is 76.75% which shows at least some level of success given the 8 labels involved. The result of conversion is 48557 features per selected email out of which exactly 40 features per email are non-zero. The result of conversion is a data set named MeeefTCD (Massive Enhanced Extracted Email Features Tailored for Cosine Distance) available at [this https URL](https://web.cs.dal.ca/~barahimi/data-sets/meeeftcd/) and on a github repository mentioned in this paper."
Reconstruction Enhanced Multi-View Contrastive Learning for AnomalyDetection on Attributed Networks,"JiaqiangZhang, SenzhangWang, SongcanChen",10 May 2022,Machine Learning (cs.LG)," Detecting abnormal nodes from attributed networks is of great importance in many real applications, such as financial fraud detection and cyber security. This task is challenging due to both the complex interactions between the anomalous nodes with other counterparts and their inconsistency in terms of attributes. This paper proposes a self-supervised learning framework that jointly optimizes a multi-view contrastive learning- based module and an attribute reconstruction-based module to more accurately detect anomalies on attributed networks. Specifically, two contrastive learning views are firstly established, which allow the model to better encode rich local and global information related to the abnormality. Motivated by the attribute consistency principle between neighboring nodes, a masked autoencoder-based reconstruction module is also introduced to identify the nodes which have large reconstruction errors, then are regarded as anomalies. Finally, the two complementary modules are integrated for more accurately detecting the anomalous nodes. Extensive experiments conducted on five benchmark datasets show our model outperforms current state-of-the-art models."
The Impact of Partial Occlusion on Pedestrian Detectability,"ShaneGilroy, DarraghMullins, EdwardJones, AshkanParsi, MartinGlavin","10 May 2022 (v1(https://arxiv.org/abs/2205.04812v1)), lastrevised 12 May 2022 (this version, v3)",Computer Vision and Pattern Recognition (cs.CV)," Robust detection of vulnerable road users is a safety critical requirement for the deployment of autonomous vehicles in heterogeneous traffic. One of the most complex outstanding challenges is that of partial occlusion where a target object is only partially available to the sensor due to obstruction by another foreground object. A number of leading pedestrian detection benchmarks provide annotation for partial occlusion, however each benchmark varies greatly in their definition of the occurrence and severity of occlusion. Recent research demonstrates that a high degree of subjectivity is used to classify occlusion level in these cases and occlusion is typically categorized into 2 to 3 broad categories such as partially and heavily occluded. This can lead to inaccurate or inconsistent reporting of pedestrian detection model performance depending on which benchmark is used. This research introduces a novel, objective benchmark for partially occluded pedestrian detection to facilitate the objective characterization of pedestrian detection models. Characterization is carried out on seven popular pedestrian detection models for a range of occlusion levels from 0-99%. Results demonstrate that pedestrian detection performance degrades, and the number of false negative detections increase as pedestrian occlusion level increases. Of the seven popular pedestrian detection routines characterized, CenterNet has the greatest overall performance, followed by SSDlite. RetinaNet has the lowest overall detection performance across the range of occlusion levels."
The Importance of Context in Very Low Resource Language Modeling,"LukasEdman, AntonioToral, Gertjan vanNoord",10 May 2022,Computation and Language (cs.CL)," This paper investigates very low resource language model pretraining, when less than 100 thousand sentences are available. We find that, in very low resource scenarios, statistical n-gram language models outperform state-of-the-art neural models. Our experiments show that this is mainly due to the focus of the former on a local context. As such, we introduce three methods to improve a neural model's performance in the low- resource setting, finding that limiting the model's self-attention is the most effective one, improving on downstream tasks such as NLI and POS tagging by up to 5% for the languages we test on: English, Hindi, and Turkish."
Weisfeiler-Leman Invariant Promise Valued CSPs,"LiborBarto, Silvia Butti",10 May 2022,Data Structures and Algorithms (cs.DS)," In a recent line of work, Butti and Dalmau have shown that a fixed-template Constraint Satisfaction Problem is solvable by a certain natural linear programming relaxation (equivalent to the basic linear programming relaxation) if and only if it is solvable on a certain distributed network, and this happens if and only if its set of Yes instances is closed under Weisfeiler-Leman equivalence. We generalize this result to the much broader framework of fixed-template Promise Valued Constraint Satisfaction Problems. Moreover, we show that two commonly used linear programming relaxations are no longer equivalent in this broader framework."
Vibration-based communication for deafblind people,"David C.Kutner, SunčicaHadžidedić",10 May 2022,Human-Computer Interaction (cs.HC)," Deafblind people have both hearing and visual impairments, which makes communication with other people often dependent on expensive technologies e.g., Braille displays, or on caregivers acting as interpreters. This paper presents Morse I/O (MIO), a vibrotactile interface for Android, evaluated through experiments and interviews with deafblind participants. MIO was shown to enable consistent text entry and recognition after only a few hours of practice. The participants were willing to continue using the interface, although there were perceived difficulties in learning to use it. Overall, MIO is a cost-effective, portable interface for deafblind people without access to Braille displays or similar."
Non-Isometric Shape Matching via Functional Maps on Landmark-AdaptedBases,"MikhailPanine, MaximeKirgo, MaksOvsjanikov",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We propose a principled approach for non-isometric landmark- preserving non-rigid shape matching. Our method is based on the functional maps framework, but rather than promoting isometries we focus instead on near-conformal maps that preserve landmarks exactly. We achieve this, first, by introducing a novel landmark-adapted basis using an intrinsic Dirichlet- Steklov eigenproblem. Second, we establish the functional decomposition of conformal maps expressed in this basis. Finally, we formulate a conformally- invariant energy that promotes high-quality landmark-preserving maps, and show how it can be solved via a variant of the recently proposed ZoomOut method that we extend to our setting. Our method is descriptor-free, efficient and robust to significant mesh variability. We evaluate our approach on a range of benchmark datasets and demonstrate state-of-the-art performance on non-isometric benchmarks and near state-of-the-art performance on isometric ones."
Designing a Recurrent Neural Network to Learn a Motion Planner forHigh-Dimensional Inputs,JohnathanChiu,10 May 2022,Robotics (cs.RO)," The use of machine learning in the self-driving industry has boosted a number of recent advancements. In particular, the usage of large deep learning models in the perception and prediction stack have proved quite successful, but there still lacks significant literature on the use of machine learning in the planning stack. The current state of the art in the planning stack often relies on fast constrained optimization or rule-based approaches. Both of these techniques fail to address a significant number of fundamental problems that would allow the vehicle to operate more similarly to that of human drivers. In this paper, we attempt to design a basic deep learning system to approach this problem. Furthermore, the main underlying goal of this paper is to demonstrate the potential uses of machine learning in the planning stack for autonomous vehicles (AV) and provide a baseline work for ongoing and future research."
State Encoders in Reinforcement Learning for Recommendation: AReproducibility Study,"JinHuang, HarrieOosterhuis, BunyaminCetinkaya, Thijs Rood, Maarten deRijke","10 May 2022 (v1(https://arxiv.org/abs/2205.04797v1)), lastrevised 11 May 2022 (this version, v2)",Information Retrieval (cs.IR)," Methods for reinforcement learning for recommendation (RL4Rec) are increasingly receiving attention as they can quickly adapt to user feedback. A typical RL4Rec framework consists of (1) a state encoder to encode the state that stores the users' historical interactions, and (2) an RL method to take actions and observe rewards. Prior work compared four state encoders in an environment where user feedback is simulated based on real-world logged user data. An attention-based state encoder was found to be the optimal choice as it reached the highest performance. However, this finding is limited to the actor-critic method, four state encoders, and evaluation- simulators that do not debias logged user data. In response to these shortcomings, we reproduce and expand on the existing comparison of attention-based state encoders (1) in the publicly available debiased RL4Rec SOFA simulator with (2) a different RL method, (3) more state encoders, and (4) a different dataset. Importantly, our experimental results indicate that existing findings do not generalize to the debiased SOFA simulator generated from a different dataset and a Deep Q-Network (DQN)-based method when compared with more state encoders."
Efficient Learning of Inverse Dynamics Models for Adaptive ComputedTorque Control,"DavidJorge, GabriellaPizzuto, MichaelMistry",10 May 2022,Robotics (cs.RO)," Modelling robot dynamics accurately is essential for control, motion optimisation and safe human-robot collaboration. Given the complexity of modern robotic systems, dynamics modelling remains non-trivial, mostly in the presence of compliant actuators, mechanical inaccuracies, friction and sensor noise. Recent efforts have focused on utilising data-driven methods such as Gaussian processes and neural networks to overcome these challenges, as they are capable of capturing these dynamics without requiring extensive knowledge beforehand. While Gaussian processes have shown to be an effective method for learning robotic dynamics with the ability to also represent the uncertainty in the learned model through its variance, they come at a cost of cubic time complexity rather than linear, as is the case for deep neural networks. In this work, we leverage the use of deep kernel models, which combine the computational efficiency of deep learning with the non- parametric flexibility of kernel methods (Gaussian processes), with the overarching goal of realising an accurate probabilistic framework for uncertainty quantification. Through using the predicted variance, we adapt the feedback gains as more accurate models are learned, leading to low-gain control without compromising tracking accuracy. Using simulated and real data recorded from a seven degree-of-freedom robotic manipulator, we illustrate how using stochastic variational inference with deep kernel models increases compliance in the computed torque controller, and retains tracking accuracy. We empirically show how our model outperforms current state-of-the-art methods with prediction uncertainty for online inverse dynamics model learning, and solidify its adaptation and generalisation capabilities across different setups."
Neural Networks with Different Initialization Methods for DepressionDetection,TianleYang,10 May 2022,Neural and Evolutionary Computing (cs.NE)," As a common mental disorder, depression is a leading cause of various diseases worldwide. Early detection and treatment of depression can dramatically promote remission and prevent relapse. However, conventional ways of depression diagnosis require considerable human effort and cause economic burden, while still being prone to misdiagnosis. On the other hand, recent studies report that physical characteristics are major contributors to the diagnosis of depression, which inspires us to mine the internal relationship by neural networks instead of relying on clinical experiences. In this paper, neural networks are constructed to predict depression from physical characteristics. Two initialization methods are examined - Xaiver and Kaiming initialization. Experimental results show that a 3-layers neural network with Kaiming initialization achieves $83\%$ accuracy."
Fixed-Template Promise Model Checking Problems,"KristinaAsimi, LiborBarto, Silvia Butti",10 May 2022,Computational Complexity (cs.CC)," The fixed-template constraint satisfaction problem (CSP) can be seen as the problem of deciding whether a given primitive positive first- order sentence is true in a fixed structure (also called model). We study a class of problems that generalizes the CSP simultaneously in two directions: we fix a set $\mathcal{L}$ of quantifiers and Boolean connectives, and we specify two versions of each constraint, one strong and one weak. Given a sentence which only uses symbols from $\mathcal{L}$, the task is to distinguish whether the sentence is true in the strong sense, or it is false even in the weak sense. We classify the computational complexity of these problems for the existential positive equality-free fragment of first-order logic, i.e., $\mathcal{L} = \\{\exists,\land,\lor\\}$, and we prove some upper and lower bounds for the positive equality-free fragment, $\mathcal{L} = \\{\exists,\forall,\land,\lor\\}$. The partial results are sufficient, e.g., for all extensions of the latter fragment."
Upper Bounds to Genome Rearrangement Problem using PrefixTranspositions,Pramod PNair,10 May 2022,Discrete Mathematics (cs.DM)," A Genome rearrangement problem studies large-scale mutations on a set of DNAs in living organisms. Various rearrangements like reversals, transpositions, translocations, fissions, fusions, and combinations and different variations have been studied extensively by computational biologists and computer scientists over the past four decades. From a mathematical point of view, a genome is represented by a permutation. The genome rearrangement problem is interpreted as a problem that transforms one permutation into another in a minimum number of moves under certain constraints depending on the chosen rearrangements. Finding the minimum number of moves is equivalent to sorting the permutation with the given rearrangement. A transposition is an operation on a permutation that moves a sublist of a permutation to a different position in the same permutation. A \emph{Prefix Transposition}, as the name suggests, is a transposition that moves a sublist which is a prefix of the permutation.   In this thesis, we study prefix transpositions on permutations and present a better upper bound for sorting permutations with prefix transpositions. A greedy algorithm called the \emph{generalised sequence length algorithm} is defined as an extension of the sequence length algorithm where suitable alternate moves are also considered. This algorithm is used to sequentially improve the upper bound to $n-\log_{3.3} n$ and $n-\log_3 n$. In the latter part of the thesis, we defined the concept of a \emph{block}. We used it along with the greedy moves of the generalised sequence length algorithm to get an upper bound of $n-\log_2 n$ to sort permutations by prefix transpositions."
Spike-based computational models of bio-inspired memories in thehippocampal CA3 region on SpiNNaker,"Daniel Casanueva-Morato, Alvaro Ayuso-Martinez, Juan P. Dominguez-Morales, Angel Jimenez-Fernandez, Gabriel Jimenez-Moreno",10 May 2022,Neural and Evolutionary Computing (cs.NE)," The human brain is the most powerful and efficient machine in existence today, surpassing in many ways the capabilities of modern computers. Currently, lines of research in neuromorphic engineering are trying to develop hardware that mimics the functioning of the brain to acquire these superior capabilities. One of the areas still under development is the design of bio-inspired memories, where the hippocampus plays an important role. This region of the brain acts as a short-term memory with the ability to store associations of information from different sensory streams in the brain and recall them later. This is possible thanks to the recurrent collateral network architecture that constitutes CA3, the main sub-region of the hippocampus. In this work, we developed two spike- based computational models of fully functional hippocampal bio-inspired memories for the storage and recall of complex patterns implemented with spiking neural networks on the SpiNNaker hardware platform. These models present different levels of biological abstraction, with the first model having a constant oscillatory activity closer to the biological model, and the second one having an energy-efficient regulated activity, which, although it is still bio-inspired, opts for a more functional approach. Different experiments were performed for each of the models, in order to test their learning/recalling capabilities. A comprehensive comparison between the functionality and the biological plausibility of the presented models was carried out, showing their strengths and weaknesses. The two models, which are publicly available for researchers, could pave the way for future spike-based implementations and applications."
Deep Learning-based Schemes for Singularly Perturbed Convection-Diffusion Problems,"A.Beguinet, V.Ehrlacher, R.Flenghi, M.Fuente, O. Mula, A.Somacal",10 May 2022,Numerical Analysis (math.NA)," Deep learning-based numerical schemes such as Physically Informed Neural Networks (PINNs) have recently emerged as an alternative to classical numerical schemes for solving Partial Differential Equations (PDEs). They are very appealing at first sight because implementing vanilla versions of PINNs based on strong residual forms is easy, and neural networks offer very high approximation capabilities. However, when the PDE solutions are low regular, an expert insight is required to build deep learning formulations that do not incur in variational crimes. Optimization solvers are also significantly challenged, and can potentially spoil the final quality of the approximated solution due to the convergence to bad local minima, and bad generalization capabilities. In this paper, we present an exhaustive numerical study of the merits and limitations of these schemes when solutions exhibit low-regularity, and compare performance with respect to more benign cases when solutions are very smooth. As a support for our study, we consider singularly perturbed convection-diffusion problems where the regularity of solutions typically degrades as certain multiscale parameters go to zero."
SYNFI: Pre-Silicon Fault Analysis of an Open-Source Secure Element,"PascalNasahl, MiguelOsorio, PirminVogel, MichaelSchaffner, TimothyTrippel, DominicRizzo, StefanMangard",10 May 2022,Cryptography and Security (cs.CR)," Fault attacks are active, physical attacks that an adversary can leverage to alter the control-flow of embedded devices to gain access to sensitive information or bypass protection mechanisms. Due to the severity of these attacks, manufacturers deploy hardware-based fault defenses into security-critical systems, such as secure elements. The development of these countermeasures is a challenging task due to the complex interplay of circuit components and because contemporary design automation tools tend to optimize inserted structures away, thereby defeating their purpose. Hence, it is critical that such countermeasures are rigorously verified post- synthesis. As classical functional verification techniques fall short of assessing the effectiveness of countermeasures, developers have to resort to methods capable of injecting faults in a simulation testbench or into a physical chip. However, developing test sequences to inject faults in simulation is an error-prone task and performing fault attacks on a chip requires specialized equipment and is incredibly time-consuming. To that end, this paper introduces SYNFI, a formal pre-silicon fault verification framework that operates on synthesized netlists. SYNFI can be used to analyze the general effect of faults on the input-output relationship in a circuit and its fault countermeasures, and thus enables hardware designers to assess and verify the effectiveness of embedded countermeasures in a systematic and semi-automatic way. To demonstrate that SYNFI is capable of handling unmodified, industry-grade netlists synthesized with commercial and open tools, we analyze OpenTitan, the first open-source secure element. In our analysis, we identified critical security weaknesses in the unprotected AES block, developed targeted countermeasures, reassessed their security, and contributed these countermeasures back to the OpenTitan repository."
Automorphism Shuffles for Graphs and Hypergraphs and Its Applications,"KazumasaShinagawa, KengoMiyamoto",10 May 2022,Cryptography and Security (cs.CR)," In card-based cryptography, a deck of physical cards is used to achieve secure computation. A shuffle, which randomly permutes a card- sequence along with some probability distribution, ensures the security of a card-based protocol. The authors proposed a new class of shuffles called graph shuffles, which randomly permutes a card-sequence by an automorphism of a directed graph (New Generation Computing 2022). For a directed graph $G$ with $n$ vertices and $m$ edges, such a shuffle could be implemented with pile-scramble shuffles with $2(n+m)$ cards. In this paper, we study graph shuffles and give an implementation, an application, and a slight generalization of them. First, we propose a new protocol for graph shuffles with $2n+m$ cards. Second, as a new application of graph shuffles, we show that any cyclic group shuffle, which is a shuffle over a cyclic group, is a graph shuffle associated with some graph. Third, we define a hypergraph shuffle, which is a shuffle by an automorphism of a hypergraph, and show that any hypergraph shuffle can also be implemented with pile-scramble shuffles."
Domain Invariant Masked Autoencoders for Self-supervised Learning fromMulti-domains,"HaiyangYang, MeilinChen, YizhouWang, ShixiangTang, FengZhu, LeiBai, RuiZhao, WanliOuyang",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Generalizing learned representations across significantly different visual domains is a fundamental yet crucial ability of the human visual system. While recent self-supervised learning methods have achieved good performances with evaluation set on the same domain as the training set, they will have an undesirable performance decrease when tested on a different domain. Therefore, the self-supervised learning from multiple domains task is proposed to learn domain-invariant features that are not only suitable for evaluation on the same domain as the training set but also can be generalized to unseen domains. In this paper, we propose a Domain- invariant Masked AutoEncoder (DiMAE) for self-supervised learning from multi-domains, which designs a new pretext task, \emph{i.e.,} the cross- domain reconstruction task, to learn domain-invariant features. The core idea is to augment the input image with style noise from different domains and then reconstruct the image from the embedding of the augmented image, regularizing the encoder to learn domain-invariant features. To accomplish the idea, DiMAE contains two critical designs, 1) content-preserved style mix, which adds style information from other domains to input while persevering the content in a parameter-free manner, and 2) multiple domain- specific decoders, which recovers the corresponding domain style of input to the encoded domain-invariant features for reconstruction. Experiments on PACS and DomainNet illustrate that DiMAE achieves considerable gains compared with recent state-of-the-art methods."
Reliable Monte Carlo Localization for Mobile Robots,NaokiAkai,10 May 2022,Robotics (cs.RO)," Reliability is a key factor for realizing safety guarantee of full autonomous robot systems. In this paper, we focus on reliability in mobile robot localization. Monte Carlo localization (MCL) is widely used for mobile robot localization. However, it is still difficult to guarantee its safety because there are no methods determining reliability for MCL estimate. This paper presents a novel localization framework that enables robust localization, reliability estimation, and quick re-localization, simultaneously. The presented method can be implemented using similar estimation manner to that of MCL. The method can increase localization robustness to environment changes by estimating known and unknown obstacles while performing localization; however, localization failure of course occurs by unanticipated errors. The method also includes a reliability estimation function that enables us to know whether localization has failed. Additionally, the method can seamlessly integrate a global localization method via importance sampling. Consequently, quick re-localization from failures can be realized while mitigating noisy influence of global localization. Through three types of experiments, we show that reliable MCL that performs robust localization, self-failure detection, and quick failure recovery can be realized."
Hybrid RIS and DMA Assisted Multiuser MIMO Uplink Transmission WithElectromagnetic Exposure Constraints,"HanyuJiang, LiYou, JueWang, WenjinWang, XiqiGao",10 May 2022,Information Theory (cs.IT)," In the fifth-generation and beyond era, reconfigurable intelligent surface (RIS) and dynamic metasurface antennas (DMAs) are emerging metamaterials keeping up with the demand for high-quality wireless communication services, which promote the diversification of portable wireless terminals. However, along with the rapid expansion of wireless devices, the electromagnetic (EM) radiation increases unceasingly and inevitably affects public health, which requires a limited exposure level in the transmission design. To reduce the EM radiation and preserve the quality of communication service, we investigate the spectral efficiency (SE) maximization with EM constraints for uplink transmission in hybrid RIS and DMA assisted multiuser multiple-input multiple-output systems. Specifically, alternating optimization is adopted to optimize the transmit covariance, RIS phase shift, and DMA weight matrices. We first figure out the water-filling solutions of transmit covariance matrices with given RIS and DMA parameters. Then, the RIS phase shift matrix is optimized via the weighted minimum mean square error, block coordinate descent and minorization-maximization methods. Furthermore, we solve the unconstrainted DMA weight matrix optimization problem in closed form and then design the DMA weight matrix to approach this performance under DMA constraints. Numerical results confirm the effectiveness of the EM aware SE maximization transmission scheme over the conventional baselines."
A spatial-temporal short-term traffic flow prediction model based ondynamical-learning graph convolution mechanism,ZhijunChen (1) ZheLu (2) QiushiChen (3)HongliangZhong (3)Yishi Zhang(4) Jie Xue(5) ChaozhongWu (1) ((1)Intelligent Transportation Systems Research Center Wuhan University ofTechnology Wuhan China (2) School of Transportation and LogisticsEngineering Wuhan University of Technology Wuhan China (3) School ofComputer Science and Technology Wuhan University of Technology Wuhan China(4) School of Management Wuhan University of Technology Wuhan China (5)Faculty of Technology Policy and Management Safety and Security ScienceGroup ,10 May 2022,Machine Learning (cs.LG)," Short-term traffic flow prediction is a vital branch of the Intelligent Traffic System (ITS) and plays an important role in traffic management. Graph convolution network (GCN) is widely used in traffic prediction models to better deal with the graphical structure data of road networks. However, the influence weights among different road sections are usually distinct in real life, and hard to be manually analyzed. Traditional GCN mechanism, relying on manually-set adjacency matrix, is unable to dynamically learn such spatial pattern during the training. To deal with this drawback, this paper proposes a novel location graph convolutional network (Location-GCN). Location-GCN solves this problem by adding a new learnable matrix into the GCN mechanism, using the absolute value of this matrix to represent the distinct influence levels among different nodes. Then, long short-term memory (LSTM) is employed in the proposed traffic prediction model. Moreover, Trigonometric function encoding is used in this study to enable the short-term input sequence to convey the long-term periodical information. Ultimately, the proposed model is compared with the baseline models and evaluated on two real word traffic flow datasets. The results show our model is more accurate and robust on both datasets than other representative traffic prediction models."
WG-VITON: Wearing-Guide Virtual Try-On for Top and Bottom Clothes,"SoonchanPark, JinahPark",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Studies of virtual try-on (VITON) have been shown their effectiveness in utilizing the generative neural network for virtually exploring fashion products, and some of recent researches of VITON attempted to synthesize human image wearing given multiple types of garments (e.g., top and bottom clothes). However, when replacing the top and bottom clothes of the target human, numerous wearing styles are possible with a certain combination of the clothes. In this paper, we address the problem of variation in wearing style when simultaneously replacing the top and bottom clothes of the model. We introduce Wearing-Guide VITON (i.e., WG-VITON) which utilizes an additional input binary mask to control the wearing styles of the generated image. Our experiments show that WG-VITON effectively generates an image of the model wearing given top and bottom clothes, and create complicated wearing styles such as partly tucking in the top to the bottom"
Adaptive $\mathcal{H}$-Matrix Computations in Linear Elasticity,"MaximilianBauer, MarioBebendorf",10 May 2022,Numerical Analysis (math.NA)," This article deals with the adaptive and approximative computation of the Lamé equations. The equations of linear elasticity are considered as boundary integral equations and solved in the setting of the boundary element method (BEM). Using BEM, one is faced with the solution of a system of equations with a fully populated system matrix, which is in general very costly. Some adaptive algorithms based on hierarchical matrices and the adaptive cross approximation are proposed. At first, an adaptive matrix- vector multiplication scheme is introduced for the efficient treatment of multiplying discretizations with given data. The strategy, to reach this aim, is to use error estimators and techniques known from adaptivity. The case of approximating the system matrix appearing in the linear system of equations with this new type of adaptivity is also discussed."
Spatio-Temporal Transformer for Dynamic Facial Expression Recognitionin the Wild,"FuyanMa, BinSun, ShutaoLi",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Previous methods for dynamic facial expression in the wild are mainly based on Convolutional Neural Networks (CNNs), whose local operations ignore the long-range dependencies in videos. To solve this problem, we propose the spatio-temporal Transformer (STT) to capture discriminative features within each frame and model contextual relationships among frames. Spatio-temporal dependencies are captured and integrated by our unified Transformer. Specifically, given an image sequence consisting of multiple frames as input, we utilize the CNN backbone to translate each frame into a visual feature sequence. Subsequently, the spatial attention and the temporal attention within each block are jointly applied for learning spatio-temporal representations at the sequence level. In addition, we propose the compact softmax cross entropy loss to further encourage the learned features have the minimum intra-class distance and the maximum inter-class distance. Experiments on two in-the-wild dynamic facial expression datasets (i.e., DFEW and AFEW) indicate that our method provides an effective way to make use of the spatial and temporal dependencies for dynamic facial expression recognition. The source code and the training logs will be made publicly available."
Controlling Extra-Textual Attributes about Dialogue Participants: ACase Study of English-to-Polish Neural Machine Translation,"Sebastian T.Vincent, LoïcBarrault, CarolinaScarton",10 May 2022,Computation and Language (cs.CL)," Unlike English, morphologically rich languages can reveal characteristics of speakers or their conversational partners, such as gender and number, via pronouns, morphological endings of words and syntax. When translating from English to such languages, a machine translation model needs to opt for a certain interpretation of textual context, which may lead to serious translation errors if extra-textual information is unavailable. We investigate this challenge in the English-to-Polish language direction. We focus on the underresearched problem of utilising external metadata in automatic translation of TV dialogue, proposing a case study where a wide range of approaches for controlling attributes in translation is employed in a multi-attribute scenario. The best model achieves an improvement of +5.81 chrF++/+6.03 BLEU, with other models achieving competitive performance. We additionally contribute a novel attribute-annotated dataset of Polish TV dialogue and a morphological analysis script used to evaluate attribute control in models."
PaCHash: Packed and Compressed Hash Tables,"FlorianKurpicz, Hans-PeterLehmann, PeterSanders",10 May 2022,Data Structures and Algorithms (cs.DS)," We introduce PaCHash, a hash table that stores its objects contiguously in an array without intervening space, even if the objects have variable size. In particular, each object can be compressed using standard compression techniques. A small search data structure allows locating the objects in constant expected time. PaCHash is most naturally described as a static external hash table where it needs a constant number of bits of internal memory per block of external memory. However, PaCHash can be dynamized and is also useful for internal memory, having lower space consumption than all previous approaches even when considering only objects of identical size. For example, in some sense it beats a lower bound on the space consumption of k-perfect hashing. An implementation for fast SSDs needs about 5 bits of internal memory per block of external memory, requires only one disk access (of variable length) per search operation and has internal search overhead small compared to the disk access cost."
Constant approximation for fault-tolerant median problems viaiterative rounding,ShichuanDeng,10 May 2022,Data Structures and Algorithms (cs.DS)," In this paper, we study the fault-tolerant matroid median and fault-tolerant knapsack median problems. These two problems generalize many fundamental clustering and facility location problems, such as uniform fault-tolerant $k$-median, uniform fault-tolerant facility location, matroid median, knapsack median, etc. We present a versatile iterative rounding framework and obtain a unifying constant-factor approximation algorithm."
"The Road to Industry 4.0 and Beyond: A Communications-, Information-,and Operation Technology Collaboration Perspective","ZiweiWan, ZhenGao, Marco DiRenzo, Lajos Hanzo",10 May 2022,Information Theory (cs.IT)," The fourth industrial revolution, i.e., Industry 4.0, is evolving all around the globe. In this article, we introduce the landscape of Industry 4.0 and beyond empowered by the seamless collaboration of communication technology (CT), information technology (IT), and operation technology (OT), i.e., CIOT collaboration. Specifically, CIOT collaboration is regarded as a main improvement of Industry 4.0 compared to the previous industrial revolutions. We commence by reviewing the previous three industrial revolutions and we argue that the key feature of Industry 4.0 is the CIOT collaboration. More particularly, CT domain supports ubiquitous connectivity of the industrial elements and further bridges the physical world and the cyber world, which is a pivotal prerequisite. Then, we present the potential impacts of CIOT collaboration on typical industrial use cases with the objective of creating a more intelligent and human-friendly industry. Furthermore, the technical challenges of paving the way for the CIOT collaboration with an emphasis on the CT domain are discussed. Finally, we shed light on a roadmap for Industry 4.0 and beyond. The salient steps to be taken in the future CIOT collaboration are highlighted, which may be expected to expedite the paradigm shift towards the next industrial revolution."
AI training resources for GLAM: a snapshot,"AndrewDarby, Catherine NicoleColeman, ClaudiaEngel, Daniel vanStrien, MikeTrizna, Zachary W.Painter",10 May 2022,Machine Learning (cs.LG)," We take a snapshot of current resources available for teaching and learning AI with a focus on the Galleries, Libraries, Archives and Museums (GLAM) community. The review was carried out in 2021 and 2022. The review provides an overview of material we identified as being relevant, offers a description of this material and makes recommendations for future work in this area."
Characterization of electric consumers through an automated clusteringpipeline,FrancescaSoldan(1) AlbertoMaldarella(1) GabrielePaludetto(1) EneaBionda(1) FedericoBelloni(2) SamueleGrillo (3)((1) RSE S.p.A. (2) Unareti S.p.A. ,10 May 2022,Systems and Control (eess.SY)," Clustering analysis of daily load profiles represents an effective technique to classify and aggregate electric users based on their actual consumption patterns. Among other purposes, it may be exploited as a preliminary stage for load forecasting, which is applied in the same way to consumers in the same cluster. Several clustering algorithms have been proposed and developed in the literature, and the choice of the most appropriate set of clustering parameters is crucial for ensuring reliable results. In this paper, an automated service, suited for repeated clustering analysis, is presented. The pipeline is able to process a generic time series dataset and is easily adjustable to test other clustering input parameters; therefore, it may be utilized to find the best set of parameters with the specific dataset. Moreover, it facilitates repeated characterization on real-time load profiles with the aim of detecting sudden changes of consumers behaviors and variable external conditions, which influence the real power forecasting activity on a short temporal scale."
Brezzi--Douglas--Marini interpolation on anisotropic simplices andprisms,VolkerKempf,10 May 2022,Numerical Analysis (math.NA)," The Brezzi--Douglas--Marini interpolation error on anisotropic elements has been analyzed in two recent publications, the first focusing on simplices with estimates in $L^2$, the other considering parallelotopes with estimates in terms of $L^p$-norms. This contribution provides generalized estimates for anisotropic simplices for the $L^p$ case, $1\leq p\leq\infty$, and shows new estimates for anisotropic prisms with triangular base."
From Distillation to Hard Negative Sampling: Making Sparse Neural IRModels More Effective,"ThibaultFormal, CarlosLassance, BenjaminPiwowarski, StéphaneClinchant","10 May 2022 (v1(https://arxiv.org/abs/2205.04733v1)), lastrevised 12 May 2022 (this version, v2)",Information Retrieval (cs.IR)," Neural retrievers based on dense representations combined with Approximate Nearest Neighbors search have recently received a lot of attention, owing their success to distillation and/or better sampling of examples for training -- while still relying on the same backbone architecture. In the meantime, sparse representation learning fueled by traditional inverted indexing techniques has seen a growing interest, inheriting from desirable IR priors such as explicit lexical matching. While some architectural variants have been proposed, a lesser effort has been put in the training of such models. In this work, we build on SPLADE -- a sparse expansion-based retriever -- and show to which extent it is able to benefit from the same training improvements as dense models, by studying the effect of distillation, hard-negative mining as well as the Pre-trained Language Model initialization. We furthermore study the link between effectiveness and efficiency, on in-domain and zero-shot settings, leading to state-of- the-art results in both scenarios for sufficiently expressive models."
Explainable Data Imputation using Constraints,"SandeepHans, DiptikalyanSaha, AniyaAggarwal",10 May 2022,Artificial Intelligence (cs.AI)," Data values in a dataset can be missing or anomalous due to mishandling or human error. Analysing data with missing values can create bias and affect the inferences. Several analysis methods, such as principle components analysis or singular value decomposition, require complete data. Many approaches impute numeric data and some do not consider dependency of attributes on other attributes, while some require human intervention and domain knowledge. We present a new algorithm for data imputation based on different data type values and their association constraints in data, which are not handled currently by any system. We show experimental results using different metrics comparing our algorithm with state of the art imputation techniques. Our algorithm not only imputes the missing values but also generates human readable explanations describing the significance of attributes used for every imputation."
Weakly-supervised segmentation of referring expressions,"RobinStrudel, IvanLaptev, CordeliaSchmid","10 May 2022 (v1(https://arxiv.org/abs/2205.04725v1)), lastrevised 12 May 2022 (this version, v2)",Computer Vision and Pattern Recognition (cs.CV)," Visual grounding localizes regions (boxes or segments) in the image corresponding to given referring expressions. In this work we address image segmentation from referring expressions, a problem that has so far only been addressed in a fully-supervised setting. A fully-supervised setup, however, requires pixel-wise supervision and is hard to scale given the expense of manual annotation. We therefore introduce a new task of weakly- supervised image segmentation from referring expressions and propose Text grounded semantic SEGgmentation (TSEG) that learns segmentation masks directly from image-level referring expressions without pixel-level annotations. Our transformer-based method computes patch-text similarities and guides the classification objective during training with a new multi- label patch assignment mechanism. The resulting visual grounding model segments image regions corresponding to given natural language expressions. Our approach TSEG demonstrates promising results for weakly-supervised referring expression segmentation on the challenging PhraseCut and RefCOCO datasets. TSEG also shows competitive performance when evaluated in a zero- shot setting for semantic segmentation on Pascal VOC."
Comparision of Traditional and Fuzzy Failure Mode and Effects Analysisfor Smart Grid Electrical Distribution Systems,"Shravan KumarAkula, HosseinSalehfar, ShayanBehzadirafi",10 May 2022,Systems and Control (eess.SY)," Reliability Assessment is an indispensable technology for identifying, interpreting, and lessening the potential failures in safety- critical systems like smart grids. Failure modes and effects analysis (FMEA) is one of the well documented techniques for risk analysis to study the impact of failure modes on safety critical systems like smart grid. In traditional FMEA failure modes are prioritized based on a numeric assessment known as risk priority number. Risk priority number (RPN) is defined as the product of three risk factors namely severity (S), occurrence (O), and detection (D). These risk factors are generally attained by extensive team efforts and judgments which can lead to errors and inconsistencies. To address the shortcomings of the traditional FMEA, a fuzzy-based FMEA approach is proposed to generate reliable risk priority rankings. In this study, traditional and fuzzy-based FMEA risk priority rankings for smart grid electrical distribution systems are compared and recommendations are made based on the analysis. Results prove the efficiency of the proposed fuzzy-FMEA method."
Integrating Parcel Deliveries into a Ride-Pooling Service -- An Agent-Based Simulation Study,"FabianFehn, RomanEngelhardt, FlorianDandl, KlausBogenberger, Fritz Busch",10 May 2022,Multiagent Systems (cs.MA)," This paper examines the integration of freight delivery into the passenger transport of an on-demand ride-pooling service. The goal of this research is to use existing passenger trips for logistics services and thus reduce additional vehicle kilometers for freight delivery and the total number of vehicles on the road network. This is achieved by merging the need for two separate fleets into a single one by combining the services. To evaluate the potential of such a mobility-on-demand service, this paper uses an agent-based simulation framework and integrates three heuristic parcel assignment strategies into a ride-pooling fleet control algorithm. Two integration scenarios (moderate and full) are set up. While in both scenarios passengers and parcels share rides in one vehicle, in the moderate scenario no stops for parcel pick-up and delivery are allowed during a passenger ride to decrease customer inconvenience. Using real-world demand data for a case study of Munich, Germany, the two integration scenarios together with the three assignment strategies are compared to the status quo, which uses two separate vehicle fleets for passenger and logistics transport. The results indicate that the integration of logistics services into a ride-pooling service is possible and can exploit unused system capacities without deteriorating passenger transport. Depending on the assignment strategies nearly all parcels can be served until a parcel to passenger demand ratio of 1:10 while the overall fleet kilometers can be deceased compared to the status quo."
InfraRisk: An Open-Source Simulation Platform for Asset-LevelResilience Analysis in Interconnected Infrastructure Networks,"SrijithBalakrishnan, BeatriceCassottana",10 May 2022,Systems and Control (eess.SY)," Integrated simulation models are emerging as an alternative for analyzing large-scale interdependent infrastructure networks due to their modeling advantages over traditional interdependency models. This paper presents an open-source integrated simulation package for the asset-level analysis of interdependent infrastructure systems. The simulation platform, named 'InfraRisk' and developed in Python, can simulate disaster-induced infrastructure failures and subsequent post-disaster restoration in interconnected water-, power-, and road networks. InfraRisk consists of an infrastructure module, a hazard module, a recovery module, a simulation module, and a resilience quantification module. The infrastructure module integrates existing infrastructure network packages (wntr for water networks, pandapower for power systems, and a static traffic assignment model for transportation networks) through an interface that facilitates the network-level simulation of interdependent failures. The hazard module generates infrastructure component failure sequences based on various disaster characteristics. The recovery module determines repair sequences and assigns repair crews based on predefined heuristics-based recovery strategies or model predictive control (MPC) based optimization. Based on the schedule, the simulation module implements the network-wide simulation of the consequences of the disaster impacts and the recovery actions. The resilience quantification module offers system-level and consumer-level metrics to quantify both the risks and resilience of the integrated infrastructure networks against disaster events. InfraRisk provides a virtual platform for decision-makers to experiment and develop region- specific pre-disaster and post-disaster policies to enhance the overall resilience of interdependent urban infrastructure networks."
Serving and Optimizing Machine Learning Workflows on HeterogeneousInfrastructures,"YongjiWu, MatthewLentz, Danyang Zhuo, Yao Lu",10 May 2022,Machine Learning (cs.LG)," With the advent of ubiquitous deployment of smart devices and the Internet of Things, data sources for machine learning inference have increasingly moved to the edge of the network. Existing machine learning inference platforms typically assume a homogeneous infrastructure and do not take into account the more complex and tiered computing infrastructure that includes edge devices, local hubs, edge datacenters, and cloud datacenters. On the other hand, recent machine learning efforts have provided viable solutions for model compression, pruning and quantization for heterogeneous environments; for a machine learning model, now we may easily find or even generate a series of models with different tradeoffs between accuracy and efficiency.   We design and implement JellyBean, a framework for serving and optimizing machine learning inference workflows on heterogeneous infrastructures. Given service-level objectives (e.g., throughput, accuracy), JellyBean automatically selects the most cost-efficient models that met the accuracy target and decides how to deploy them across different tiers of infrastructures. Evaluations show that JellyBean reduces the total serving cost of visual question answering by up to 58%, and vehicle tracking from the NVIDIA AI City Challenge by up to 36% compared with state-of-the-art model selection and worker assignment solutions. JellyBean also outperforms prior ML serving systems (e.g., Spark on the cloud) up to 5x in serving costs."
Knowledge Augmented Machine Learning with Applications in AutonomousDriving: A Survey,"JulianWörmann, DanielBogdoll, EtienneBührle, Han Chen, Evaristus FuhChuo, KostadinCvejoski, Ludger vanElst, TobiasGleißner, PhilipGottschall, StefanGriesche, ChristianHellert, ChristianHesels, SebastianHouben, TimJoseph, Niklas Keil, JohannKelsch, HendrikKönigshof, Erwin Kraft, LeonieKreuser, Kevin Krone, TobiasLatka, DennyMattern, StefanMatthes, MohsinMunir, MoritzNekolla, AdrianPaschke, Maximilian AlexanderPintz, Tianming Qiu, FarazQureishi, Syed Tahseen RazaRizvi, JörgReichardt, Laura vonRueden, StefanRudolph, AlexanderSagel, GerhardSchunk, HaoShen, HendrikStapelbroek, Vera Stehr, GurucharanSrinivas, Anh TuanTran, AbhishekVivekanandan, Ya Wang, FlorianWasserrab, TinoWerner, ChristianWirth, StefanZwicklbauer",10 May 2022,Machine Learning (cs.LG)," The existence of representative datasets is a prerequisite of many successful artificial intelligence and machine learning models. However, the subsequent application of these models often involves scenarios that are inadequately represented in the data used for training. The reasons for this are manifold and range from time and cost constraints to ethical considerations. As a consequence, the reliable use of these models, especially in safety-critical applications, is a huge challenge. Leveraging additional, already existing sources of knowledge is key to overcome the limitations of purely data-driven approaches, and eventually to increase the generalization capability of these models. Furthermore, predictions that conform with knowledge are crucial for making trustworthy and safe decisions even in underrepresented scenarios. This work provides an overview of existing techniques and methods in the literature that combine data-based models with existing knowledge. The identified approaches are structured according to the categories integration, extraction and conformity. Special attention is given to applications in the field of autonomous driving."
SmartSAGE: Training Large-scale Graph Neural Networks using In-StorageProcessing Architectures,"YunjaeLee, JinhaChung, Minsoo Rhu",10 May 2022,Hardware Architecture (cs.AR)," Graph neural networks (GNNs) can extract features by learning both the representation of each objects (i.e., graph nodes) and the relationship across different objects (i.e., the edges that connect nodes), achieving state-of-the-art performance in various graph-based tasks. Despite its strengths, utilizing these algorithms in a production environment faces several challenges as the number of graph nodes and edges amount to several billions to hundreds of billions scale, requiring substantial storage space for training. Unfortunately, state-of-the-art ML frameworks employ an in- memory processing model which significantly hampers the productivity of ML practitioners as it mandates the overall working set to fit within DRAM capacity. In this work, we first conduct a detailed characterization on a state-of-the-art, large-scale GNN training algorithm, GraphSAGE. Based on the characterization, we then explore the feasibility of utilizing capacity- optimized NVM SSDs for storing memory-hungry GNN data, which enables large- scale GNN training beyond the limits of main memory size. Given the large performance gap between DRAM and SSD, however, blindly utilizing SSDs as a direct substitute for DRAM leads to significant performance loss. We therefore develop SmartSAGE, our software/hardware co-design based on an in- storage processing (ISP) architecture. Our work demonstrates that an ISP based large-scale GNN training system can achieve both high capacity storage and high performance, opening up opportunities for ML practitioners to train large GNN datasets without being hampered by the physical limitations of main memory size."
Client Selection and Bandwidth Allocation for Federated Learning: AnOnline Optimization Perspective,"Yun Ji, Zhoubin Kou, XiaoxiongZhong, ShengZhang, Hangfan Li, Fan Yang",10 May 2022,Networking and Internet Architecture (cs.NI)," Federated learning (FL) can train a global model from clients' local data set, which can make full use of the computing resources of clients and performs more extensive and efficient machine learning on clients with protecting user information requirements. Many existing works have focused on optimizing FL accuracy within the resource constrained in each individual round, however there are few works comprehensively consider the optimization for latency, accuracy and energy consumption over all rounds in wireless federated learning. Inspired by this, in this paper, we investigate FL in wireless network where client selection and bandwidth allocation are two crucial factors which significantly affect the latency, accuracy and energy consumption of clients. We formulate the optimization problem as a mixed-integer problem, which is to minimize the cost of time and accuracy within the long-term energy constrained over all rounds. To address this optimization, we propose the Perround Energy Drift Plus Cost (PEDPC) algorithm in an online perspective, and the performance of the PEDPC algorithm is verified in simulation results in terms of latency, accuracy and energy consumption in IID and NON-IID dat distributions."
Training Personalized Recommendation Systems from (GPU) Scratch: LookForward not Backwards,"YoungeunKwon, MinsooRhu",10 May 2022,Hardware Architecture (cs.AR)," Personalized recommendation models (RecSys) are one of the most popular machine learning workload serviced by hyperscalers. A critical challenge of training RecSys is its high memory capacity requirements, reaching hundreds of GBs to TBs of model size. In RecSys, the so-called embedding layers account for the majority of memory usage so current systems employ a hybrid CPU-GPU design to have the large CPU memory store the memory hungry embedding layers. Unfortunately, training embeddings involve several memory bandwidth intensive operations which is at odds with the slow CPU memory, causing performance overheads. Prior work proposed to cache frequently accessed embeddings inside GPU memory as means to filter down the embedding layer traffic to CPU memory, but this paper observes several limitations with such cache design. In this work, we present a fundamentally different approach in designing embedding caches for RecSys. Our proposed ScratchPipe architecture utilizes unique properties of RecSys training to develop an embedding cache that not only sees the past but also the ""future"" cache accesses. ScratchPipe exploits such property to guarantee that the active working set of embedding layers can ""always"" be captured inside our proposed cache design, enabling embedding layer training to be conducted at GPU memory speed."
Stabilized Doubly Robust Learning for Recommendation on Data MissingNot at Random,"HaoxuanLi, ChunyuanZheng, Xiao-Hua Zhou, Peng Wu",10 May 2022,Machine Learning (cs.LG)," In recommender systems, users always choose favorite items to rate, which results in data missing not at random and poses a great challenge for unbiased evaluation and learning of prediction models. Currently, the doubly robust (DR) method and its variants have been widely studied and demonstrate superior performance. However, we show that DR methods are unstable to extremely small propensities and rely on extrapolations, resulting in sub-optimal performances. In this paper, we propose a stabilized doubly robust (SDR) estimator to address the above limitations while retaining double robustness. Theoretical analysis shows that SDR has bounded bias, variance and generalization error bound under inaccurate imputed errors and arbitrarily small propensities. In addition, we propose a novel learning approach for SDR that updates the imputation, propensity, and prediction models cyclically, achieving more stable and accurate predictions. Extensive experiments show that our approach significantly outperforms the existing methods."
An Empirical Evaluation of Various Information Gain Criteria forActive Tactile Action Selection for Pose Estimation,"Prajval KumarMurali, RavinderDahiya, MohsenKaboli",10 May 2022,Robotics (cs.RO)," Accurate object pose estimation using multi-modal perception such as visual and tactile sensing have been used for autonomous robotic manipulators in literature. Due to variation in density of visual and tactile data, we previously proposed a novel probabilistic Bayesian filter- based approach termed translation-invariant Quaternion filter (TIQF) for pose estimation. As tactile data collection is time consuming, active tactile data collection is preferred by reasoning over multiple potential actions for maximal expected information gain. In this paper, we empirically evaluate various information gain criteria for action selection in the context of object pose estimation. We demonstrate the adaptability and effectiveness of our proposed TIQF pose estimation approach with various information gain criteria. We find similar performance in terms of pose accuracy with sparse measurements across all the selected criteria."
A simple and optimal algorithm for strict circular seriation,"MikhaelCarmona, VictorChepoi, GuyslainNaves, PascalPréa",10 May 2022,Discrete Mathematics (cs.DM)," Recently, Armstrong, Guzmán, and Sing Long (2021), presented an optimal $O(n^2)$ time algorithm for strict circular seriation (called also the recognition of strict quasi-circular Robinson spaces). In this paper, we give a very simple $O(n\log n)$ time algorithm for computing a compatible circular order for strict circular seriation. When the input space is not known to be strict quasi-circular Robinson, our algorithm is complemented by an $O(n^2)$ time verification of compatibility of the returned order. This algorithm also works for recognition of other types of strict circular Robinson spaces known in the literature. We also prove that the circular Robinson dissimilarities (which are defined by the existence of compatible orders on one of the two arcs between each pair of points) are exactly the pre-circular Robinson dissimilarities (which are defined by a four-point condition)."
Meta-Learning Based Knowledge Extrapolation for Knowledge Graphs inthe Federated Setting,"MingyangChen, WenZhang, ZhenYao, XiangnanChen, MengxiaoDing, FeiHuang, Huajun Chen",10 May 2022,Computation and Language (cs.CL)," We study the knowledge extrapolation problem to embed new components (i.e., entities and relations) that come with emerging knowledge graphs (KGs) in the federated setting. In this problem, a model trained on an existing KG needs to embed an emerging KG with unseen entities and relations. To solve this problem, we introduce the meta-learning setting, where a set of tasks are sampled on the existing KG to mimic the link prediction task on the emerging KG. Based on sampled tasks, we meta-train a graph neural network framework that can construct features for unseen components based on structural information and output embeddings for them. Experimental results show that our proposed method can effectively embed unseen components and outperforms models that consider inductive settings for KGs and baselines that directly use conventional KG embedding methods."
An asynchronous event-based algorithm for periodic signals,"David El-Chai Ben-Ezra, Ron Arad, AyeletPadowicz, IsraelTugendhaft",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In this paper, we present a simple event-oriented algorithm for detection of pixel-size signals with a known frequency, by the novel technology of an event camera. In addition, we analyze the ability of the algorithm to filter out the desired periodic signals from random fluctuations. We demonstrate this ability and show how the algorithm can distinguish, during twilight, between the signals of a streetlight that flicker with frequency of 100 Hz, and sun glitter originating from windows in far-away buildings in the field of view."
Optimal Price Discrimination for Randomized Mechanisms,"Shao-HengKo, KameshMunagala",10 May 2022,Computer Science and Game Theory (cs.GT)," We study the power of price discrimination via an intermediary in bilateral trade, when there is a revenue-maximizing seller selling an item to a buyer with a private value drawn from a prior. Between the seller and the buyer, there is an intermediary that can segment the market by releasing information about the true values to the seller. This is termed signaling, and enables the seller to price discriminate. In this setting, Bergemann et al. showed the existence of a signaling scheme that simultaneously raises the optimal consumer surplus, guarantees the item always sells, and ensures the seller's revenue does not increase.   Our work extends the positive result of Bergemann et al. to settings where the type space is larger, and where optimal auction is randomized, possibly over a menu that can be exponentially large. In particular, we consider two settings motivated by budgets: The first is when there is a publicly known budget constraint on the price the seller can charge and the second is the FedEx problem where the buyer has a private deadline or service level (equivalently, a private budget that is guaranteed to never bind). For both settings, we present a novel signaling scheme and its analysis via a continuous construction process that recreates the optimal consumer surplus guarantee of Bergemann et al.   The settings we consider are special cases of the more general problem where the buyer has a private budget constraint in addition to a private value. We finally show that our positive results do not extend to this more general setting. Here, we show that any efficient signaling scheme necessarily transfers almost all the surplus to the seller instead of the buyer."
AdMix: A Mixed Sample Data Augmentation Method for Neural MachineTranslation,"ChangJin, ShiguiQiu, NiniXiao, HaoJia",10 May 2022,Computation and Language (cs.CL)," In Neural Machine Translation (NMT), data augmentation methods such as back-translation have proven their effectiveness in improving translation performance. In this paper, we propose a novel data augmentation approach for NMT, which is independent of any additional training data. Our approach, AdMix, consists of two parts: 1) introduce faint discrete noise (word replacement, word dropping, word swapping) into the original sentence pairs to form augmented samples; 2) generate new synthetic training data by softly mixing the augmented samples with their original samples in training corpus. Experiments on three translation datasets of different scales show that AdMix achieves signifi cant improvements (1.0 to 2.7 BLEU points) over strong Transformer baseline. When combined with other data augmentation techniques (e.g., back-translation), our approach can obtain further improvements."
DNS based In-Browser Cryptojacking Detection,"Rohit KumarSachan, RachitAgarwal, Sandeep KumarShukla",10 May 2022,Cryptography and Security (cs.CR)," The metadata aspect of Domain Names (DNs) enables us to perform a behavioral study of DNs and detect if a DN is involved in in-browser cryptojacking. Thus, we are motivated to study different temporal and behavioral aspects of DNs involved in cryptojacking. We use temporal features such as query frequency and query burst along with graph-based features such as degree and diameter, and non-temporal features such as the string-based to detect if a DNs is suspect to be involved in the in-browser cryptojacking. Then, we use them to train the Machine Learning (ML) algorithms over different temporal granularities such as 2 hours datasets and complete dataset. Our results show DecisionTrees classifier performs the best with 59.5% Recall on cryptojacked DN, while for unsupervised learning, K-Means with K=2 perform the best. Similarity analysis of the features reveals a minimal divergence between the cryptojacking DNs and other already known malicious DNs. It also reveals the need for improvements in the feature set of state-of-the-art methods to improve their accuracy in detecting in-browser cryptojacking. As added analysis, our signature-based analysis identifies that none-of-the Indian Government websites were involved in cryptojacking during October-December 2021. However, based on the resource utilization, we identify 10 DNs with different properties than others."
OTFPF: Optimal Transport-Based Feature Pyramid Fusion Network forBrain Age Estimation with 3D Overlapped ConvNeXt,"Yu Fu, YanyanHuang, YalinWang, ShunjieDong, LeXue, XunzhaoYin, QianqianYang, YiyuShi, ChengZhuo","10 May 2022 (v1(https://arxiv.org/abs/2205.04684v1)), lastrevised 11 May 2022 (this version, v2)",Computer Vision and Pattern Recognition (cs.CV)," Chronological age of healthy brain is able to be predicted using deep neural networks from T1-weighted magnetic resonance images (T1 MRIs), and the predicted brain age could serve as an effective biomarker for detecting aging-related diseases or disorders. In this paper, we propose an end-to-end neural network architecture, referred to as optimal transport based feature pyramid fusion (OTFPF) network, for the brain age estimation with T1 MRIs. The OTFPF consists of three types of modules: Optimal Transport based Feature Pyramid Fusion (OTFPF) module, 3D overlapped ConvNeXt (3D OL-ConvNeXt) module and fusion module. These modules strengthen the OTFPF network's understanding of each brain's semi-multimodal and multi- level feature pyramid information, and significantly improve its estimation performances. Comparing with recent state-of-the-art models, the proposed OTFPF converges faster and performs better. The experiments with 11,728 MRIs aged 3-97 years show that OTFPF network could provide accurate brain age estimation, yielding mean absolute error (MAE) of 2.097, Pearson's correlation coefficient (PCC) of 0.993 and Spearman's rank correlation coefficient (SRCC) of 0.989, between the estimated and chronological ages. Widespread quantitative experiments and ablation experiments demonstrate the superiority and rationality of OTFPF network. The codes and implement details will be released on GitHub: [this https URL](https://github.com/ZJU- Brain/OTFPF) after final decision."
UNITS: Unsupervised Intermediate Training Stage for Scene TextDetection,"YouhuiGuo, YuZhou, XugongQin, EnzeXie, WeipingWang",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Recent scene text detection methods are almost based on deep learning and data-driven. Synthetic data is commonly adopted for pre- training due to expensive annotation cost. However, there are obvious domain discrepancies between synthetic data and real-world data. It may lead to sub-optimal performance to directly adopt the model initialized by synthetic data in the fine-tuning stage. In this paper, we propose a new training paradigm for scene text detection, which introduces an \textbf{UN}supervised \textbf{I}ntermediate \textbf{T}raining \textbf{S}tage (UNITS) that builds a buffer path to real-world data and can alleviate the gap between the pre- training stage and fine-tuning stage. Three training strategies are further explored to perceive information from real-world data in an unsupervised way. With UNITS, scene text detectors are improved without introducing any parameters and computations during inference. Extensive experimental results show consistent performance improvements on three public datasets."
Selective Fairness in Recommendation via Prompts,"YiqingWu, RuobingXie, YongchunZhu, FuzhenZhuang, Xiang Ao, XuZhang, LeyuLin, QingHe",10 May 2022,Information Retrieval (cs.IR)," Recommendation fairness has attracted great attention recently. In real-world systems, users usually have multiple sensitive attributes (e.g. age, gender, and occupation), and users may not want their recommendation results influenced by those attributes. Moreover, which of and when these user attributes should be considered in fairness-aware modeling should depend on users' specific demands. In this work, we define the selective fairness task, where users can flexibly choose which sensitive attributes should the recommendation model be bias-free. We propose a novel parameter- efficient prompt-based fairness-aware recommendation (PFRec) framework, which relies on attribute-specific prompt-based bias eliminators with adversarial training, enabling selective fairness with different attribute combinations on sequential recommendation. Both task-specific and user- specific prompts are considered. We conduct extensive evaluations to verify PFRec's superiority in selective fairness. The source codes are released in \url{[this https URL](https://github.com/wyqing20/PFRec)}."
Real-time Forecasting of Time Series in Financial Markets UsingSequentially Trained Many-to-one LSTMs,"KelumGajamannage, Yonggi Park",10 May 2022,Machine Learning (cs.LG)," Financial markets are highly complex and volatile; thus, learning about such markets for the sake of making predictions is vital to make early alerts about crashes and subsequent recoveries. People have been using learning tools from diverse fields such as financial mathematics and machine learning in the attempt of making trustworthy predictions on such markets. However, the accuracy of such techniques had not been adequate until artificial neural network (ANN) frameworks were developed. Moreover, making accurate real-time predictions of financial time series is highly subjective to the ANN architecture in use and the procedure of training it. Long short- term memory (LSTM) is a member of the recurrent neural network family which has been widely utilized for time series predictions. Especially, we train two LSTMs with a known length, say $T$ time steps, of previous data and predict only one time step ahead. At each iteration, while one LSTM is employed to find the best number of epochs, the second LSTM is trained only for the best number of epochs to make predictions. We treat the current prediction as in the training set for the next prediction and train the same LSTM. While classic ways of training result in more error when the predictions are made further away in the test period, our approach is capable of maintaining a superior accuracy as training increases when it proceeds through the testing period. The forecasting accuracy of our approach is validated using three time series from each of the three diverse financial markets: stock, cryptocurrency, and commodity. The results are compared with those of an extended Kalman filter, an autoregressive model, and an autoregressive integrated moving average model."
Spatial Monitoring and Insect Behavioural Analysis Using ComputerVision for Precision Pollination,"Malika NisalRatnayake, Don ChathurikaAmarathunga, AsaduzZaman, Adrian G.Dyer, AlanDorin",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Insects are the most important global pollinator of crops and play a key role in maintaining the sustainability of natural ecosystems. Insect pollination monitoring and management are therefore essential for improving crop production and food security. Computer vision facilitated pollinator monitoring can intensify data collection over what is feasible using manual approaches. The new data it generates may provide a detailed understanding of insect distributions and facilitate fine-grained analysis sufficient to predict their pollination efficacy and underpin precision pollination. Current computer vision facilitated insect tracking in complex outdoor environments is restricted in spatial coverage and often constrained to a single insect species. This limits its relevance to agriculture. Therefore, in this article we introduce a novel system to facilitate markerless data capture for insect counting, insect motion tracking, behaviour analysis and pollination prediction across large agricultural areas. Our system is comprised of Edge Computing multi-point video recording, offline automated multi-species insect counting, tracking and behavioural analysis. We implement and test our system on a commercial berry farm to demonstrate its capabilities. Our system successfully tracked four insect varieties, at nine monitoring stations within a poly-tunnel, obtaining an F-score above 0.8 for each variety. The system enabled calculation of key metrics to assess the relative pollination impact of each insect variety. With this technological advancement, detailed, ongoing data collection for precision pollination becomes achievable. This is important to inform growers and apiarists managing crop pollination, as it allows data-driven decisions to be made to improve food production and food security."
Balanced control between performance and saturation for constrainednonlinear systems,"PengWang, HaibinWang, Shuzhi SamGe, XiaobingZhang",10 May 2022,Systems and Control (eess.SY)," This paper addresses the balanced control between performance and saturation for a class of constrained nonlinear systems, including the branches: balanced command filtered backstepping (BCFB) and balanced performance control (BPC). To balance the interconnection and conflict between performance and saturation constraints, define a performance safety evaluation (PSE) function, which evaluates the system safety under the destabilizing effect variables (DEVs) like saturation quantity and filter errors, then the cumulative effects of DEVs are fully utilized and compensated for the performance recovery. Specifically, there exists some degree of tolerance for the DEVs in the safety region, and the compensation operation works when the evaluation of the system goes dangerous. The advantages of the proposed methodology are illustrated in the numerical simulation."
Improving genetic risk prediction across diverse population bydisentangling ancestry representations,"Prashnna KGyawali, Yann LeGuen, Xiaoxia Liu, Hua Tang, James Zou, Zihuai He",10 May 2022,Machine Learning (cs.LG)," Risk prediction models using genetic data have seen increasing traction in genomics. However, most of the polygenic risk models were developed using data from participants with similar (mostly European) ancestry. This can lead to biases in the risk predictors resulting in poor generalization when applied to minority populations and admixed individuals such as African Americans. To address this bias, largely due to the prediction models being confounded by the underlying population structure, we propose a novel deep-learning framework that leverages data from diverse population and disentangles ancestry from the phenotype-relevant information in its representation. The ancestry disentangled representation can be used to build risk predictors that perform better across minority populations. We applied the proposed method to the analysis of Alzheimer's disease genetics. Comparing with standard linear and nonlinear risk prediction methods, the proposed method substantially improves risk prediction in minority populations, particularly for admixed individuals."
Rate-Convergence Tradeoff of Federated Learning over Wireless Channel,"AyoobSalari, MahyarShirvanimoghaddam, BrankaVucetic, SarahJohnson",10 May 2022,Information Theory (cs.IT)," In this paper, we consider a federated learning problem over wireless channel that takes into account the coding rate and packet transmission errors. Communication channels are modelled as packet erasure channels (PEC), where the erasure probability is determined by the block length, code rate, and signal-to-noise ratio (SNR). To lessen the effect of packet erasure on the FL performance, we propose two schemes in which the central node (CN) reuses either the past local updates or the previous global parameters in case of packet erasure. We investigate the impact of coding rate on the convergence of federated learning (FL) for both short packet and long packet communications considering erroneous transmissions. Our simulation results shows that even one unit of memory has considerable impact on the performance of FL in erroneous communication."
Real-Time Wearable Gait Phase Segmentation For Running And Walking,"Jien-DeSui, Wei-HanChen, Tzyy-YuangShiang, Tian-SheuanChang",10 May 2022,Machine Learning (cs.LG)," Previous gait phase detection as convolutional neural network (CNN) based classification task requires cumbersome manual setting of time delay or heavy overlapped sliding windows to accurately classify each phase under different test cases, which is not suitable for streaming Inertial- Measurement-Unit (IMU) sensor data and fails to adapt to different scenarios. This paper presents a segmentation based gait phase detection with only a single six-axis IMU sensor, which can easily adapt to both walking and running at various speeds. The proposed segmentation uses CNN with gait phase aware receptive field setting and IMU oriented processing order, which can fit to high sampling rate of IMU up to 1000Hz for high accuracy and low sampling rate down to 20Hz for real time calculation. The proposed model on the 20Hz sampling rate data can achieve average error of 8.86 ms in swing time, 9.12 ms in stance time and 96.44\% accuracy of gait phase detection and 99.97\% accuracy of stride detection. Its real-time implementation on mobile phone only takes 36 ms for 1 second length of sensor data."
Variational Inference MPC using Normalizing Flows and Out-of-Distribution Projection,"ThomasPower, DmitryBerenson",10 May 2022,Robotics (cs.RO)," We propose a Model Predictive Control (MPC) method for collision- free navigation that uses amortized variational inference to approximate the distribution of optimal control sequences by training a normalizing flow conditioned on the start, goal and environment. This representation allows us to learn a distribution that accounts for both the dynamics of the robot and complex obstacle geometries. We can then sample from this distribution to produce control sequences which are likely to be both goal-directed and collision-free as part of our proposed FlowMPPI sampling-based MPC method. However, when deploying this method, the robot may encounter an out-of- distribution (OOD) environment, i.e. one which is radically different from those used in training. In such cases, the learned flow cannot be trusted to produce low-cost control sequences. To generalize our method to OOD environments we also present an approach that performs projection on the representation of the environment as part of the MPC process. This projection changes the environment representation to be more in-distribution while also optimizing trajectory quality in the true environment. Our simulation results on a 2D double-integrator and a 3D 12DoF underactuated quadrotor suggest that FlowMPPI with projection outperforms state-of-the-art MPC baselines on both in-distribution and OOD environments, including OOD environments generated from real-world data."
Deep Gait Tracking With Inertial Measurement Unit,"Jien DeSui, TianSheuanChang",10 May 2022,Machine Learning (cs.LG)," This paper presents a convolutional neural network based foot motion tracking with only six-axis Inertial-Measurement-Unit (IMU) sensor data. The presented approach can adapt to various walking conditions by adopting differential and window based input. The training data are further augmented by sliding and random window samplings on IMU sensor data to increase data diversity for better performance. The proposed approach fuses predictions of three dimensional output into one model. The proposed fused model can achieve average error of 2.30+-2.23 cm in X-axis, 0.91+-0.95 cm in Y-axis and 0.58+-0.52 cm in Z-axis."
A 14uJ/Decision Keyword Spotting Accelerator with In-SRAM-Computingand On Chip Learning for Customization,"Yu-HsiangChiang, Tian-SheuanChang, ShyhJye Jou",10 May 2022,Hardware Architecture (cs.AR)," Keyword spotting has gained popularity as a natural way to interact with consumer devices in recent years. However, because of its always-on nature and the variety of speech, it necessitates a low-power design as well as user customization. This paper describes a low-power, energy-efficient keyword spotting accelerator with SRAM based in-memory computing (IMC) and on-chip learning for user customization. However, IMC is constrained by macro size, limited precision, and non-ideal effects. To address the issues mentioned above, this paper proposes bias compensation and fine-tuning using an IMC-aware model design. Furthermore, because learning with low-precision edge devices results in zero error and gradient values due to quantization, this paper proposes error scaling and small gradient accumulation to achieve the same accuracy as ideal model training. The simulation results show that with user customization, we can recover the accuracy loss from 51.08\% to 89.76\% with compensation and fine-tuning and further improve to 96.71\% with customization. The chip implementation can successfully run the model with only 14$uJ$ per decision. When compared to the state-of-the-art works, the presented design has higher energy efficiency with additional on-chip model customization capabilities for higher accuracy."
SoK: Rethinking Sensor Spoofing Attacks against Robotic Vehicles froma Systematic View,"YuanXu, XingshuoHan, GeleiDeng, GuanlinLi, YangLiu, JiweiLi, TianweiZhang",10 May 2022,Cryptography and Security (cs.CR)," Robotic Vehicles (RVs) have gained great popularity over the past few years. Meanwhile, they are also demonstrated to be vulnerable to sensor spoofing attacks. Although a wealth of research works have presented various attacks, some key questions remain unanswered: are these existing works complete enough to cover all the sensor spoofing threats? If not, how many attacks are not explored, and how difficult is it to realize them?   This paper answers the above questions by comprehensively systematizing the knowledge of sensor spoofing attacks against RVs. Our contributions are threefold. (1) We identify seven common attack paths in an RV system pipeline. We categorize and assess existing spoofing attacks from the perspectives of spoofer property, operation, victim characteristic and attack goal. Based on this systematization, we identify 4 interesting insights about spoofing attack designs. (2) We propose a novel action flow model to systematically describe robotic function executions and sensor spoofing vulnerabilities. With this model, we successfully discover 104 spoofing attack vectors, 25 of which have been verified by prior works, while 55 attacks are practical but never considered. (3) We design two novel attack methodologies to verify the feasibility of newly discovered spoofing attack vectors."
Operations Smart Contract to Realize Decentralized System OperationsWorkflow for Consortium Blockchain,"TatsuyaSato, TakuShimosawa, YosukeHimura",10 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Enterprises have paid attention to consortium blockchains like Hyperledger Fabric, which is one of the most promising platforms, for efficient decentralized transactions without depending on any particular organization. A consortium blockchain-based system will be typically built across multiple organizations. In such blockchain-based systems, system operations across multiple organizations in a decentralized manner are essential to maintain the value of introducing consortium blockchains. Decentralized system operations have recently been becoming realistic with the evolution of consortium blockchains. For instance, the release of Hyperledger Fabric v2.x, in which individual operational tasks for a blockchain network, such as command execution of configuration change of channels (Fabric's sub-networks) and upgrade of chaincodes (Fabric's smart contracts), can be partially executed in a decentralized manner. However, the operations workflows also include the preceding procedure of pre- sharing, coordinating, and pre-agreeing the operational information (e.g., configuration parameters) among organizations, after which operation executions can be conducted, and this preceding procedure relies on costly manual tasks. To realize efficient decentralized operations workflows for consortium blockchain-based systems in general, we propose a decentralized inter-organizational operations method that we call Operations Smart Contract (OpsSC), which defines an operations workflow as a smart contract. Furthermore, we design and implement OpsSC for blockchain network operations with Hyperledger Fabric v2.x. This paper presents OpsSC for operating channels and chaincodes, which are essential for managing the blockchain networks, through clarifying detailed workflows of those operations. The implementation of OpsSC has been open-sourced and registered as one of Hyperledger Labs projects."
SuMe: A Dataset Towards Summarizing Biomedical Mechanisms,"MohaddesehBastan, NishantShankar, MihaiSurdeanu, NiranjanBalasubramanian",10 May 2022,Computation and Language (cs.CL)," Can language models read biomedical texts and explain the biomedical mechanisms discussed? In this work we introduce a biomedical mechanism summarization task. Biomedical studies often investigate the mechanisms behind how one entity (e.g., a protein or a chemical) affects another in a biological context. The abstracts of these publications often include a focused set of sentences that present relevant supporting statements regarding such relationships, associated experimental evidence, and a concluding sentence that summarizes the mechanism underlying the relationship. We leverage this structure and create a summarization task, where the input is a collection of sentences and the main entities in an abstract, and the output includes the relationship and a sentence that summarizes the mechanism. Using a small amount of manually labeled mechanism sentences, we train a mechanism sentence classifier to filter a large biomedical abstract collection and create a summarization dataset with 22k instances. We also introduce conclusion sentence generation as a pretraining task with 611k instances. We benchmark the performance of large bio-domain language models. We find that while the pretraining task help improves performance, the best model produces acceptable mechanism outputs in only 32% of the instances, which shows the task presents significant challenges in biomedical language understanding and summarization."
ParaCotta: Synthetic Multilingual Paraphrase Corpora from the MostDiverse Translation Sample Pair,"Alham FikriAji, TiranaNoorFatyanosa, Radityo EkoPrasojo, PhilipArthur, SuciFitriany, SalmaQonitah, NadhifaZulfa, TomiSantoso, Mahendra Data",10 May 2022,Computation and Language (cs.CL)," We release our synthetic parallel paraphrase corpus across 17 languages: Arabic, Catalan, Czech, German, English, Spanish, Estonian, French, Hindi, Indonesian, Italian, Dutch, Romanian, Russian, Swedish, Vietnamese, and Chinese. Our method relies only on monolingual data and a neural machine translation system to generate paraphrases, hence simple to apply. We generate multiple translation samples using beam search and choose the most lexically diverse pair according to their sentence BLEU. We compare our generated corpus with the \texttt{ParaBank2}. According to our evaluation, our synthetic paraphrase pairs are semantically similar and lexically diverse."
Robust Learning of Parsimonious Deep Neural Networks,"Valentin Frank IngmarGuenter, AthanasiosSideris",10 May 2022,Machine Learning (cs.LG)," We propose a simultaneous learning and pruning algorithm capable of identifying and eliminating irrelevant structures in a neural network during the early stages of training. Thus, the computational cost of subsequent training iterations, besides that of inference, is considerably reduced. Our method, based on variational inference principles, learns the posterior distribution of Bernoulli random variables multiplying the units/filters similarly to adaptive dropout. We derive a novel hyper-prior distribution over the prior parameters that is crucial for their optimal selection in a way that the Bernoulli parameters practically converge to either 0 or 1 establishing a deterministic final network. Our algorithm is robust in the sense that it achieves consistent pruning levels and prediction accuracy regardless of weight initialization or the size of the starting network. We provide an analysis of its convergence properties establishing theoretical and practical pruning conditions. We evaluate the proposed algorithm on the MNIST data set and commonly used fully connected and convolutional LeNet architectures. The simulations show that our method achieves pruning levels on par with state-of the-art methods for structured pruning, while maintaining better test-accuracy and more importantly in a manner robust with respect to network initialization and initial size."
Crypto Pump and Dump Detection via Deep Learning Techniques,"ViswanathChadalapaka, Kyle Chang, GireeshMahajan, Anuj Vasil",10 May 2022,Machine Learning (cs.LG)," Despite the fact that cryptocurrencies themselves have experienced an astonishing rate of adoption over the last decade, cryptocurrency fraud detection is a heavily under-researched problem area. Of all fraudulent activity regarding cryptocurrencies, pump and dump schemes are some of the most common. Though some studies have been done on these kinds of scams in the stock market, the lack of labelled stock data and the volatility unique to the cryptocurrency space constrains the applicability of studies on the stock market toward this problem domain. Furthermore, the only work done in this space thus far has been either statistical in nature, or has been concerned with classical machine learning models such as random forest trees. We propose the novel application of two existing neural network architectures to this problem domain and show that deep learning solutions can significantly outperform all other existing pump and dump detection methods for cryptocurrencies."
Burning Number for the Points in the Plane,"J. MarkKeil, DebajyotiMondal, EhsanMoradi",10 May 2022,Computational Geometry (cs.CG)," The burning process on a graph $G$ starts with a single burnt vertex, and at each subsequent step, burns the neighbors of the currently burnt vertices, as well as one other unburnt vertex. The burning number of $G$ is the smallest number of steps required to burn all the vertices of the graph. In this paper, we examine the problem of computing the burning number in a geometric setting. The input is a set of points $P$ in the Euclidean plane. The burning process starts with a single burnt point, and at each subsequent step, burns all the points that are within a distance of one unit from the currently burnt points and one other unburnt point. The burning number of $P$ is the smallest number of steps required to burn all the points of $P$. We call this variant \emph{point burning}. We consider another variant called \emph{anywhere burning}, where we are allowed to burn any point of the plane. We show that point burning and anywhere burning problems are both NP-complete, but $(2+\varepsilon)$ approximable for every $\varepsilon0$. Moreover, if we put a restriction on the number of burning sources that can be used, then the anywhere burning problem becomes NP-hard to approximate within a factor of $\frac{2}{\sqrt{3}}-\varepsilon$."
On Causality in Domain Adaptation and Semi-Supervised Learning: anInformation-Theoretic Analysis,"XuetongWu, MingmingGong, Jonathan H.Manton, UweAickelin, Jingge Zhu",10 May 2022,Machine Learning (cs.LG)," The establishment of the link between causality and unsupervised domain adaptation (UDA)/semi-supervised learning (SSL) has led to methodological advances in these learning problems in recent years. However, a formal theory that explains the role of causality in the generalization performance of UDA/SSL is still lacking. In this paper, we consider the UDA/SSL setting where we access m labeled source data and n unlabeled target data as training instances under a parametric probabilistic model. We study the learning performance (e.g., excess risk) of prediction in the target domain. Specifically, we distinguish two scenarios: the learning problem is called causal learning if the feature is the cause and the label is the effect, and is called anti-causal learning otherwise. We show that in causal learning, the excess risk depends on the size of the source sample at a rate of O(1/m) only if the labelling distribution between the source and target domains remains unchanged. In anti-causal learning, we show that the unlabeled data dominate the performance at a rate of typically O(1/n). Our analysis is based on the notion of potential outcome random variables and information theory. These results bring out the relationship between the data sample size and the hardness of the learning problem with different causal mechanisms."
STDC-MA Network for Semantic Segmentation,"XiaochunLei, LinjunLu, ZetaoJiang, ZhaotingGong, ChangLu, JiamingLiang","10 May 2022 (v1(https://arxiv.org/abs/2205.04639v1)), lastrevised 11 May 2022 (this version, v2)",Computer Vision and Pattern Recognition (cs.CV)," Semantic segmentation is applied extensively in autonomous driving and intelligent transportation with methods that highly demand spatial and semantic information. Here, an STDC-MA network is proposed to meet these demands. First, the STDC-Seg structure is employed in STDC-MA to ensure a lightweight and efficient structure. Subsequently, the feature alignment module (FAM) is applied to understand the offset between high-level and low- level features, solving the problem of pixel offset related to upsampling on the high-level feature map. Our approach implements the effective fusion between high-level features and low-level features. A hierarchical multiscale attention mechanism is adopted to reveal the relationship among attention regions from two different input sizes of one image. Through this relationship, regions receiving much attention are integrated into the segmentation results, thereby reducing the unfocused regions of the input image and improving the effective utilization of multiscale features. STDC- MA maintains the segmentation speed as an STDC-Seg network while improving the segmentation accuracy of small objects. STDC-MA was verified on the verification set of Cityscapes. The segmentation result of STDC-MA attained 76.81% mIOU with the input of 0.5x scale, 3.61% higher than STDC-Seg."
Using Frequency Attention to Make Adversarial Patch Powerful AgainstPerson Detector,"XiaochunLei, ChangLu, ZetaoJiang, ZhaotingGong, XiangCai, LinjunLu","10 May 2022 (v1(https://arxiv.org/abs/2205.04638v1)), lastrevised 11 May 2022 (this version, v2)",Computer Vision and Pattern Recognition (cs.CV)," Deep neural networks (DNNs) are vulnerable to adversarial attacks. In particular, object detectors may be attacked by applying a particular adversarial patch to the image. However, because the patch shrinks during preprocessing, most existing approaches that employ adversarial patches to attack object detectors would diminish the attack success rate on small and medium targets. This paper proposes a Frequency Module(FRAN), a frequency- domain attention module for guiding patch generation. This is the first study to introduce frequency domain attention to optimize the attack capabilities of adversarial patches. Our method increases the attack success rates of small and medium targets by 4.18% and 3.89%, respectively, over the state-of-the-art attack method for fooling the human detector while assaulting YOLOv3 without reducing the attack success rate of big targets."
Edge Connectivity Augmentation in Near-Linear Time,"RuoxuCen, JasonLi, DebmalyaPanigrahi",10 May 2022,Data Structures and Algorithms (cs.DS), We give an $\tilde{O}(m)$-time algorithm for the edge connectivity augmentation problem and the closely related edge splitting-off problem. This is optimal up to lower order terms and closes the long line of work on these problems.
On some studies of Fraud Detection Pipeline and related issues fromthe scope of Ensemble Learning and Graph-based Learning,TuanTran,10 May 2022,Machine Learning (cs.LG)," The UK anti-fraud charity Fraud Advisory Panel (FAP) in their review of 2016 estimates business costs of fraud at 144 billion, and its individual counterpart at 9.7 billion. Banking, insurance, manufacturing, and government are the most common industries affected by fraud activities. Designing an efficient fraud detection system could avoid losing the money; however, building this system is challenging due to many difficult problems, e.g.imbalanced data, computing costs, etc. Over the last three decades, there are various research relates to fraud detection but no agreement on what is the best approach to build the fraud detection system. In this thesis, we aim to answer some questions such as i) how to build a simplified and effective Fraud Detection System that not only easy to implement but also providing reliable results and our proposed Fraud Detection Pipeline is a potential backbone of the system and is easy to be extended or upgraded, ii) when to update models in our system (and keep the accuracy stable) in order to reduce the cost of updating process, iii) how to deal with an extreme imbalance in big data classification problem, e.g. fraud detection, since this is the gap between two difficult problems, iv) further, how to apply graph-based semi-supervised learning to detect fraudulent transactions."
KEMP: Keyframe-Based Hierarchical End-to-End Deep Model for Long-TermTrajectory Prediction,"QiujingLu, WeiqiaoHan, JeffreyLing, MinfaWang, HaoyuChen, BalakrishnanVaradarajan, PaulCovington",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Predicting future trajectories of road agents is a critical task for autonomous driving. Recent goal-based trajectory prediction methods, such as DenseTNT and PECNet, have shown good performance on prediction tasks on public datasets. However, they usually require complicated goal-selection algorithms and optimization. In this work, we propose KEMP, a hierarchical end-to-end deep learning framework for trajectory prediction. At the core of our framework is keyframe-based trajectory prediction, where keyframes are representative states that trace out the general direction of the trajectory. KEMP first predicts keyframes conditioned on the road context, and then fills in intermediate states conditioned on the keyframes and the road context. Under our general framework, goal-conditioned methods are special cases in which the number of keyframes equal to one. Unlike goal- conditioned methods, our keyframe predictor is learned automatically and does not require hand-crafted goal-selection algorithms. We evaluate our model on public benchmarks and our model ranked 1st on Waymo Open Motion Dataset Leaderboard (as of September 1, 2021)."
An Edge-Cloud Integrated Framework for Flexible and Dynamic StreamAnalytics,"XinWang, AzimKhan, JianwuWang, AryyaGangopadhyay, Carl E.Busart, JadeFreeman","10 May 2022 (v1(https://arxiv.org/abs/2205.04622v1)), lastrevised 11 May 2022 (this version, v2)","Distributed, Parallel, and Cluster Computing (cs.DC)"," With the popularity of Internet of Things (IoT), edge computing and cloud computing, more and more stream analytics applications are being developed including real-time trend prediction and object detection on top of IoT sensing data. One popular type of stream analytics is the recurrent neural network (RNN) deep learning model based time series or sequence data prediction and forecasting. Different from traditional analytics that assumes data to be processed are available ahead of time and will not change, stream analytics deals with data that are being generated continuously and data trend/distribution could change (aka concept drift), which will cause prediction/forecasting accuracy to drop over time. One other challenge is to find the best resource provisioning for stream analytics to achieve good overall latency. In this paper, we study how to best leverage edge and cloud resources to achieve better accuracy and latency for RNN-based stream analytics. We propose a novel edge-cloud integrated framework for hybrid stream analytics that support low latency inference on the edge and high capacity training on the cloud. We study the flexible deployment of our hybrid learning framework, namely edge-centric, cloud-centric and edge-cloud integrated. Further, our hybrid learning framework can dynamically combine inference results from an RNN model pre- trained based on historical data and another RNN model re-trained periodically based on the most recent data. Using real-world and simulated stream datasets, our experiments show the proposed edge-cloud deployment is the best among all three deployment types in terms of latency. For accuracy, the experiments show our dynamic learning approach performs the best among all learning approaches for all three concept drift scenarios."
Entropic CLT for Order Statistics,"MartinaCardone, Alex Dytso, Cynthia Rush",10 May 2022,Information Theory (cs.IT)," It is well known that central order statistics exhibit a central limit behavior and converge to a Gaussian distribution as the sample size grows. This paper strengthens this known result by establishing an entropic version of the CLT that ensures a stronger mode of convergence using the relative entropy. In particular, an order $O(1/\sqrt{n})$ rate of convergence is established under mild conditions on the parent distribution of the sample generating the order statistics. To prove this result, ancillary results on order statistics are derived, which might be of independent interest."
Risk Aversion In Learning Algorithms and an Application ToRecommendation Systems,"AndreasHaupt, AroonNarayanan",10 May 2022,Machine Learning (cs.LG)," Consider a bandit learning environment. We demonstrate that popular learning algorithms such as Upper Confidence Band (UCB) and $\varepsilon$-Greedy exhibit risk aversion: when presented with two arms of the same expectation, but different variance, the algorithms tend to not choose the riskier, i.e. higher variance, arm. We prove that $\varepsilon$-Greedy chooses the risky arm with probability tending to $0$ when faced with a deterministic and a Rademacher-distributed arm. We show experimentally that UCB also shows risk-averse behavior, and that risk aversion is present persistently in early rounds of learning even if the riskier arm has a slightly higher expectation. We calibrate our model to a recommendation system and show that algorithmic risk aversion can decrease consumer surplus and increase homogeneity. We discuss several extensions to other bandit algorithms, reinforcement learning, and investigate the impacts of algorithmic risk aversion for decision theory."
CoDo: Contrastive Learning with Downstream Background Invariance forDetection,"BingZhao, JunLi, HongZhu",10 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The prior self-supervised learning researches mainly select image- level instance discrimination as pretext task. It achieves a fantastic classification performance that is comparable to supervised learning methods. However, with degraded transfer performance on downstream tasks such as object detection. To bridge the performance gap, we propose a novel object-level self-supervised learning method, called Contrastive learning with Downstream background invariance (CoDo). The pretext task is converted to focus on instance location modeling for various backgrounds, especially for downstream datasets. The ability of background invariance is considered vital for object detection. Firstly, a data augmentation strategy is proposed to paste the instances onto background images, and then jitter the bounding box to involve background information. Secondly, we implement architecture alignment between our pretraining network and the mainstream detection pipelines. Thirdly, hierarchical and multi views contrastive learning is designed to improve performance of visual representation learning. Experiments on MSCOCO demonstrate that the proposed CoDo with common backbones, ResNet50-FPN, yields strong transfer learning results for object detection."
Nightly Automobile Claims Prediction from Telematics-Derived Features:A Multilevel Approach,"Allen R.Williams, Yoolim Jin, Anthony Duer, TukaAlhanai, MohammadGhassemi",10 May 2022,Machine Learning (cs.LG)," In recent years it has become possible to collect GPS data from drivers and to incorporate this data into automobile insurance pricing for the driver. This data is continuously collected and processed nightly into metadata consisting of mileage and time summaries of each discrete trip taken, and a set of behavioral scores describing attributes of the trip (e.g, driver fatigue or driver distraction) so we examine whether it can be used to identify periods of increased risk by successfully classifying trips that occur immediately before a trip in which there was an incident leading to a claim for that driver. Identification of periods of increased risk for a driver is valuable because it creates an opportunity for intervention and, potentially, avoidance of a claim. We examine metadata for each trip a driver takes and train a classifier to predict whether \textit{the following trip} is one in which a claim occurs for that driver. By achieving a area under the receiver-operator characteristic above 0.6, we show that it is possible to predict claims in advance. Additionally, we compare the predictive power, as measured by the area under the receiver-operator characteristic of XGBoost classifiers trained to predict whether a driver will have a claim using exposure features such as driven miles, and those trained using behavioral features such as a computed speed score."
Calibrating for Class Weights by Modeling Machine Learning,"AndrewCaplin, DanielMartin, Philip Marx",10 May 2022,Machine Learning (cs.LG)," A much studied issue is the extent to which the confidence scores provided by machine learning algorithms are calibrated to ground truth probabilities. Our starting point is that calibration is seemingly incompatible with class weighting, a technique often employed when one class is less common (class imbalance) or with the hope of achieving some external objective (cost-sensitive learning). We provide a model-based explanation for this incompatibility and use our anthropomorphic model to generate a simple method of recovering likelihoods from an algorithm that is miscalibrated due to class weighting. We validate this approach in the binary pneumonia detection task of Rajpurkar, Irvin, Zhu, et al. (2017)."
Reconfigurable Robots for Scaling Reef Restoration,"SerenaMou, DorianTsai, MatthewDunbabin",10 May 2022,Robotics (cs.RO)," Coral reefs are under increasing threat from the impacts of climate change. Whilst current restoration approaches are effective, they require significant human involvement and equipment, and have limited deployment scale. Harvesting wild coral spawn from mass spawning events, rearing them to the larval stage and releasing the larvae onto degraded reefs is an emerging solution for reef restoration known as coral reseeding. This paper presents a reconfigurable autonomous surface vehicle system that can eliminate risky diving, cover greater areas with coral larvae, has a sensory suite for additional data measurement, and requires minimal non- technical expert training. A key feature is an on-board real-time benthic substrate classification model that predicts when to release larvae to increase settlement rate and ultimately, survivability. The presented robot design is reconfigurable, light weight, scalable, and easy to transport. Results from restoration deployments at Lizard Island demonstrate improved coral larvae release onto appropriate coral substrate, while also achieving 21.8 times more area coverage compared to manual methods."
Optimizing a DIscrete Loss (ODIL) to solve forward and inverseproblems for partial differential equations using machine learning tools,"PetrKarnakov, SergeyLitvinov, PetrosKoumoutsakos",10 May 2022,Numerical Analysis (math.NA)," We introduce the Optimizing a Discrete Loss (ODIL) framework for the numerical solution of Partial Differential Equations (PDE) using machine learning tools. The framework formulates numerical methods as a minimization of discrete residuals that are solved using gradient descent and Newton's methods. We demonstrate the value of this approach on equations that may have missing parameters or where no sufficient data is available to form a well-posed initial-value problem. The framework is presented for mesh based discretizations of PDEs and inherits their accuracy, convergence, and conservation properties. It preserves the sparsity of the solutions and is readily applicable to inverse and ill-posed problems. It is applied to PDE- constrained optimization, optical flow, system identification, and data assimilation using gradient descent algorithms including those often deployed in machine learning. We compare ODIL with related approach that represents the solution with neural networks. We compare the two methodologies and demonstrate advantages of ODIL that include significantly higher convergence rates and several orders of magnitude lower computational cost. We evaluate the method on various linear and nonlinear partial differential equations including the Navier-Stokes equations for flow reconstruction problems."
"Towards Intersectionality in Machine Learning: Including MoreIdentities, Handling Underrepresentation, and Performing Evaluation","AngelinaWang, VikramV.Ramaswamy, OlgaRussakovsky",10 May 2022,Machine Learning (cs.LG)," Research in machine learning fairness has historically considered a single binary demographic attribute; however, the reality is of course far more complicated. In this work, we grapple with questions that arise along three stages of the machine learning pipeline when incorporating intersectionality as multiple demographic attributes: (1) which demographic attributes to include as dataset labels, (2) how to handle the progressively smaller size of subgroups during model training, and (3) how to move beyond existing evaluation metrics when benchmarking model fairness for more subgroups. For each question, we provide thorough empirical evaluation on tabular datasets derived from the US Census, and present constructive recommendations for the machine learning community. First, we advocate for supplementing domain knowledge with empirical validation when choosing which demographic attribute labels to train on, while always evaluating on the full set of demographic attributes. Second, we warn against using data imbalance techniques without considering their normative implications and suggest an alternative using the structure in the data. Third, we introduce new evaluation metrics which are more appropriate for the intersectional setting. Overall, we provide substantive suggestions on three necessary (albeit not sufficient!) considerations when incorporating intersectionality into machine learning."
Sentence-level Privacy for Document Embeddings,"CaseyMeehan, KhalilMrini, KamalikaChaudhuri",10 May 2022,Machine Learning (cs.LG)," User language data can contain highly sensitive personal content. As such, it is imperative to offer users a strong and interpretable privacy guarantee when learning from their data. In this work, we propose SentDP: pure local differential privacy at the sentence level for a single user document. We propose a novel technique, DeepCandidate, that combines concepts from robust statistics and language modeling to produce high- dimensional, general-purpose $\epsilon$-SentDP document embeddings. This guarantees that any single sentence in a document can be substituted with any other sentence while keeping the embedding $\epsilon$-indistinguishable. Our experiments indicate that these private document embeddings are useful for downstream tasks like sentiment analysis and topic classification and even outperform baseline methods with weaker guarantees like word-level Metric DP."
A Unified Model for Reverse Dictionary and Definition Modelling,"PinzhenChen, ZhengZhao",9 May 2022,Computation and Language (cs.CL)," We train a dual-way neural dictionary to guess words from definitions (reverse dictionary), and produce definitions given words (definition modelling). Our method learns the two tasks simultaneously, and handles unknown words via embeddings. It casts a word or a definition to the same representation space through a shared layer, then generates the other form from there, in a multi-task fashion. The model achieves promising automatic scores without extra resources. Human annotators prefer the proposed model's outputs in both reference-less and reference-based evaluation, which indicates its practicality. Analysis suggests that multiple objectives benefit learning."
Long-term stability and generalization of observationally-constrainedstochastic data-driven models for geophysical turbulence,"AsheshChattopadhyay, JaideepPathak, EbrahimNabizadeh, WahidBhimji, PedramHassanzadeh",9 May 2022,Machine Learning (cs.LG)," Recent years have seen a surge in interest in building deep learning-based fully data-driven models for weather prediction. Such deep learning models if trained on observations can mitigate certain biases in current state-of-the-art weather models, some of which stem from inaccurate representation of subgrid-scale processes. However, these data-driven models, being over-parameterized, require a lot of training data which may not be available from reanalysis (observational data) products. Moreover, an accurate, noise-free, initial condition to start forecasting with a data- driven weather model is not available in realistic scenarios. Finally, deterministic data-driven forecasting models suffer from issues with long- term stability and unphysical climate drift, which makes these data-driven models unsuitable for computing climate statistics. Given these challenges, previous studies have tried to pre-train deep learning-based weather forecasting models on a large amount of imperfect long-term climate model simulations and then re-train them on available observational data. In this paper, we propose a convolutional variational autoencoder-based stochastic data-driven model that is pre-trained on an imperfect climate model simulation from a 2-layer quasi-geostrophic flow and re-trained, using transfer learning, on a small number of noisy observations from a perfect simulation. This re-trained model then performs stochastic forecasting with a noisy initial condition sampled from the perfect simulation. We show that our ensemble-based stochastic data-driven model outperforms a baseline deterministic encoder-decoder-based convolutional model in terms of short- term skills while remaining stable for long-term climate simulations yielding accurate climatology."
Parsing Expression GLL,AaronMoss,9 May 2022,Formal Languages and Automata Theory (cs.FL)," This paper presents an extension of the GLL parsing algorithm for context-free grammars which also supports parsing expression grammars with ordered choice and lookahead. The new PEGLL algorithm retains support for unordered choice, and thus parses a common superset of context-free grammars and parsing expression grammars. As part of this work, the authors have modified an existing GLL parser-generator to support parsing expression grammars, adding operators for common parsing expressions and modifying the lexer algorithm to better support ordered choice."
Affective Medical Estimation and Decision Making via VisualizedLearning and Deep Learning,"MohammadEslami, SolaleTabarestani, Ehsan Adeli, Glyn Elwyn, Tobias Elze, Mengyu Wang, NazleeZebardast, NassirNavab, MalekAdjouadi",9 May 2022,Machine Learning (cs.LG)," With the advent of sophisticated machine learning (ML) techniques and the promising results they yield, especially in medical applications, where they have been investigated for different tasks to enhance the decision-making process. Since visualization is such an effective tool for human comprehension, memorization, and judgment, we have presented a first- of-its-kind estimation approach we refer to as Visualized Learning for Machine Learning (VL4ML) that not only can serve to assist physicians and clinicians in making reasoned medical decisions, but it also allows to appreciate the uncertainty visualization, which could raise incertitude in making the appropriate classification or prediction. For the proof of concept, and to demonstrate the generalized nature of this visualized estimation approach, five different case studies are examined for different types of tasks including classification, regression, and longitudinal prediction. A survey analysis with more than 100 individuals is also conducted to assess users' feedback on this visualized estimation method. The experiments and the survey demonstrate the practical merits of the VL4ML that include: (1) appreciating visually clinical/medical estimations; (2) getting closer to the patients' preferences; (3) improving doctor-patient communication, and (4) visualizing the uncertainty introduced through the black box effect of the deployed ML algorithm. All the source codes are shared via a GitHub repository."
When does dough become a bagel? Analyzing the remaining mistakes onImageNet,"VijayVasudevan, BenjaminCaine, Raphael Gontijo-Lopes, Sara Fridovich-Keil, RebeccaRoelofs",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Image classification accuracy on the ImageNet dataset has been a barometer for progress in computer vision over the last decade. Several recent papers have questioned the degree to which the benchmark remains useful to the community, yet innovations continue to contribute gains to performance, with today's largest models achieving 90%+ top-1 accuracy. To help contextualize progress on ImageNet and provide a more meaningful evaluation for today's state-of-the-art models, we manually review and categorize every remaining mistake that a few top models make in order to provide insight into the long-tail of errors on one of the most benchmarked datasets in computer vision. We focus on the multi-label subset evaluation of ImageNet, where today's best models achieve upwards of 97% top-1 accuracy. Our analysis reveals that nearly half of the supposed mistakes are not mistakes at all, and we uncover new valid multi-labels, demonstrating that, without careful review, we are significantly underestimating the performance of these models. On the other hand, we also find that today's best models still make a significant number of mistakes (40%) that are obviously wrong to human reviewers. To calibrate future progress on ImageNet, we provide an updated multi-label evaluation set, and we curate ImageNet-Major: a 68-example ""major error"" slice of the obvious mistakes made by today's top models -- a slice where models should achieve near perfection, but today are far from doing so."
A General Formula for Uniform Common Randomness Capacity,"RamiEzzine, MoritzWiese, ChristianDeppe, Holger Boche",9 May 2022,Information Theory (cs.IT)," We generalize the uniform common randomness capacity formula, initially established by Ahslwede and Csiszár for a two-source model with unidirectional communication over rate-limited discrete noiseless channels to arbitrary single-user channels. In our proof, we will make use of the transmission capacity formula established by Verdú and Han for arbitrary point-to-point channels."
Galois theory for analogical classifiers,"MiguelCouceiro, ErkkoLehtonen",9 May 2022,Artificial Intelligence (cs.AI)," Analogical proportions are 4-ary relations that read ""A is to B as C is to D"". Recent works have highlighted the fact that such relations can support a specific form of inference, called analogical inference. This inference mechanism was empirically proved to be efficient in several reasoning and classification tasks. In the latter case, it relies on the notion of analogy preservation.   In this paper, we explore this relation between formal models of analogy and the corresponding classes of analogy preserving functions, and we establish a Galois theory of analogical classifiers. We illustrate the usefulness of this Galois framework over Boolean domains, and we explicitly determine the closed sets of analogical classifiers, i.e., classifiers that are compatible with the analogical inference, for each pair of Boolean analogies."
A Verification Framework for Certifying Learning-Based Safety-CriticalAviation Systems,"AliBaheri, Hao Ren, BenjaminJohnson, PouriaRazzaghi, Peng Wei",9 May 2022,Systems and Control (eess.SY)," We present a safety verification framework for design-time and run-time assurance of learning-based components in aviation systems. Our proposed framework integrates two novel methodologies. From the design-time assurance perspective, we propose offline mixed-fidelity verification tools that incorporate knowledge from different levels of granularity in simulated environments. From the run-time assurance perspective, we propose reachability- and statistics-based online monitoring and safety guards for a learning-based decision-making model to complement the offline verification methods. This framework is designed to be loosely coupled among modules, allowing the individual modules to be developed using independent methodologies and techniques, under varying circumstances and with different tool access. The proposed framework offers feasible solutions for meeting system safety requirements at different stages throughout the system development and deployment cycle, enabling the continuous learning and assessment of the system product."
Underactuated Source Seeking by Surge Force Tuning: Theory and BoatExperiments,"BoWang, SergeyNersesov, HashemAshrafiuon, PeimanNaseradinmousavi, MiroslavKrstić",9 May 2022,Systems and Control (eess.SY)," We extend source seeking algorithms, in the absence of position and velocity measurements, and with tuning of the surge input, from velocity-actuated (unicycle) kinematic models to force-actuated generic Euler-Lagrange dynamic underactuated models. In the design and analysis, we employ a symmetric product approximation, averaging, passivity, and partial- state stability theory. The proposed control law requires only real-time measurement of the source signal at the current position of the vehicle and ensures semi-global practical uniform asymptotic stability (SPUAS) with respect to the linear motion coordinates for the closed-loop system. The performance of our source seeker with surge force tuning is illustrated with both numerical simulations and experiments of an underactuated boat."
Towards Optimal VPU Compiler Cost Modeling by using Neural Networks toInfer Hardware Performances,"Ian Frederick Vigogne GoodbodyHunter, AlessandroPalla, Sebastian EusebiuNagy, RichardRichmond, Kyle McAdoo",9 May 2022,Machine Learning (cs.LG)," Calculating the most efficient schedule of work in a neural network compiler is a difficult task. There are many parameters to be accounted for that can positively or adversely affect that schedule depending on their configuration - How work is shared between distributed targets, the subdivision of tensors to fit in memory, toggling the enablement of optimizations, etc. Traditionally, neural network compilers determine how to set these values by building a graph of choices and choosing the path with minimal 'cost'. These choices and their corresponding costs are usually determined by an algorithm crafted by engineers with a deep knowledge of the target platform. However, when the amount of options available to a compiler is large, it is very difficult to ensure that these models consistently produce an optimal schedule for all scenarios, whilst still completing compilation in an acceptable timeframe. This paper presents 'VPUNN' - a neural network-based cost model trained on low-level task profiling that consistently outperforms the state-of-the-art cost modeling in Intel's line of VPU processors."
Composite IG/FTR Channel Performance in Wireless Communication Systems,"MaryamOlyaee, Juan M. Romero-Jerez, F. Javier López-Martínez, Andrea J.Goldsmith",9 May 2022,Information Theory (cs.IT)," We present a composite wireless fading model encompassing multipath fading and shadowing based on fluctuating two-ray (FTR) fading and inverse gamma (IG) shadowing. We first determine an alternative framework for the statistical characterization and performance evaluation of the FTR fading model, which is based on the fact that the FTR fading distribution can be described as an underlying Rician Shadowed (RS) distribution with continuously varying parameter Kr (ratio of specular to diffuse components). We demonstrate that this new formulation permits to obtain a closed-form expression of the generalized moment generating function (GMGF) of the FTR model, from which the PDF and CDF of the composite IG/FTR model can be obtained in closed-form. The exact and asymptotic outage probability of the IG/FTR model are analyzed and verified by Monte Carlo simulations."
JCSP: Joint Caching and Service Placement for Edge Computing Systems,"YichengGao, GiulianoCasale",9 May 2022,Performance (cs.PF)," With constrained resources, what, where, and how to cache at the edge is one of the key challenges for edge computing systems. The cached items include not only the application data contents but also the local caching of edge services that handle incoming requests. However, current systems separate the contents and services without considering the latency interplay of caching and queueing. Therefore, in this paper, we propose a novel class of stochastic models that enable the optimization of content caching and service placement decisions jointly. We first explain how to apply layered queueing networks (LQNs) models for edge service placement and show that combining this with genetic algorithms provides higher accuracy in resource allocation than an established baseline. Next, we extend LQNs with caching components to establish a joint modeling method for content caching and service placement (JCSP) and present analytical methods to analyze the resulting model. Finally, we simulate real-world Azure traces to evaluate the JCSP method and find that JCSP achieves up to 35% improvement in response time and 500MB reduction in memory usage than baseline heuristics for edge caching resource allocation."
The Compound Information Bottleneck Outlook,"MichaelDikshtein, NirWeinberger, ShlomoShamai",9 May 2022,Information Theory (cs.IT)," We formulate and analyze the compound information bottleneck programming. In this problem, a Markov chain $ \mathsf{X} \rightarrow \mathsf{Y} \rightarrow \mathsf{Z} $ is assumed with fixed marginal distributions $\mathsf{P}_{\mathsf{X}}$ and $\mathsf{P}_{\mathsf{Y}}$, and the mutual information between $ \mathsf{X} $ and $ \mathsf{Z} $ is sought to be maximized over the choice of conditional probability of $\mathsf{Z}$ given $\mathsf{Y}$ from a given class, under the \textit{worst choice} of the joint probability of the pair $(\mathsf{X},\mathsf{Y})$ from a different class. We consider several classes based on extremes of: mutual information; minimal correlation; total variation; and the relative entropy class. We provide values, bounds, and various characterizations for specific instances of this problem: the binary symmetric case, the scalar Gaussian case, the vector Gaussian case and the symmetric modulo-additive case. Finally, for the general case, we propose a Blahut-Arimoto type of alternating iterations algorithm to find a consistent solution to this problem."
Is my Depth Ground-Truth Good Enough? HAMMER -- Highly Accurate Multi-Modal Dataset for DEnse 3D Scene Regression,"HyunJunJung, PatrickRuhkamp, GuangyaoZhai, NikolasBrasch, Yitong Li, YannickVerdie, Jifei Song, Yiren Zhou, AnilArmagan, SlobodanIlic, AlesLeonardis, BenjaminBusam",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Depth estimation is a core task in 3D computer vision. Recent methods investigate the task of monocular depth trained with various depth sensor modalities. Every sensor has its advantages and drawbacks caused by the nature of estimates. In the literature, mostly mean average error of the depth is investigated and sensor capabilities are typically not discussed. Especially indoor environments, however, pose challenges for some devices. Textureless regions pose challenges for structure from motion, reflective materials are problematic for active sensing, and distances for translucent material are intricate to measure with existing sensors. This paper proposes HAMMER, a dataset comprising depth estimates from multiple commonly used sensors for indoor depth estimation, namely ToF, stereo, structured light together with monocular RGB+P data. We construct highly reliable ground truth depth maps with the help of 3D scanners and aligned renderings. A popular depth estimators is trained on this data and typical depth senosors. The estimates are extensively analyze on different scene structures. We notice generalization issues arising from various sensor technologies in household environments with challenging but everyday scene content. HAMMER, which we make publicly available, provides a reliable base to pave the way to targeted depth improvements and sensor fusion approaches."
"Scim: Intelligent Faceted Highlights for Interactive, Multi-PassSkimming of Scientific Papers","RaymondFok, AndrewHead, JonathanBragg, KyleLo, Marti A.Hearst, Daniel S.Weld",9 May 2022,Human-Computer Interaction (cs.HC)," Researchers are expected to keep up with an immense literature, yet often find it prohibitively time-consuming to do so. This paper explores how intelligent agents can help scaffold in-situ information seeking across scientific papers. Specifically, we present Scim, an AI-augmented reading interface designed to help researchers skim papers by automatically identifying, classifying, and highlighting salient sentences, organized into rhetorical facets rooted in common information needs. Using Scim as a design probe, we explore the benefits and drawbacks of imperfect AI assistance within an augmented reading interface. We found researchers used Scim in several different ways: from reading primarily in the `highlight browser' (side panel) to making multiple passes through the paper with different facets activated (e.g., focusing solely on objective and novelty in their first pass). From our study, we identify six key design recommendations and avenues for future research in augmented reading interfaces."
A Song of (Dis)agreement: Evaluating the Evaluation of ExplainableArtificial Intelligence in Natural Language Processing,"MichaelNeely, Stefan F.Schouten, MauritsBleeker, Ana Lucic",9 May 2022,Computation and Language (cs.CL)," There has been significant debate in the NLP community about whether or not attention weights can be used as an explanation - a mechanism for interpreting how important each input token is for a particular prediction. The validity of ""attention as explanation"" has so far been evaluated by computing the rank correlation between attention-based explanations and existing feature attribution explanations using LSTM-based models. In our work, we (i) compare the rank correlation between five more recent feature attribution methods and two attention-based methods, on two types of NLP tasks, and (ii) extend this analysis to also include transformer-based models. We find that attention-based explanations do not correlate strongly with any recent feature attribution methods, regardless of the model or task. Furthermore, we find that none of the tested explanations correlate strongly with one another for the transformer-based model, leading us to question the underlying assumption that we should measure the validity of attention-based explanations based on how well they correlate with existing feature attribution explanation methods. After conducting experiments on five datasets using two different models, we argue that the community should stop using rank correlation as an evaluation metric for attention-based explanations. We suggest that researchers and practitioners should instead test various explanation methods and employ a human-in-the-loop process to determine if the explanations align with human intuition for the particular use case at hand."
"Designing an Interactive, Notebook-Embedded, Tree Visualization toSupport Exploratory Performance Analysis","Connor Scully-Allison, IanLumsden, KatyWilliams, JesseBartels, MichelaTaufer, StephanieBrink, AbhinavBhatele, OlgaPearce, Katherine E.Isaacs",9 May 2022,Human-Computer Interaction (cs.HC)," Interactive visualization via direct manipulation has inherent design trade-offs in flexibility, discoverability, and ease-of-use. Scripting languages can support a vast range of user queries and tasks, but may be more cumbersome for free-form exploration. Embedding interactive visualization in a scripting environment, such as a computational notebook, provides an opportunity for leveraging the strengths of both direct manipulation and scripting. We conduct a design study investigating this opportunity in the context of calling context trees as used for performance analysis of parallel software. Our collaborators make new performance analysis functionality available to users via Jupyter notebook examples, making the project setting conducive to such an investigation. Through a series of semi-structured interviews and regular meetings with project stakeholders, we produce a formal task analysis grounded in the expectation that tasks may be supported by scripting, interactive visualization, or both paradigms. We then design an interactive bivariate calling context tree visualization for embedding in Jupyter notebooks with features to pass data and state between the scripting and visualization contexts. We evaluated our embedded design with seven high performance computing experts. The experts were able to complete tasks and provided further feedback on the visualization and the notebook-embedded interactive visualization paradigm. We reflect upon the project and discuss factors in both the process and the design of the embedded visualization."
A hybridizable discontinuous Galerkin method for the fully coupledtime-dependent Stokes/Darcy-transport problem,"AycilCesmelioglu, Dinh DongPham, SanderRhebergen",9 May 2022,Numerical Analysis (math.NA)," We present a high-order hybridized discontinuous Galerkin (HDG) method for the fully coupled time-dependent Stokes-Darcy-transport problem where the fluid viscosity and source/sink terms depend on the concentration and the dispersion/diffusion tensor depends on the fluid velocity. This HDG method is such that the discrete flow equations are compatible with the discrete transport equation. Furthermore, the HDG method guarantees strong mass conservation in the $H^{\rm div}$ sense and naturally treats the interface conditions between the Stokes and Darcy regions via facet variables. We employ a linearizing decoupling strategy where the Stokes/Darcy and the transport equations are solved sequentially by time- lagging the concentration. We prove well-posedness and optimal a priori error estimates for the velocity and the concentration in the energy norm. We present numerical examples that respect compatibility of the flow and transport discretizations and demonstrate that the discrete solution is robust with respect to the problem parameters."
Casting the inverse problem as a database query. The case ofpersonalized tumor growth modeling,"IvanEzhov, MarcelRosier, LucasZimmer, FlorianKofler, SuprosannaShit, JohannesPaetzold, KevinScibilia, LeonMaechler, KatharinaFranitza, TamazAmiranashvili, Marie Metz, SaileshConjeti, BenediktWiestler, Bjoern Menze","9 May 2022 (v1(https://arxiv.org/abs/2205.04550v1)), lastrevised 11 May 2022 (this version, v2)","Computational Engineering, Finance, and Science (cs.CE)"," Solving the inverse problem is the key step in evaluating the capacity of a physical model to describe real phenomena. In medical image computing, it aligns with the classical theme of image-based model personalization. Traditionally, a solution to the problem is obtained by performing either sampling or variational inference based methods. Both approaches aim to identify a set of free physical model parameters that results in a simulation best matching an empirical observation. When applied to brain tumor modeling, one of the instances of image-based model personalization in medical image computing, the overarching drawback of the methods is the time complexity for finding such a set. In a clinical setting with limited time between imaging and diagnosis or even intervention, this time complexity may prove critical. As the history of quantitative science is the history of compression, we align in this paper with the historical tendency and propose a method compressing complex traditional strategies for solving an inverse problem into a simple database query task. We evaluated different ways of performing the database query task assessing the trade-off between accuracy and execution time. On the exemplary task of brain tumor growth modeling, we prove that the proposed method achieves one order speed- up compared to existing approaches for solving the inverse problem. The resulting compute time offers critical means for relying on more complex and, hence, realistic models, for integrating image preprocessing and inverse modeling even deeper, or for implementing the current model into a clinical workflow."
Informed Steiner Trees: Sampling and Pruning for Multi-Goal PathFinding in High Dimensions,"NikhilChandak, Kenny Chour, SivakumarRathinam, R. Ravi",9 May 2022,Multiagent Systems (cs.MA)," We interleave sampling based motion planning methods with pruning ideas from minimum spanning tree algorithms to develop a new approach for solving a Multi-Goal Path Finding (MGPF) problem in high dimensional spaces. The approach alternates between sampling points from selected regions in the search space and de-emphasizing regions that may not lead to good solutions for MGPF. Our approach provides an asymptotic, 2-approximation guarantee for MGPF. We also present extensive numerical results to illustrate the advantages of our proposed approach over uniform sampling in terms of the quality of the solutions found and computation speed."
CODEC: Complex Document and Entity Collection,"IainMackie, PaulOwoicho, CarlosGemmell, SophieFischer, SeanMacAvaney, JeffreyDalton",9 May 2022,Information Retrieval (cs.IR)," CODEC is a document and entity ranking benchmark that focuses on complex research topics. We target essay-style information needs of social science researchers, i.e. ""How has the UK's Open Banking Regulation benefited Challenger Banks?"". CODEC includes 42 topics developed by researchers and a new focused web corpus with semantic annotations including entity links. This resource includes expert judgments on 17,509 documents and entities (416.9 per topic) from diverse automatic and interactive manual runs. The manual runs include 387 query reformulations, providing data for query performance prediction and automatic rewriting evaluation.   CODEC includes analysis of state-of-the-art systems, including dense retrieval and neural re-ranking. The results show the topics are challenging with headroom for document and entity ranking improvement. Query expansion with entity information shows significant gains on document ranking, demonstrating the resource's value for evaluating and improving entity- oriented search. We also show that the manual query reformulations significantly improve the performance of document and entity ranking. Overall, CODEC provides challenging research topics to support the development and evaluation of entity-centric search methods."
A Probabilistic Generative Model of Free Categories,"EliSennesh, Tom Xu, YoshihiroMaruyama",9 May 2022,Artificial Intelligence (cs.AI)," Applied category theory has recently developed libraries for computing with morphisms in interesting categories, while machine learning has developed ways of learning programs in interesting languages. Taking the analogy between categories and languages seriously, this paper defines a probabilistic generative model of morphisms in free monoidal categories over domain-specific generating objects and morphisms. The paper shows how acyclic directed wiring diagrams can model specifications for morphisms, which the model can use to generate morphisms. Amortized variational inference in the generative model then enables learning of parameters (by maximum likelihood) and inference of latent variables (by Bayesian inversion). A concrete experiment shows that the free category prior achieves competitive reconstruction performance on the Omniglot dataset."
Characterizing the country-wide adoption and evolution of the Jodelmessaging app in Saudi Arabia,"Jens HelgeReelfs, OliverHohlfeld, MarkusStrohmaier, NiklasHenckell",9 May 2022,Social and Information Networks (cs.SI)," Social media is subject to constant growth and evolution, yet little is known about their early phases of adoption. To shed light on this aspect, this paper empirically characterizes the initial and country-wide adoption of a new type of social media in Saudi Arabia that happened in 2017. Unlike established social media, the studied network Jodel is anonymous and location-based to form hundreds of independent communities country-wide whose adoption pattern we compare. We take a detailed and full view from the operators perspective on the temporal and geographical dimension on the evolution of these different communities -- from their very first the first months of establishment to saturation. This way, we make the early adoption of a new type of social media visible, a process that is often invisible due to the lack of data covering the first days of a new network."
On Nested Justification Systems (full version),"SimonMarynissen, JesseHeyninck, BartBogaerts, MarcDenecker",9 May 2022,Artificial Intelligence (cs.AI)," Justification theory is a general framework for the definition of semantics of rule-based languages that has a high explanatory potential. Nested justification systems, first introduced by Denecker et al. (2015), allow for the composition of justification systems. This notion of nesting thus enables the modular definition of semantics of rule-based languages, and increases the representational capacities of justification theory. As we show in this paper, the original semantics for nested justification systems lead to the loss of information relevant for explanations. In view of this problem, we provide an alternative characterization of semantics of nested justification systems and show that this characterization is equivalent to the original semantics. Furthermore, we show how nested justification systems allow representing fixpoint definitions (Hou and Denecker 2009)."
A Realistic Cyclist Model for SUMO Based on the SimRa Dataset,"Ahmet-SerdarKarakaya, KonstantinKöhler, JulianHeinovski, FalkoDressler, DavidBermbach",5 May 2022,Multiagent Systems (cs.MA)," Increasing the modal share of bicycle traffic to reduce carbon emissions, reduce urban car traffic, and to improve the health of citizens, requires a shift away from car-centric city planning. For this, traffic planners often rely on simulation tools such as SUMO which allow them to study the effects of construction changes before implementing them. Similarly, studies of vulnerable road users, here cyclists, also use such models to assess the performance of communication-based road traffic safety systems. The cyclist model in SUMO, however, is very imprecise as SUMO cyclists behave either like slow cars or fast pedestrians, thus, casting doubt on simulation results for bicycle traffic. In this paper, we analyze acceleration, velocity, and intersection left-turn behavior of cyclists in a large dataset of real world cycle tracks. We use the results to derive an improved cyclist model and implement it in SUMO."
The Bedrock of BFT: A Unified Platform for BFT Protocol Design andImplementation,"Mohammad JavadAmiri, Chenyuan Wu, DivyakantAgrawal, Amr ElAbbadi, Boon ThauLoo, MohammadSadoghi",9 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Byzantine fault-tolerant protocols cover a broad spectrum of design dimensions from environmental setting on communication topology, to more technical features such as commitment strategy and even fundamental social choice related properties like order fairness. Designing and building BFT protocols remains a laborious task despite of years of intensive research. The proliferation of different BFT protocols has rendered it difficult to navigate BFT landscape, let alone determine the protocol that best meets application needs. This paper presents Bedrock, a unified platform for BFT protocols design and implementation. Bedrock exposes an API that presents a set of design choices capturing the trade-offs between different design space dimensions in BFT implementations. Based on user choices, Bedrock then generates the BFT protocols within the space of plausible choices, evolves current protocols to generate new ones, and even uncovers previously unknown protocols. Our experimental results validate the capability of Bedrock in deriving existing and new BFT protocols."
How Does Frequency Bias Affect the Robustness of Neural ImageClassifiers against Common Corruption and Adversarial Perturbations?,"AlvinChan, Yew-Soon Ong, Clement Tan",9 May 2022,Machine Learning (cs.LG)," Model robustness is vital for the reliable deployment of machine learning models in real-world applications. Recent studies have shown that data augmentation can result in model over-relying on features in the low- frequency domain, sacrificing performance against low-frequency corruptions, highlighting a connection between frequency and robustness. Here, we take one step further to more directly study the frequency bias of a model through the lens of its Jacobians and its implication to model robustness. To achieve this, we propose Jacobian frequency regularization for models' Jacobians to have a larger ratio of low-frequency components. Through experiments on four image datasets, we show that biasing classifiers towards low (high)-frequency components can bring performance gain against high (low)-frequency corruption and adversarial perturbation, albeit with a tradeoff in performance for low (high)-frequency corruption. Our approach elucidates a more direct connection between the frequency bias and robustness of deep learning models."
"Foveated Rendering: Motivation, Taxonomy, and Research Directions","SusmijaJabbireddy, Xuetong Sun, Xiaoxu Meng, AmitabhVarshney",9 May 2022,Graphics (cs.GR)," With the recent interest in virtual reality and augmented reality, there is a newfound demand for displays that can provide high resolution with a wide field of view (FOV). However, such displays incur significantly higher costs for rendering the larger number of pixels. This poses the challenge of rendering realistic real-time images that have a wide FOV and high resolution using limited computing resources. The human visual system does not need every pixel to be rendered at a uniformly high quality. Foveated rendering methods provide perceptually high-quality images while reducing computational workload and are becoming a crucial component for large-scale rendering. In this paper, we present key motivations, research directions, and challenges for leveraging the limitations of the human visual system as they relate to foveated rendering. We provide a taxonomy to compare and contrast various foveated techniques based on key factors. We also review aliasing artifacts arising due to foveation methods and discuss several approaches that attempt to mitigate such effects. Finally, we present several open problems and possible future research directions that can further reduce computational costs while generating perceptually high- quality renderings."
Selectively Contextual Bandits,"ClaudiaRoberts, MariaDimakopoulou, Qifeng Qiao, AshokChandrashekhar, Tony Jebara",9 May 2022,Machine Learning (cs.LG)," Contextual bandits are widely used in industrial personalization systems. These online learning frameworks learn a treatment assignment policy in the presence of treatment effects that vary with the observed contextual features of the users. While personalization creates a rich user experience that reflect individual interests, there are benefits of a shared experience across a community that enable participation in the zeitgeist. Such benefits are emergent through network effects and are not captured in regret metrics typically employed in evaluating bandits. To balance these needs, we propose a new online learning algorithm that preserves benefits of personalization while increasing the commonality in treatments across users. Our approach selectively interpolates between a contextual bandit algorithm and a context-free multi-arm bandit and leverages the contextual information for a treatment decision only if it promises significant gains. Apart from helping users of personalization systems balance their experience between the individualized and shared, simplifying the treatment assignment policy by making it selectively reliant on the context can help improve the rate of learning in some cases. We evaluate our approach in a classification setting using public datasets and show the benefits of the hybrid policy."
Towards a multi-stakeholder value-based assessment framework foralgorithmic systems,"MireiaYurrita, Dave Murray-Rust, AgatheBalayn, AlessandroBozzon",9 May 2022,Machine Learning (cs.LG)," In an effort to regulate Machine Learning-driven (ML) systems, current auditing processes mostly focus on detecting harmful algorithmic biases. While these strategies have proven to be impactful, some values outlined in documents dealing with ethics in ML-driven systems are still underrepresented in auditing processes. Such unaddressed values mainly deal with contextual factors that cannot be easily quantified. In this paper, we develop a value-based assessment framework that is not limited to bias auditing and that covers prominent ethical principles for algorithmic systems. Our framework presents a circular arrangement of values with two bipolar dimensions that make common motivations and potential tensions explicit. In order to operationalize these high-level principles, values are then broken down into specific criteria and their manifestations. However, some of these value-specific criteria are mutually exclusive and require negotiation. As opposed to some other auditing frameworks that merely rely on ML researchers' and practitioners' input, we argue that it is necessary to include stakeholders that present diverse standpoints to systematically negotiate and consolidate value and criteria tensions. To that end, we map stakeholders with different insight needs, and assign tailored means for communicating value manifestations to them. We, therefore, contribute to current ML auditing practices with an assessment framework that visualizes closeness and tensions between values and we give guidelines on how to operationalize them, while opening up the evaluation and deliberation process to a wide range of stakeholders."
Surreal-GAN:Semi-Supervised Representation Learning via GAN foruncovering heterogeneous disease-related imaging patterns,"ZhijianYang, JunhaoWen, ChristosDavatzikos",9 May 2022,Machine Learning (cs.LG)," A plethora of machine learning methods have been applied to imaging data, enabling the construction of clinically relevant imaging signatures of neurological and neuropsychiatric diseases. Oftentimes, such methods don't explicitly model the heterogeneity of disease effects, or approach it via nonlinear models that are not interpretable. Moreover, unsupervised methods may parse heterogeneity that is driven by nuisance confounding factors that affect brain structure or function, rather than heterogeneity relevant to a pathology of interest. On the other hand, semi- supervised clustering methods seek to derive a dichotomous subtype membership, ignoring the truth that disease heterogeneity spatially and temporally extends along a continuum. To address the aforementioned limitations, herein, we propose a novel method, termed Surreal-GAN (Semi- SUpeRvised ReprEsentAtion Learning via GAN). Using cross-sectional imaging data, Surreal-GAN dissects underlying disease-related heterogeneity under the principle of semi-supervised clustering (cluster mappings from normal control to patient), proposes a continuously dimensional representation, and infers the disease severity of patients at individual level along each dimension. The model first learns a transformation function from normal control (CN) domain to the patient (PT) domain with latent variables controlling transformation directions. An inverse mapping function together with regularization on function continuity, pattern orthogonality and monotonicity was also imposed to make sure that the transformation function captures necessarily meaningful imaging patterns with clinical significance. We first validated the model through extensive semi-synthetic experiments, and then demonstrate its potential in capturing biologically plausible imaging patterns in Alzheimer's disease (AD)."
Assessing Confidence with Assurance 2.0,"JohnRushby, RobinBloomfield",3 May 2022,Artificial Intelligence (cs.AI)," An assurance case is intended to provide justifiable confidence in the truth of its top claim, which typically concerns safety or security. A natural question is then ""how much"" confidence does the case provide? We argue that confidence cannot be reduced to a single attribute or measurement. Instead, we suggest it should be based on attributes that draw on three different perspectives: positive, negative, and residual doubts. Positive Perspectives consider the extent to which the evidence and overall argument of the case combine to make a positive statement justifying belief in its claims. We set a high bar for justification, requiring it to be indefeasible. The primary positive measure for this is soundness, which interprets the argument as a logical proof. Confidence in evidence can be expressed probabilistically and we use confirmation measures to ensure that the ""weight"" of evidence crosses some threshold. In addition, probabilities can be aggregated from evidence through the steps of the argument using probability logics to yield what we call probabilistic valuations for the claims. Negative Perspectives record doubts and challenges to the case, typically expressed as defeaters, and their exploration and resolution. Assurance developers must guard against confirmation bias and should vigorously explore potential defeaters as they develop the case, and should record them and their resolution to avoid rework and to aid reviewers. Residual Doubts: the world is uncertain so not all potential defeaters can be resolved. We explore risks and may deem them acceptable or unavoidable. It is crucial however that these judgments are conscious ones and that they are recorded in the assurance case. This report examines the perspectives in detail and indicates how Clarissa, our prototype toolset for Assurance 2.0, assists in their evaluation."
Implicit Particle Filtering via a Bank of Nonlinear Kalman Filters,"ImanAskari, Mulugeta A.Haile, Xuemin Tu, HuazhenFang",9 May 2022,Systems and Control (eess.SY), The implicit particle filter seeks to mitigate particle degeneracy by identifying particles in the target distribution's high-probability regions. This study is motivated by the need to enhance computational tractability in implementing this approach. We investigate the connection of the particle update step in the implicit particle filter with that of the Kalman filter and then formulate a novel realization of the implicit particle filter based on a bank of nonlinear Kalman filters. This realization is more amenable and efficient computationally.
Image2Gif: Generating Continuous Realistic Animations with WarpingNODEs,"JurijsNazarovs, ZhichunHuang",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Generating smooth animations from a limited number of sequential observations has a number of applications in vision. For example, it can be used to increase number of frames per second, or generating a new trajectory only based on first and last frames, e.g. a motion of face emotions. Despite the discrete observed data (frames), the problem of generating a new trajectory is a continues problem. In addition, to be perceptually realistic, the domain of an image should not alter drastically through the trajectory of changes. In this paper, we propose a new framework, Warping Neural ODE, for generating a smooth animation (video frame interpolation) in a continuous manner, given two (""farther apart"") frames, denoting the start and the end of the animation. The key feature of our framework is utilizing the continuous spatial transformation of the image based on the vector field, derived from a system of differential equations. This allows us to achieve the smoothness and the realism of an animation with infinitely small time steps between the frames. We show the application of our work in generating an animation given two frames, in different training settings, including Generative Adversarial Network (GAN) and with $L_2$ loss."
Unsupervised Slot Schema Induction for Task-oriented Dialog,"DianYu, MingqiuWang, YuanCao, IzhakShafran, Laurent ElShafey, HagenSoltau",9 May 2022,Computation and Language (cs.CL)," Carefully-designed schemas describing how to collect and annotate dialog corpora are a prerequisite towards building task-oriented dialog systems. In practical applications, manually designing schemas can be error- prone, laborious, iterative, and slow, especially when the schema is complicated. To alleviate this expensive and time consuming process, we propose an unsupervised approach for slot schema induction from unlabeled dialog corpora. Leveraging in-domain language models and unsupervised parsing structures, our data-driven approach extracts candidate slots without constraints, followed by coarse-to-fine clustering to induce slot types. We compare our method against several strong supervised baselines, and show significant performance improvement in slot schema induction on MultiWoz and SGD datasets. We also demonstrate the effectiveness of induced schemas on downstream applications including dialog state tracking and response generation."
PinnerFormer: Sequence Modeling for User Representation at Pinterest,"NikilPancha, Andrew Zhai, JureLeskovec, CharlesRosenberg",9 May 2022,Machine Learning (cs.LG)," Sequential models have become increasingly popular in powering personalized recommendation systems over the past several years. These approaches traditionally model a user's actions on a website as a sequence to predict the user's next action. While theoretically simplistic, these models are quite challenging to deploy in production, commonly requiring streaming infrastructure to reflect the latest user activity and potentially managing mutable data for encoding a user's hidden state. Here we introduce PinnerFormer, a user representation trained to predict a user's future long- term engagement using a sequential model of a user's recent actions. Unlike prior approaches, we adapt our modeling to a batch infrastructure via our new dense all-action loss, modeling long-term future actions instead of next action prediction. We show that by doing so, we significantly close the gap between batch user embeddings that are generated once a day and realtime user embeddings generated whenever a user takes an action. We describe our design decisions via extensive offline experimentation and ablations and validate the efficacy of our approach in A/B experiments showing substantial improvements in Pinterest's user retention and engagement when comparing PinnerFormer against our previous user representation. PinnerFormer is deployed in production as of Fall 2021."
Sampling-Based Nonlinear MPC of Neural Network Dynamics withApplication to Autonomous Vehicle Motion Planning,"ImanAskari, BabakBadnava, ThomasWoodruff, Shen Zeng, Huazhen Fang",9 May 2022,Robotics (cs.RO)," Control of machine learning models has emerged as an important paradigm for a broad range of robotics applications. In this paper, we present a sampling-based nonlinear model predictive control (NMPC) approach for control of neural network dynamics. We show its design in two parts: 1) formulating conventional optimization-based NMPC as a Bayesian state estimation problem, and 2) using particle filtering/smoothing to achieve the estimation. Through a principled sampling-based implementation, this approach can potentially make effective searches in the control action space for optimal control and also facilitate computation toward overcoming the challenges caused by neural network dynamics. We apply the proposed NMPC approach to motion planning for autonomous vehicles. The specific problem considers nonlinear unknown vehicle dynamics modeled as neural networks as well as dynamic on-road driving scenarios. The approach shows significant effectiveness in successful motion planning in case studies."
Behind the Mask: Demographic bias in name detection for PII masking,"CourtneyMansfield, AmandalynnePaullada, KristenHowell",9 May 2022,Computation and Language (cs.CL)," Many datasets contain personally identifiable information, or PII, which poses privacy risks to individuals. PII masking is commonly used to redact personal information such as names, addresses, and phone numbers from text data. Most modern PII masking pipelines involve machine learning algorithms. However, these systems may vary in performance, such that individuals from particular demographic groups bear a higher risk for having their personal information exposed. In this paper, we evaluate the performance of three off-the-shelf PII masking systems on name detection and redaction. We generate data using names and templates from the customer service domain. We find that an open-source RoBERTa-based system shows fewer disparities than the commercial models we test. However, all systems demonstrate significant differences in error rate based on demographics. In particular, the highest error rates occurred for names associated with Black and Asian/Pacific Islander individuals."
TinyGenius: Intertwining Natural Language Processing with MicrotaskCrowdsourcing for Scholarly Knowledge Graph Creation,"AllardOelen, MarkusStocker, Sören Auer",9 May 2022,Digital Libraries (cs.DL)," As the number of published scholarly articles grows steadily each year, new methods are needed to organize scholarly knowledge so that it can be more efficiently discovered and used. Natural Language Processing (NLP) techniques are able to autonomously process scholarly articles at scale and to create machine readable representations of the article content. However, autonomous NLP methods are by far not sufficiently accurate to create a high-quality knowledge graph. Yet quality is crucial for the graph to be useful in practice. We present TinyGenius, a methodology to validate NLP- extracted scholarly knowledge statements using microtasks performed with crowdsourcing. The scholarly context in which the crowd workers operate has multiple challenges. The explainability of the employed NLP methods is crucial to provide context in order to support the decision process of crowd workers. We employed TinyGenius to populate a paper-centric knowledge graph, using five distinct NLP methods. In the end, the resulting knowledge graph serves as a digital library for scholarly articles."
Multiview Stereo with Cascaded Epipolar RAFT,"ZeyuMa, ZacharyTeed, JiaDeng",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We address multiview stereo (MVS), an important 3D vision task that reconstructs a 3D model such as a dense point cloud from multiple calibrated images. We propose CER-MVS (Cascaded Epipolar RAFT Multiview Stereo), a new approach based on the RAFT (Recurrent All-Pairs Field Transforms) architecture developed for optical flow. CER-MVS introduces five new changes to RAFT: epipolar cost volumes, cost volume cascading, multiview fusion of cost volumes, dynamic supervision, and multiresolution fusion of depth maps. CER-MVS is significantly different from prior work in multiview stereo. Unlike prior work, which operates by updating a 3D cost volume, CER- MVS operates by updating a disparity field. Furthermore, we propose an adaptive thresholding method to balance the completeness and accuracy of the reconstructed point clouds. Experiments show that our approach achieves competitive performance on DTU (the second best among known results) and state-of-the-art performance on the Tanks-and-Temples benchmark (both the intermediate and advanced set). Code is available at [this https URL](https://github.com/princeton-vl/CER-MVS)"
Nonlinear Model Predictive Control Based on Constraint-Aware ParticleFiltering/Smoothing,"ImanAskari, Shen Zeng, HuazhenFang",9 May 2022,Systems and Control (eess.SY)," Nonlinear model predictive control (NMPC) has gained widespread use in many applications. Its formulation traditionally involves repetitively solving a nonlinear constrained optimization problem online. In this paper, we investigate NMPC through the lens of Bayesian estimation and highlight that the Monte Carlo sampling method can offer a favorable way to implement NMPC. We develop a constraint-aware particle filtering/smoothing method and exploit it to implement NMPC. The new sampling-based NMPC algorithm can be executed easily and efficiently even for complex nonlinear systems, while potentially mitigating the issues of computational complexity and local minima faced by numerical optimization in conventional studies. The effectiveness of the proposed algorithm is evaluated through a simulation study."
Statistical Guarantees for Approximate Stationary Points of SimpleNeural Networks,"MahsaTaheri, Fang Xie, JohannesLederer",9 May 2022,Machine Learning (cs.LG)," Since statistical guarantees for neural networks are usually restricted to global optima of intricate objective functions, it is not clear whether these theories really explain the performances of actual outputs of neural-network pipelines. The goal of this paper is, therefore, to bring statistical theory closer to practice. We develop statistical guarantees for simple neural networks that coincide up to logarithmic factors with the global optima but apply to stationary points and the points nearby. These results support the common notion that neural networks do not necessarily need to be optimized globally from a mathematical perspective. More generally, despite being limited to simple neural networks for now, our theories make a step forward in describing the practical properties of neural networks in mathematical terms."
Are Quantum Computers Practical Yet? A Case for Feature Selection inRecommender Systems using Tensor Networks,"ArtyomNikitin, AndreiChertkov, Rafael Ballester-Ripoll, IvanOseledets, EvgenyFrolov","9 May 2022 (v1(https://arxiv.org/abs/2205.04490v1)), lastrevised 12 May 2022 (this version, v2)",Information Retrieval (cs.IR)," Collaborative filtering models generally perform better than content-based filtering models and do not require careful feature engineering. However, in the cold-start scenario collaborative information may be scarce or even unavailable, whereas the content information may be abundant, but also noisy and expensive to acquire. Thus, selection of particular features that improve cold-start recommendations becomes an important and non-trivial task. In the recent approach by Nembrini et al., the feature selection is driven by the correlational compatibility between collaborative and content-based models. The problem is formulated as a Quadratic Unconstrained Binary Optimization (QUBO) which, due to its NP-hard complexity, is solved using Quantum Annealing on a quantum computer provided by D-Wave. Inspired by the reported results, we contend the idea that current quantum annealers are superior for this problem and instead focus on classical algorithms. In particular, we tackle QUBO via TTOpt, a recently proposed black-box optimizer based on tensor networks and multilinear algebra. We show the computational feasibility of this method for large problems with thousands of features, and empirically demonstrate that the solutions found are comparable to the ones obtained with D-Wave across all examined datasets."
Architectural Partitioning and Deployment Modeling on Hybrid Clouds,"SreekrishnanVenkateswaran, SantonuSarkar",9 May 2022,Software Engineering (cs.SE)," The hybrid cloud idea is increasingly gaining momentum because it brings distinct advantages as a hosting platform for complex software systems. However, there are several challenges that need to be surmounted before hybrid hosting can become pervasive and penetrative. One main problem is to architecturally partition workloads across permutations of feasible cloud and non-cloud deployment choices to yield the best-fit hosting combination. Another is to predict the effort estimate to deliver such an advantageous hybrid deployment. In this paper, we describe a heuristic solution to address the said obstacles and converge on the ideal hybrid cloud deployment architecture, based on properties and characteristics of workloads that are sought to be hosted. We next propose a model to represent such a hybrid cloud deployment, and demonstrate a method to estimate the effort required to implement and sustain that deployment. We also validate our model through dozens of case studies spanning several industry verticals and record results pertaining to how the industrial grouping of a software system can impact the aforementioned hybrid deployment model."
A Contraction-constrained Model Predictive Control for Multi-timescaleNonlinear Processes,"RyanMcCloy, Lai Wei, Jie Bao",9 May 2022,Systems and Control (eess.SY)," Many chemical processes exhibit diverse timescale dynamics with a strong coupling between timescale sensitive variables. Model predictive control with a non-uniformly spaced optimisation horizon is an effective approach to multi-timescale control and offers opportunities for reduced computational complexity. In such an approach the fast, moderate and slow dynamics can be included in the optimisation problem by implementing smaller time intervals earlier in the prediction horizon and increasingly larger intervals towards the end of the prediction. In this paper, a reference- flexible condition is developed based on the contraction theory to provide a stability guarantee for a nonlinear system under non-uniform prediction horizons."
Concepts and Algorithms for Agent-based Decentralized and IntegratedScheduling of Production and Auxiliary Processes,"FelixGehlhoff, Alexander Fay","6 May 2022 (v1(https://arxiv.org/abs/2205.04461v1)), lastrevised 12 May 2022 (this version, v2)",Multiagent Systems (cs.MA)," Individualized products and shorter product life cycles have driven companies to rethink traditional mass production. New concepts like Industry 4.0 foster the advent of decentralized production control and distribution of information. A promising technology for realizing such scenarios are Multi-agent systems. This contribution analyses the requirements for an agent-based decentralized and integrated scheduling approach. Part of the requirements is to develop a linearly scaling communication architecture, as the communication between the agents is a major driver of the scheduling execution time. The approach schedules production, transportation, buffering and shared resource operations such as tools in an integrated manner to account for interdependencies between them. Part of the logistics requirements reflect constraints for large workpieces such as buffer scarcity. The approach aims at providing a general solution that is also applicable to large system sizes that, for example, can be found in production networks with multiple companies. Further, it is applicable for different kinds of factory organization (flow shop, job shop etc.). The approach is explained using an example based on industrial requirements. Experiments have been conducted to evaluate the scheduling execution time. The results show the approach's linear scaling behavior. Also, analyses of the concurrent negotiation ability are conducted."
Rethinking Fairness: An Interdisciplinary Survey of Critiques ofHegemonic ML Fairness Approaches,LindsayWeinberg,6 May 2022,Machine Learning (cs.LG)," This survey article assesses and compares existing critiques of current fairness-enhancing technical interventions into machine learning (ML) that draw from a range of non-computing disciplines, including philosophy, feminist studies, critical race and ethnic studies, legal studies, anthropology, and science and technology studies. It bridges epistemic divides in order to offer an interdisciplinary understanding of the possibilities and limits of hegemonic computational approaches to ML fairness for producing just outcomes for society's most marginalized. The article is organized according to nine major themes of critique wherein these different fields intersect: 1) how ""fairness"" in AI fairness research gets defined; 2) how problems for AI systems to address get formulated; 3) the impacts of abstraction on how AI tools function and its propensity to lead to technological solutionism; 4) how racial classification operates within AI fairness research; 5) the use of AI fairness measures to avoid regulation and engage in ethics washing; 6) an absence of participatory design and democratic deliberation in AI fairness considerations; 7) data collection practices that entrench ""bias,"" are non-consensual, and lack transparency; 8) the predatory inclusion of marginalized groups into AI systems; and 9) a lack of engagement with AI's long-term social and ethical outcomes. Drawing from these critiques, the article concludes by imagining future ML fairness research directions that actively disrupt entrenched power dynamics and structural injustices in society."
Fundamental limitations on optimization in variational quantumalgorithms,"Hao-Kai Zhang, ChengkaiZhu, Geng Liu, XinWang",10 May 2022,Quantum Physics (quant-ph)," Exploring quantum applications of near-term quantum devices is a rapidly growing field of quantum information science with both theoretical and practical interests. A leading paradigm to establish such near-term quantum applications is variational quantum algorithms (VQAs). These algorithms use a classical optimizer to train a parameterized quantum circuit to accomplish certain tasks, where the circuits are usually randomly initialized. In this work, we prove that for a broad class of such random circuits, the variation range of the cost function via adjusting any local quantum gate within the circuit vanishes exponentially in the number of qubits with a high probability. This result can unify the restrictions on gradient-based and gradient-free optimizations in a natural manner and reveal extra harsh constraints on the training landscapes of VQAs. Hence a fundamental limitation on the trainability of VQAs is unraveled, indicating the essence of the optimization hardness in the Hilbert space with exponential dimension. We further showcase the validity of our results with numerical simulations of representative VQAs. We believe that these results would deepen our understanding of the scalability of VQAs and shed light on the search for near-term quantum applications with advantages."
On learning agent-based models from data,"CorradoMonti, MarcoPangallo, Gianmarco De FrancisciMorales, FrancescoBonchi",10 May 2022,Physics and Society (physics.soc-ph)," Agent-Based Models (ABMs) are used in several fields to study the evolution of complex systems from micro-level assumptions. However, ABMs typically can not estimate agent-specific (or ""micro"") variables: this is a major limitation which prevents ABMs from harnessing micro-level data availability and which greatly limits their predictive power. In this paper, we propose a protocol to learn the latent micro-variables of an ABM from data. The first step of our protocol is to reduce an ABM to a probabilistic model, characterized by a computationally tractable likelihood. This reduction follows two general design principles: balance of stochasticity and data availability, and replacement of unobservable discrete choices with differentiable approximations. Then, our protocol proceeds by maximizing the likelihood of the latent variables via a gradient-based expectation maximization algorithm. We demonstrate our protocol by applying it to an ABM of the housing market, in which agents with different incomes bid higher prices to live in high-income neighborhoods. We demonstrate that the obtained model allows accurate estimates of the latent variables, while preserving the general behavior of the ABM. We also show that our estimates can be used for out-of-sample forecasting. Our protocol can be seen as an alternative to black-box data assimilation methods, that forces the modeler to lay bare the assumptions of the model, to think about the inferential process, and to spot potential identification problems."
Bike Share's Impact on COVID-19 Transmission and Bike Share'sResponses to COVID-19: A case study of Washington DC,"PedramBeigi, MohaiminulHaque, Mohammad SadraRajabi, SamerHamdar",10 May 2022,Physics and Society (physics.soc-ph)," Due to the wide-ranging travel restrictions and lockdowns applied to limit the diffusion of the SARS-CoV2 virus, the coronavirus disease of 2019 (COVID-19) pandemic has had an immediate and significant effect on human mobility at the global, national, and local levels. At the local level, bike-sharing played a significant role in urban transport during the pandemic since riders could travel outdoors with reduced infection risk. However, based on different data resources, this non-motorized mode of transportation was still negatively affected by the pandemic (i.e., relative reduction in ridership). This study has two objectives: 1) to investigate the impact of the COVID-19 pandemic on the numbers and duration of trips conducted through a bike-sharing system -- the Capital Bikeshare in Washington, DC, USA; and 2) to explore whether land use and household income in the nation's capital influence the spatial variation of ridership during the pandemic. Towards realizing these objectives, this research looks at the relationship between bike sharing and COVID-19 transmission as a two- directional relationship rather than a one-directional causal relationship. Accordingly, this study models i) the impact of COVID-19 infection numbers and rates on the use of the Capital Bikeshare system and ii) the risk of COVID-19 transmission among individual bike-sharing users. In other words, we examine i) the cyclist's behavior as a function of the COVID-19 transmission evolution in an urban environment and ii) the possible relationship between the bike share usage and the COVID-19 transmission through adopting a probabilistic contagion model. The findings show the risk of using a bike-sharing system during the pandemic and whether bike sharing remains a healthier alternative mode of transportation in terms of infection risk."
Using Deep Learning-based Features Extracted from CT scans to PredictOutcomes in COVID-19 Patients,"Sai VidyaranyaNuthalapati, MarcelaVizcaychipi, PallavShah, PiotrChudzik, Chee HauLeow, PariaYousefi, AhmedSelim, KeiranTait, BenIrving",10 May 2022,Image and Video Processing (eess.IV)," The COVID-19 pandemic has had a considerable impact on day-to-day life. Tackling the disease by providing the necessary resources to the affected is of paramount importance. However, estimation of the required resources is not a trivial task given the number of factors which determine the requirement. This issue can be addressed by predicting the probability that an infected patient requires Intensive Care Unit (ICU) support and the importance of each of the factors that influence it. Moreover, to assist the doctors in determining the patients at high risk of fatality, the probability of death is also calculated. For determining both the patient outcomes (ICU admission and death), a novel methodology is proposed by combining multi-modal features, extracted from Computed Tomography (CT) scans and Electronic Health Record (EHR) data. Deep learning models are leveraged to extract quantitative features from CT scans. These features combined with those directly read from the EHR database are fed into machine learning models to eventually output the probabilities of patient outcomes. This work demonstrates both the ability to apply a broad set of deep learning methods for general quantification of Chest CT scans and the ability to link these quantitative metrics to patient outcomes. The effectiveness of the proposed method is shown by testing it on an internally curated dataset, achieving a mean area under Receiver operating characteristic curve (AUC) of 0.77 on ICU admission prediction and a mean AUC of 0.73 on death prediction using the best performing classifiers."
FastHare: Fast Hamiltonian Reduction for Large-scale Quantum Annealing,"Phuc Thai, My T.Thai, Tam Vu, Thang N. Dinh",10 May 2022,Quantum Physics (quant-ph)," Quantum annealing (QA) that encodes optimization problems into Hamiltonians remains the only near-term quantum computing paradigm that provides sufficient many qubits for real-world applications. To fit larger optimization instances on existing quantum annealers, reducing Hamiltonians into smaller equivalent Hamiltonians provides a promising approach. Unfortunately, existing reduction techniques are either computationally expensive or ineffective in practice. To this end, we introduce a novel notion of non-separable~group, defined as a subset of qubits in a Hamiltonian that obtains the same value in optimal solutions. We develop a theoretical framework on non-separability accordingly and propose FastHare, a highly efficient reduction method. FastHare, iteratively, detects and merges non-separable groups into single qubits. It does so within a provable worst-case time complexity of only $O(\alpha n^2)$, for some user-defined parameter $\alpha$. Our extensive benchmarks for the feasibility of the reduction are done on both synthetic Hamiltonians and 3000+ instances from the MQLIB library. The results show FastHare outperforms the roof duality, the implemented reduction method in D-Wave's SDK library, with 3.6x higher average reduction ratio. It demonstrates a high level of effectiveness with an average of 62% qubits saving and 0.3s processing time, advocating for Hamiltonian reduction as an inexpensive necessity for QA."
Disentangling A Single MR Modality,"LianruiZuo, YihaoLiu, YuanXue, ShuoHan, MuratBilgel, Susan M.Resnick, Jerry L.Prince, AaronCarass",10 May 2022,Image and Video Processing (eess.IV)," Disentangling anatomical and contrast information from medical images has gained attention recently, demonstrating benefits for various image analysis tasks. Current methods learn disentangled representations using either paired multi-modal images with the same underlying anatomy or auxiliary labels (e.g., manual delineations) to provide inductive bias for disentanglement. However, these requirements could significantly increase the time and cost in data collection and limit the applicability of these methods when such data are not available. Moreover, these methods generally do not guarantee disentanglement. In this paper, we present a novel framework that learns theoretically and practically superior disentanglement from single modality magnetic resonance images. Moreover, we propose a new information-based metric to quantitatively evaluate disentanglement. Comparisons over existing disentangling methods demonstrate that the proposed method achieves superior performance in both disentanglement and cross-domain image-to-image translation tasks."
Gromov Centrality: A Multi-Scale Measure of Network Centrality UsingTriangle Inequality Excess,"Shazia'AynBabul, KarelDevriendt, RenaudLambiotte",10 May 2022,Physics and Society (physics.soc-ph)," Centrality measures quantify the importance of a node in a network based on different geometric or diffusive properties, and focus on different scales. Here, we adopt a geometrical viewpoint to define a multi-scale centrality in networks. Given a metric distance between the nodes, we measure the centrality of a node by its tendency to be close to geodesics between nodes in its neighborhood, via the concept of triangle inequality excess. Depending on the size of the neighborhood, the resulting Gromov centrality defines the importance of a node at different scales in the graph, and recovers as limits well-known concept such as the clustering coefficient and closeness centrality. We argue that Gromov centrality is affected by the geometric and boundary constraints of the network, and illustrate how it can help distinguish different types of nodes in random geometric graphs and empirical transportation networks."
Hybrid Far- and Near-Field Channel Estimation for THz Ultra-MassiveMIMO via Fixed Point Networks,"WentaoYu, YifeiShen, Hengtao He, Xianghao Yu, Jun Zhang, Khaled B.Letaief",10 May 2022,Signal Processing (eess.SP)," Terahertz ultra-massive multiple-input multiple-output (THz UM- MIMO) is envisioned as one of the key enablers of 6G wireless systems. Due to the joint effect of its large array aperture and small wavelength, the near-field region of THz UM-MIMO systems is greatly enlarged. The high- dimensional channel of such systems thus consists of a stochastic mixture of far and near fields, which renders channel estimation extremely challenging. Previous works based on uni-field assumptions cannot capture the hybrid far- and near-field features, and will suffer significant performance loss. This motivates us to consider hybrid-field channel estimation. We draw inspirations from fixed point theory to develop an efficient deep learning based channel estimator with adaptive complexity and linear convergence guarantee. Built upon classic orthogonal approximate message passing, we transform each iteration into a contractive mapping, comprising a closed- form linear estimator and a neural network based non-linear estimator. A major algorithmic innovation involves applying fixed point iteration to compute the channel estimate while modeling neural networks with arbitrary depth and adapting to the hybrid-field channel conditions. Simulation results will verify our theoretical analysis and show significant performance gains over state-of-the-art approaches in the estimation accuracy and convergence rate."
"A Closer Look at Blind Super-Resolution: Degradation Models,Baselines, and Performance Upper Bounds","WenlongZhang, GuangyuanShi, YihaoLiu, ChaoDong, Xiao-Ming Wu",10 May 2022,Image and Video Processing (eess.IV)," Degradation models play an important role in Blind super- resolution (SR). The classical degradation model, which mainly involves blur degradation, is too simple to simulate real-world scenarios. The recently proposed practical degradation model includes a full spectrum of degradation types, but only considers complex cases that use all degradation types in the degradation process, while ignoring many important corner cases that are common in the real world. To address this problem, we propose a unified gated degradation model to generate a broad set of degradation cases using a random gate controller. Based on the gated degradation model, we propose simple baseline networks that can effectively handle non-blind, classical, practical degradation cases as well as many other corner cases. To fairly evaluate the performance of our baseline networks against state-of-the-art methods and understand their limits, we introduce the performance upper bound of an SR network for every degradation type. Our empirical analysis shows that with the unified gated degradation model, the proposed baselines can achieve much better performance than existing methods in quantitative and qualitative results, which are close to the performance upper bounds."
Consensus based optimization via jump-diffusion stochasticdifferential equations,"D.Kalise, A.Sharma, M.V.Tretyakov",10 May 2022,Probability (math.PR), We introduce a new consensus based optimization (CBO) method where interacting particle system is driven by jump-diffusion stochastic differential equations. We study well-posedness of the particle system as well as of its mean-field limit. The major contributions of this paper are proofs of convergence of the interacting particle system towards the mean- field limit and convergence of a discretized particle system towards the continuous-time dynamics in the mean-square sense. We also prove convergence of the mean-field jump-diffusion SDEs towards global minimizer for a large class of objective functions. We demonstrate improved performance of the proposed CBO method over earlier CBO methods in numerical simulations on benchmark objective functions.
Hyperparameter optimization of hybrid quantum neural networks for carclassification,"Asel Sagingalieva, AndriiKurkin, ArtemMelnikov, DaniilKuhmistrov, MichaelPerelshtein, AlexeyMelnikov, AndreaSkolik, David VonDollen",10 May 2022,Quantum Physics (quant-ph)," Image recognition is one of the primary applications of machine learning algorithms. Nevertheless, machine learning models used in modern image recognition systems consist of millions of parameters that usually require significant computational time to be adjusted. Moreover, adjustment of model hyperparameters leads to additional overhead. Because of this, new developments in machine learning models and hyperparameter optimization techniques are required. This paper presents a quantum-inspired hyperparameter optimization technique and a hybrid quantum-classical machine learning model for supervised learning. We benchmark our hyperparameter optimization method over standard black-box objective functions and observe performance improvements in the form of reduced expected run times and fitness in response to the growth in the size of the search space. We test our approaches in a car image classification task, and demonstrate a full- scale implementation of the hybrid quantum neural network model with the tensor train hyperparameter optimization. Our tests show a qualitative and quantitative advantage over the corresponding standard classical tabular grid search approach used with a deep neural network ResNet34. A classification accuracy of 0.97 was obtained by the hybrid model after 18 iterations, whereas the classical model achieved an accuracy of 0.92 after 75 iterations."
Turtle Score -- Similarity Based Developer Analyzer,"SanjjushriVarshini, PonshrihariniV, SanthoshKannan, SnekhaSuresh, HarshavardhanRamesh, RohithMahadevan, Raja CSPRaman",10 May 2022,Machine Learning (stat.ML)," In day-to-day life, a highly demanding task for IT companies is to find the right candidates who fit the companies' culture. This research aims to comprehend, analyze and automatically produce convincing outcomes to find a candidate who perfectly fits right in the company. Data is examined and collected for each employee who works in the IT domain focusing on their performance measure. This is done based on various different categories which bring versatility and a wide view of focus. To this data, learner analysis is done using machine learning algorithms to obtain learner similarity and developer similarity in order to recruit people with identical working patterns. It's been proven that the efficiency and capability of a particular worker go higher when working with a person of a similar personality. Therefore this will serve as a useful tool for recruiters who aim to recruit people with high productivity. This is to say that the model designed will render the best outcome possible with high accuracy and an immaculate recommendation score."
Accelerated functional brain aging in major depressive disorder:evidence from a large scale fMRI analysis of Chinese participants,"YunsongLuo, WenyuChen, Jiang Qiu, Tao Jia",8 May 2022,Neurons and Cognition (q-bio.NC)," Major depressive disorder (MDD) is one of the most common mental health conditions that has been intensively investigated for its association with brain atrophy and mortality. Recent studies reveal that the deviation between the predicted and the chronological age can be a marker of accelerated brain aging to characterize MDD. However, current conclusions are usually drawn based on structural MRI information collected from Caucasian participants. The universality of this biomarker needs to be further validated by subjects with different ethnic/racial backgrounds and by different types of data. Here we make use of the REST-meta-MDD, a large scale resting-state fMRI dataset collected from multiple cohort participants in China. We develop a stacking machine learning model based on 1101 healthy controls, which estimates a subject's chronological age from fMRI with promising accuracy. The trained model is then applied to 1276 MDD patients from 24 sites. We observe that MDD patients exhibit a $+4.43$ years ($\text{$p$} < 0.0001$, $\text{Cohen's $d$} = 0.35$, $\text{95\% CI}:1.86 - 3.91$) higher brain-predicted age difference (brain-PAD) compared to controls. In the MDD subgroup, we observe a statistically significant $+2.09$ years ($\text{$p$} < 0.05$, $\text{Cohen's $d$} = 0.134483$) brain- PAD in antidepressant users compared to medication-free patients. The statistical relationship observed is further checked by three different machine learning algorithms. The positive brain-PAD observed in participants in China confirms the presence of accelerated brain aging in MDD patients. The utilization of functional brain connectivity for age estimation verifies existing findings from a new dimension."
Joint Study of Above Ground Biomass and Soil Organic Carbon for TotalCarbon Estimation using Satellite Imagery in Scotland,"TerrenceChan, CarlaArusGomez, AnishKothikar, Pedro Baiz",8 May 2022,Applications (stat.AP)," Land Carbon verification has long been a challenge in the carbon credit market. Carbon verification methods currently available are expensive, and may generate low-quality credit. Scalable and accurate remote sensing techniques enable new approaches to monitor changes in Above Ground Biomass (AGB) and Soil Organic Carbon (SOC). The majority of state-of-the- art research employs remote sensing on AGB and SOC separately, although some studies indicate a positive correlation between the two. We intend to combine the two domains in our research to improve state-of-the-art total carbon estimation and to provide insight into the voluntary carbon trading market. We begin by establishing baseline model in our study area in Scotland, using state-of-the-art methodologies in the SOC and AGB domains. The effects of feature engineering techniques such as variance inflation factor and feature selection on machine learning models are then investigated. This is extended by combining predictor variables from the two domains. Finally, we leverage the possible correlation between AGB and SOC to establish a relationship between the two and propose novel models in an attempt outperform the state-of-the-art results. We compared three machine learning techniques, boosted regression tree, random forest, and xgboost. These techniques have been demonstrated to be the most effective in both domains."
Practical application-specific advantage through hybrid quantumcomputing,"Michael Perelshtein, AselSagingalieva, KaranPinto, Vishal Shete, AlexeyPakhomchik, ArtemMelnikov, FlorianNeukart, GeorgGesek, Alexey Melnikov, ValeriiVinokur",10 May 2022,Quantum Physics (quant-ph)," Quantum computing promises to tackle technological and industrial problems insurmountable for classical computers. However, today's quantum computers still have limited demonstrable functionality, and it is expected that scaling up to millions of qubits is required for them to live up to this touted promise. The feasible route in achieving practical quantum advantage goals is to implement a hybrid operational mode that realizes the cohesion of quantum and classical computers. Here we present a hybrid quantum cloud based on a memory-centric and heterogeneous multiprocessing architecture, integrated into a high-performance computing data center grade environment. We demonstrate that utilizing the quantum cloud, our hybrid quantum algorithms including Quantum Encoding (QuEnc), Hybrid Quantum Neural Networks and Tensor Networks enable advantages in optimization, machine learning, and simulation fields. We show the advantage of hybrid algorithms compared to standard classical algorithms in both the computational speed and quality of the solution. The achieved advance in hybrid quantum hardware and software makes quantum computing useful in practice today."
MNet: Rethinking 2D/3D Networks for Anisotropic Medical ImageSegmentation,"ZhangfuDong, Yuting He, Xiaoming Qi, Yang Chen, HuazhongShu, Jean-LouisCoatrieux, GuanyuYang, ShuoLi",10 May 2022,Image and Video Processing (eess.IV)," The nature of thick-slice scanning causes severe inter-slice discontinuities of 3D medical images, and the vanilla 2D/3D convolutional neural networks (CNNs) fail to represent sparse inter-slice information and dense intra-slice information in a balanced way, leading to severe underfitting to inter-slice features (for vanilla 2D CNNs) and overfitting to noise from long-range slices (for vanilla 3D CNNs). In this work, a novel mesh network (MNet) is proposed to balance the spatial representation inter axes via learning. 1) Our MNet latently fuses plenty of representation processes by embedding multi-dimensional convolutions deeply into basic modules, making the selections of representation processes flexible, thus balancing representation for sparse inter-slice information and dense intra- slice information adaptively. 2) Our MNet latently fuses multi-dimensional features inside each basic module, simultaneously taking the advantages of 2D (high segmentation accuracy of the easily recognized regions in 2D view) and 3D (high smoothness of 3D organ contour) representations, thus obtaining more accurate modeling for target regions. Comprehensive experiments are performed on four public datasets (CT\&MR), the results consistently demonstrate the proposed MNet outperforms the other methods. The code and datasets are available at: [this https URL](https://github.com/zfdong- code/MNet)"
Symplectic Groupoids for Poisson Integrators,OscarCosserat,10 May 2022,Differential Geometry (math.DG)," We use local symplectic Lie groupoids to construct Poisson integrators for generic Poisson structures. More precisely, recursively obtained solutions of a Hamilton-Jacobi-like equation are interpreted as Lagrangian bisections in a neighborhood of the unit manifold, that, in turn, give Poisson integrators. We also insist on the role of the Magnus formula, in the context of Poisson geometry, for the backward analysis of such integrators."
Self-supervised regression learning using domain knowledge:Applications to improving self-supervised denoising in imaging,"Il YongChun, DongwonPark, XuehangZheng, SeYoungChun, Yong Long",10 May 2022,Image and Video Processing (eess.IV)," Regression that predicts continuous quantity is a central part of applications using computational imaging and computer vision technologies. Yet, studying and understanding self-supervised learning for regression tasks - except for a particular regression task, image denoising - have lagged behind. This paper proposes a general self-supervised regression learning (SSRL) framework that enables learning regression neural networks with only input data (but without ground-truth target data), by using a designable pseudo-predictor that encapsulates domain knowledge of a specific application. The paper underlines the importance of using domain knowledge by showing that under different settings, the better pseudo-predictor can lead properties of SSRL closer to those of ordinary supervised learning. Numerical experiments for low-dose computational tomography denoising and camera image denoising demonstrate that proposed SSRL significantly improves the denoising quality over several existing self-supervised denoising methods."
Don't Throw it Away! The Utility of Unlabeled Data in Fair DecisionMaking,"MiriamRateike, AyanMajumdar, OlgaMineeva, Krishna P.Gummadi, IsabelValera","10 May 2022 (v1(https://arxiv.org/abs/2205.04790v1)), lastrevised 11 May 2022 (this version, v2)",Machine Learning (stat.ML)," Decision making algorithms, in practice, are often trained on data that exhibits a variety of biases. Decision-makers often aim to take decisions based on some ground-truth target that is assumed or expected to be unbiased, i.e., equally distributed across socially salient groups. In many practical settings, the ground-truth cannot be directly observed, and instead, we have to rely on a biased proxy measure of the ground-truth, i.e., biased labels, in the data. In addition, data is often selectively labeled, i.e., even the biased labels are only observed for a small fraction of the data that received a positive decision. To overcome label and selection biases, recent work proposes to learn stochastic, exploring decision policies via i) online training of new policies at each time-step and ii) enforcing fairness as a constraint on performance. However, the existing approach uses only labeled data, disregarding a large amount of unlabeled data, and thereby suffers from high instability and variance in the learned decision policies at different times. In this paper, we propose a novel method based on a variational autoencoder for practical fair decision-making. Our method learns an unbiased data representation leveraging both labeled and unlabeled data and uses the representations to learn a policy in an online process. Using synthetic data, we empirically validate that our method converges to the optimal (fair) policy according to the ground-truth with low variance. In real-world experiments, we further show that our training approach not only offers a more stable learning process but also yields policies with higher fairness as well as utility than previous approaches."
Matrix and graph representations of vine copula structures,"DánielPfeifer, Edith AliceKovács",10 May 2022,Machine Learning (stat.ML)," Vine copulas can efficiently model a large portion of probability distributions. This paper focuses on a more thorough understanding of their structures. We are building on well-known existing constructions to represent vine copulas with graphs as well as matrices. The graph representations include the regular, cherry and chordal graph sequence structures, which we show equivalence between. Importantly we also show that when a perfect elimination ordering of a vine structure is given, then it can always be uniquely represented with a matrix. O. M. Nápoles has shown a way to represent them in a matrix, and we algorithmify this previous approach, while also showing a new method for constructing such a matrix, through cherry tree sequences. Lastly, we prove that these two matrix- building algorithms are equivalent if the same perfect elimination ordering is being used."
Explainable Deep Learning Methods in Medical Diagnosis: A Survey,"CristianoPatrício, João C.Neves, Luís F.Teixeira",10 May 2022,Image and Video Processing (eess.IV)," The remarkable success of deep learning has prompted interest in its application to medical diagnosis. Even tough state-of-the-art deep learning models have achieved human-level accuracy on the classification of different types of medical data, these models are hardly adopted in clinical workflows, mainly due to their lack of interpretability. The black-box-ness of deep learning models has raised the need for devising strategies to explain the decision process of these models, leading to the creation of the topic of eXplainable Artificial Intelligence (XAI). In this context, we provide a thorough survey of XAI applied to medical diagnosis, including visual, textual, and example-based explanation methods. Moreover, this work reviews the existing medical imaging datasets and the existing metrics for evaluating the quality of the explanations . Complementary to most existing surveys, we include a performance comparison among a set of report generation-based methods. Finally, the major challenges in applying XAI to medical imaging are also discussed."
Deep learning based Chinese text sentiment mining and stock marketcorrelation research,ChenruiZhang,10 May 2022,Computational Finance (q-fin.CP)," We explore how to crawl financial forum data such as stock bars and combine them with deep learning models for sentiment analysis. In this paper, we will use the BERT model to train against the financial corpus and predict the SZSE Component Index, and find that applying the BERT model to the financial corpus through the maximum information coefficient comparison study. The obtained sentiment features will be able to reflect the fluctuations in the stock market and help to improve the prediction accuracy effectively. Meanwhile, this paper combines deep learning with financial text, in further exploring the mechanism of investor sentiment on stock market through deep learning method, which will be beneficial for national regulators and policy departments to develop more reasonable policy guidelines for maintaining the stability of stock market."
Flow Completion Network: Inferring the Fluid Dynamics from IncompleteFlow Information using Graph Neural Networks,XiaodongHe (1)YinanWang (2)Juan Li(3) ((1) Department of R and D UnionString Technology Co. Ltd. (2) School ofEngineering University of Liverpool Liverpool UK. ,10 May 2022,Fluid Dynamics (physics.flu-dyn)," This paper introduces a novel neural network -- the flow completion network (FCN) -- to infer the fluid dynamics, including the flow field and the force acting on the body, from the incomplete data based on Graph Convolution Attention Network. The FCN is composed of several graph convolution layers and spatial attention layers. It is designed to infer the velocity field and the vortex force contribution of the flow field when combined with the vortex force map (VFM) method. Compared with other neural networks adopted in fluid dynamics, the FCN is capable of dealing with both structured data and unstructured data. The performance of the proposed FCN is assessed by the computational fluid dynamics (CFD) data on the flow field around a circular cylinder. The force coefficients predicted by our model are validated against those obtained directly from CFD. Moreover, it is shown that our model effectively utilizes the existing flow field information and the gradient information simultaneously, giving a better performance than the traditional CNN-based and DNN-based models."
Theory of Quantum Generative Learning Models with Maximum MeanDiscrepancy,"Yuxuan Du, ZhuozhuoTu, Bujiao Wu, XiaoYuan, Dacheng Tao",10 May 2022,Quantum Physics (quant-ph)," The intrinsic probabilistic nature of quantum mechanics invokes endeavors of designing quantum generative learning models (QGLMs) with computational advantages over classical ones. To date, two prototypical QGLMs are quantum circuit Born machines (QCBMs) and quantum generative adversarial networks (QGANs), which approximate the target distribution in explicit and implicit ways, respectively. Despite the empirical achievements, the fundamental theory of these models remains largely obscure. To narrow this knowledge gap, here we explore the learnability of QCBMs and QGANs from the perspective of generalization when their loss is specified to be the maximum mean discrepancy. Particularly, we first analyze the generalization ability of QCBMs and identify their superiorities when the quantum devices can directly access the target distribution and the quantum kernels are employed. Next, we prove how the generalization error bound of QGANs depends on the employed Ansatz, the number of qudits, and input states. This bound can be further employed to seek potential quantum advantages in Hamiltonian learning tasks. Numerical results of QGLMs in approximating quantum states, Gaussian distribution, and ground states of parameterized Hamiltonians accord with the theoretical analysis. Our work opens the avenue for quantitatively understanding the power of quantum generative learning models."
Preliminary assessment of a cost-effective headphone calibrationprocedure for soundscape evaluations,"BhanLam, KennethOoi, Karn N.Watcharasupat, Zhen-TingOng, Yun-Ting Lau, TrevorWong, Woon-Seng Gan",10 May 2022,Audio and Speech Processing (eess.AS)," The introduction of ISO 12913-2:2018 has provided a framework for standardized data collection and reporting procedures for soundscape practitioners. A strong emphasis was placed on the use of calibrated head and torso simulators (HATS) for binaural audio capture to obtain an accurate subjective impression and acoustic measure of the soundscape under evaluation. To auralise the binaural recordings as recorded or at set levels, the audio stimuli and the headphone setup are usually calibrated with a HATS. However, calibrated HATS are too financially prohibitive for most research teams, inevitably diminishing the availability of the soundscape standard. With the increasing availability of soundscape binaural recording datasets, and the importance of cross-cultural validation of the soundscape ISO standards, e.g.\ via the Soundscape Attributes Translation Project (SATP), it is imperative to assess the suitability of cost-effective headphone calibration methods to maximise availability without severely compromising on accuracy. Hence, this study objectively examines an open- circuit voltage (OCV) calibration method in comparison to a calibrated HATS on various soundcard and headphone combinations. Preliminary experiments found that calibration with the OCV method differed significantly from the reference binaural recordings in sound pressure levels, whereas negligible differences in levels were observed with the HATS calibration."
Robust Medical Image Classification from Noisy Labeled Data withGlobal and Local Representation Guided Co-training,"ChengXue, LequanYu, PengfeiChen, QiDou, Pheng-Ann Heng",10 May 2022,Image and Video Processing (eess.IV)," Deep neural networks have achieved remarkable success in a wide variety of natural image and medical image computing tasks. However, these achievements indispensably rely on accurately annotated training data. If encountering some noisy-labeled images, the network training procedure would suffer from difficulties, leading to a sub-optimal classifier. This problem is even more severe in the medical image analysis field, as the annotation quality of medical images heavily relies on the expertise and experience of annotators. In this paper, we propose a novel collaborative training paradigm with global and local representation learning for robust medical image classification from noisy-labeled data to combat the lack of high quality annotated medical data. Specifically, we employ the self-ensemble model with a noisy label filter to efficiently select the clean and noisy samples. Then, the clean samples are trained by a collaborative training strategy to eliminate the disturbance from imperfect labeled samples. Notably, we further design a novel global and local representation learning scheme to implicitly regularize the networks to utilize noisy samples in a self-supervised manner. We evaluated our proposed robust learning strategy on four public medical image classification datasets with three types of label noise,ie,random noise, computer-generated label noise, and inter- observer variability noise. Our method outperforms other learning from noisy label methods and we also conducted extensive experiments to analyze each component of our method."
Efficient Burst Raw Denoising with Variance Stabilization and Multi-frequency Denoising Network,"DasongLi, YiZhang, KaLung Law, XiaogangWang, Hongwei Qin, Hongsheng Li",10 May 2022,Image and Video Processing (eess.IV)," With the growing popularity of smartphones, capturing high-quality images is of vital importance to smartphones. The cameras of smartphones have small apertures and small sensor cells, which lead to the noisy images in low light environment. Denoising based on a burst of multiple frames generally outperforms single frame denoising but with the larger compututional cost. In this paper, we propose an efficient yet effective burst denoising system. We adopt a three-stage design: noise prior integration, multi-frame alignment and multi-frame denoising. First, we integrate noise prior by pre-processing raw signals into a variance- stabilization space, which allows using a small-scale network to achieve competitive performance. Second, we observe that it is essential to adopt an explicit alignment for burst denoising, but it is not necessary to integrate a learning-based method to perform multi-frame alignment. Instead, we resort to a conventional and efficient alignment method and combine it with our multi-frame denoising network. At last, we propose a denoising strategy that processes multiple frames sequentially. Sequential denoising avoids filtering a large number of frames by decomposing multiple frames denoising into several efficient sub-network denoising. As for each sub-network, we propose an efficient multi-frequency denoising network to remove noise of different frequencies. Our three-stage design is efficient and shows strong performance on burst denoising. Experiments on synthetic and real raw datasets demonstrate that our method outperforms state-of-the-art methods, with less computational cost. Furthermore, the low complexity and high- quality performance make deployment on smartphones possible."
Automatic Detection of Microaneurysms in OCT Images Using Bag ofFeatures,"Elahe Sadat KazemiNasab, RaminAlmasi, BijanShoushtarian, EhsanGolkar, HosseinRabbani",10 May 2022,Image and Video Processing (eess.IV)," Diabetic Retinopathy (DR) caused by diabetes occurs as a result of changes in the retinal vessels and causes visual impairment. Microaneurysms (MAs) are the early clinical signs of DR, whose timely diagnosis can help detecting DR in the early stages of its development. It has been observed that MAs are more common in the inner retinal layers compared to the outer retinal layers in eyes suffering from DR. Optical Coherence Tomography (OCT) is a noninvasive imaging technique that provides a cross-sectional view of the retina and it has been used in recent years to diagnose many eye diseases. As a result, in this paper has attempted to identify areas with MA from normal areas of the retina using OCT images. This work is done using the dataset collected from FA and OCT images of 20 patients with DR. In this regard, firstly Fluorescein Angiography (FA) and OCT images were registered. Then the MA and normal areas were separated and the features of each of these areas were extracted using the Bag of Features (BOF) approach with Speeded-Up Robust Feature (SURF) descriptor. Finally, the classification process was performed using a multilayer perceptron network. For each of the criteria of accuracy, sensitivity, specificity, and precision, the obtained results were 96.33%, 97.33%, 95.4%, and 95.28%, respectively. Utilizing OCT images to detect MAsautomatically is a new idea and the results obtained as preliminary research in this field are promising ."
Classical verification of quantum depth,"Nai-Hui Chia, Shih-HanHung",10 May 2022,Quantum Physics (quant-ph)," We present two protocols for classical verification of quantum depth. Our protocols allow a purely classical verifier to distinguish devices with different quantum circuit depths even in the presence of classical computation. We show that a device with quantum circuit depth at most d will be rejected by the verifier even if the prover applies additional polynomial-time classical computation to cheat. On the other hand, the verifier accepts a device which has quantum circuit depth d' for some d'd. In our first protocol, we introduce an additional untrusted quantum machine which shares entanglements with the target machine. Applying a robust self-test, our first protocol certifies the depth of the target machine with information theoretic security and nearly optimal separation. The protocol relies on the oracle separation problem for quantum depth by Chia, Chung and Lai [STOC 2020] and a transformation from an oracle separation problem to a two-player non-local game. Our second protocol certifies the quantum depth of a single device based on quantum hardness of learning with errors. The protocol relies on the noisy trapdoor claw-free function family and the idea of pointer chasing to force the prover to keep quantum coherence until all preceding message exchanges are completed. To our knowledge, we give the first constructions for distinguishing hybrid quantum-classical computers with different circuit depths in unrelativized models."
An optimal oracle separation of classical and quantum hybrid schemes,"Atsuya Hasegawa, François LeGall",10 May 2022,Quantum Physics (quant-ph)," Recently, Chia, Chung and Lai (STOC 2020) and Coudron and Menda (STOC 2020) have shown that there exists an oracle $\mathcal{O}$ such that $\mathsf{BQP}^\mathcal{O} \neq (\mathsf{BPP^{BQNC}})^\mathcal{O} \cup (\mathsf{BQNC^{BPP}})^\mathcal{O}$. In fact, Chia et al. proved a stronger statement: for any depth parameter $d$, there exists an oracle that separates quantum depth $d$ and $2d+1$, when polynomial-time classical computation is allowed. This implies that relative to an oracle, doubling quantum depth gives classical and quantum hybrid schemes more computational power.   In this paper, we show that for any depth parameter $d$, there exists an oracle that separates quantum depth $d$ and $d+1$, when polynomial-time classical computation is allowed. This gives an optimal oracle separation of classical and quantum hybrid schemes. To prove our result, we consider $d$-Bijective Shuffling Simon's Problem (which is a variant of $d$-Shuffling Simon's Problem considered by Chia et al.) and an oracle inspired by an ""in- place"" permutation oracle."
Deep Learning Enabled Semantic Communications with Speech Recognitionand Synthesis,"ZhenziWeng, Zhijin Qin, XiaomingTao, ChengkangPan, GuangyiLiu, Geoffrey YeLi",9 May 2022,Audio and Speech Processing (eess.AS)," In this paper, we develop a deep learning based semantic communication system for speech transmission, named DeepSC-ST. We take the speech recognition and speech synthesis as the transmission tasks of the communication system, respectively. First, the speech recognition-related semantic features are extracted for transmission by a joint semantic-channel encoder and the text is recovered at the receiver based on the received semantic features, which significantly reduces the required amount of data transmission without performance degradation. Then, we perform speech synthesis at the receiver, which dedicates to re-generate the speech signals by feeding the recognized text transcription into a neural network based speech synthesis module. To enable the DeepSC-ST adaptive to dynamic channel environments, we identify a robust model to cope with different channel conditions. According to the simulation results, the proposed DeepSC-ST significantly outperforms conventional communication systems, especially in the low signal-to-noise ratio (SNR) regime. A demonstration is further developed as a proof-of-concept of the DeepSC-ST."
"Can transit investments in low-income neighbourhoods increase transituse? Exploring the nexus of income, car-ownership, and transit accessibilityin Toronto","Elnaz YousefzadehBarri, StevenFarber, AnnaKramer, HadiJahanshahi, JeffAllen, EdaBeyazit",5 May 2022,Physics and Society (physics.soc-ph)," Transportation equity advocates recommend improving public transit in low-income neighbourhoods to alleviate socio-spatial inequalities and increase quality of life. However, transportation planners often overlook transit investments in neighbourhoods with ""transit-captive"" populations because they are assumed to result in less mode-shifting, congestion relief, and environmental benefits, compared to investments that aim to attract choice riders in wealthier communities. In North American cities, while many low-income households are already transit users, some also own and use private vehicles. It suggests that transit improvements in low-income communities could indeed result in more transit use and less car use. Accordingly, the main objective of this article is to explore the statistical relationship between transit use and transit accessibility as well as how this varies by household income and vehicle ownership in the Greater Toronto and Hamilton Area (GTHA). Using stratified regression models, we find that low-income households with one or more cars per adult have the most elastic relationship between transit accessibility and transit use; they are more likely to be transit riders if transit improves. However, we confirm that in auto-centric areas with poor transit, the transit use of low-income households drops off sharply as car ownership increases. On the other hand, a sensitivity analysis suggests more opportunities for increasing transit ridership among car-deficit households when transit is improved. These findings indicate that improving transit in low-income inner suburbs, where most low-income car-owning households are living, would align social with environmental planning goals."
An efficient acceleration technique for methods for finding thenearest point in a polytope and computing the distance between two polytopes,M.V.Dolgopolik,9 May 2022,Optimization and Control (math.OC)," We present a simple and efficient acceleration technique for an arbitrary method for computing the Euclidean projection of a point onto a convex polytope, defined as the convex hull of a finite number of points, in the case when the number of points in the polytope is much greater than the dimension of the space. The technique consists in applying any given method to a ""small"" subpolytope of the original polytope and gradually shifting it, till the projection of a given point onto the subpolytope coincides with the projection onto the original polytope. The results of numerical experiments demonstrate the high efficiency of the proposed accelerations technique. In particular, they show that the reduction of computation time increases with the increase of the number of points in the polytope and is proportional to this number for some methods. In the end of the paper, we also discuss a straightforward extension of the proposed acceleration technique to the case of arbitrary methods for computing the distance between two convex polytopes, defined as the convex hulls of finite sets of points."
Machine Learning Diffusion Monte Carlo Energy Densities,"Kevin Ryczko, Jaron T.Krogel, IsaacTamblyn",9 May 2022,Mesoscale and Nanoscale Physics (cond-mat.mes-hall)," We present two machine learning methodologies which are capable of predicting diffusion Monte Carlo (DMC) energies with small datasets ($\approx$60 DMC calculations in total). The first uses voxel deep neural networks (VDNNs) to predict DMC energy densities using Kohn-Sham density functional theory (DFT) electron densities as input. The second uses kernel ridge regression (KRR) to predict atomic contributions to the DMC total energy using atomic environment vectors as input (we used atom centred symmetry functions, atomic environment vectors from the ANI models, and smooth overlap of atomic positions). We first compare the methodologies on pristine graphene lattices, where we find the KRR methodology performs best in comparison to gradient boosted decision trees, random forest, gaussian process regression, and multilayer perceptrons. In addition, KRR outperforms VDNNs by an order of magnitude. Afterwards, we study the generalizability of KRR to predict the energy barrier associated with a Stone-Wales defect. Lastly, we move from 2D to 3D materials and use KRR to predict total energies of liquid water. In all cases, we find that the KRR models are more accurate than Kohn-Sham DFT and all mean absolute errors are less than chemical accuracy."
Repeated Averages on Graphs,"RamisMovassagh, MarioSzegedy, GuanyangWang",9 May 2022,Probability (math.PR)," Sourav Chatterjee, Persi Diaconis, Allan Sly and Lingfu Zhang, prompted by a question of Ramis Movassagh, renewed the study of a process proposed in the early 1980s by Jean Bourgain. A state vector $v \in \mathbb R^n$, labeled with the vertices of a connected graph, $G$, changes in discrete time steps following the simple rule that at each step a random edge $(i,j)$ is picked and $v_i$ and $v_j$ are both replaced by their average $(v_i+v_j)/2$. It is easy to see that the value associated with each vertex converges to $1/n$. The question was how quickly will $v$ be $\epsilon$-close to uniform in the $L^{1}$ norm in the case of the complete graph, $K_{n}$, when $v$ is initialized as a standard basis vector that takes the value 1 on one coordinate, and zeros everywhere else. They have established a sharp cutoff of $\frac{1}{2\log 2}n\log n + O(n\sqrt{\log n})$. Our main result is to prove, that $\frac{(1-\epsilon)}{2\log2}n\log n-O(n)$ is a general lower bound for all connected graphs on $n$ nodes. We also get sharp magnitude of $t_{\epsilon,1}$ for several important families of graphs, including star, expander, dumbbell, and cycle. In order to establish our results we make several observations about the process, such as the worst case initialization is always a standard basis vector. Our results add to the body of work of Aldous, Aldous and Lanoue, Quattropani and Sau, Cao, Olshevsky and Tsitsiklis, and others. The renewed interest is due to an analogy to a question related to the Google's supremacy circuit. For the proof of our main theorem we employ a concept that we call 'augmented entropy function' which may find independent interest in the computer science and probability theory communities."
The role of harvesting and growth rate for spatially heterogeneouspopulations,"Md. Mashih Ibn YasinAdan, Md.Kamrujjaman, Md. MamunMolla, MuhammadMohebujjaman, ClarisaBuenrostro",9 May 2022,Dynamical Systems (math.DS)," This paper investigates the competition of two species in a heterogeneous environment subject to the effect of harvesting. The most realistic harvesting case is connected with the intrinsic growth rate, and the harvesting functions are developed based on this clause instead of random choice. We prove the existence and uniqueness of the solution to the model we consider. Theoretically, we state that when species coexist, one may drive the other to die out, and both species extinct, considering all possible rational values of parameters. These results highlight a comparative study between two harvesting coefficients. Finally, we solve the model using a backward-Euler, decoupled, and linearized time-stepping fully discrete algorithm and observe a match between the theoretical and numerical findings."
Energy Games over Totally Ordered Groups,AlexanderKozachinskiy,10 May 2022,Group Theory (math.GR)," Kopczyński (ICALP 2006) conjectured that prefix-independent half- positional winning conditions are closed under finite unions. We refute this conjecture over finite arenas. For that, we introduce a new class of prefix- independent bi-positional winning conditions called energy conditions over totally ordered groups. We give an example of two such conditions whose union is not half-positional. We also conjecture that every prefix- independent bi-positional winning condition coincides with some energy condition over a totally ordered group on periodic sequences."
Insights into the origin of halo mass profiles from machine learning,"Luisa Lucie-Smith, SusmitaAdhikari, Risa H.Wechsler",9 May 2022,Cosmology and Nongalactic Astrophysics (astro-ph.CO)," The mass distribution of dark matter haloes is the result of the hierarchical growth of initial density perturbations through mass accretion and mergers. We use an interpretable machine-learning framework to provide physical insights into the origin of the spherically-averaged mass profile of dark matter haloes. We train a gradient-boosted-trees algorithm to predict the final mass profiles of cluster-sized haloes, and measure the importance of the different inputs provided to the algorithm. We find two primary scales in the initial conditions (ICs) that impact the final mass profile: the density at approximately the scale of the haloes' Lagrangian patch $R_L$ ($R\sim 0.7\, R_L$) and that in the large-scale environment ($R\sim 1.7~R_L$). The model also identifies three primary time-scales in the halo assembly history that affect the final profile: (i) the formation time of the virialized, collapsed material inside the halo, (ii) the dynamical time, which captures the dynamically unrelaxed, infalling component of the halo over its first orbit, (iii) a third, most recent time- scale, which captures the impact on the outer profile of recent massive merger events. While the inner profile retains memory of the ICs, this information alone is insufficient to yield accurate predictions for the outer profile. As we add information about the haloes' mass accretion history, we find a significant improvement in the predicted profiles at all radii. Our machine-learning framework provides novel insights into the role of the ICs and the mass assembly history in determining the final mass profile of cluster-sized haloes."
Skin disease diagnosis using image analysis and natural languageprocessing,"MartinChileshe, MayumboNyirenda",9 May 2022,Image and Video Processing (eess.IV)," In Zambia, there is a serious shortage of medical staff where each practitioner attends to about 17000 patients in a given district while still, other patients travel over 10 km to access the basic medical services. In this research, we implement a deep learning model that can perform the clinical diagnosis process. The study will prove whether image analysis is capable of performing clinical diagnosis. It will also enable us to understand if we can use image analysis to lessen the workload on medical practitioners by delegating some tasks to an AI. The success of this study has the potential to increase the accessibility of medical services to Zambians, which is one of the national goals of Vision 2030."
Differentiable Electron Microscopy Simulation: Methods andApplications for Visualization,"NganNguyen, FengLiang, DominikEngel, CirilBohak, PeterWonka, TimoRopinski, IvanViola",8 May 2022,Quantitative Methods (q-bio.QM)," We propose a new microscopy simulation system that can depict atomistic models in a micrograph visual style, similar to results of physical electron microscopy imaging. This system is scalable, able to represent simulation of electron microscopy of tens of viral particles and synthesizes the image faster than previous methods. On top of that, the simulator is differentiable, both its deterministic as well as stochastic stages that form signal and noise representations in the micrograph. This notable property has the capability for solving inverse problems by means of optimization and thus allows for generation of microscopy simulations using the parameter settings estimated from real data. We demonstrate this learning capability through two applications: (1) estimating the parameters of the modulation transfer function defining the detector properties of the simulated and real micrographs, and (2) denoising the real data based on parameters trained from the simulated examples. While current simulators do not support any parameter estimation due to their forward design, we show that the results obtained using estimated parameters are very similar to the results of real micrographs. Additionally, we evaluate the denoising capabilities of our approach and show that the results showed an improvement over state-of-the-art methods. Denoised micrographs exhibit less noise in the tilt-series tomography reconstructions, ultimately reducing the visual dominance of noise in direct volume rendering of microscopy tomograms."
Efficient bending and lifting patterns in snake locomotion,SilasAlben,9 May 2022,Biological Physics (physics.bio-ph)," We optimize three-dimensional snake kinematics for locomotor efficiency. We assume a general space-curve representation of the snake backbone with small-to-moderate lifting off the ground and negligible body inertia. The cost of locomotion includes work against friction and internal viscous dissipation. When restricted to planar kinematics, our population- based optimization method finds the same types of optima as a previous Newton-based method. A few types of optimal motions prevail. We find an s-shaped body with alternating lifting of the middle and ends for small-to- moderate transverse friction. For large transverse friction, curling and sliding motions are typical with small viscous dissipation, replaced by large-amplitude bending with large viscous dissipation. With small viscous dissipation we find local optima that resemble sidewinding motions across friction coefficient space. They are always suboptimal to alternating lifting motions, with average input power 10--100\% higher."
OpenPodcar: an Open Source Vehicle for Self-Driving Car Research,"FantaCamara, ChrisWaltham, GreyChurchill, Charles Fox",9 May 2022,Robotics (cs.RO)," OpenPodcar is a low-cost, open source hardware and software, autonomous vehicle research platform based on an off-the-shelf, hard-canopy, mobility scooter donor vehicle. Hardware and software build instructions are provided to convert the donor vehicle into a low-cost and fully autonomous platform. The open platform consists of (a) hardware components: CAD designs, bill of materials, and build instructions; (b) Arduino, ROS and Gazebo control and simulation software files which provide standard ROS interfaces and simulation of the vehicle; and (c) higher-level ROS software implementations and configurations of standard robot autonomous planning and control, including the move_base interface with Timed-Elastic-Band planner which enacts commands to drive the vehicle from a current to a desired pose around obstacles. The vehicle is large enough to transport a human passenger or similar load at speeds up to 15km/h, for example for use as a last-mile autonomous taxi service or to transport delivery containers similarly around a city center. It is small and safe enough to be parked in a standard research lab and be used for realistic human-vehicle interaction studies. System build cost from new components is around USD7,000 in total in 2022. OpenPodcar thus provides a good balance between real world utility, safety, cost and research convenience."
Introspective Deep Metric Learning,"ChengkunWang, WenzhaoZheng, ZhengZhu, JieZhou, JiwenLu",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," This paper proposes an introspective deep metric learning (IDML) framework for uncertainty-aware comparisons of images. Conventional deep metric learning methods produce confident semantic distances between images regardless of the uncertainty level. However, we argue that a good similarity model should consider the semantic discrepancies with caution to better deal with ambiguous images for more robust training. To achieve this, we propose to represent an image using not only a semantic embedding but also an accompanying uncertainty embedding, which describes the semantic characteristics and ambiguity of an image, respectively. We further propose an introspective similarity metric to make similarity judgments between images considering both their semantic differences and ambiguities. Our framework attains state-of-the-art performance on the widely used CUB-200-2011, Cars196, and Stanford Online Products datasets for image retrieval. We further evaluate our framework for image classification on the ImageNet-1K, CIFAR-10, and CIFAR-100 datasets, which shows that equipping existing data mixing methods with the proposed introspective metric consistently achieves better results (e.g., +0.44 for CutMix on ImageNet-1K). Code is available at: [this https URL](https://github.com/wangck20/IDML)."
Energy conserving and well-balanced discontinuous Galerkin methods forthe Euler-Poisson equations in spherical symmetry,"WeijieZhang, YulongXing, EirikEndeve",9 May 2022,Numerical Analysis (math.NA)," This paper presents high-order Runge-Kutta (RK) discontinuous Galerkin methods for the Euler-Poisson equations in spherical symmetry. The scheme can preserve a general polytropic equilibrium state and achieve total energy conservation up to machine precision with carefully designed spatial and temporal discretizations. To achieve the well-balanced property, the numerical solutions are decomposed into equilibrium and fluctuation components which are treated differently in the source term approximation. One non-trivial challenge encountered in the procedure is the complexity of the equilibrium state, which is governed by the Lane-Emden equation. For total energy conservation, we present second- and third-order RK time discretization, where different source term approximations are introduced in each stage of the RK method to ensure the conservation of total energy. A carefully designed slope limiter for spherical symmetry is also introduced to eliminate oscillations near discontinuities while maintaining the well- balanced and total-energy-conserving properties. Extensive numerical examples -- including a toy model of stellar core-collapse with a phenomenological equation of state that results in core-bounce and shock formation -- are provided to demonstrate the desired properties of the proposed methods, including the well-balanced property, high-order accuracy, shock capturing capability, and total energy conservation."
MixAugment & Mixup: Augmentation Methods for Facial ExpressionRecognition,"AndreasPsaroudakis, DimitriosKollias",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Automatic Facial Expression Recognition (FER) has attracted increasing attention in the last 20 years since facial expressions play a central role in human communication. Most FER methodologies utilize Deep Neural Networks (DNNs) that are powerful tools when it comes to data analysis. However, despite their power, these networks are prone to overfitting, as they often tend to memorize the training data. What is more, there are not currently a lot of in-the-wild (i.e. in unconstrained environment) large databases for FER. To alleviate this issue, a number of data augmentation techniques have been proposed. Data augmentation is a way to increase the diversity of available data by applying constrained transformations on the original data. One such technique, which has positively contributed to various classification tasks, is Mixup. According to this, a DNN is trained on convex combinations of pairs of examples and their corresponding labels. In this paper, we examine the effectiveness of Mixup for in-the-wild FER in which data have large variations in head poses, illumination conditions, backgrounds and contexts. We then propose a new data augmentation strategy which is based on Mixup, called MixAugment. According to this, the network is trained concurrently on a combination of virtual examples and real examples; all these examples contribute to the overall loss function. We conduct an extensive experimental study that proves the effectiveness of MixAugment over Mixup and various state-of-the- art methods. We further investigate the combination of dropout with Mixup and MixAugment, as well as the combination of other data augmentation techniques with MixAugment."
Higher-order in-and-outeractions reveal synergy and logical dependencebeyond Shannon-information,AbelJansma,9 May 2022,Information Theory (cs.IT)," Information-theoretic quantities reveal dependencies among variables in the structure of joint, marginal, and conditional entropies, but leave some fundamentally different systems indistinguishable. Furthermore, there is no consensus on how to construct and interpret a higher-order generalisation of mutual information (MI). In this manuscript, we show that a recently proposed model-free definition of higher-order interactions amongst binary variables (MFIs), like mutual information, is a Möbius inversion on a Boolean algebra, but of surprisal instead of entropy. This gives an information-theoretic interpretation to the MFIs, and by extension to Ising interactions. We study the dual objects to MI and MFIs on the order-reversed lattice, and find that dual MI is related to the previously studied differential mutual information, while dual interactions (outeractions) are interactions with respect to a different background state. Unlike mutual information, in- and outeractions uniquely identify all six 2-input logic gates, the dy- and triadic distributions, and different causal dynamics that are identical in terms of their Shannon-information content."
BLINK with Elasticsearch for Efficient Entity Linking in BusinessConversations,"Md Tahmid RahmanLaskar, Cheng Chen, AliaksandrMartsinovich, JonathanJohnston, Xue-Yong Fu, Shashi BhushanTN, SimonCorston-Oliver",9 May 2022,Computation and Language (cs.CL)," An Entity Linking system aligns the textual mentions of entities in a text to their corresponding entries in a knowledge base. However, deploying a neural entity linking system for efficient real-time inference in production environments is a challenging task. In this work, we present a neural entity linking system that connects the product and organization type entities in business conversations to their corresponding Wikipedia and Wikidata entries. The proposed system leverages Elasticsearch to ensure inference efficiency when deployed in a resource limited cloud machine, and obtains significant improvements in terms of inference speed and memory consumption while retaining high accuracy."
Performance Analysis of Cascaded Reconfigurable Intelligent SurfaceNetworks,"DimitriosTyrovolas, Sotiris ATegos, Emmanouela C DimitriadouPanidou, Panagiotis DDiamantoulakis, Christos KLiaskos, George KKaragiannidis",9 May 2022,Information Theory (cs.IT)," Reconfigurable intelligent surfaces (RIS) have been presented as a solution to realize the concept of smart radio environments, wherein uninterrupted coverage and extremely high quality of service can be ensured. In this paper, assuming that multiple RIS are deployed in the propagation environment, the performance of a cascaded RIS network affected by imperfect phase estimation is evaluated. Specifically, we derive closed-form expressions for the outage probability, the ergodic capacity and the average symbol error probability that can be utilized to evaluate the coverage of the proposed network, as well as the average capacity and the data transmission accuracy. Finally, we validate the derived expressions through simulations and show that by choosing the number of the participating RIS correctly, a cascaded RIS network can outperform a single RIS aided system and extend the network's coverage efficiently."
Static Analysis for AWS Best Practices in Python Code,"RajdeepMukherjee, Omer Tripp, Ben Liblit, MichaelWilson",9 May 2022,Programming Languages (cs.PL)," Amazon Web Services (AWS) is a comprehensive and broadly adopted cloud provider, offering over 200 fully featured services, including compute, database, storage, networking and content delivery, machine learning, Internet of Things and many others. AWS SDKs provide access to AWS services through API endpoints. However, incorrect use of these APIs can lead to code defects, crashes, performance issues, and other problems.   This paper presents automated static analysis rules, developed in the context of a commercial service for detection of code defects and security vulnerabilities, to identify deviations from AWS best practices in Python applications that use the AWS SDK. Such applications use the AWS SDK for Python, called ""Boto3"", to access AWS cloud services. However, precise static analysis of Python applications that use cloud SDKs requires robust type inference for inferring the types of cloud service clients. The dynamic style of Boto3 APIs poses unique challenges for type resolution, as does the interprocedural style in which service clients are used in practice. In support of our best-practices goal, we present a layered strategy for type inference that combines multiple type-resolution and tracking strategies in a staged manner. From our experiments across 3,000 popular Python GitHub repos that make use of the AWS SDK, our layered type inference system achieves 85% precision and 100% recall in inferring Boto3 clients in Python client code.   Additionally, we present a representative sample of eight AWS best-practice rules that detect a wide range of issues including pagination, polling, and batch operations. We have assessed the efficacy of these rules based on real-world developer feedback. Developers have accepted more than 85% of the recommendations made by five out of eight Python rules, and almost 83% of all recommendations."
Spike-based building blocks for performing logic operations usingSpiking Neural Networks on SpiNNaker,"Alvaro Ayuso-Martinez, Daniel Casanueva-Morato, Juan P. Dominguez-Morales, Angel Jimenez-Fernandez, Gabriel Jimenez-Moreno",9 May 2022,Neural and Evolutionary Computing (cs.NE)," One of the most interesting and still growing scientific fields is neuromorphic engineering, which is focused on studying and designing hardware and software with the purpose of mimicking the basic principles of biological nervous systems. Currently, there are many research groups developing practical applications based on neuroscientific knowledge. This work provides researchers with a novel toolkit of building blocks based on Spiking Neural Networks that emulate the behavior of different logic gates. These could be very useful in many spike-based applications, since logic gates are the basis of digital circuits. The designs and models proposed are presented and implemented on a SpiNNaker hardware platform. Different experiments were performed in order to validate the expected behavior, and the obtained results are discussed. The functionality of traditional logic gates and the proposed blocks is studied, and the feasibility of the presented approach is discussed."
Accelerated Reinforcement Learning for Temporal Logic ControlObjectives,YiannisKantaros,"9 May 2022 (v1(https://arxiv.org/abs/2205.04424v1)), lastrevised 10 May 2022 (this version, v2)",Robotics (cs.RO)," This paper addresses the problem of learning control policies for mobile robots modeled as unknown Markov Decision Processes (MDPs) that are tasked with temporal logic missions, such as sequencing, coverage, or surveillance. The MDP captures uncertainty in the workspace structure and the outcomes of control decisions. The control objective is to synthesize a control policy that maximizes the probability of accomplishing a high-level task, specified as a Linear Temporal Logic (LTL) formula. To address this problem, we propose a novel accelerated model-based reinforcement learning (RL) algorithm for LTL control objectives that is capable of learning control policies significantly faster than related approaches. Its sample- efficiency relies on biasing exploration towards directions that may contribute to task satisfaction. This is accomplished by leveraging an automaton representation of the LTL task as well as a continuously learned MDP model. Finally, we provide extensive comparative experiments that demonstrate the sample efficiency of the proposed method against recent temporal logic RL methods."
Graph Neural Networks for Propositional Model Counting,"GaiaSaveri, LucaBortolussi",9 May 2022,Artificial Intelligence (cs.AI)," Graph Neural Networks (GNNs) have been recently leveraged to solve several logical reasoning tasks. Nevertheless, counting problems such as propositional model counting (#SAT) are still mostly approached with traditional solvers. Here we tackle this gap by presenting an architecture based on the GNN framework for belief propagation (BP) of Kuch et al., extended with self-attentive GNN and trained to approximately solve the #SAT problem. We ran a thorough experimental investigation, showing that our model, trained on a small set of random Boolean formulae, is able to scale effectively to much larger problem sizes, with comparable or better performances of state of the art approximate solvers. Moreover, we show that it can be efficiently fine-tuned to provide good generalization results on different formulae distributions, such as those coming from SAT-encoded combinatorial problems."
Motion Planning around Obstacles with Convex Optimization,"TobiaMarcucci, MarkPetersen, David vonWrangel, RussTedrake",9 May 2022,Robotics (cs.RO)," Trajectory optimization offers mature tools for motion planning in high-dimensional spaces under dynamic constraints. However, when facing complex configuration spaces, cluttered with obstacles, roboticists typically fall back to sampling-based planners that struggle in very high dimensions and with continuous differential constraints. Indeed, obstacles are the source of many textbook examples of problematic nonconvexities in the trajectory-optimization problem. Here we show that convex optimization can, in fact, be used to reliably plan trajectories around obstacles. Specifically, we consider planning problems with collision-avoidance constraints, as well as cost penalties and hard constraints on the shape, the duration, and the velocity of the trajectory. Combining the properties of Bézier curves with a recently-proposed framework for finding shortest paths in Graphs of Convex Sets (GCS), we formulate the planning problem as a compact mixed-integer optimization. In stark contrast with existing mixed- integer planners, the convex relaxation of our programs is very tight, and a cheap rounding of its solution is typically sufficient to design globally- optimal trajectories. This reduces the mixed-integer program back to a simple convex optimization, and automatically provides optimality bounds for the planned trajectories. We name the proposed planner GCS, after its underlying optimization framework. We demonstrate GCS in simulation on a variety of robotic platforms, including a quadrotor flying through buildings and a dual-arm manipulator (with fourteen degrees of freedom) moving in a confined space. Using numerical experiments on a seven-degree-of-freedom manipulator, we show that GCS can outperform widely-used sampling-based planners by finding higher-quality trajectories in less time."
Efficient algorithms for Bayesian Inverse Problems with Whittle--Matérn Priors,"HarbirAntil, Arvind K.Saibaba","9 May 2022 (v1(https://arxiv.org/abs/2205.04417v1)), lastrevised 11 May 2022 (this version, v2)",Numerical Analysis (math.NA)," This paper tackles efficient methods for Bayesian inverse problems with priors based on Whittle--Matérn Gaussian random fields. The Whittle-- Matérn prior is characterized by a mean function and a covariance operator that is taken as a negative power of an elliptic differential operator. This approach is flexible in that it can incorporate a wide range of prior information including non-stationary effects, but it is currently computationally advantageous only for integer values of the exponent. In this paper, we derive an efficient method for handling all admissible noninteger values of the exponent. The method first discretizes the covariance operator using finite elements and quadrature, and uses preconditioned Krylov subspace solvers for shifted linear systems to efficiently apply the resulting covariance matrix to a vector. This approach can be used for generating samples from the distribution in two different ways: by solving a stochastic partial differential equation, and by using a truncated Karhunen-Loève expansion. We show how to incorporate this prior representation into the infinite-dimensional Bayesian formulation, and show how to efficiently compute the maximum a posteriori estimate, and approximate the posterior variance. Although the focus of this paper is on Bayesian inverse problems, the techniques developed here are applicable to solving systems with fractional Laplacians and Gaussian random fields. Numerical experiments demonstrate the performance and scalability of the solvers and their applicability to model and real-data inverse problems in tomography and a time-dependent heat equation."
Model-Contrastive Learning for Backdoor Defense,"ZhihaoYue, JunXia, ZhiweiLing, TingWang, XianWei, MingsongChen",9 May 2022,Machine Learning (cs.LG)," Along with the popularity of Artificial Intelligence (AI) techniques, an increasing number of backdoor injection attacks are designed to maliciously threaten Deep Neural Networks (DNNs) deployed in safety- critical systems. Although there exist various defense methods that can effectively erase backdoor triggers from DNNs, they still greatly suffer from a non-negligible Attack Success Rate (ASR) as well as a major loss in benign accuracy. Inspired by the observation that a backdoored DNN will form new clusters in its feature space for poisoned data, in this paper we propose a novel backdoor defense method named MCL based on model-contrastive learning. Specifically, model-contrastive learning to implement backdoor defense consists of two steps. First, we use the backdoor attack trigger synthesis technique to invert the trigger. Next, the inversion trigger is used to construct poisoned data, so that model-contrastive learning can be used, which makes the feature representations of poisoned data close to that of the benign data while staying away from the original poisoned feature representations. Through extensive experiments against five start-of-the-art attack methods on multiple benchmark datasets, using only 5% of clean data, MCL is more effective for reducing backdoor threats while maintaining higher accuracy of benign data. MCL can make the benign accuracy degenerate by less than 1%."
Tight Differential Privacy Blanket for Shuffle Model,"SayanBiswas, Kangsoo Jung, CatusciaPalamidessi",9 May 2022,Cryptography and Security (cs.CR)," With the recent bloom of focus on digital economy, the importance of personal data has seen a massive surge of late. Keeping pace with this trend, the model of data market is starting to emerge as a process to obtain high-quality personal information in exchange of incentives. To have a formal guarantee to protect the privacy of the sensitive data involved in digital economy, \emph{differential privacy (DP)} is the go-to technique, which has gained a lot of attention by the community recently. However, it is essential to optimize the privacy-utility trade-off by ensuring the highest level of privacy protection is ensured while preserving the utility of the data. In this paper, we theoretically derive sufficient and necessary conditions to have tight $(\epsilon,\,\delta)$-DP blankets for the shuffle model, which, to the best of our knowledge, have not been proven before, and, thus, characterize the best possible DP protection for shuffle models which can be implemented in data markets to ensure privacy-preserving trading of digital economy."
Self-Serviced IoT: Practical and Private IoT Computation Offloadingwith Full User Control,"DohyunKim, PrasoonPatidar, Han Zhang, AbhijithAnilkumar, YuvrajAgarwal",9 May 2022,Cryptography and Security (cs.CR)," The rapid increase in the adoption of Internet-of-Things (IoT) devices raises critical privacy concerns as these devices can access a variety of sensitive data. The current status quo of relying on manufacturers' cloud services to process this data is especially problematic since users cede control once their data leaves their home. Multiple recent incidents further call into question if vendors can indeed be trusted with users' data. At the same time, users desire compelling features supported by IoT devices and ML-based cloud inferences which compels them to subscribe to manufacturer-managed cloud services. An alternative to use a local in-home hub requires substantial hardware investment, management, and scalability limitations. This paper proposes Self-Serviced IoT (SSIoT), a clean-slate approach of using a hybrid hub-cloud setup to enable privacy-aware computation offload for IoT applications. Uniquely, SSIoT enables opportunistic computation offload to public cloud providers while still ensuring that the end-user retains complete end-to-end control of their private data reducing the trust required from public cloud providers. We show that SSIoT can leverage emerging function-as-a-service computation (e.g. AWS Lambda) to make these offloads cost-efficient, scalable and high performance as long as key limitations of being stateless, limited resources, and security isolation can be addressed. We build an end-to-end prototype of SSIoT and evaluate it using several micro-benchmarks and example applications representing real-world IoT use cases. Our results show that SSIoT is highly scalable, as compared to local-only approaches which struggle with as little as 2-4 apps in parallel. We also show that SSIoT is cost-efficient (operating a smart doorbell for $10 a year) at the cost of minimal additional latency as compared to a local-only hub, even with a hardware ML accelerator."
TeamX@DravidianLangTech-ACL2022: A Comparative Analysis for Troll-Based Meme Classification,"Rabindra NathNandi, Firoj Alam, PreslavNakov",9 May 2022,Computation and Language (cs.CL)," The spread of fake news, propaganda, misinformation, disinformation, and harmful content online raised concerns among social media platforms, government agencies, policymakers, and society as a whole. This is because such harmful or abusive content leads to several consequences to people such as physical, emotional, relational, and financial. Among different harmful content \textit{trolling-based} online content is one of them, where the idea is to post a message that is provocative, offensive, or menacing with an intent to mislead the audience. The content can be textual, visual, a combination of both, or a meme. In this study, we provide a comparative analysis of troll-based memes classification using the textual, visual, and multimodal content. We report several interesting findings in terms of code-mixed text, multimodal setting, and combining an additional dataset, which shows improvements over the majority baseline."
Detecting the Role of an Entity in Harmful Memes: Techniques and TheirLimitations,"Rabindra NathNandi, Firoj Alam, PreslavNakov",9 May 2022,Computation and Language (cs.CL)," Harmful or abusive online content has been increasing over time, raising concerns for social media platforms, government agencies, and policymakers. Such harmful or abusive content can have major negative impact on society, e.g., cyberbullying can lead to suicides, rumors about COVID-19 can cause vaccine hesitance, promotion of fake cures for COVID-19 can cause health harms and deaths. The content that is posted and shared online can be textual, visual, or a combination of both, e.g., in a meme. Here, we describe our experiments in detecting the roles of the entities (hero, villain, victim) in harmful memes, which is part of the CONSTRAINT-2022 shared task, as well as our system for the task. We further provide a comparative analysis of different experimental settings (i.e., unimodal, multimodal, attention, and augmentation). For reproducibility, we make our experimental code publicly available. \url{[this https URL](https://github.com/robi56/harmful_memes_block_fusion)}"
Accelerating potential evaluation over unstructured meshes in twodimensions,"ZewenShen, KirillSerkh",9 May 2022,Numerical Analysis (math.NA)," The accurate and efficient evaluation of potentials with singular or weakly-singular kernels is of great importance for the numerical solution of partial differential equations. When the integration domain of the potential is irregular and is discretized by an unstructured mesh, the function spaces of near field and self-interactions are non-compact, and, thus, their computations cannot be easily accelerated. In this paper, we propose several novel and complementary techniques for accelerating the evaluation of potentials over unstructured meshes. Firstly, we observe that the standard approximation of the near field by a ball or a triangle often leads to an over-estimated near field. We rigorously characterize the geometry of the near field, and show that this analysis can be used to reduce the number of near field interaction computations dramatically. Secondly, as the near field can be made arbitrarily small by increasing the order of the far field quadrature rule, the expensive near field interaction computation can be efficiently offloaded onto the FMM-based far field interaction computation, which leverages the computational efficiency of highly optimized parallel FMM libraries. Finally, we observe that the usual arrangement in which the interpolation nodes are placed on the same mesh over which the potential is integrated results in an artificially large number of near field interaction calculations, since the discretization points tend to cluster near the boundaries of mesh elements. We show that the use of a separate staggered mesh for interpolation effectively reduces the cost of near field and self-interaction computations. Besides these contributions, we present a robust and extensible framework for the evaluation and interpolation of 2-D volume potentials over complicated geometries. We demonstrate the effectiveness of the techniques with several numerical experiments."
Energy Büchi Problems,"SvenDziadek, UliFahrenberg, Philipp Schlehuber-Caissier",9 May 2022,Logic in Computer Science (cs.LO), We show how to efficiently solve energy Büchi problems in finite weighted Büchi automata and in one-clock weighted timed Büchi automata; all our algorithms are implemented in a pipeline based on TChecker and Spot. Solving the latter problem is done by using the corner-point abstraction; the former problem is handled by a modified version of Bellman-Ford interleaved with Couvreur's algorithm.
High-Cardinality Geometrical Constellation Shaping for the NonlinearFibre Channel,"EricSillekens, GabrieleLiga, DomaniçLavery, PolinaBayvel, Robert I.Killey",9 May 2022,Information Theory (cs.IT)," This paper presents design methods for highly efficient optimisation of geometrically shaped constellations to maximise data throughput in optical communications. It describes methods to analytically calculate the information-theoretical loss and the gradient of this loss as a function of the input constellation shape. The gradients of the \ac{MI} and \ac{GMI} are critical to the optimisation of geometrically-shaped constellations. It presents the analytical derivative of the achievable information rate metrics with respect to the input constellation. The proposed method allows for improved design of higher cardinality and higher- dimensional constellations for optimising both linear and nonlinear fibre transmission throughput. Near-capacity achieving constellations with up to 8192 points for both 2 and 4 dimensions, with generalised mutual information (GMI) within 0.06 bit/2Dsymbol of additive white Gaussian noise channel (AWGN) capacity, are presented. Additionally, a design algorithm reducing the design computation time from days to minutes is introduced, allowing the presentation of optimised constellations for both linear AWGN and nonlinear fibre channels for a wide range of signal-to-noise ratios."
A computable and continuous metric on isometry classes of high-dimensional periodic sequences,VitaliyKurlin,9 May 2022,Computational Geometry (cs.CG)," This paper introduces a metric that continuously quantifies the similarity between high-dimensional periodic sequences considered up to natural equivalences maintaining inter-point distances. This metric problem is motivated by periodic time series and point sets that model real periodic structures with noise. Most past advances focused on finite sets or simple periodic lattices. The key novelty is the continuity of the new metric under perturbations that can change the minimum period. For any sequences with at most m points within their periods, the metric is computed in time O(m^3)."
Applying consensus and replication securely with FLAQR,"PriyankaMondal, MaximilianAlgehed, Owen Arden",9 May 2022,Programming Languages (cs.PL)," Availability is crucial to the security of distributed systems, but guaranteeing availability is hard, especially when participants in the system may act maliciously. Quorum replication protocols provide both integrity and availability: data and computation is replicated at multiple independent hosts, and a quorum of these hosts must agree on the output of all operations applied to the data. Unfortunately, these protocols have high overhead and can be difficult to calibrate for a specific application's needs. Ideally, developers could use high-level abstractions for consensus and replication to write fault-tolerant code by that is secure by construction. This paper presents Flow-Limited Authorization for Quorum Replication (FLAQR), a core calculus for building distributed applications with heterogeneous quorum replication protocols while enforcing end-to-end information security. Our type system ensures that well-typed FLAQR programs cannot_fail_ (experience an unrecoverable error) in ways that violate their type-level specifications. We present noninterference theorems that characterize FLAQR's confidentiality, integrity, and availability in the presence of consensus, replication, and failures, as well as a liveness theorem for the class of majority quorum protocols under a bounded number of faults."
Online Unsupervised Domain Adaptation for Person Re-identification,"HamzaRami, MatthieuOspici, StéphaneLathuilière",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Unsupervised domain adaptation for person re-identification (Person Re-ID) is the task of transferring the learned knowledge on the labeled source domain to the unlabeled target domain. Most of the recent papers that address this problem adopt an offline training setting. More precisely, the training of the Re-ID model is done assuming that we have access to the complete training target domain data set. In this paper, we argue that the target domain generally consists of a stream of data in a practical real-world application, where data is continuously increasing from the different network's cameras. The Re-ID solutions are also constrained by confidentiality regulations stating that the collected data can be stored for only a limited period, hence the model can no longer get access to previously seen target images. Therefore, we present a new yet practical online setting for Unsupervised Domain Adaptation for person Re-ID with two main constraints: Online Adaptation and Privacy Protection. We then adapt and evaluate the state-of-the-art UDA algorithms on this new online setting using the well-known Market-1501, Duke, and MSMT17 benchmarks."
FlowBot3D: Learning 3D Articulation Flow to Manipulate ArticulatedObjects,"BenEisner, Harry Zhang, David Held",9 May 2022,Robotics (cs.RO)," We explore a novel method to perceive and manipulate 3D articulated objects that generalizes to enable a robot to articulate unseen classes of objects. We propose a vision-based system that learns to predict the potential motions of the parts of a variety of articulated objects to guide downstream motion planning of the system to articulate the objects. To predict the object motions, we train a neural network to output a dense vector field representing the point-wise motion direction of the points in the point cloud under articulation. We then deploy an analytical motion planner based on this vector field to achieve a policy that yields maximum articulation. We train the vision system entirely in simulation, and we demonstrate the capability of our system to generalize to unseen object instances and novel categories in both simulation and the real world, deploying our policy on a Sawyer robot with no finetuning. Results show that our system achieves state-of-the-art performance in both simulated and real- world experiments."
EigenNoise: A Contrastive Prior to Warm-Start Representations,"Hunter ScottHeidenreich, Jake RylandWilliams",9 May 2022,Computation and Language (cs.CL)," In this work, we present a naive initialization scheme for word vectors based on a dense, independent co-occurrence model and provide preliminary results that suggest it is competitive and warrants further investigation. Specifically, we demonstrate through information-theoretic minimum description length (MDL) probing that our model, EigenNoise, can approach the performance of empirically trained GloVe despite the lack of any pre-training data (in the case of EigenNoise). We present these preliminary results with interest to set the stage for further investigations into how this competitive initialization works without pre- training data, as well as to invite the exploration of more intelligent initialization schemes informed by the theory of harmonic linguistic structure. Our application of this theory likewise contributes a novel (and effective) interpretation of recent discoveries which have elucidated the underlying distributional information that linguistic representations capture from data and contrast distributions."
Making ProB compatible with SWI-Prolog,"DavidGeleßus, MichaelLeuschel",9 May 2022,Programming Languages (cs.PL)," Even though the core of the Prolog programming language has been standardized by ISO since 1995, it remains difficult to write complex Prolog programs that can run unmodified on multiple Prolog implementations. Indeed, implementations sometimes deviate from the ISO standard and the standard itself fails to cover many features that are essential in practice.   Most Prolog applications thus have to rely on non-standard features, often making them dependent on one particular Prolog implementation and incompatible with others. We examine one such Prolog application: ProB, which has been developed for over 20 years in SICStus Prolog.   The article describes how we managed to refactor the codebase of ProB to also support SWI-Prolog, with the goal of verifying ProB's results using two independent toolchains. This required a multitude of adjustments, ranging from extending the SICStus emulation in SWI-Prolog on to better modularizing the monolithic ProB codebase. We also describe notable compatibility issues and other differences that we encountered in the process, and how we were able to deal with them with few major code changes.   Under consideration for acceptance in TPLP."
Data Size-Aware Downlink Massive MIMO: A Session-Based Approach,"Tung T.Vu, Hien QuocNgo, Minh N.Dao, MichailMatthaiou, Erik G.Larsson","9 May 2022 (v1(https://arxiv.org/abs/2205.04369v1)), lastrevised 11 May 2022 (this version, v3)",Information Theory (cs.IT)," This letter considers the development of transmission strategies for the downlink of massive multiple-input multiple-output networks, with the objective of minimizing the completion time of the transmission. Specifically, we introduce a session-based scheme that splits time into sessions and allocates different rates in different sessions for the different users. In each session, one user is selected to complete its transmission and will not join subsequent sessions, which results in successively lower levels of interference when moving from one session to the next. An algorithm is developed to assign users and allocate transmit power that minimizes the completion time. Numerical results show that our proposed session-based scheme significantly outperforms conventional non- session-based schemes."
Effectively Using Long and Short Sessions for Multi-Session-basedRecommendations,"ZihanWang, GangWu, YanWang",9 May 2022,Information Retrieval (cs.IR)," It is not accurate to make recommendations only based one single current session. Therefore, multi-session-based recommendation(MSBR) is a solution for the problem. Compared with the previous MSBR models, we have made three improvements in this paper. First, the previous work choose to use all the history sessions of the user and/or of his similar users. When the user's current interest changes greatly from the past, most of these sessions can only have negative impacts. Therefore, we select a large number of randomly chosen sessions from the dataset as candidate sessions to avoid over depending on history data. Then we only choose to use the most similar sessions to get the most useful information while reduce the noise caused by dissimilar sessions. Second, in real-world datasets, short sessions account for a large proportion. The RNN often used in previous work is not suitable to process short sessions, because RNN only focuses on the sequential relationship, which we find is not the only relationship between items in short sessions. So, we designed a more suitable method named GAFE based on attention to process short sessions. Third, Although there are few long sessions, they can not be ignored. Not like previous models, which simply process long sessions in the same way as short sessions, we propose LSIS, which can split the interest of long sessions, to make better use of long sessions. Finally, to help recommendations, we also have considered users' long-term interests captured by a multi-layer GRU. Considering the four points above, we built the model ENIREC. Experiments on two real-world datasets show that the comprehensive performance of ENIREC is better than other existing models."
Beyond a Pre-Trained Object Detector: Cross-Modal Textual and VisualContext for Image Captioning,"Chia-WenKuo, ZsoltKira",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Significant progress has been made on visual captioning, largely relying on pre-trained features and later fixed object detectors that serve as rich inputs to auto-regressive models. A key limitation of such methods, however, is that the output of the model is conditioned only on the object detector's outputs. The assumption that such outputs can represent all necessary information is unrealistic, especially when the detector is transferred across datasets. In this work, we reason about the graphical model induced by this assumption, and propose to add an auxiliary input to represent missing information such as object relationships. We specifically propose to mine attributes and relationships from the Visual Genome dataset and condition the captioning model on them. Crucially, we propose (and show to be important) the use of a multi-modal pre-trained model (CLIP) to retrieve such contextual descriptions. Further, object detector models are frozen and do not have sufficient richness to allow the captioning model to properly ground them. As a result, we propose to condition both the detector and description outputs on the image, and show qualitatively and quantitatively that this can improve grounding. We validate our method on image captioning, perform thorough analyses of each component and importance of the pre-trained multi-modal model, and demonstrate significant improvements over the current state of the art, specifically +7.5% in CIDEr and +1.3% in BLEU-4 metrics."
FC$^3$: Feasibility-Based Control Chain Coordination,"JasonHarris, DannyDriess, MarcToussaint",9 May 2022,Robotics (cs.RO)," Hierarchical coordination of controllers often uses symbolic state representations that fully abstract their underlying low-level controllers, treating them as ""black boxes"" to the symbolic action abstraction. This paper proposes a framework to realize robust behavior, which we call Feasibility-based Control Chain Coordination (FC$^3$). Our controllers expose the geometric features and constraints they operate on. Based on this, FC$^3$ can reason over the controllers' feasibility and their sequence feasibility. For a given task, FC$^3$ first automatically constructs a library of potential controller chains using a symbolic action tree, which is then used to coordinate controllers in a chain, evaluate task feasibility, as well as switching between controller chains if necessary. In several real-world experiments we demonstrate FC$^3$'s robustness and awareness of the task's feasibility through its own actions and gradual responses to different interferences."
The Soft Skills of Software Learning Development: the PsychologicalDimensions of Computing and Security Behaviours,MatthewIvory,9 May 2022,Software Engineering (cs.SE)," When writing software code, developers typically prioritise functionality over security, either consciously or unconsciously through biases and heuristics. This is often attributed to tangible pressures such as client requirements, but little is understood about the psychological dimensions affecting security behaviours. There is an increasing demand for understanding how psychological skills affect secure software development and to understand how these skills themselves are developed during the learning process.   This doctoral research explores this research space, with aims to identify important workplace-based skills for software developers; to identify and empirically investigate the soft skills behind these workplace skills in order to understand how soft skills can influence security behaviours; and, to identify ways to introduce and teach soft skills to computer science students to prepare the future generation of software developers.   The motivations behind this research are presented alongside the work plan. Three distinct phases are introduced, along with planned analyses. Phase one is currently in the data collection stage, with the second phase in planning. Prior relevant work is highlighted, and the paper concludes with a presentation of preliminary results and the planned next steps."
Towards Operationalising Responsible AI: An Empirical Study,"ConradSanderson, Qinghua Lu, DavidDouglas, Xiwei Xu, Liming Zhu, JonWhittle",9 May 2022,Computers and Society (cs.CY)," While artificial intelligence (AI) has great potential to transform many industries, there are concerns about its ability to make decisions in a responsible way. Many AI ethics guidelines and principles have been recently proposed by governments and various organisations, covering areas such as privacy, accountability, safety, reliability, transparency, explainability, contestability, and fairness. However, such principles are typically high-level and do not provide tangible guidance on how to design and develop responsible AI systems. To address this shortcoming, we present an empirical study involving interviews with 21 scientists and engineers, designed to gain insight into practitioners' perceptions of AI ethics principles, their possible implementation, and the trade-offs between the principles. The salient findings cover four aspects of AI system development: (i) overall development process, (ii) requirements engineering, (iii) design and implementation, (iv) deployment and operation."
Unified framework for Identity and Imagined Action Recognition fromEEG patterns,"MarcoBuzzelli, PaoloNapoletano, SimoneBianco",9 May 2022,Human-Computer Interaction (cs.HC)," We present a unified deep learning framework for user identity recognition and imagined action recognition, based on electroencephalography (EEG) signals. Our solution exploits a novel phased subsampling preprocessing step as a form of data augmentation, and a mesh-to-image representation to encode the inherent local spatial relationships of multi- electrode EEG signals. The resulting image-like data is then fed to a convolutional neural network, to process the local spatial dependencies, and eventually analyzed through a Bidirectional LSTM module, to focus on temporal relationships. Our solution is compared against several methods in the state of the art, showing comparable or superior performance on different tasks. Preliminary experiments are also conducted in order to direct future works towards everyday applications relying on a reduced set of EEG electrodes."
Seamless Integration of Analysis and Design: Automatic CADReconstruction of Post-Analysis Geometries:,"SebastianHube, RoxanaPohlmann, StefanieElgeti",9 May 2022,"Computational Engineering, Finance, and Science (cs.CE)"," A key step during industrial design is the passing of design information from computer aided design (CAD) to analysis tools (CAE) and vice versa. Here, one is faced with a severe incompatibility in geometry representation: While CAD is usually based on surface representations, analysis mostly relies on volumetric representations. The forward pass, i.e., converting CAD data to computational meshes, is well understood and established. However, the same does not hold for the inverse direction, i.e., CAD reconstruction of deformed geometries resulting, e.g., from shape optimization. The few reconstruction methods reported mainly rely on spline fitting, in particular methods that rely on creating new splines simililar to shape reconstruction from 3D imaging. In contrast, this paper studies a novel approach that reuses the CAD data given in the initial design. We show that this concept leads to precise shape reconstructions while also preserving the initial notion of features defined during design. Furthermore, reusing the initial CAD representation reduces the shape reconstruction problem to a shape modification problem. We study this unique feature and show that it enables the reconstruction of CAD data from computational meshes by composing each spline in the initial CAD data with a single, global deformation spline. While post-processing is needed for use in current CAD software, this novel approach not only allows creating watertight models, but also enables reconstructing complete CAD models even from defeatured computational meshes."
XSTEM: An exemplar-based stemming algorithm,KirkBaker,9 May 2022,Computation and Language (cs.CL)," Stemming is the process of reducing related words to a standard form by removing affixes from them. Existing algorithms vary with respect to their complexity, configurability, handling of unknown words, and ability to avoid under- and over-stemming. This paper presents a fast, simple, configurable, high-precision, high-recall stemming algorithm that combines the simplicity and performance of word-based lookup tables with the strong generalizability of rule-based methods to avert problems with out-of- vocabulary words."
Learning Self-adaptations for IoT Networks: A Genetic ProgrammingApproach,"Jia Li, ShivaNejati, MehrdadSabetzadeh",9 May 2022,Software Engineering (cs.SE)," Internet of Things (IoT) is a pivotal technology in application domains that require connectivity and interoperability between large numbers of devices. IoT systems predominantly use a software-defined network (SDN) architecture as their core communication backbone. This architecture offers several advantages, including the flexibility to make IoT networks self- adaptive through software programmability. In general, self-adaptation solutions need to periodically monitor, reason about, and adapt a running system. The adaptation step involves generating an adaptation strategy and applying it to the running system whenever an anomaly arises. In this paper, we argue that, rather than generating individual adaptation strategies, the goal should be to adapt the logic / code of the running system in such a way that the system itself would learn how to steer clear of future anomalies, without triggering self-adaptation too frequently. We instantiate and empirically assess this idea in the context of IoT networks. Specifically, using genetic programming (GP), we propose a self-adaptation solution that continuously learns and updates the control constructs in the data- forwarding logic of SDN-based IoT networks. Our evaluation, performed using open-source synthetic and industrial data, indicates that, compared to a baseline adaptation technique that attempts to generate individual adaptations, our GP-based approach is more effective in resolving network congestion, and further, reduces the frequency of adaptation interventions over time. In addition, we compare our approach against a standard data- forwarding algorithm from the network literature, demonstrating that our approach significantly reduces packet loss."
A Novel Augmented Reality Ultrasound Framework Using an RGB-D Cameraand a 3D-printed Marker,"YitianZhou, GaétanLelu, BorisLabbé, GuillaumePasquier, Pierre LeGargasson, AlbertMurienne, LaurentLaunay",9 May 2022,Image and Video Processing (eess.IV)," Purpose. Ability to locate and track ultrasound images in the 3D operating space is of great benefit for multiple clinical applications. This is often accomplished by tracking the probe using a precise but expensive optical or electromagnetic tracking system. Our goal is to develop a simple and low cost augmented reality echography framework using a standard RGB-D Camera.   Methods. A prototype system consisting of an Occipital Structure Core RGB-D camera, a specifically-designed 3D marker, and a fast point cloud registration algorithm FaVoR was developed and evaluated on an Ultrasonix ultrasound system. The probe was calibrated on a 3D-printed N-wire phantom using the software PLUS toolkit. The proposed calibration method is simplified, requiring no additional markers or sensors attached to the phantom. Also, a visualization software based on OpenGL was developed for the augmented reality application.   Results. The calibrated probe was used to augment a real-world video in a simulated needle insertion scenario. The ultrasound images were rendered on the video, and visually-coherent results were observed. We evaluated the end-to-end accuracy of our AR US framework on localizing a cube of 5 cm size. From our two experiments, the target pose localization error ranges from 5.6 to 5.9 mm and from -3.9 to 4.2 degrees.   Conclusion. We believe that with the potential democratization of RGB-D cameras integrated in mobile devices and AR glasses in the future, our prototype solution may facilitate the use of 3D freehand ultrasound in clinical routine. Future work should include a more rigorous and thorough evaluation, by comparing the calibration accuracy with those obtained by commercial tracking solutions in both simulated and real medical scenarios."
Towards Feature Selection for Ranking and Classification ExploitingQuantum Annealers,"Maurizio FerrariDacrema, FabioMoroni, RiccardoNembrini, NicolaFerro, GuglielmoFaggioli, PaoloCremonesi",9 May 2022,Information Retrieval (cs.IR)," Feature selection is a common step in many ranking, classification, or prediction tasks and serves many purposes. By removing redundant or noisy features, the accuracy of ranking or classification can be improved and the computational cost of the subsequent learning steps can be reduced. However, feature selection can be itself a computationally expensive process. While for decades confined to theoretical algorithmic papers, quantum computing is now becoming a viable tool to tackle realistic problems, in particular special-purpose solvers based on the Quantum Annealing paradigm. This paper aims to explore the feasibility of using currently available quantum computing architectures to solve some quadratic feature selection algorithms for both ranking and classification. The experimental analysis includes 15 state-of-the-art datasets. The effectiveness obtained with quantum computing hardware is comparable to that of classical solvers, indicating that quantum computers are now reliable enough to tackle interesting problems. In terms of scalability, current generation quantum computers are able to provide a limited speedup over certain classical algorithms and hybrid quantum-classical strategies show lower computational cost for problems of more than a thousand features."
Transfer Learning Based Efficient Traffic Prediction with LimitedTraining Data,"SajalSaha, AnwarHaque, GregSidebottom",9 May 2022,Machine Learning (cs.LG)," Efficient prediction of internet traffic is an essential part of Self Organizing Network (SON) for ensuring proactive management. There are many existing solutions for internet traffic prediction with higher accuracy using deep learning. But designing individual predictive models for each service provider in the network is challenging due to data heterogeneity, scarcity, and abnormality. Moreover, the performance of the deep sequence model in network traffic prediction with limited training data has not been studied extensively in the current works. In this paper, we investigated and evaluated the performance of the deep transfer learning technique in traffic prediction with inadequate historical data leveraging the knowledge of our pre-trained model. First, we used a comparatively larger real-world traffic dataset for source domain prediction based on five different deep sequence models: Recurrent Neural Network (RNN), Long Short-Term Memory (LSTM), LSTM Encoder-Decoder (LSTM_En_De), LSTM_En_De with Attention layer (LSTM_En_De_Atn), and Gated Recurrent Unit (GRU). Then, two best-performing models, LSTM_En_De and LSTM_En_De_Atn, from the source domain with an accuracy of 96.06% and 96.05% are considered for the target domain prediction. Finally, four smaller traffic datasets collected for four particular sources and destination pairs are used in the target domain to compare the performance of the standard learning and transfer learning in terms of accuracy and execution time. According to our experimental result, transfer learning helps to reduce the execution time for most cases, while the model's accuracy is improved in transfer learning with a larger training session."
Fatigue Prediction in Outdoor Running Conditions using Audio Data,"AndreasTriantafyllopoulos, Sandra Ottl, AlexanderGebhard, Esther Rituerto-González, MirkoJaumann, SteffenHüttner, ValerieDieter, PatrickSchneeweiß, IngaKrauß, MauriceGerczuk, ShahinAmiriparian, Björn W.Schuller",9 May 2022,Sound (cs.SD)," Although running is a common leisure activity and a core training regiment for several athletes, between $29\%$ and $79\%$ of runners sustain an overuse injury each year. These injuries are linked to excessive fatigue, which alters how someone runs. In this work, we explore the feasibility of modelling the Borg received perception of exertion (RPE) scale (range: $[6-20]$), a well-validated subjective measure of fatigue, using audio data captured in realistic outdoor environments via smartphones attached to the runners' arms. Using convolutional neural networks (CNNs) on log-Mel spectrograms, we obtain a mean absolute error of $2.35$ in subject-dependent experiments, demonstrating that audio can be effectively used to model fatigue, while being more easily and non-invasively acquired than by signals from other sensors."
Object Detection with Spiking Neural Networks on Automotive Event Data,"LoïcCordone, BenoîtMiramond, PhilippeThierion",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Automotive embedded algorithms have very high constraints in terms of latency, accuracy and power consumption. In this work, we propose to train spiking neural networks (SNNs) directly on data coming from event cameras to design fast and efficient automotive embedded applications. Indeed, SNNs are more biologically realistic neural networks where neurons communicate using discrete and asynchronous spikes, a naturally energy- efficient and hardware friendly operating mode. Event data, which are binary and sparse in space and time, are therefore the ideal input for spiking neural networks. But to date, their performance was insufficient for automotive real-world problems, such as detecting complex objects in an uncontrolled environment. To address this issue, we took advantage of the latest advancements in matter of spike backpropagation - surrogate gradient learning, parametric LIF, SpikingJelly framework - and of our new \textit{voxel cube} event encoding to train 4 different SNNs based on popular deep learning networks: SqueezeNet, VGG, MobileNet, and DenseNet. As a result, we managed to increase the size and the complexity of SNNs usually considered in the literature. In this paper, we conducted experiments on two automotive event datasets, establishing new state-of-the-art classification results for spiking neural networks. Based on these results, we combined our SNNs with SSD to propose the first spiking neural networks capable of performing object detection on the complex GEN1 Automotive Detection event dataset."
On the Distribution of Partially Symmetric Codes for AutomorphismEnsemble Decoding,"CharlesPillet, ValerioBioglio",9 May 2022,Information Theory (cs.IT)," Permutation list decoding recently draws attention as a possible alternative for list decoding of polar codes. In this letter, we investigate the distribution of Reed-Muller partially symmetric codes (RM-PSC), a family of polar codes yielding good performances under permutation list decoding. We prove the existence of these codes for almost all code dimensions if the code length is not greater than 256. Moreover, we analyze the absorption group of this family of codes under SC decoding, showing that it may include one or more blocks of size larger than one. Finally, we show by simulations that RM-PSC can outperform state-of-the-art polar codes constructions in terms of error correcting performance for short code lengths, while reducing decoding latency."
Tensor rank bounds and explicit QTT representations for the inversesof circulant matrices,"LevVysotsky, MaximRakhuba",9 May 2022,Numerical Analysis (math.NA)," In this paper, we are concerned with the inversion of circulant matrices and their quantized tensor-train (QTT) structure. In particular, we show that the inverse of a complex circulant matrix $A$, generated by the first column of the form $(a_0,\dots,a_{m-1},0,\dots,0,a_{-n},\dots, a_{-1})^\top$ admits a QTT representation with the QTT ranks bounded by $(m+n)$. Under certain assumptions on the entries of $A$, we also derive an explicit QTT representation of $A^{-1}$. The latter can be used, for instance, to overcome stability issues arising when numerically solving differential equations with periodic boundary conditions in the QTT format."
Panoptic Neural Fields: A Semantic Object-Aware Neural SceneRepresentation,"AbhijitKundu, KyleGenova, Xiaoqi Yin, AlirezaFathi, CarolinePantofaru, LeonidasGuibas, AndreaTagliasacchi, FrankDellaert, ThomasFunkhouser",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We present Panoptic Neural Fields (PNF), an object-aware neural scene representation that decomposes a scene into a set of objects (things) and background (stuff). Each object is represented by an oriented 3D bounding box and a multi-layer perceptron (MLP) that takes position, direction, and time and outputs density and radiance. The background stuff is represented by a similar MLP that additionally outputs semantic labels. Each object MLPs are instance-specific and thus can be smaller and faster than previous object-aware approaches, while still leveraging category- specific priors incorporated via meta-learned initialization. Our model builds a panoptic radiance field representation of any scene from just color images. We use off-the-shelf algorithms to predict camera poses, object tracks, and 2D image semantic segmentations. Then we jointly optimize the MLP weights and bounding box parameters using analysis-by-synthesis with self-supervision from color images and pseudo-supervision from predicted semantic segmentations. During experiments with real-world dynamic scenes, we find that our model can be used effectively for several tasks like novel view synthesis, 2D panoptic segmentation, 3D scene editing, and multiview depth prediction."
Wavelet-Based Hybrid Machine Learning Model for Out-of-distributionInternet Traffic Prediction,"SajalSaha, AnwarHaque, GregSidebottom",9 May 2022,Machine Learning (cs.LG)," Efficient prediction of internet traffic is essential for ensuring proactive management of computer networks. Nowadays, machine learning approaches show promising performance in modeling real-world complex traffic. However, most existing works assumed that model training and evaluation data came from identical distribution. But in practice, there is a high probability that the model will deal with data from a slightly or entirely unknown distribution in the deployment phase. This paper investigated and evaluated machine learning performances using eXtreme Gradient Boosting, Light Gradient Boosting Machine, Stochastic Gradient Descent, Gradient Boosting Regressor, CatBoost Regressor, and their stacked ensemble model using data from both identical and out-of distribution. Also, we proposed a hybrid machine learning model integrating wavelet decomposition for improving out-of-distribution prediction as standalone models were unable to generalize very well. Our experimental results show the best performance of the standalone ensemble model with an accuracy of 96.4%, while the hybrid ensemble model improved it by 1% for in-distribution data. But its performance dropped significantly when tested with three different datasets having a distribution shift than the training set. However, our proposed hybrid model considerably reduces the performance gap between identical and out-of-distribution evaluation compared with the standalone model, indicating the decomposition technique's effectiveness in the case of out-of-distribution generalization."
Protecting Data from all Parties: Combining FHE and DP in FederatedLearning,"Arnaud GrivetSébert, RenaudSirdey, Oana Stan, Cédric Gouy-Pailler",9 May 2022,Cryptography and Security (cs.CR)," This paper tackles the problem of ensuring training data privacy in a federated learning context. Relying on Fully Homomorphic Encryption (FHE) and Differential Privacy (DP), we propose a secure framework addressing an extended threat model with respect to privacy of the training data. Notably, the proposed framework protects the privacy of the training data from all participants, namely the training data owners and an aggregating server. In details, while homomorphic encryption blinds a semi- honest server at learning stage, differential privacy protects the data from semi-honest clients participating in the training process as well as curious end-users with black-box or white-box access to the trained model. This paper provides with new theoretical and practical results to enable these techniques to be effectively combined. In particular, by means of a novel stochastic quantization operator, we prove differential privacy guarantees in a context where the noise is quantified and bounded due to the use of homomorphic encryption. The paper is concluded by experiments which show the practicality of the entire framework in spite of these interferences in terms of both model quality (impacted by DP) and computational overheads (impacted by FHE)."
"Insights on Modelling Physiological, Appraisal, and AffectiveIndicators of Stress using Audio Features","AndreasTriantafyllopoulos, SandraZänkert, Alice Baird, JulianKonzok, Brigitte M.Kudielka, Björn W.Schuller",9 May 2022,Sound (cs.SD)," Stress is a major threat to well-being that manifests in a variety of physiological and mental symptoms. Utilising speech samples collected while the subject is undergoing an induced stress episode has recently shown promising results for the automatic characterisation of individual stress responses. In this work, we introduce new findings that shed light onto whether speech signals are suited to model physiological biomarkers, as obtained via cortisol measurements, or self-assessed appraisal and affect measurements. Our results show that different indicators impact acoustic features in a diverse way, but that their complimentary information can nevertheless be effectively harnessed by a multi-tasking architecture to improve prediction performance for all of them."
HierAttn: Effectively Learn Representations from Stage Attention andBranch Attention for Skin Lesions Diagnosis,"WeiDai, RuiLiu, TianyiWu, MinWang, Jianqin Yin, Jun Liu","9 May 2022 (v1(https://arxiv.org/abs/2205.04326v1)), lastrevised 10 May 2022 (this version, v2)",Image and Video Processing (eess.IV)," An accurate and unbiased examination of skin lesions is critical for the early diagnosis and treatment of skin cancers. The visual feature of the skin lesions varies significantly because skin images are collected from patients with different skin colours by using various devices. Recent studies have developed ensembled convolutional neural networks (CNNs) to classify the images for early diagnosis. However, the practical use of CNNs is limited because their network structures are heavyweight and neglect contextual information. Vision transformers (ViTs) learn the global features by self-attention mechanisms, but they also have comparatively large model sizes (more than 100M). To address these limitations, we introduce HierAttn, a lite and effective neural network with hierarchical and self attention. HierAttn applies a novel strategy based on learning local and global features by a multi-stage and hierarchical network. The efficacy of HierAttn was evaluated by using the dermoscopy images dataset ISIC2019 and smartphone photos dataset PAD-UFES-20. The experimental results show that HierAttn achieves the best top-1 accuracy and AUC among state-of-the-art mobile networks, including MobileNetV3 and MobileViT. The code is available at [this https URL](https://github.com/anthonyweidai/HierAttn)."
ISA-bEL: Intelligent Search Algorithm based on Entity Linking,"Rubén GonzálezSendino, MónicaOrtega, CarlosCarrasco",9 May 2022,Computation and Language (cs.CL)," Nowadays, the way in which the people interact with computers has changed. Text- or voice-based interfaces are being widely applied in different industries. Among the most used ways of processing the user input are those based on intents or retrieval algorithms. In these solutions, important information of the user could be lost in the process. For the proposed natural language processing pipeline the entities are going to take a principal role, under the assumption that entities are where the purpose of the user resides. Entities fed with context will be projected to a specific domain supported by a knowledge graph, resulting in what has been named as linked entities. These linked entities serve then as a key for searching a top level aggregation concept within our knowledge graph."
Evaluating the Fairness Impact of Differentially Private SyntheticData,"BlakeBullwinkel, KristenGrabarz, Lily Ke, ScarlettGong, ChrisTanner, Joshua Allen",9 May 2022,Machine Learning (cs.LG)," Differentially private (DP) synthetic data is a promising approach to maximizing the utility of data containing sensitive information. Due to the suppression of underrepresented classes that is often required to achieve privacy, however, it may be in conflict with fairness. We evaluate four DP synthesizers and present empirical results indicating that three of these models frequently degrade fairness outcomes on downstream binary classification tasks. We draw a connection between fairness and the proportion of minority groups present in the generated synthetic data, and find that training synthesizers on data that are pre-processed via a multi- label undersampling method can promote more fair outcomes without degrading accuracy."
NEPTUNE: Network- and GPU-aware Management of Serverless Functions atthe Edge,"LucianoBaresi, Davide Yi XianHu, GiovanniQuattrocchi, LucaTerracciano",9 May 2022,Software Engineering (cs.SE)," Nowadays a wide range of applications is constrained by low- latency requirements that cloud infrastructures cannot meet. Multi-access Edge Computing (MEC) has been proposed as the reference architecture for executing applications closer to users and reduce latency, but new challenges arise: edge nodes are resource-constrained, the workload can vary significantly since users are nomadic, and task complexity is increasing (e.g., machine learning inference). To overcome these problems, the paper presents NEPTUNE, a serverless-based framework for managing complex MEC solutions. NEPTUNE i) places functions on edge nodes according to user locations, ii) avoids the saturation of single nodes, iii) exploits GPUs when available, and iv) allocates resources (CPU cores) dynamically to meet foreseen execution times. A prototype, built on top of K3S, was used to evaluate NEPTUNE on a set of experiments that demonstrate a significant reduction in terms of response time, network overhead, and resource consumption compared to three state-of-the-art approaches."
Competition and Cooperation of Autonomous Ridepooling Services: Game-Based Simulation of a Broker Concept,"RomanEngelhardt, PatrickMalcolm, FlorianDandl, KlausBogenberger",9 May 2022,Multiagent Systems (cs.MA)," Autonomous mobility on demand services have the potential to disrupt the future mobility system landscape. Ridepooling services in particular can decrease land consumption and increase transportation efficiency by increasing the average vehicle occupancy. Nevertheless, because ridepooling services require a sufficient user base for pooling to take effect, their performance can suffer if multiple operators offer such a service and must split the demand. This study presents a simulation framework for evaluating the impact of competition and cooperation among multiple ridepooling providers. Two different kinds of interaction via a broker platform are compared with the base cases of a single monopolistic operator and two independent operators with divided demand. In the first, the broker presents trip offers from all operators to customers (similar to a mobility-as-a-service platform), who can then freely choose an operator. In the second, a regulated broker platform can manipulate operator offers with the goal of shifting the customer-operator assignment from a user equilibrium towards a system optimum. To model adoptions of the service design depending on the different interaction scenario, a game setting is introduced. Within alternating turns between operators, operators can adapt parameters of their service (fleet size and objective function) to maximize profit. Results for a case study based on Manhattan taxi data, show that operators generate the highest profit in the broker setting while operating the largest fleet. Additionally, pooling efficiency can nearly be maintained compared to a single operator. With the resulting increased service rate, the regulated competition benefits not only operators (profit) and cities (increased pooling efficiency), but also customers. Contrarily, when users can decide freely, the lowest pooling efficiency and operator profit is observed."
Integrating Social Media into the Design Process,"MorvaSaaty, Jaitun V.Patel, Derek Haqq, Timothy L.Stelter, D. ScottMcCrickard",9 May 2022,Human-Computer Interaction (cs.HC)," Social media captures examples of people's behaviors, actions, beliefs, and sentiments. As a result, it can be a valuable source of information and inspiration for HCI research and design. Social media technologies can improve, inform, and strengthen insights to better understand and represent user populations. To understand the position of social media research and analysis in the design process, this paper seeks to highlight shortcomings of using traditional research methods (e.g., interviews, focus groups) that ignore or don't adequately reflect relevant social media, and this paper speculates about the importance and benefits of leveraging social media for establishing context in supplement with these methods. We present examples that guide our thinking and introduce discussion around concerns related to using social media data."
Characterizing Positionality in Games of Infinite Duration overInfinite Graphs,PierreOhlmann,9 May 2022,Computer Science and Game Theory (cs.GT)," We study turn-based quantitative games of infinite duration opposing two antagonistic players and played over graphs. This model is widely accepted as providing the adequate framework for formalizing the synthesis question for reactive systems. This important application motivates the question of strategy complexity: which valuations (or payoff functions) admit optimal positional strategies (without memory)? Valuations for which both players have optimal positional strategies have been characterized by Gimbert and Zielonka for finite graphs and by Colcombet and Niwiński for infinite graphs.   However, for reactive synthesis, existence of optimal positional strategies for the opponent (which models an antagonistic environment) is irrelevant. Despite this fact, not much is known about valuations for which the protagonist admits optimal positional strategies, regardless of the opponent. In this work, we characterize valuations which admit such strategies over infinite graphs. Our characterization uses the vocabulary of universal graphs, which has also proved useful in understanding recent breakthrough results regarding the complexity of parity games.   More precisely, we show that a valuation admitting universal graphs which are monotonic and well-ordered is positional over all game graphs, and -- more surprisingly -- that the converse is also true for valuations admitting neutral colors. We prove the applicability and elegance of the framework by unifying a number of known positionality results, proving a few stronger ones, and establishing closure under lexicographical products."
Visualizing WSPDs and their applications,"AnirbanGhosh, F.N.U.Shariful, DavidWisnosky",9 May 2022,Computational Geometry (cs.CG)," Introduced by Callahan and Kosaraju back in 1995, the concept of well-separated pair decomposition (WSPD) has occupied a special significance in computational geometry when it comes to solving distance problems in $d$-space. We present an in-browser tool that can be used to visualize WSPDs and several of their applications in $2$-space. Apart from research, it can also be used by instructors for introducing WSPDs in a classroom setting. The tool will be permanently maintained by the third author at [this https URL](https://wisno33.github.io/VisualizingWSPDsAndTheirApplications/)."
"CounterGeDi: A controllable approach to generate polite, detoxifiedand emotional counterspeech","PunyajoySaha, KanishkSingh, AdarshKumar, BinnyMathew, AnimeshMukherjee",9 May 2022,Computation and Language (cs.CL)," Recently, many studies have tried to create generation models to assist counter speakers by providing counterspeech suggestions for combating the explosive proliferation of online hate. However, since these suggestions are from a vanilla generation model, they might not include the appropriate properties required to counter a particular hate speech instance. In this paper, we propose CounterGeDi - an ensemble of generative discriminators (GeDi) to guide the generation of a DialoGPT model toward more polite, detoxified, and emotionally laden counterspeech. We generate counterspeech using three datasets and observe significant improvement across different attribute scores. The politeness and detoxification scores increased by around 15% and 6% respectively, while the emotion in the counterspeech increased by at least 10% across all the datasets. We also experiment with triple-attribute control and observe significant improvement over single attribute results when combining complementing attributes, e.g., politeness, joyfulness and detoxification. In all these experiments, the relevancy of the generated text does not deteriorate due to the application of these controls"
Multi-modal Semantic SLAM for Complex Dynamic Environments,"Jing YingKo, HanWang, LihuaXie",9 May 2022,Robotics (cs.RO)," Simultaneous Localization and Mapping (SLAM) is one of the most essential techniques in many real-world robotic applications. The assumption of static environments is common in most SLAM algorithms, which however, is not the case for most applications. Recent work on semantic SLAM aims to understand the objects in an environment and distinguish dynamic information from a scene context by performing image-based segmentation. However, the segmentation results are often imperfect or incomplete, which can subsequently reduce the quality of mapping and the accuracy of localization. In this paper, we present a robust multi-modal semantic framework to solve the SLAM problem in complex and highly dynamic environments. We propose to learn a more powerful object feature representation and deploy the mechanism of looking and thinking twice to the backbone network, which leads to a better recognition result to our baseline instance segmentation model. Moreover, both geometric-only clustering and visual semantic information are combined to reduce the effect of segmentation error due to small-scale objects, occlusion and motion blur. Thorough experiments have been conducted to evaluate the performance of the proposed method. The results show that our method can precisely identify dynamic objects under recognition imperfection and motion blur. Moreover, the proposed SLAM framework is able to efficiently build a static dense map at a processing rate of more than 10 Hz, which can be implemented in many practical applications. Both training data and the proposed method is open sourced at [this https URL](https://github.com/wh200720041/MMS_SLAM)."
Learning A Simulation-based Visual Policy for Real-world Peg In UnseenHoles,"LiangXie, HongxiangYu, KechunXu, TongYang, MinhangWang, HaojianLu, RongXiong, YueWang",9 May 2022,Robotics (cs.RO)," This paper proposes a learning-based visual peg-in-hole that enables training with several shapes in simulation, and adapting to arbitrary unseen shapes in real world with minimal sim-to-real cost. The core idea is to decouple the generalization of the sensory-motor policy to the design of a fast-adaptable perception module and a simulated generic policy module. The framework consists of a segmentation network (SN), a virtual sensor network (VSN), and a controller network (CN). Concretely, the VSN is trained to measure the pose of the unseen shape from a segmented image. After that, given the shape-agnostic pose measurement, the CN is trained to achieve generic peg-in-hole. Finally, when applying to real unseen holes, we only have to fine-tune the SN required by the simulated VSN+CN. To further minimize the transfer cost, we propose to automatically collect and annotate the data for the SN after one-minute human teaching. Simulated and real-world results are presented under the configurations of eye-to/in-hand. An electric vehicle charging system with the proposed policy inside achieves a 10/10 success rate in 2-3s, using only hundreds of auto- labeled samples for the SN transfer."
A modular software framework for the design and implementation ofptychography algorithms,"FrancescoGuzzi, GeorgeKourousias, FulvioBillè, RobertoPugliese, AlessandraGianoncelli, SergioCarrato",6 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Computational methods are driving high impact microscopy techniques such as ptychography. However, the design and implementation of new algorithms is often a laborious process, as many parts of the code are written in close-to-the-hardware programming constructs to speed up the reconstruction. In this paper, we present SciComPty, a new ptychography software framework aiming at simulating ptychography datasets and testing state-of-the-art and new reconstruction algorithms. Despite its simplicity, the software leverages GPU accelerated processing through the PyTorch CUDA interface. This is essential to design new methods that can readily be employed. As an example, we present an improved position refinement method based on Adam and a new version of the rPIE algorithm, adapted for partial coherence setups. Results are shown on both synthetic and real datasets. The software is released as open-source."
Do You Think You Can Hold Me? The Real Challenge of Problem-SpaceEvasion Attacks,"HarelBerger, Amit Dvir, Chen Hajaj, Rony Ronen",9 May 2022,Cryptography and Security (cs.CR)," Android malware is a spreading disease in the virtual world. Anti- virus and detection systems continuously undergo patches and updates to defend against these threats. Most of the latest approaches in malware detection use Machine Learning (ML). Against the robustifying effort of detection systems, raise the \emph{evasion attacks}, where an adversary changes its targeted samples so that they are misclassified as benign. This paper considers two kinds of evasion attacks: feature-space and problem- space. \emph{Feature-space} attacks consider an adversary who manipulates ML features to evade the correct classification while minimizing or constraining the total manipulations. \textit{Problem-space} attacks refer to evasion attacks that change the actual sample. Specifically, this paper analyzes the gap between these two types in the Android malware domain. The gap between the two types of evasion attacks is examined via the retraining process of classifiers using each one of the evasion attack types. The experiments show that the gap between these two types of retrained classifiers is dramatic and may increase to 96\%. Retrained classifiers of feature-space evasion attacks have been found to be either less effective or completely ineffective against problem-space evasion attacks. Additionally, exploration of different problem-space evasion attacks shows that retraining of one problem-space evasion attack may be effective against other problem- space evasion attacks."
A rational and complete notion of delay for streaming stringtransducers,"EmmanuelFiliot, IsmaëlJecker, ChristofLöding, SarahWinter",9 May 2022,Formal Languages and Automata Theory (cs.FL)," The notion of delay between finite transducers is a core element of numerous fundamental results of transducer theory. The goal of this work is to provide a similar notion for more complex abstract machines: we introduce a new notion of delay tailored to measure the similarity between streaming string transducers (SST). We show that our notion is rational: we design a finite automaton that can check whether the delay between two SSTs is smaller than some given bound. As a consequence, our notion enjoys good decidability properties: in particular, while equivalence between (non- deterministic) SSTs is undecidable, we show that equivalence up to fixed delay is decidable. Moreover, we show that our notion has good completeness properties: we prove that two functional SSTs are equivalent if and only if they are equivalent up to some (computable) bounded delay."
Machine Learning Based Propagation Loss Module for Enabling DigitalTwins of Wireless Networks in ns-3,"Eduardo NunoAlmeida, MohammedRushad, Sumanth ReddyKota, AkshatNambiar, Hardik L.Harti, ChinmayGupta, DanishWaseem, GonçaloSantos, HelderFontes, RuiCampos, Mohit P.Tahiliani",9 May 2022,Networking and Internet Architecture (cs.NI)," The creation of digital twins of experimental testbeds allows the validation of novel wireless networking solutions and the evaluation of their performance in realistic conditions, without the cost, complexity and limited availability of experimental testbeds. Current trace-based simulation approaches for ns-3 enable the repetition and reproduction of the same exact conditions observed in past experiments. However, they are limited by the fact that the simulation setup must exactly match the original experimental setup, including the network topology, the mobility patterns and the number of network nodes. In this paper, we propose the Machine Learning based Propagation Loss (MLPL) module for ns-3. Based on network traces collected in an experimental testbed, the MLPL module estimates the propagation loss as the sum of a deterministic path loss and a stochastic fast-fading loss. The MLPL module is validated with unit tests. Moreover, we test the MLPL module with real network traces, and compare the results obtained with existing propagation loss models in ns-3 and real experimental results. The results obtained show that the MLPL module can accurately predict the propagation loss observed in a real environment and reproduce the experimental conditions of a given testbed, enabling the creation of digital twins of wireless network environments in ns-3."
Anatomy-aware Self-supervised Learning for Anomaly Detection in ChestRadiographs,"JunyaSato, YukiSuzuki, TomohiroWataya, DaikiNishigaki, Kosuke Kita, KazukiYamagata, NoriyukiTomiyama, Shoji Kido",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Large numbers of labeled medical images are essential for the accurate detection of anomalies, but manual annotation is labor-intensive and time-consuming. Self-supervised learning (SSL) is a training method to learn data-specific features without manual annotation. Several SSL-based models have been employed in medical image anomaly detection. These SSL methods effectively learn representations in several field-specific images, such as natural and industrial product images. However, owing to the requirement of medical expertise, typical SSL-based models are inefficient in medical image anomaly detection. We present an SSL-based model that enables anatomical structure-based unsupervised anomaly detection (UAD). The model employs the anatomy-aware pasting (AnatPaste) augmentation tool. AnatPaste employs a threshold-based lung segmentation pretext task to create anomalies in normal chest radiographs, which are used for model pretraining. These anomalies are similar to real anomalies and help the model recognize them. We evaluate our model on three opensource chest radiograph datasets. Our model exhibit area under curves (AUC) of 92.1%, 78.7%, and 81.9%, which are the highest among existing UAD models. This is the first SSL model to employ anatomical information as a pretext task. AnatPaste can be applied in various deep learning models and downstream tasks. It can be employed for other modalities by fixing appropriate segmentation. Our code is publicly available at: [this https URL](https://github.com/jun-sato/AnatPaste)."
Siamese Object Tracking for Unmanned Aerial Vehicle: A Review andComprehensive Analysis,"ChanghongFu, KunhanLu, GuangzeZheng, Junjie Ye, Ziang Cao, Bowen Li",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Unmanned aerial vehicle (UAV)-based visual object tracking has enabled a wide range of applications and attracted increasing attention in the field of remote sensing because of its versatility and effectiveness. As a new force in the revolutionary trend of deep learning, Siamese networks shine in visual object tracking with their promising balance of accuracy, robustness, and speed. Thanks to the development of embedded processors and the gradual optimization of deep neural networks, Siamese trackers receive extensive research and realize preliminary combinations with UAVs. However, due to the UAV's limited onboard computational resources and the complex real-world circumstances, aerial tracking with Siamese networks still faces severe obstacles in many aspects. To further explore the deployment of Siamese networks in UAV tracking, this work presents a comprehensive review of leading-edge Siamese trackers, along with an exhaustive UAV-specific analysis based on the evaluation using a typical UAV onboard processor. Then, the onboard tests are conducted to validate the feasibility and efficacy of representative Siamese trackers in real-world UAV deployment. Furthermore, to better promote the development of the tracking community, this work analyzes the limitations of existing Siamese trackers and conducts additional experiments represented by low-illumination evaluations. In the end, prospects for the development of Siamese UAV tracking in the remote sensing field are discussed. The unified framework of leading-edge Siamese trackers, i.e., code library, and the results of their experimental evaluations are available at [this https URL](https://github.com/vision4robotics/SiameseTracking4UAV) ."
Aligned with Whom? Direct and social goals for AI systems,"AntonKorinek, AvitalBalwit",9 May 2022,Computers and Society (cs.CY)," As artificial intelligence (AI) becomes more powerful and widespread, the AI alignment problem - how to ensure that AI systems pursue the goals that we want them to pursue - has garnered growing attention. This article distinguishes two types of alignment problems depending on whose goals we consider, and analyzes the different solutions necessitated by each. The direct alignment problem considers whether an AI system accomplishes the goals of the entity operating it. In contrast, the social alignment problem considers the effects of an AI system on larger groups or on society more broadly. In particular, it also considers whether the system imposes externalities on others. Whereas solutions to the direct alignment problem center around more robust implementation, social alignment problems typically arise because of conflicts between individual and group-level goals, elevating the importance of AI governance to mediate such conflicts. Addressing the social alignment problem requires both enforcing existing norms on their developers and operators and designing new norms that apply directly to AI systems."
Long Document Re-ranking with Modular Re-ranker,"LuyuGao, JamieCallan",9 May 2022,Information Retrieval (cs.IR)," Long document re-ranking has been a challenging problem for neural re-rankers based on deep language models like BERT. Early work breaks the documents into short passage-like chunks. These chunks are independently mapped to scalar scores or latent vectors, which are then pooled into a final relevance score. These encode-and-pool methods however inevitably introduce an information bottleneck: the low dimension representations. In this paper, we propose instead to model full query-to-document interaction, leveraging the attention operation and modular Transformer re-ranker framework. First, document chunks are encoded independently with an encoder module. An interaction module then encodes the query and performs joint attention from the query to all document chunk representations. We demonstrate that the model can use this new degree of freedom to aggregate important information from the entire document. Our experiments show that this design produces effective re-ranking on two classical IR collections Robust04 and ClueWeb09, and a large-scale supervised collection MS-MARCO document ranking."
Detecting and Understanding Harmful Memes: A Survey,"ShivamSharma, Firoj Alam, Md. ShadAkhtar, DimitarDimitrov, Giovanni Da SanMartino, HamedFirooz, AlonHalevy, FabrizioSilvestri, PreslavNakov, TanmoyChakraborty",9 May 2022,Computation and Language (cs.CL)," The automatic identification of harmful content online is of major concern for social media platforms, policymakers, and society. Researchers have studied textual, visual, and audio content, but typically in isolation. Yet, harmful content often combines multiple modalities, as in the case of memes, which are of particular interest due to their viral nature. With this in mind, here we offer a comprehensive survey with a focus on harmful memes. Based on a systematic analysis of recent literature, we first propose a new typology of harmful memes, and then we highlight and summarize the relevant state of the art. One interesting finding is that many types of harmful memes are not really studied, e.g., such featuring self-harm and extremism, partly due to the lack of suitable datasets. We further find that existing datasets mostly capture multi-class scenarios, which are not inclusive of the affective spectrum that memes can represent. Another observation is that memes can propagate globally through repackaging in different languages and that they can also be multilingual, blending different cultures. We conclude by highlighting several challenges related to multimodal semiotics, technological constraints and non-trivial social engagement, and we present several open-ended aspects such as delineating online harm and empirically examining related frameworks and assistive interventions, which we believe will motivate and drive future research."
Modeling Interconnected Social and Technical Risks in Open SourceSoftware Ecosystems,"WilliamSchueller, JohannesWachs","9 May 2022 (v1(https://arxiv.org/abs/2205.04268v1)), lastrevised 10 May 2022 (this version, v2)",Software Engineering (cs.SE)," Open source software ecosystems consist of thousands of interdependent libraries, which users can combine to great effect. Recent work has pointed out two kinds of risks in these systems: that technical problems like bugs and vulnerabilities can spread through dependency links, and that relatively few developers are responsible for maintaining even the most widely used libraries. However, a more holistic diagnosis of systemic risk in software ecosystem should consider how these social and technical sources of risk interact and amplify one another. Motivated by the observation that the same individuals maintain several libraries within dependency networks, we present a methodological framework to measure risk in software ecosystems as a function of both dependencies and developers. In our models, a library's chance of failure increases as its developers leave and as its upstream dependencies fail. We apply our method to data from the Rust ecosystem, highlighting several systemically important libraries that are overlooked when only considering technical dependencies. We compare potential interventions, seeking better ways to deploy limited developer resources with a view to improving overall ecosystem health and software supply chain resilience."
On Designing Data Models for Energy Feature Stores,"GregorCerar, BlažBertalanič, AnžePirnat, AndrejČampa, CarolinaFortuna",9 May 2022,Artificial Intelligence (cs.AI)," The digitization of the energy infrastructure enables new, data driven, applications often supported by machine learning models. However, domain specific data transformations, pre-processing and management in modern data driven pipelines is yet to be addressed. In this paper we perform a first time study on data models, energy feature engineering and feature management solutions for developing ML-based energy applications. We first propose a taxonomy for designing data models suitable for energy applications, analyze feature engineering techniques able to transform the data model into features suitable for ML model training and finally also analyze available designs for feature stores. Using a short-term forecasting dataset, we show the benefits of designing richer data models and engineering the features on the performance of the resulting models. Finally, we benchmark three complementary feature management solutions, including an open-source feature store."
SwinIQA: Learned Swin Distance for Compressed Image Quality Assessment,"JianzhaoLiu, XinLi, YandingPeng, TaoYu, ZhiboChen",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Image compression has raised widespread interest recently due to its significant importance for multimedia storage and transmission. Meanwhile, a reliable image quality assessment (IQA) for compressed images can not only help to verify the performance of various compression algorithms but also help to guide the compression optimization in turn. In this paper, we design a full-reference image quality assessment metric SwinIQA to measure the perceptual quality of compressed images in a learned Swin distance space. It is known that the compression artifacts are usually non-uniformly distributed with diverse distortion types and degrees. To warp the compressed images into the shared representation space while maintaining the complex distortion information, we extract the hierarchical feature representations from each stage of the Swin Transformer. Besides, we utilize cross attention operation to map the extracted feature representations into a learned Swin distance space. Experimental results show that the proposed metric achieves higher consistency with human's perceptual judgment compared with both traditional methods and learning-based methods on CLIC datasets."
Discontinuous Galerkin approximation of the fully-coupled thermo-poroelastic problem,"StefanoBonetti, MicheleBotti, Paola F.Antonietti","9 May 2022 (v1(https://arxiv.org/abs/2205.04262v1)), lastrevised 11 May 2022 (this version, v2)",Numerical Analysis (math.NA)," We present and analyze a discontinuous Galerkin method for the numerical modelling of the fully-coupled quasi-static thermo-poroelastic problem. In particular, for the space discretization we introduce a discontinuous Galerkin method over polygonal and polyhedral grids and we present the stability analysis via two different approaches: first exploiting the Poincarè's inequality and second using the generalized inf- sup condition. Error estimates are derived for the resulting semi-discrete formulation in a suitable mesh dependent energy norm. Numerical simulations are presented in order to validate the theoretical analysis and to show the application of the model to a realistic case test."
CoCoLoT: Combining Complementary Trackers in Long-Term Visual Tracking,"MatteoDunnhofer, ChristianMicheloni",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," How to combine the complementary capabilities of an ensemble of different algorithms has been of central interest in visual object tracking. A significant progress on such a problem has been achieved, but considering short-term tracking scenarios. Instead, long-term tracking settings have been substantially ignored by the solutions. In this paper, we explicitly consider long-term tracking scenarios and provide a framework, named CoCoLoT, that combines the characteristics of complementary visual trackers to achieve enhanced long-term tracking performance. CoCoLoT perceives whether the trackers are following the target object through an online learned deep verification model, and accordingly activates a decision policy which selects the best performing tracker as well as it corrects the performance of the failing one. The proposed methodology is evaluated extensively and the comparison with several other solutions reveals that it competes favourably with the state-of-the-art on the most popular long-term visual tracking benchmarks."
EASE: Entity-Aware Contrastive Learning of Sentence Embedding,"SosukeNishikawa, Ryokan Ri, IkuyaYamada, YoshimasaTsuruoka, IsaoEchizen",9 May 2022,Computation and Language (cs.CL)," We present EASE, a novel method for learning sentence embeddings via contrastive learning between sentences and their related entities. The advantage of using entity supervision is twofold: (1) entities have been shown to be a strong indicator of text semantics and thus should provide rich training signals for sentence embeddings; (2) entities are defined independently of languages and thus offer useful cross-lingual alignment supervision. We evaluate EASE against other unsupervised models both in monolingual and multilingual settings. We show that EASE exhibits competitive or better performance in English semantic textual similarity (STS) and short text clustering (STC) tasks and it significantly outperforms baseline methods in multilingual settings on a variety of tasks. Our source code, pre-trained models, and newly constructed multilingual STC dataset are available at [this https URL](https://github.com/studio-ousia/ease)."
Multi-segment preserving sampling for deep manifold sampler,"DanielBerenberg, Jae HyeonLee, SimonKelow, JiWon Park, AndrewWatkins, VladimirGligorijević, RichardBonneau, Stephen Ra, Kyunghyun Cho",9 May 2022,Machine Learning (cs.LG)," Deep generative modeling for biological sequences presents a unique challenge in reconciling the bias-variance trade-off between explicit biological insight and model flexibility. The deep manifold sampler was recently proposed as a means to iteratively sample variable-length protein sequences by exploiting the gradients from a function predictor. We introduce an alternative approach to this guided sampling procedure, multi- segment preserving sampling, that enables the direct inclusion of domain- specific knowledge by designating preserved and non-preserved segments along the input sequence, thereby restricting variation to only select regions. We present its effectiveness in the context of antibody design by training two models: a deep manifold sampler and a GPT-2 language model on nearly six million heavy chain sequences annotated with the IGHV1-18 gene. During sampling, we restrict variation to only the complementarity-determining region 3 (CDR3) of the input. We obtain log probability scores from a GPT-2 model for each sampled CDR3 and demonstrate that multi-segment preserving sampling generates reasonable designs while maintaining the desired, preserved regions."
Enough Hot Air: The Role of Immersion Cooling,"KawsarHaghshenas, Brian Setz, YannisBloch, MarcoAiello",9 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Air cooling is the traditional solution to chill servers in data centers. However, the continuous increase in global data center energy consumption combined with the increase of the racks' power dissipation calls for the use of more efficient alternatives. Immersion cooling is one such alternative. In this paper, we quantitatively examine and compare air cooling and immersion cooling solutions. The examined characteristics include power usage efficiency (PUE), computing and power density, cost, and maintenance overheads. A direct comparison shows a reduction of about 50% in energy consumption and a reduction of about two-thirds of the occupied space, by using immersion cooling. In addition, the higher heat capacity of used liquids in immersion cooling compared to air allows for much higher rack power densities. Moreover, immersion cooling requires less capital and operational expenditures. However, challenging maintenance procedures together with the increased number of IT failures are the main downsides. By selecting immersion cooling, cloud providers must trade-off the decrease in energy and cost and the increase in power density with its higher maintenance and reliability concerns. Finally, we argue that retrofitting an air-cooled data center with immersion cooling will result in high costs and is generally not recommended."
Improved Evaluation and Generation of Grid Layouts using DistancePreservation Quality and Linear Assignment Sorting,"Kai UweBarthel, Nico Hezel, Klaus Jung, KonstantinSchall","9 May 2022 (v1(https://arxiv.org/abs/2205.04255v1)), lastrevised 11 May 2022 (this version, v2)",Computer Vision and Pattern Recognition (cs.CV)," Images sorted by similarity enables more images to be viewed simultaneously, and can be very useful for stock photo agencies or e-commerce applications. Visually sorted grid layouts attempt to arrange images so that their proximity on the grid corresponds as closely as possible to their similarity. Various metrics exist for evaluating such arrangements, but there is low experimental evidence on correlation between human perceived quality and metric value. We propose Distance Preservation Quality (DPQ) as a new metric to evaluate the quality of an arrangement. Extensive user testing revealed stronger correlation of DPQ with user- perceived quality and performance in image retrieval tasks compared to other metrics. In addition, we introduce Fast Linear Assignment Sorting (FLAS) as a new algorithm for creating visually sorted grid layouts. FLAS achieves very good sorting qualities while improving run time and computational resources."
Improved Price of Anarchy via Predictions,"VasilisGkatzelis, KostasKollias, AlkminiSgouritsa, Xizhi Tan",9 May 2022,Computer Science and Game Theory (cs.GT)," A central goal in algorithmic game theory is to analyze the performance of decentralized multiagent systems, like communication and information networks. In the absence of a central planner who can enforce how these systems are utilized, the users can strategically interact with the system, aiming to maximize their own utility, possibly leading to very inefficient outcomes, and thus a high price of anarchy. To alleviate this issue, the system designer can use decentralized mechanisms that regulate the use of each resource (e.g., using local queuing protocols or scheduling mechanisms), but with only limited information regarding the state of the system. These information limitations have a severe impact on what such decentralized mechanisms can achieve, so most of the success stories in this literature have had to make restrictive assumptions (e.g., by either restricting the structure of the networks or the types of cost functions).   In this paper, we overcome some of the obstacles that the literature has imposed on decentralized mechanisms, by designing mechanisms that are enhanced with predictions regarding the missing information. Specifically, inspired by the big success of the literature on ""algorithms with predictions"", we design decentralized mechanisms with predictions and evaluate their price of anarchy as a function of the prediction error, focusing on two very well-studied classes of games: scheduling games and multicast network formation games."
A Music-Therapy Robotic Platform for Children with Autism: A PilotStudy,"HuanghaoFengr, Mohammad H.Mahoor, FrancescaDino",9 May 2022,Human-Computer Interaction (cs.HC)," Children with Autism Spectrum Disorder (ASD) experience deficits in verbal and nonverbal communication skills including motor control, turn- taking, and emotion recognition. Innovative technology, such as socially assistive robots, has shown to be a viable method for Autism therapy. This paper presents a novel robot-based music-therapy platform for modeling and improving the social responses and behaviors of children with ASD. Our autonomous social interactive system consists of three modules. We adopted Short-time Fourier Transform and Levenshtein distance to fulfill the design requirements: a) ""music detection"" and b) ""smart scoring and feedback"", which allows NAO to understand music and provide additional practice and oral feedback to the users as applicable. We designed and implemented six Human-Robot-Interaction (HRI) sessions including four intervention sessions. Nine children with ASD and seven Typically Developing participated in a total of fifty HRI experimental sessions. Using our platform, we collected and analyzed data on social behavioral changes and emotion recognition using Electrodermal Activity (EDA) signals. The results of our experiments demonstrate most of the participants were able to complete motor control tasks with ~70% accuracy. Six out of the 9 ASD participants showed stable turn-taking behavior when playing music. The results of automated emotion classification using Support Vector Machines illustrate that emotional arousal in the ASD group can be detected and well recognized via EDA bio- signals. In summary, the results of our data analyses, including emotion classification using EDA signals, indicate that the proposed robot-music based therapy platform is an attractive and promising assistive tool to facilitate the improvement of fine motor control and turn-taking skills in children with ASD."
Counterfactually Augmented Data and Unintended Bias: The Case ofSexism and Hate Speech Detection,"IndiraSen, MattiaSamory, ClaudiaWagner, IsabelleAugenstein",9 May 2022,Computation and Language (cs.CL)," Counterfactually Augmented Data (CAD) aims to improve out-of- domain generalizability, an indicator of model robustness. The improvement is credited with promoting core features of the construct over spurious artifacts that happen to correlate with it. Yet, over-relying on core features may lead to unintended model bias. Especially, construct-driven CAD -- perturbations of core features -- may induce models to ignore the context in which core features are used. Here, we test models for sexism and hate speech detection on challenging data: non-hateful and non-sexist usage of identity and gendered terms. In these hard cases, models trained on CAD, especially construct-driven CAD, show higher false-positive rates than models trained on the original, unperturbed data. Using a diverse set of CAD -- construct-driven and construct-agnostic -- reduces such unintended bias."
An Effective Scheme for Maize Disease Recognition based on DeepNetworks,"SaeedehOsouli, Behrouz BolourianHaghighi, EhsanSadrossadat",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In the last decades, the area under cultivation of maize products has increased because of its essential role in the food cycle for humans, livestock, and poultry. Moreover, the diseases of plants impact food safety and can significantly reduce both the quality and quantity of agricultural products. There are many challenges to accurate and timely diagnosis of the disease. This research presents a novel scheme based on a deep neural network to overcome the mentioned challenges. Due to the limited number of data, the transfer learning technique is employed with the help of two well- known architectures. In this way, a new effective model is adopted by a combination of pre-trained MobileNetV2 and Inception Networks due to their effective performance on object detection problems. The convolution layers of MoblieNetV2 and Inception modules are parallelly arranged as earlier layers to extract crucial features. In addition, the imbalance problem of classes has been solved by an augmentation strategy. The proposed scheme has a superior performance compared to other state-of-the-art models published in recent years. The accuracy of the model reaches 97%, approximately. In summary, experimental results prove the method's validity and significant performance in diagnosing disease in plant leaves."
Near-collisions and their Impact on Biometric Security (long),"AxelDurbet, Paul-MarieGrollemund, PascalLafourcade, Kevin Thiry-Atighehchi","6 May 2022 (v1(https://arxiv.org/abs/2205.04229v1)), lastrevised 10 May 2022 (this version, v2)",Cryptography and Security (cs.CR)," Biometric recognition encompasses two operating modes. The first one is biometric identification which consists in determining the identity of an individual based on her biometrics and requires browsing the entire database (i.e., a 1:N search). The other one is biometric authentication which corresponds to verifying claimed biometrics of an individual (i.e., a 1:1 search) to authenticate her, or grant her access to some services. The matching process is based on the similarities between a fresh and an enrolled biometric template. Considering the case of binary templates, we investigate how a highly populated database yields near-collisions, impacting the security of both the operating modes. Insight into the security of binary templates is given by establishing a lower bound on the size of templates and an upper bound on the size of a template database depending on security parameters. We provide efficient algorithms for partitioning a leaked template database in order to improve the generation of a master-template-set that can impersonates any enrolled user and possibly some future users. Practical impacts of proposed algorithms are finally emphasized with experimental studies."
Worst-case Analysis for Interactive Evaluation of Boolean Provenance,"AntoineAmarilli, YaelAmsterdamer",9 May 2022,Databases (cs.DB)," In recent work, we have introduced a framework for fine-grained consent management in databases, which combines Boolean data provenance with the field of interactive Boolean evaluation. In turn, interactive Boolean evaluation aims at unveiling the underlying truth value of a Boolean expression by frugally probing the truth values of individual values. The required number of probes depends on the Boolean provenance structure and on the (a-priori unknown) probe answers. Prior work has analyzed and aimed to optimize the expected number of probes, where expectancy is with respect to a probability distribution over probe answers. This paper gives a novel worst-case analysis for the problem, inspired by the decision tree depth of Boolean functions.   Specifically, we introduce a notion of evasive provenance expressions, namely expressions, where one may need to probe all variables in the worst case. We show that read-once expressions are evasive, and identify an additional class of expressions (acyclic monotone 2-DNF) for which evasiveness may be decided in PTIME. As for the more general question of finding the optimal strategy, we show that it is coNP-hard in general. We are still able to identify a sub-class of provenance expressions that is ""far from evasive"", namely, where an optimal worst-case strategy probes only log(n) out of the n variables in the expression, and show that we can find this optimal strategy in polynomial time."
Alternative Data Augmentation for Industrial Monitoring usingAdversarial Learning,"SilvanMertes, AndreasMargraf, SteffenGeinitz, ElisabethAndré",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Visual inspection software has become a key factor in the manufacturing industry for quality control and process monitoring. Semantic segmentation models have gained importance since they allow for more precise examination. These models, however, require large image datasets in order to achieve a fair accuracy level. In some cases, training data is sparse or lacks of sufficient annotation, a fact that especially applies to highly specialized production environments. Data augmentation represents a common strategy to extend the dataset. Still, it only varies the image within a narrow range. In this article, a novel strategy is proposed to augment small image datasets. The approach is applied to surface monitoring of carbon fibers, a specific industry use case. We apply two different methods to create binary labels: a problem-tailored trigonometric function and a WGAN model. Afterwards, the labels are translated into color images using pix2pix and used to train a U-Net. The results suggest that the trigonometric function is superior to the WGAN model. However, a precise examination of the resulting images indicate that WGAN and image-to-image translation achieve good segmentation results and only deviate to a small degree from traditional data augmentation. In summary, this study examines an industry application of data synthesization using generative adversarial networks and explores its potential for monitoring systems of production environments. \keywords{Image-to-Image Translation, Carbon Fiber, Data Augmentation, Computer Vision, Industrial Monitoring, Adversarial Learning."
The Forgotten Margins of AI Ethics,"AbebaBirhane, ElayneRuane, ThomasLaurent, Matthew S.Brown, JohnathanFlowers, AnthonyVentresque, Christopher L.Dancy",9 May 2022,Computers and Society (cs.CY)," How has recent AI Ethics literature addressed topics such as fairness and justice in the context of continued social and structural power asymmetries? We trace both the historical roots and current landmark work that have been shaping the field and categorize these works under three broad umbrellas: (i) those grounded in Western canonical philosophy, (ii) mathematical and statistical methods, and (iii) those emerging from critical data/algorithm/information studies. We also survey the field and explore emerging trends by examining the rapidly growing body of literature that falls under the broad umbrella of AI Ethics. To that end, we read and annotated peer-reviewed papers published over the past four years in two premier conferences: FAccT and AIES. We organize the literature based on an annotation scheme we developed according to three main dimensions: whether the paper deals with concrete applications, use-cases, and/or people's lived experience; to what extent it addresses harmed, threatened, or otherwise marginalized groups; and if so, whether it explicitly names such groups. We note that although the goals of the majority of FAccT and AIES papers were often commendable, their consideration of the negative impacts of AI on traditionally marginalized groups remained shallow. Taken together, our conceptual analysis and the data from annotated papers indicate that the field would benefit from an increased focus on ethical analysis grounded in concrete use-cases, people's experiences, and applications as well as from approaches that are sensitive to structural and historical power asymmetries."
Deep learning framework for robot for person detection and tracking,"AdarshGhimire, XiaoxiongZhang, NaoufelWerghi, Sajid Javed, Jorge Dias",19 Apr 2022,Robotics (cs.RO)," Robustly tracking a person of interest in the crowd with a robotic platform is one of the cornerstones of human-robot interaction. The robot platform which is limited by the computational power, rapid movements, and occlusions of the target requires an efficient and robust framework to perform tracking. This paper proposes a deep learning framework for tracking a person using a mobile robot with a stereo camera. The proposed system detects a person based on its head, then utilizes the low-cost, high-speed regression network-based tracker to track the person of interest in real- time. The visual servoing of the mobile robot has been designed using a PID controller which utilizes tracker output and depth estimation of the person in subsequent frames, hence providing smooth and adaptive movement of the robot based on target movement. The proposed system has been tested in a real environment, thus proving its effectiveness."
Think outside the search box: A comparative study of visual and form-based query builders,"TanjaSvarre, Tony Russell-Rose",9 May 2022,Information Retrieval (cs.IR)," Knowledge workers such as healthcare information professionals, legal researchers, and librarians need to create and execute search strategies that are comprehensive, transparent, and reproducible. The traditional solution is to use proprietary query building tools provided by literature database vendors. In the majority of cases, these query builders are designed using a form-based paradigm that requires the user to enter keywords and ontology terms on a line-by-line basis and then combine them using Boolean operators. However, recent years have witnessed significant changes in human-computer interaction technologies and users can now engage with online information systems using a variety of novel data visualisation techniques. In this paper, we evaluate a new approach to query building in which users express concepts as objects on a visual canvas and compare this with traditional form-based query building in a lab-based user study. The results demonstrate the potential of visual interfaces to mitigate some of the shortcomings associated with form-based interfaces and encourage more exploratory search behaviour. They also demonstrate the value of having a temporary 'scratch' space in query formulation. In addition, the findings highlight an ongoing need for transparency and reproducibility in professional search and raise further questions around how these properties may best be supported."
Boolean Expressions in Firewall Analysis,"AdamHamilton, MatthewRoughan, Giang T.Nguyen",3 May 2022,Cryptography and Security (cs.CR)," Firewall policies are an important line of defence in cybersecurity, specifying which packets are allowed to pass through a network and which are not. These firewall policies are made up of a list of interacting rules. In practice, firewall can consist of hundreds or thousands of rules. This can be very difficult for a human to correctly configure. One proposed solution is to model firewall policies as Boolean expressions and use existing computer programs such as SAT solvers to verify that the firewall satisfies certain conditions. This paper takes an in-depth look at the Boolean expressions that represent firewall policies. We present an algorithm that translates a list of firewall rules into a Boolean expression in conjunctive normal form (CNF) or disjunctive normal form (DNF). We also place an upper bound on the size of the CNF and DNF that is polynomial in the number of rules in the firewall policy. This shows that past results suggesting a combinatorial explosion when converting from a Boolean expression in CNF to one in DNF does note occur in the context of firewall analysis"
Robust Parameter Identifiability Analysis via Column Subset Selection,"Katherine J.Pearce, Ilse C.F.Ipsen, Mansoor A.Haider, Arvind K.Saibaba, Ralph C.Smith",9 May 2022,Numerical Analysis (math.NA)," We advocate a numerically reliable and accurate approach for practical parameter identifiability analysis: Applying column subset selection (CSS) to the sensitivity matrix, instead of computing an eigenvalue decomposition of the Fischer information matrix. Identifiability analysis via CSS has three advantages: (i) It quantifies reliability of the subsets of parameters selected as identifiable and unidentifiable. (ii) It establishes criteria for comparing the accuracy of different algorithms. (iii) The implementations are numerically more accurate and reliable than eigenvalue methods applied to the Fischer matrix, yet without an increase in computational cost. The effectiveness of the CSS methods is illustrated with extensive numerical experiments on sensitivity matrices from six physical models, as well as on adversarial synthetic matrices. Among the CSS methods, we recommend an implementation based on the strong rank-revealing QR algorithm because of its rigorous accuracy guarantees for both identifiable and non-identifiable parameters."
Multimodel Sensor Fusion for Learning Rich Models for Interacting SoftRobots,"Thomas GeorgeThuruthel, Fumiya Iida",9 May 2022,Robotics (cs.RO)," Soft robots are typically approximated as low-dimensional systems, especially when learning-based methods are used. This leads to models that are limited in their capability to predict the large number of deformation modes and interactions that a soft robot can have. In this work, we present a deep-learning methodology to learn high-dimensional visual models of a soft robot combining multimodal sensorimotor information. The models are learned in an end-to-end fashion, thereby requiring no intermediate sensor processing or grounding of data. The capabilities and advantages of such a modelling approach are shown on a soft anthropomorphic finger with embedded soft sensors. We also show that how such an approach can be extended to develop higher level cognitive functions like identification of the self and the external environment and acquiring object manipulation skills. This work is a step towards the integration of soft robotics and developmental robotics architectures to create the next generation of intelligent soft robots."
Towards Development with Multi-Version Models: Detecting MergeConflicts and Checking Well-Formedness,"MatthiasBarkowsky, Holger Giese",9 May 2022,Software Engineering (cs.SE)," Developing complex software requires that multiple views and versions of the software can be developed in parallel and merged as supported by views and managed by version control systems.   In this context, this paper considers monitoring merging and related consistency problems permanently at the level of models and abstract syntax to permit early and frequent conflict detection while developing in parallel. The presented approach introduces multi-version models based on typed graphs that permit to store changes and multiple versions in one graph in a compact form and allow (1) to study well-formedness for all versions without the need to extract each version individually, (2) to report all possible merge conflicts without the need to merge all pairs of versions, and (3) to report all violations of well-formedness conditions that will result for merges of any two versions independent of any merge decisions without the need to merge all pairs of versions.   The paper defines the related concepts and algorithms operating on multi- version models, proves their correctness w.r.t.~the usually employed three- way-merge, and reports on preliminary experiments concerning the scalability."
Timed Games with Bounded Window Parity Objectives,"James C. A.Main, MickaelRandour, JeremySproston",9 May 2022,Computer Science and Game Theory (cs.GT)," The window mechanism, introduced by Chatterjee et al. for mean- payoff and total-payoff objectives in two-player turn-based games on graphs, refines long-term objectives with time bounds. This mechanism has proven useful in a variety of settings, and most recently in timed systems.   In the timed setting, the so-called fixed timed window parity objectives have been studied. A fixed timed window parity objective is defined with respect to some time bound and requires that, at all times, we witness a time frame, i.e., a window, of size less than the fixed bound in which the smallest priority is even. In this work, we focus on the bounded timed window parity objective. Such an objective is satisfied if there exists some bound for which the fixed objective is satisfied. The satisfaction of bounded objectives is robust to modeling choices such as constants appearing in constraints, unlike fixed objectives, for which the choice of constants may affect the satisfaction for a given bound.   We show that verification of bounded timed window objectives in timed automata can be performed in polynomial space, and that timed games with these objectives can be solved in exponential time, even for multi-objective extensions. This matches the complexity classes of the fixed case. We also provide a comparison of the different variants of window parity objectives."
Disturbance-Injected Robust Imitation Learning with Task Achievement,"HirotakaTahara, HikaruSasaki, Hanbit Oh, BrendanMichael, TakamitsuMatsubara",9 May 2022,Robotics (cs.RO)," Robust imitation learning using disturbance injections overcomes issues of limited variation in demonstrations. However, these methods assume demonstrations are optimal, and that policy stabilization can be learned via simple augmentations. In real-world scenarios, demonstrations are often of diverse-quality, and disturbance injection instead learns sub-optimal policies that fail to replicate desired behavior. To address this issue, this paper proposes a novel imitation learning framework that combines both policy robustification and optimal demonstration learning. Specifically, this combinatorial approach forces policy learning and disturbance injection optimization to focus on mainly learning from high task achievement demonstrations, while utilizing low achievement ones to decrease the number of samples needed. The effectiveness of the proposed method is verified through experiments using an excavation task in both simulations and a real robot, resulting in high-achieving policies that are more stable and robust to diverse-quality demonstrations. In addition, this method utilizes all of the weighted sub-optimal demonstrations without eliminating them, resulting in practical data efficiency benefits."
Computational issues by interpolating with inverse multiquadrics: asolution,"Stefano DeMarchi, NadanielaEgidi, JosephinGiacomini, PierluigiMaponi, AlessiaPerticarini",9 May 2022,Numerical Analysis (math.NA), We consider the interpolation problem with the inverse multiquadric radial basis function. The problem usually produces a large dense linear system that has to be solved by iterative methods. The efficiency of such methods is strictly related to the computational cost of the multiplication between the coefficient matrix and the vectors computed by the solver at each iteration. We propose an efficient technique for the calculation of the product of the coefficient matrix and a generic vector. This computation is mainly based on the well-known spectral decomposition in spherical coordinates of the Green's function of the Laplacian operator. We also show the efficiency of the proposed method through numerical simulations.
SRv6: Is There Anybody Out There?,"Victor-AlexandruPădurean, OliverGasser, Randy Bush, AnjaFeldmann",9 May 2022,Networking and Internet Architecture (cs.NI)," Segment routing is a modern form of source-based routing, i.e., a routing technique where all or part of the routing decision is predetermined by the source or a hop on the path. Since initial standardization efforts in 2013, segment routing seems to have garnered substantial industry and operator support. Especially segment routing over IPv6 (SRv6) is advertised as having several advantages for easy deployment and flexibility in operations in networks. Many people, however, argue that the deployment of segment routing and SRv6 in particular poses a significant security threat if not done with the utmost care. In this paper we conduct a first empirical analysis of SRv6 deployment in the Internet. First, we analyze SRv6 behavior in an emulation environment and find that different SRv6 implementations have the potential to leak information to the outside. Second, we search for signs of SRv6 deployment in publicly available route collector data, but could not find any traces. Third, we run large-scale traceroute campaigns to investigate possible SRv6 deployments. In this first empirical study on SRv6 we are unable to find traces of SRv6 deployment even for companies that claim to have it deployed in their networks. This lack of leakage might be an indication of good security practices being followed by network operators when deploying SRv6."
"The Role of Idle Waves, Desynchronization, and Bottleneck Evasion inthe Performance of Parallel Programs","AyeshaAfzal, GeorgHager, GerhardWellein",9 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," The performance of highly parallel applications on distributed- memory systems is influenced by many factors. Analytic performance modeling techniques aim to provide insight into performance limitations and are often the starting point of optimization efforts. However, coupling analytic models across the system hierarchy (socket, node, network) fails to encompass the intricate interplay between the program code and the hardware, especially when execution and communication bottlenecks are involved. In this paper we investigate the effect of ""bottleneck evasion"" and how it can lead to automatic overlap of communication overhead with computation. Bottleneck evasion leads to a gradual loss of the initial bulk-synchronous behavior of a parallel code so that its processes become desynchronized. This occurs most prominently in memory-bound programs, which is why we choose memory-bound benchmark and application codes, specifically an MPI- augmented STREAM Triad, sparse matrix-vector multiplication, and a collective-avoiding Chebyshev filter diagonalization code to demonstrate the consequences of desynchronization on two different supercomputing platforms. We investigate the role of idle waves as possible triggers for desynchronization and show the impact of automatic asynchronous communication for a spectrum of code properties and parameters, such as saturation point, matrix structures, domain decomposition, and communication concurrency. Our findings reveal how eliminating synchronization points (such as collective communication or barriers) precipitates performance improvements that go beyond what can be expected by simply subtracting the overhead of the collective from the overall runtime."
FoReCo: a forecast-based recovery mechanism for real-time remotecontrol of robotic manipulators,"MilanGroshev, Jorge Martín-Pérez, CarlosGuimarães, Antonio de laOliva, Carlos J.Bernardos",9 May 2022,Networking and Internet Architecture (cs.NI)," Wireless communications represent a game changer for future manufacturing plants, enabling flexible production chains as machinery and other components are not restricted to a location by the rigid wired connections on the factory floor. However, the presence of electromagnetic interference in the wireless spectrum may result in packet loss and delay, making it a challenging environment to meet the extreme reliability requirements of industrial applications. In such conditions, achieving real- time remote control, either from the Edge or Cloud, becomes complex. In this paper, we investigate a forecast-based recovery mechanism for real-time remote control of robotic manipulators (FoReCo) that uses Machine Learning (ML) to infer lost commands caused by interference in the wireless channel. FoReCo is evaluated through both simulation and experimentation in interference prone IEEE 802.11 wireless links, and using a commercial research robot that performs pick-and-place tasks. Results show that in case of interference, FoReCo trajectory error is decreased by x18 and x2 times in simulation and experimentation, and that FoReCo is sufficiently lightweight to be deployed in the hardware of already used in existing solutions."
Joint learning of object graph and relation graph for visual questionanswering,"Hao Li, Xu Li, BelhalKarimi, JieChen, Mingming Sun",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Modeling visual question answering(VQA) through scene graphs can significantly improve the reasoning accuracy and interpretability. However, existing models answer poorly for complex reasoning questions with attributes or relations, which causes false attribute selection or missing relation in Figure 1(a). It is because these models cannot balance all kinds of information in scene graphs, neglecting relation and attribute information. In this paper, we introduce a novel Dual Message-passing enhanced Graph Neural Network (DM-GNN), which can obtain a balanced representation by properly encoding multi-scale scene graph information. Specifically, we (i)transform the scene graph into two graphs with diversified focuses on objects and relations; Then we design a dual structure to encode them, which increases the weights from relations (ii)fuse the encoder output with attribute features, which increases the weights from attributes; (iii)propose a message-passing mechanism to enhance the information transfer between objects, relations and attributes. We conduct extensive experiments on datasets including GQA, VG, motif-VG and achieve new state of the art."
Finite-State Semi-Markov Channels for Nanopore Sequencing,"BrendonMcBain, EmanueleViterbo, JamesSaunderson",9 May 2022,Information Theory (cs.IT)," Nanopore sequencing is an emerging DNA sequencing technology that has been proposed for use in DNA storage systems. We propose the noisy nanopore channel model for nanopore sequencing. This model captures duplications, inter-symbol interference, and noisy measurements by concatenating an i.i.d. duplication channel with a finite-state semi-Markov channel. Compared to previous models, this channel models the dominant distortions of the nanopore while remaining tractable. Anticipating future coding schemes, we derive MAP detection algorithms and estimate achievable rates. Given that finite-state semi-Markov channels are a subclass of channels with memory, we conjecture that the achievable rate of the noisy nanopore channel can be optimised using a variation of the generalised Blahut-Arimoto algorithm."
Paired Image-to-Image Translation Quality Assessment Using Multi-Method Fusion,"StefanBorasinski, Esin Yavuz, SébastienBéhuret",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," How best to evaluate synthesized images has been a longstanding problem in image-to-image translation, and to date remains largely unresolved. This paper proposes a novel approach that combines signals of image quality between paired source and transformation to predict the latter's similarity with a hypothetical ground truth. We trained a Multi- Method Fusion (MMF) model via an ensemble of gradient-boosted regressors using Image Quality Assessment (IQA) metrics to predict Deep Image Structure and Texture Similarity (DISTS), enabling models to be ranked without the need for ground truth data. Analysis revealed the task to be feature- constrained, introducing a trade-off at inference between metric computation time and prediction accuracy. The MMF model we present offers an efficient way to automate the evaluation of synthesized images, and by extension the image-to-image translation models that generated them."
A Dataset and BERT-based Models for Targeted Sentiment Analysis onTurkish Texts,"M. MelihMutlu, ArzucanÖzgür",9 May 2022,Computation and Language (cs.CL)," Targeted Sentiment Analysis aims to extract sentiment towards a particular target from a given text. It is a field that is attracting attention due to the increasing accessibility of the Internet, which leads people to generate an enormous amount of data. Sentiment analysis, which in general requires annotated data for training, is a well-researched area for widely studied languages such as English. For low-resource languages such as Turkish, there is a lack of such annotated data. We present an annotated Turkish dataset suitable for targeted sentiment analysis. We also propose BERT-based models with different architectures to accomplish the task of targeted sentiment analysis. The results demonstrate that the proposed models outperform the traditional sentiment analysis models for the targeted sentiment analysis task."
Local Prediction Aggregation: A Frustratingly Easy Source-free DomainAdaptation Method,"ShiqiYang, YaxingWang, KaiWang, Joostvan deWeijer, Shangling Jui",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We propose a simple but effective source-free domain adaptation (SFDA) method. Treating SFDA as an unsupervised clustering problem and following the intuition that local neighbors in feature space should have more similar predictions than other features, we propose to optimize an objective of prediction consistency. This objective encourages local neighborhood features in feature space to have similar predictions while features farther away in feature space have dissimilar predictions, leading to efficient feature clustering and cluster assignment simultaneously. For efficient training, we seek to optimize an upper-bound of the objective which contains two simple terms. Furthermore, we relate popular existing methods in domain adaptation, source-free domain adaptation and contrastive learning via the perspective of discriminability and diversity. The experimental results prove the superiority of our method, and our method can be adopted as a simple but strong baseline for future research in SFDA. Code is available in [this https URL](https://github.com/Albert0147/LPA_SFDA)."
Enhancing Cross-lingual Transfer by Manifold Mixup,"HuiyunYang, HuadongChen, HaoZhou, LeiLi",9 May 2022,Computation and Language (cs.CL)," Based on large-scale pre-trained multilingual representations, recent cross-lingual transfer methods have achieved impressive transfer performances. However, the performance of target languages still lags far behind the source language. In this paper, our analyses indicate such a performance gap is strongly associated with the cross-lingual representation discrepancy. To achieve better cross-lingual transfer performance, we propose the cross-lingual manifold mixup (X-Mixup) method, which adaptively calibrates the representation discrepancy and gives a compromised representation for target languages. Experiments on the XTREME benchmark show X-Mixup achieves 1.8% performance gains on multiple text understanding tasks, compared with strong baselines, and significantly reduces the cross- lingual representation discrepancy."
Price DOES Matter! Modeling Price and Interest Preferences in Session-based Recommendation,"XiaokunZhang, BoXu, LiangYang, Chenliang Li, Fenglong Ma, Haifeng Liu, Hongfei Lin",9 May 2022,Information Retrieval (cs.IR)," Session-based recommendation aims to predict items that an anonymous user would like to purchase based on her short behavior sequence. The current approaches towards session-based recommendation only focus on modeling users' interest preferences, while they all ignore a key attribute of an item, i.e., the price. Many marketing studies have shown that the price factor significantly influences users' behaviors and the purchase decisions of users are determined by both price and interest preferences simultaneously. However, it is nontrivial to incorporate price preferences for session-based recommendation. Firstly, it is hard to handle heterogeneous information from various features of items to capture users' price preferences. Secondly, it is difficult to model the complex relations between price and interest preferences in determining user choices.   To address the above challenges, we propose a novel method Co-guided Heterogeneous Hypergraph Network (CoHHN) for session-based recommendation. Towards the first challenge, we devise a heterogeneous hypergraph to represent heterogeneous information and rich relations among them. A dual- channel aggregating mechanism is then designed to aggregate various information in the heterogeneous hypergraph. After that, we extract users' price preferences and interest preferences via attention layers. As to the second challenge, a co-guided learning scheme is designed to model the relations between price and interest preferences and enhance the learning of each other. Finally, we predict user actions based on item features and users' price and interest preferences. Extensive experiments on three real- world datasets demonstrate the effectiveness of the proposed CoHHN. Further analysis reveals the significance of price for session-based recommendation."
EF-BV: A Unified Theory of Error Feedback and Variance ReductionMechanisms for Biased and Unbiased Compression in Distributed Optimization,"LaurentCondat, KaiYi, PeterRichtárik",9 May 2022,Machine Learning (cs.LG)," In distributed or federated optimization and learning, communication between the different computing units is often the bottleneck, and gradient compression is a widely used technique for reducing the number of bits sent within each communication round of iterative methods. There are two classes of compression operators and separate algorithms making use of them. In the case of unbiased random compressors with bounded variance (e.g., rand-k), the DIANA algorithm of Mishchenko et al. [2019], which implements a variance reduction technique for handling the variance introduced by compression, is the current state of the art. In the case of biased and contractive compressors (e.g., top-k), the EF21 algorithm of Richtárik et al. [2021], which implements an error-feedback mechanism for handling the error introduced by compression, is the current state of the art. These two classes of compression schemes and algorithms are distinct, with different analyses and proof techniques. In this paper, we unify them into a single framework and propose a new algorithm, recovering DIANA and EF21 as particular cases. We prove linear convergence under certain conditions. Our general approach works with a new, larger class of compressors, which includes unbiased and biased compressors as particular cases, and has two parameters, the bias and the variance. These gives a finer control and allows us to inherit the best of the two worlds: biased compressors, whose good performance in practice is recognized, can be used. And independent randomness at the compressors allows to mitigate the effects of compression, with the convergence rate improving when the number of parallel workers is large. This is the first time that an algorithm with all these features is proposed. Our approach takes a step towards better understanding of two so-far distinct worlds of communication-efficient distributed learning."
High Performance Consensus without Duplication: Multi-pipelineHotstuff,TainingCheng,"9 May 2022 (v1(https://arxiv.org/abs/2205.04179v1)), lastrevised 11 May 2022 (this version, v3)","Distributed, Parallel, and Cluster Computing (cs.DC)"," This paper elaborates a new consensus protocol Multi-pipeline Hotstuff in permissioned blockchain, the first protocol that combines multiple Hotstuff instances to propose batches in order without concurrently proposing. The state-of-the-art Hotstuff operates that pipeline in which a stable leader drives decisions with linear communication. Although, this paradigm can commit a block every two rounds of messages. The proposing- voting pattern in a single consensus instance is mutually exclusive; it's not enough to exert the bandwidth and concurrency performance of the modern system. We try to use multiple consensus instance to propose in a total order rather than using a predefined order in the pattern of multiple leaders. Our protocol allows proposing and voting to happen at the same round without transaction duplication so that it produces more proposals in every two rounds of messages; it further boosts throughput at comparable latency with Hostuff."
NeuralHDHair: Automatic High-fidelity Hair Modeling from a SingleImage Using Implicit Neural Representations,"KeyuWu, YifanYe, LingchenYang, HongboFu, KunZhou, YouyiZheng",9 May 2022,Graphics (cs.GR)," Undoubtedly, high-fidelity 3D hair plays an indispensable role in digital humans. However, existing monocular hair modeling methods are either tricky to deploy in digital systems (e.g., due to their dependence on complex user interactions or large databases) or can produce only a coarse geometry. In this paper, we introduce NeuralHDHair, a flexible, fully automatic system for modeling high-fidelity hair from a single image. The key enablers of our system are two carefully designed neural networks: an IRHairNet (Implicit representation for hair using neural network) for inferring high-fidelity 3D hair geometric features (3D orientation field and 3D occupancy field) hierarchically and a GrowingNet(Growing hair strands using neural network) to efficiently generate 3D hair strands in parallel. Specifically, we perform a coarse-to-fine manner and propose a novel voxel- aligned implicit function (VIFu) to represent the global hair feature, which is further enhanced by the local details extracted from a hair luminance map. To improve the efficiency of a traditional hair growth algorithm, we adopt a local neural implicit function to grow strands based on the estimated 3D hair geometric features. Extensive experiments show that our method is capable of constructing a high-fidelity 3D hair model from a single image, both efficiently and effectively, and achieves the-state-of- the-art performance."
"""The World Is Its Own Best Model"": Robust Real-World ManipulationThrough Online Behavior Selection","ManuelBaum, OliverBrock",9 May 2022,Robotics (cs.RO), Robotic manipulation behavior should be robust to disturbances that violate high-level task-structure. Such robustness can be achieved by constantly monitoring the environment to observe the discrete high-level state of the task. This is possible because different phases of a task are characterized by different sensor patterns and by monitoring these patterns a robot can decide which controllers to execute in the moment. This relaxes assumptions about the temporal sequence of those controllers and makes behavior robust to unforeseen disturbances. We implement this idea as probabilistic filter over discrete states where each state is direcly associated with a controller. Based on this framework we present a robotic system that is able to open a drawer and grasp tennis balls from it in a surprisingly robust way.
Multi-Fingered In-Hand Manipulation with Various Object PropertiesUsing Graph Convolutional Networks and Distributed Tactile Sensors,"SatoshiFunabashi, TomokiIsobe, FeiHongyi, AtsumuHiramoto, AlexanderSchmitz, ShigekiSugano, TetsuyaOgata",9 May 2022,Robotics (cs.RO)," Multi-fingered hands could be used to achieve many dexterous manipulation tasks, similarly to humans, and tactile sensing could enhance the manipulation stability for a variety of objects. However, tactile sensors on multi-fingered hands have a variety of sizes and shapes. Convolutional neural networks (CNN) can be useful for processing tactile information, but the information from multi-fingered hands needs an arbitrary pre-processing, as CNNs require a rectangularly shaped input, which may lead to unstable results. Therefore, how to process such complex shaped tactile information and utilize it for achieving manipulation skills is still an open issue. This paper presents a control method based on a graph convolutional network (GCN) which extracts geodesical features from the tactile data with complicated sensor alignments. Moreover, object property labels are provided to the GCN to adjust in-hand manipulation motions. Distributed tri-axial tactile sensors are mounted on the fingertips, finger phalanges and palm of an Allegro hand, resulting in 1152 tactile measurements. Training data is collected with a data-glove to transfer human dexterous manipulation directly to the robot hand. The GCN achieved high success rates for in-hand manipulation. We also confirmed that fragile objects were deformed less when correct object labels were provided to the GCN. When visualizing the activation of the GCN with a PCA, we verified that the network acquired geodesical features. Our method achieved stable manipulation even when an experimenter pulled a grasped object and for untrained objects."
Visual Encoding and Debiasing for CTR Prediction,"SiChen, ChenLin, WanxianGuan, JiayiWei, XingyuanBu, HeGuo, HuiLi, XubinLi, JianXu, BoZheng",9 May 2022,Information Retrieval (cs.IR)," Extracting expressive visual features is crucial for accurate Click-Through-Rate (CTR) prediction in visual search advertising systems. Current commercial systems use off-the-shelf visual encoders to facilitate fast online service. However, the extracted visual features are coarse- grained and/or biased. In this paper, we present a visual encoding framework for CTR prediction to overcome these problems. The framework is based on contrastive learning which pulls positive pairs closer and pushes negative pairs apart in the visual feature space. To obtain fine-grained visual features,we present contrastive learning supervised by click through data to fine-tune the visual encoder. To reduce sample selection bias, firstly we train the visual encoder offline by leveraging both unbiased self- supervision and click supervision signals. Secondly, we incorporate a debiasing network in the online CTR predictor to adjust the visual features by contrasting high impression items with selected items with lower impressions.We deploy the framework in the visual sponsor search system at Alibaba. Offline experiments on billion-scale datasets and online experiments demonstrate that the proposed framework can make accurate and unbiased predictions."
Residue-based Label Protection Mechanisms in Vertical LogisticRegression,"JuntaoTan, LanZhang, YangLiu, AnranLi, YeWu",9 May 2022,Machine Learning (cs.LG)," Federated learning (FL) enables distributed participants to collaboratively learn a global model without revealing their private data to each other. Recently, vertical FL, where the participants hold the same set of samples but with different features, has received increased attention. This paper first presents one label inference attack method to investigate the potential privacy leakages of the vertical logistic regression model. Specifically, we discover that the attacker can utilize the residue variables, which are calculated by solving the system of linear equations constructed by local dataset and the received decrypted gradients, to infer the privately owned labels. To deal with this, we then propose three protection mechanisms, e.g., additive noise mechanism, multiplicative noise mechanism, and hybrid mechanism which leverages local differential privacy and homomorphic encryption techniques, to prevent the attack and improve the robustness of the vertical logistic regression. model. Experimental results show that both the additive noise mechanism and the multiplicative noise mechanism can achieve efficient label protection with only a slight drop in model testing accuracy, furthermore, the hybrid mechanism can achieve label protection without any testing accuracy degradation, which demonstrates the effectiveness and efficiency of our protection techniques"
Robotic Maintenance of Road Infrastructures: The HERON Project,"IasonKatsamenis, MatthaiosBimpas, EftychiosProtopapadakis, CharalamposZafeiropoulos, DimitrisKalogeras, AnastasiosDoulamis, NikolaosDoulamis, Carlos Martín-PortuguésMontoliu, YannisHandanos, FranziskaSchmidt, Lionel Ott, MiquelCantero, Rafael Lopez",9 May 2022,Robotics (cs.RO)," Of all public assets, road infrastructure tops the list. Roads are crucial for economic development and growth, providing access to education, health, and employment. The maintenance, repair, and upgrade of roads are therefore vital to road users' health and safety as well as to a well- functioning and prosperous modern economy. The EU-funded HERON project will develop an integrated automated system to adequately maintain road infrastructure. In turn, this will reduce accidents, lower maintenance costs, and increase road network capacity and efficiency. To coordinate maintenance works, the project will design an autonomous ground robotic vehicle that will be supported by autonomous drones. Sensors and scanners for 3D mapping will be used in addition to artificial intelligence toolkits to help coordinate road maintenance and upgrade workflows."
Improved-Flow Warp Module for Remote Sensing Semantic Segmentation,"YinjieZhang, YiLiu, WeiGuo",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Remote sensing semantic segmentation aims to assign automatically each pixel on aerial images with specific label. In this letter, we proposed a new module, called improved-flow warp module (IFWM), to adjust semantic feature maps across different scales for remote sensing semantic segmentation. The improved-flow warp module is applied along with the feature extraction process in the convolutional neural network. First, IFWM computes the offsets of pixels by a learnable way, which can alleviate the misalignment of the multi-scale features. Second, the offsets help with the low-resolution deep feature up-sampling process to improve the feature accordance, which boosts the accuracy of semantic segmentation. We validate our method on several remote sensing datasets, and the results prove the effectiveness of our method.."
Attribution-based Task-specific Pruning for Multi-task Language Models,"NakyeongYang, YunahJang, HwanheeLee, SeohyeongJung, KyominJung",9 May 2022,Computation and Language (cs.CL)," Multi-task language models show outstanding performance for various natural language understanding tasks with only a single model. However, these language models inevitably utilize unnecessary large-scale model parameters, even when they are used for only a specific task. In this paper, we propose a novel training-free task-specific pruning method for multi-task language models. Specifically, we utilize an attribution method to compute the importance of each neuron for performing a specific task. Then, we prune task-specifically unimportant neurons using this computed importance. Experimental results on the six widely-used datasets show that our proposed pruning method significantly outperforms baseline compression methods. Also, we extend our method to be applicable in a low-resource setting, where the number of labeled datasets is insufficient."
Linear Runlength-Limited Subcodes of Reed-Muller Codes and CodingSchemes for Input-Constrained BMS Channels,"V. ArvindRameshwar, NavinKashyap",9 May 2022,Information Theory (cs.IT)," In this work, we address the question of the largest rate of linear subcodes of Reed-Muller (RM) codes, all of whose codewords respect a runlength-limited (RLL) constraint. Our interest is in the $(d,\infty)$-RLL constraint, which mandates that every pair of successive $1$s be separated by at least $d$ $0$s. Consider any sequence $\\{{\mathcal{C}_m}\\}_{m\geq 1}$ of RM codes with increasing blocklength, whose rates approach $R$, in the limit as the blocklength goes to infinity. We show that for any linear $(d,\infty)$-RLL subcode, $\hat{\mathcal{C}}_m$, of the code $\mathcal{C}_m$, it holds that the rate of $\hat{\mathcal{C}}_m$ is at most $\frac{R}{d+1}$, in the limit as the blocklength goes to infinity. We also consider scenarios where the coordinates of the RM codes are not ordered according to the standard lexicographic ordering, and derive rate upper bounds for linear $(d,\infty)$-RLL subcodes, in those cases as well. Next, for the setting of a $(d,\infty)$-RLL input-constrained binary memoryless symmetric (BMS) channel, we devise a new coding scheme, based on cosets of RM codes. Again, in the limit of blocklength going to infinity, this code outperforms any linear subcode of an RM code, in terms of rate, for low noise regimes of the channel."
Scaling up sign spotting through sign language dictionaries,"GülVarol, LilianeMomeni, SamuelAlbanie, TriantafyllosAfouras, AndrewZisserman",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The focus of this work is $\textit{sign spotting}$ - given a video of an isolated sign, our task is to identify $\textit{whether}$ and $\textit{where}$ it has been signed in a continuous, co-articulated sign language video. To achieve this sign spotting task, we train a model using multiple types of available supervision by: (1) $\textit{watching}$ existing footage which is sparsely labelled using mouthing cues; (2) $\textit{reading}$ associated subtitles (readily available translations of the signed content) which provide additional $\textit{weak-supervision}$; (3) $\textit{looking up}$ words (for which no co-articulated labelled examples are available) in visual sign language dictionaries to enable novel sign spotting. These three tasks are integrated into a unified learning framework using the principles of Noise Contrastive Estimation and Multiple Instance Learning. We validate the effectiveness of our approach on low-shot sign spotting benchmarks. In addition, we contribute a machine-readable British Sign Language (BSL) dictionary dataset of isolated signs, BSLDict, to facilitate study of this task. The dataset, models and code are available at our project page."
Identifying synthetic voices qualities for conversational agents,"M.Cuciniello, T.Amorese, G.Cordasco, S.Marrone, F.Marulli, F.Cavallo, O.Gordeeva, Z. CallejasCarrión, A.Esposito",9 May 2022,Human-Computer Interaction (cs.HC)," The present study aims to explore user acceptance and perceptions toward different quality levels of synthetical voices. To achieve this, four voices have been exploited considering two main factors: the quality of the voices (low vs high) and their gender (male and female). 186 volunteers were recruited and subsequently allocated into four groups of different ages respec-tively, adolescents, young adults, middle-aged and seniors. After having randomly listened to each voice, participants were asked to fill the Virtual Agent Voice Acceptance Questionnaire (VAVAQ). Outcomes show that the two higher quality voices of Antonio and Giulia were more appreciated than the low-quality voices of Edoardo and Clara by the whole sample in terms of pragmatic, hedonic and attractiveness qualities attributed to the voices. Concerning preferences towards differently aged voices, it clearly appeared that they varied according to participants age' ranges examined. Furthermore, in terms of suitability to perform different tasks, participants considered Antonio and Giulia equally adapt for healthcare and front office jobs. Antonio was also judged to be significantly more qualified to accomplish protection and security tasks, while Edoardo was classified as the absolute least skilled in conducting household chores."
Productive Performance Engineering for Weather and Climate Modelingwith Python,"Tal Ben-Nun, LinusGroner, FlorianDeconinck, TobiasWicky, EddieDavis, Johann Dahm, OliverElbert, RheaGeorge, JeremyMcGibbon, LukasTrümper, Elynn Wu, OliverFuhrer, ThomasSchulthess, TorstenHoefler",9 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Earth system models are developed with a tight coupling to target hardware, often containing highly-specialized code predicated on processor characteristics. This coupling stems from using imperative languages that hard-code computation schedules and layout. In this work, we present a detailed account of optimizing the Finite Volume Cubed-Sphere (FV3) weather model, improving productivity and performance. By using a declarative Python-embedded stencil DSL and data-centric optimization, we abstract hardware-specific details and define a semi-automated workflow for analyzing and optimizing weather and climate applications. The workflow utilizes both local optimization and full-program optimization, as well as user-guided fine-tuning. To prune the infeasible global optimization space, we automatically utilize repeating code motifs via a novel transfer tuning approach. On the Piz Daint supercomputer, we achieve speedups of up to 3.92x using GPUs over the tuned production implementation at a fraction of the original code."
Verifying Integrity of Deep Ensemble Models by Lossless Black-boxWatermarking with Sensitive Samples,"LinaLin, HanzhouWu","9 May 2022 (v1(https://arxiv.org/abs/2205.04145v1)), lastrevised 10 May 2022 (this version, v2)",Cryptography and Security (cs.CR)," With the widespread use of deep neural networks (DNNs) in many areas, more and more studies focus on protecting DNN models from intellectual property (IP) infringement. Many existing methods apply digital watermarking to protect the DNN models. The majority of them either embed a watermark directly into the internal network structure/parameters or insert a zero-bit watermark by fine-tuning a model to be protected with a set of so-called trigger samples. Though these methods work very well, they were designed for individual DNN models, which cannot be directly applied to deep ensemble models (DEMs) that combine multiple DNN models to make the final decision. It motivates us to propose a novel black-box watermarking method in this paper for DEMs, which can be used for verifying the integrity of DEMs. In the proposed method, a certain number of sensitive samples are carefully selected through mimicking real-world DEM attacks and analyzing the prediction results of the sub-models of the non-attacked DEM and the attacked DEM on the carefully crafted dataset. By analyzing the prediction results of the target DEM on these carefully crafted sensitive samples, we are able to verify the integrity of the target DEM. Different from many previous methods, the proposed method does not modify the original DEM to be protected, which indicates that the proposed method is lossless. Experimental results have shown that the DEM integrity can be reliably verified even if only one sub-model was attacked, which has good potential in practice."
Towards Self-Adaptive Peer-to-Peer Monitoring for Fog Environments,"VeraColombo, AlessandroTundo, MicheleCiavotta, LeonardoMariani",9 May 2022,Systems and Control (eess.SY)," Monitoring is a critical component in fog environments: it promptly provides insights about the behavior of systems, reveals Service Level Agreements (SLAs) violations, enables the autonomous orchestration of services and platforms, calls for the intervention of operators, and triggers self-healing actions.   In such environments, monitoring solutions have to cope with the heterogeneity of the devices and platforms present in the Fog, the limited resources available at the edge of the network, and the high dynamism of the whole Cloud-to-Thing continuum.   This paper addresses the challenge of accurately and efficiently monitoring the Fog with a self-adaptive peer-to-peer (P2P) monitoring solution that can opportunistically adjust its behavior according to the collected data exploiting a lightweight rule-based expert system.   Empirical results show that adaptation can improve monitoring accuracy, while reducing network and power consumption at the cost of higher memory consumption."
Exponential tractability of $L_2$-approximation with function values,"DavidKrieg, PawelSiedlecki, MarioUllrich, HenrykWoźniakowski",9 May 2022,Numerical Analysis (math.NA)," We study the complexity of high-dimensional approximation in the $L_2$-norm when different classes of information are available; we compare the power of function evaluations with the power of arbitrary continuous linear measurements. Here, we discuss the situation when the number of linear measurements required to achieve an error $\varepsilon \in (0,1)$ in dimension $d\in\mathbb{N}$ depends only poly-logarithmically on $\varepsilon^{-1}$. This corresponds to an exponential order of convergence of the approximation error, which often happens in applications. However, it does not mean that the high-dimensional approximation problem is easy, the main difficulty usually lies within the dependence on the dimension $d$. We determine to which extent the required amount of information changes, if we allow only function evaluation instead of arbitrary linear information. It turns out that in this case we only lose very little, and we can even restrict to linear algorithms. In particular, several notions of tractability hold simultaneously for both types of available information."
The Roles and Modes of Human Interactions with Automated MachineLearning Systems,"Thanh TungKhuat, David JacobKedziora, BogdanGabrys",9 May 2022,Machine Learning (cs.LG)," As automated machine learning (AutoML) systems continue to progress in both sophistication and performance, it becomes important to understand the `how' and `why' of human-computer interaction (HCI) within these frameworks, both current and expected. Such a discussion is necessary for optimal system design, leveraging advanced data-processing capabilities to support decision-making involving humans, but it is also key to identifying the opportunities and risks presented by ever-increasing levels of machine autonomy. Within this context, we focus on the following questions: (i) How does HCI currently look like for state-of-the-art AutoML algorithms, especially during the stages of development, deployment, and maintenance? (ii) Do the expectations of HCI within AutoML frameworks vary for different types of users and stakeholders? (iii) How can HCI be managed so that AutoML solutions acquire human trust and broad acceptance? (iv) As AutoML systems become more autonomous and capable of learning from complex open-ended environments, will the fundamental nature of HCI evolve? To consider these questions, we project existing literature in HCI into the space of AutoML; this connection has, to date, largely been unexplored. In so doing, we review topics including user-interface design, human-bias mitigation, and trust in artificial intelligence (AI). Additionally, to rigorously gauge the future of HCI, we contemplate how AutoML may manifest in effectively open-ended environments. This discussion necessarily reviews projected developmental pathways for AutoML, such as the incorporation of reasoning, although the focus remains on how and why HCI may occur in such a framework rather than on any implementational details. Ultimately, this review serves to identify key research directions aimed at better facilitating the roles and modes of human interactions with both current and future AutoML systems."
Federated Multi-Armed Bandits Under Byzantine Attacks,"IlkerDemirel, YigitYildirim, Cem Tekin",9 May 2022,Machine Learning (cs.LG)," Multi-armed bandits (MAB) is a simple reinforcement learning model where the learner controls the trade-off between exploration versus exploitation to maximize its cumulative reward. Federated multi-armed bandits (FMAB) is a recently emerging framework where a cohort of learners with heterogeneous local models play a MAB game and communicate their aggregated feedback to a parameter server to learn the global feedback model. Federated learning models are vulnerable to adversarial attacks such as model-update attacks or data poisoning. In this work, we study an FMAB problem in the presence of Byzantine clients who can send false model updates that pose a threat to the learning process. We borrow tools from robust statistics and propose a median-of-means-based estimator: Fed-MoM- UCB, to cope with the Byzantine clients. We show that if the Byzantine clients constitute at most half the cohort, it is possible to incur a cumulative regret on the order of ${\cal O} (\log T)$ with respect to an unavoidable error margin, including the communication cost between the clients and the parameter server. We analyze the interplay between the algorithm parameters, unavoidable error margin, regret, communication cost, and the arms' suboptimality gaps. We demonstrate Fed-MoM-UCB's effectiveness against the baselines in the presence of Byzantine attacks via experiments."
Reusing Comparator Networks in Pseudo-Boolean Encodings,"MichałKarpiński, MarekPiotrów",9 May 2022,Data Structures and Algorithms (cs.DS)," A Pseudo-Boolean (PB) constraint is a linear inequality constraint over Boolean literals. One of the popular, efficient ideas used to solve PB- problems (a set of PB-constraints) is to translate them to SAT instances (encodings) via, for example, sorting networks, then to process those instances using state-of-the-art SAT-solvers. In this paper we show an improvement of such technique. By using a variation of a greedy set cover algorithm, when adding constraints to our encoding, we reuse parts of the already encoded PB-instance in order to decrease the size (the number of variables and clauses) of the resulting SAT instance. The experimental evaluation shows that the proposed method increases the number of solved instances."
Single-Image 3D Face Reconstruction under Perspective Projection,"YueyingKao, BowenPan, MiaoXu, JiangjingLyu, XiangyuZhu, YuanzhangChang, Xiaobo Li, Zhen Lei, Zixiong Qin",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In 3D face reconstruction, orthogonal projection has been widely employed to substitute perspective projection to simplify the fitting process. This approximation performs well when the distance between camera and face is far enough. However, in some scenarios that the face is very close to camera or moving along the camera axis, the methods suffer from the inaccurate reconstruction and unstable temporal fitting due to the distortion under the perspective projection. In this paper, we aim to address the problem of single-image 3D face reconstruction under perspective projection. Specifically, a deep neural network, Perspective Network (PerspNet), is proposed to simultaneously reconstruct 3D face shape in canonical space and learn the correspondence between 2D pixels and 3D points, by which the 6DoF (6 Degrees of Freedom) face pose can be estimated to represent perspective projection. Besides, we contribute a large ARKitFace dataset to enable the training and evaluation of 3D face reconstruction solutions under the scenarios of perspective projection, which has 902,724 2D facial images with ground-truth 3D face mesh and annotated 6DoF pose parameters. Experimental results show that our approach outperforms current state-of-the-art methods by a significant margin."
Convergence and error analysis of compressible fluid flows with randomdata: Monte Carlo method,"EduardFeireisl, Mária Lukáčová -Medviďová, Bangwei She, Yuhuan Yuan",9 May 2022,Numerical Analysis (math.NA)," The goal of this paper is to study convergence and error estimates of the Monte Carlo method for the Navier-Stokes equations with random data. To discretize in space and time, the Monte Carlo method is combined with a suitable deterministic discretization scheme, such as a finite volume method. We assume that the initial data, force and the viscosity coefficients are random variables and study both, the statistical convergence rates as well as the approximation errors. Since the compressible Navier-Stokes equations are not known to be uniquely solvable in the class of global weak solutions, we cannot apply pathwise arguments to analyze the random Navier-Stokes equations. Instead we have to apply intrinsic stochastic compactness arguments via the Skorokhod representation theorem and the Gyöngy-Krylov method. Assuming that the numerical solutions are bounded in probability, we prove that the Monte Carlo finite volume method converges to a statistical strong solution. The convergence rates are discussed as well. Numerical experiments illustrate theoretical results."
Identifying Fixation and Saccades in Virtual Reality,"Xiao-linChen, Wen-junHou",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Gaze recognition can significantly reduce the amount of eye movement data for a better understanding of cognitive and visual processing. Gaze recognition is an essential precondition for eye-based interaction applications in virtual reality. However, the three-dimensional characteristics of virtual reality environments also pose new challenges to existing recognition algorithms. Based on seven evaluation metrics and the Overall score (the mean of the seven normalized metric values), we obtain optimal parameters of three existing recognition algorithms (Velocity- Threshold Identification, Dispersion-Threshold Identification, and Velocity & Dispersion-Threshold Identification) and our modified Velocity & Dispersion-Threshold Identification algorithm. We compare the performance of these four algorithms with optimal parameters. The results show that our modified Velocity & Dispersion-Threshold Identification performs the best. The impact of interface complexity on classification results is also preliminarily explored. The results show that the algorithms are not sensitive to interface complexity."
Cross-Utterance Conditioned VAE for Non-Autoregressive Text-to-Speech,"YangLi, ChengYu, GuangzhiSun, HuaJiang, Fanglei Sun, Weiqin Zu, Ying Wen, Yang Yang, Jun Wang",9 May 2022,Sound (cs.SD)," Modelling prosody variation is critical for synthesizing natural and expressive speech in end-to-end text-to-speech (TTS) systems. In this paper, a cross-utterance conditional VAE (CUC-VAE) is proposed to estimate a posterior probability distribution of the latent prosody features for each phoneme by conditioning on acoustic features, speaker information, and text features obtained from both past and future sentences. At inference time, instead of the standard Gaussian distribution used by VAE, CUC-VAE allows sampling from an utterance-specific prior distribution conditioned on cross- utterance information, which allows the prosody features generated by the TTS system to be related to the context and is more similar to how humans naturally produce prosody. The performance of CUC-VAE is evaluated via a qualitative listening test for naturalness, intelligibility and quantitative measurements, including word error rates and the standard deviation of prosody attributes. Experimental results on LJ-Speech and LibriTTS data show that the proposed CUC-VAE TTS system improves naturalness and prosody diversity with clear margins."
"Development of Charging, Discharging Scheduling Algorithm forEconomical and Energy Efficient Operation of Multi EV Charging Station","HojunJin, SangkeumLee, SarvarHussainNengroo, Dongsoo Har",9 May 2022,Systems and Control (eess.SY)," As the number of electric vehicles (EVs) significantly increases, the excessive charging demand of parked EVs in the charging station may incur an instability problem to the electricity network during peak hours. For the charging station to take a microgrid (MG) structure, an economical and energy-efficient power management scheme is required for the power provision of EVs while considering the local load demand of the MG. For these purposes, this study presents the power management scheme of interdependent MG and EV fleets aided by a novel EV charg-ing/discharging scheduling algorithm. In this algorithm, the maximum amount of discharging power from parked EVs is determined based on the difference between local load demand and photovoltaic (PV) power production to alleviate imbalances occurred between them. For the power management of the MG with charging/discharging scheduling of parked EVs in the PV-based charging station, multi-objective optimization is performed to minimize the operating cost and grid dependency. In addition, the proposed scheme maximizes the utilization of EV charging/discharging while satisfying the charging requirements of parked EVs. Moreover, a more economical and energy-efficient PV-based charging station is established using the future trends of local load demand and PV power production predicted by a gated recurrent unit (GRU) network. With the proposed EV charging/discharging scheduling algorithm, the operating cost of PV-based charging station is decreased by 167.71% and 28.85% compared with the EV charg-ing scheduling algorithm and the conventional EV charging/discharging scheduling algorithm, respectively. It is obvious that the economical and energy-efficient operation of PV-based charging station can be accomplished by applying the power management scheme with the proposed EV charging/discharging scheduling strategy."
Localized Adversarial Domain Generalization,"WeiZhu, LeLu, JingXiao, MeiHan, JieboLuo, Adam P.Harrison",9 May 2022,Machine Learning (cs.LG)," Deep learning methods can struggle to handle domain shifts not seen in training data, which can cause them to not generalize well to unseen domains. This has led to research attention on domain generalization (DG), which aims to the model's generalization ability to out-of-distribution. Adversarial domain generalization is a popular approach to DG, but conventional approaches (1) struggle to sufficiently align features so that local neighborhoods are mixed across domains; and (2) can suffer from feature space over collapse which can threaten generalization performance. To address these limitations, we propose localized adversarial domain generalization with space compactness maintenance~(LADG) which constitutes two major contributions. First, we propose an adversarial localized classifier as the domain discriminator, along with a principled primary branch. This constructs a min-max game whereby the aim of the featurizer is to produce locally mixed domains. Second, we propose to use a coding-rate loss to alleviate feature space over collapse. We conduct comprehensive experiments on the Wilds DG benchmark to validate our approach, where LADG outperforms leading competitors on most datasets."
Damage Maximization for Combat Network with Limited Costs,"JintaoYu, BingXiao, YuzhuCui",9 May 2022,Systems and Control (eess.SY)," Maximizing the damage of combat network plays a vital role in identifying the important nodes in combat system-of-system (SOS). In order to protect or destroy the critical part of combat network more efficiently with less costs, here we report a more realistic model to study the combat network damage problems. As a first step, the cost and effect of damage are redefined based on the network topology and the functional characteristics of nodes according to practical significance, respectively. Then, the damage maximization model for combat network with limited costs is constructed. To obtain the optimal solution of the mathematical model, an improved genetic algorithm (IPGA) based on prior information is proposed. As a result, our proposed method has a significant advantage in the feasibility and effectiveness compared with other algorithms shown in the simulated experiments. Furthermore, the attack law of combat network is explored."
On Generalisability of Machine Learning-based Network IntrusionDetection Systems,"SiamakLayeghy, MariusPortmann",9 May 2022,Networking and Internet Architecture (cs.NI)," Many of the proposed machine learning (ML) based network intrusion detection systems (NIDSs) achieve near perfect detection performance when evaluated on synthetic benchmark datasets. Though, there is no record of if and how these results generalise to other network scenarios, in particular to real-world networks. In this paper, we investigate the generalisability property of ML-based NIDSs by extensively evaluating seven supervised and unsupervised learning models on four recently published benchmark NIDS datasets. Our investigation indicates that none of the considered models is able to generalise over all studied datasets. Interestingly, our results also indicate that the generalisability has a high degree of asymmetry, i.e., swapping the source and target domains can significantly change the classification performance. Our investigation also indicates that overall, unsupervised learning methods generalise better than supervised learning models in our considered scenarios. Using SHAP values to explain these results indicates that the lack of generalisability is mainly due to the presence of strong correspondence between the values of one or more features and Attack/Benign classes in one dataset-model combination and its absence in other datasets that have different feature distributions."
Unitless Frobenius quantales,"Cédric deLacroix, LuigiSantocanale",9 May 2022,Logic in Computer Science (cs.LO)," It is often stated that Frobenius quantales are necessarily unital. By taking negation as a primitive operation, we can define Frobenius quantales that may not have a unit. We develop the elementary theory of these structures and show, in particular, how to define nuclei whose quotients are Frobenius quantales. This yields a phase semantics and a representation theorem via phase quantales. Important examples of these structures arise from Raney's notion of tight Galois connection: tight endomaps of a complete lattice always form a Girard quantale which is unital if and only if the lattice is completely distributive. We give a characterisation and an enumeration of tight endomaps of the diamond lattices Mn and exemplify the Frobenius structure on these maps. By means of phase semantics, we exhibit analogous examples built up from trace class operators on an infinite dimensional Hilbert space. Finally, we argue that units cannot be properly added to Frobenius quantales: every possible extention to a unital quantale fails to preserve negations."
A coherent differential PCF,ThomasEhrhard,9 May 2022,Logic in Computer Science (cs.LO)," The categorical models of the differential lambda-calculus are additive categories because of the Leibniz rule which requires the summation of two expressions. This means that, as far as the differential lambda- calculus and differential linear logic are concerned, these models feature finite non-determinism and indeed these languages are essentially non- deterministic. In a previous paper we introduced a categorical framework for differentiation which does not require additivity and is compatible with deterministic models such as coherence spaces and probabilistic models such as probabilistic coherence spaces. Based on this semantics we develop a syntax of a deterministic version of the differential lambda-calculus. One nice feature of this new approach to differentiation is that it is compatible with general fixpoints of terms, so our language is actually a differential extension of PCF."
On the Storage Overhead of Proof-of-Work Blockchains,"AlessandroSforzin, Matteo Maso, ClaudioSoriente, GhassanKarame",9 May 2022,Cryptography and Security (cs.CR)," Permissionless blockchains such as Bitcoin have long been criticized for their high computational and storage overhead. Unfortunately, while a number of proposals address the energy consumption of existing Proof-of-Work deployments, little attention has been given so far to remedy the storage overhead incurred by those blockchains. In fact, it seems widely acceptable that full nodes supporting the blockchains have to volunteer hundreds of GBs of their storage, to store and verify all transactions exchanged in the system. In this paper, we explore the solution space to effectively reduce the storage footprint of Proof-of-Work based blockchains. To do so, we analyze, by means of thorough empirical measurements, how existing full blockchain nodes utilize data from the shared ledger to validate incoming transactions/blocks. Based on this analysis, we show that it is possible for full nodes to locally reduce their storage footprint to approximately 15 GB, without any modification to the underlying protocol. We also discuss other client-side strategies to further reduce the storage footprint while incurring negligible computational overhead on the nodes."
Re-thinking Knowledge Graph Completion Evaluation from an InformationRetrieval Perspective,"YingZhou, XuanangChen, BenHe, ZhengYe, LeSun",9 May 2022,Computation and Language (cs.CL)," Knowledge graph completion (KGC) aims to infer missing knowledge triples based on known facts in a knowledge graph. Current KGC research mostly follows an entity ranking protocol, wherein the effectiveness is measured by the predicted rank of a masked entity in a test triple. The overall performance is then given by a micro(-average) metric over all individual answer entities. Due to the incomplete nature of the large-scale knowledge bases, such an entity ranking setting is likely affected by unlabelled top-ranked positive examples, raising questions on whether the current evaluation protocol is sufficient to guarantee a fair comparison of KGC systems. To this end, this paper presents a systematic study on whether and how the label sparsity affects the current KGC evaluation with the popular micro metrics. Specifically, inspired by the TREC paradigm for large-scale information retrieval (IR) experimentation, we create a relatively ""complete"" judgment set based on a sample from the popular FB15k-237 dataset following the TREC pooling method. According to our analysis, it comes as a surprise that switching from the original labels to our ""complete"" labels results in a drastic change of system ranking of a variety of 13 popular KGC models in terms of micro metrics. Further investigation indicates that the IR-like macro(-average) metrics are more stable and discriminative under different settings, meanwhile, less affected by label sparsity. Thus, for KGC evaluation, we recommend conducting TREC- style pooling to balance between human efforts and label completeness, and reporting also the IR-like macro metrics to reflect the ranking nature of the KGC task."
On Turedo Hierarchies and Intrinsic Universality,"SamuelNalin, GuillaumeTheyssier",9 May 2022,Computational Complexity (cs.CC)," This paper is about turedos, which are Turing machine whose head can move in the plane (or in a higher-dimensional space) but only in a selfavoiding way, by putting marks (letters) on visited positions and moving only to unmarked, therefore unvisited, positions. The key parameter of turedos is their lookup radius: the distance up to which the head can look around in order to make its decision of where to move to and what mark to write. In this paper we study the hierarchy of turedos according to their lookup radius and the dimension of space using notions of simulation up to spatio-temporal rescaling (a standard approach in cellular automata or self- assembly systems). We establish that there is a rich interplay between the turedo parameters and the notion of simulation considered. We show in particular, for the most liberal simulations, the existence of 3D turedos of radius 1 that are intrinsically universal for all radii, but that this is impossible in dimension 2, where some radius 2 turedo are impossible to simulate at radius 1. Using stricter notions of simulation, intrinsic universality becomes impossible, even in dimension 3, and there is a strict radius hierarchy. Finally, when restricting to radius 1, universality is again possible in dimension 3, but not in dimension 2, where we show however that a radius 3 turedo can simulate all radius 1 turedos."
Cascading failure model and robustness of heterogeneous interdependentcombat network,"JintaoYu, BingXiao, YuzhuCui","9 May 2022 (v1(https://arxiv.org/abs/2205.04099v1)), lastrevised 12 May 2022 (this version, v2)",Systems and Control (eess.SY)," The networked combat system-of-system (CSOS) is the trend of combat development with the innovation of technology. The achievement of combat effectiveness requires CSOS to have a good ability to deal with external interference. From the perspective of complex networks, the modeling of CSOS is carried out, and the robustness of the combat network is explored based on this. Firstly, a more realistic double-layer heterogeneous interdependent combat network model is established. Then, the conditional group dependency situation is considered to design failure rules for dependent failure, and the coupling relation between the double-layer subnets is analysed for cascading failure. Furthermore, the initial load and capacity of the node are defined, respectively, as well as the load redistribution strategy and the status judgment rules for the cascading failure model. Simulation experiments are carried out by changing the attack modes and different parameters, and the results show that the robustness of the combat network can be effectively improved by improving the tolerance limit of one-way dependency of the functional net, the node capacity of the functional net and the tolerance of the overload state. The conclusions of this paper can provide a useful reference for the network structure optimization and network security protection in military field."
SmoothNets: Optimizing CNN architecture design for differentiallyprivate deep learning,"Nicolas W.Remerscheid, AlexanderZiller, DanielRueckert, GeorgiosKaissis",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The arguably most widely employed algorithm to train deep neural networks with Differential Privacy is DPSGD, which requires clipping and noising of per-sample gradients. This introduces a reduction in model utility compared to non-private training. Empirically, it can be observed that this accuracy degradation is strongly dependent on the model architecture. We investigated this phenomenon and, by combining components which exhibit good individual performance, distilled a new model architecture termed SmoothNet, which is characterised by increased robustness to the challenges of DP-SGD training. Experimentally, we benchmark SmoothNet against standard architectures on two benchmark datasets and observe that our architecture outperforms others, reaching an accuracy of 73.5\% on CIFAR-10 at $\varepsilon=7.0$ and 69.2\% at $\varepsilon=7.0$ on ImageNette, a state-of-the-art result compared to prior architectural modifications for DP."
So Different Yet So Alike! Constrained Unsupervised Text StyleTransfer,"Abhinav RameshKashyap, DevamanyuHazarika, Min-Yen Kan, RogerZimmermann, SoujanyaPoria",9 May 2022,Computation and Language (cs.CL)," Automatic transfer of text between domains has become popular in recent times. One of its aims is to preserve the semantic content of text being translated from source to target domain. However, it does not explicitly maintain other attributes between the source and translated text, for e.g., text length and descriptiveness. Maintaining constraints in transfer has several downstream applications, including data augmentation and de-biasing. We introduce a method for such constrained unsupervised text style transfer by introducing two complementary losses to the generative adversarial network (GAN) family of models. Unlike the competing losses used in GANs, we introduce cooperative losses where the discriminator and the generator cooperate and reduce the same loss. The first is a contrastive loss and the second is a classification loss, aiming to regularize the latent space further and bring similar sentences across domains closer together. We demonstrate that such training retains lexical, syntactic, and domain-specific constraints between domains for multiple benchmark datasets, including ones where more than one attribute change. We show that the complementary cooperative losses improve text quality, according to both automated and human evaluation measures."
Age-driven Joint Sampling and Non-slot Based Scheduling for IndustrialInternet of Things,"YaliCao, YingleiTeng, MeiSong, NanWang",9 May 2022,Information Theory (cs.IT)," Effective control of time-sensitive industrial applications depends on the real-time transmission of data from underlying sensors. Quantifying the data freshness through age of information (AoI), in this paper, we jointly design sampling and non-slot based scheduling policies to minimize the maximum time-average age of information (MAoI) among sensors with the constraints of average energy cost and finite queue stability. To overcome the intractability involving high couplings of such a complex stochastic process, we first focus on the single-sensor time-average AoI optimization problem and convert the constrained Markov decision process (CMDP) into an unconstrained Markov decision process (MDP) by the Lagrangian method. With the infinite-time average energy and AoI expression expended as the Bellman equation, the single-sensor time-average AoI optimization problem can be approached through the steady-state distribution probability. Further, we propose a low-complexity sub-optimal sampling and semi- distributed scheduling scheme for the multi-sensor scenario. The simulation results show that the proposed scheme reduces the MAoI significantly while achieving a balance between the sampling rate and service rate for multiple sensors."
Approaches and Challenges in Robotic Perception for Table-topRearrangement and Planning,"AdityaAgarwal, Bipasha Sen, Shankara NarayananV, VishalReddyMandadi, BrojeshwarBhowmick, K MadhavaKrishna",9 May 2022,Robotics (cs.RO)," Table-top Rearrangement and Planning is a challenging problem that relies heavily on an excellent perception stack. The perception stack involves observing and registering the 3D scene on the table, detecting what objects are on the table, and how to manipulate them. Consequently, it greatly influences the system's task-planning and motion-planning stacks that follow. We present a comprehensive overview and discuss the different challenges associated with the perception module. This work is a result of our extensive involvement in the ICRA 2022 Open Cloud Robot Table Organization Challenge, in which we currently stand first on the leaderboard (as of 24th of April 2022, the final week of the challenge)."
Single-view 3D Body and Cloth Reconstruction under Complex Poses,"NicolasUgrinovic, AlbertPumarola, AlbertoSanfeliu, Francesc Moreno-Noguer",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Recent advances in 3D human shape reconstruction from single images have shown impressive results, leveraging on deep networks that model the so-called implicit function to learn the occupancy status of arbitrarily dense 3D points in space. However, while current algorithms based on this paradigm, like PiFuHD, are able to estimate accurate geometry of the human shape and clothes, they require high-resolution input images and are not able to capture complex body poses. Most training and evaluation is performed on 1k-resolution images of humans standing in front of the camera under neutral body poses. In this paper, we leverage publicly available data to extend existing implicit function-based models to deal with images of humans that can have arbitrary poses and self-occluded limbs. We argue that the representation power of the implicit function is not sufficient to simultaneously model details of the geometry and of the body pose. We, therefore, propose a coarse-to-fine approach in which we first learn an implicit function that maps the input image to a 3D body shape with a low level of detail, but which correctly fits the underlying human pose, despite its complexity. We then learn a displacement map, conditioned on the smoothed surface and on the input image, which encodes the high-frequency details of the clothes and body. In the experimental section, we show that this coarse-to-fine strategy represents a very good trade-off between shape detail and pose correctness, comparing favorably to the most recent state- of-the-art approaches. Our code will be made publicly available."
A Balanced Data Approach for Evaluating Cross-Lingual Transfer:Mapping the Linguistic Blood Bank,"DanMalkin, TomaszLimisiewicz, GabrielStanovsky",9 May 2022,Computation and Language (cs.CL)," We show that the choice of pretraining languages affects downstream cross-lingual transfer for BERT-based models. We inspect zero- shot performance in balanced data conditions to mitigate data size confounds, classifying pretraining languages that improve downstream performance as donors, and languages that are improved in zero-shot performance as recipients. We develop a method of quadratic time complexity in the number of languages to estimate these relations, instead of an exponential exhaustive computation of all possible combinations. We find that our method is effective on a diverse set of languages spanning different linguistic features and two downstream tasks. Our findings can inform developers of large-scale multilingual language models in choosing better pretraining configurations."
Automated Evaluation for Student Argumentative Writing: A Survey,"XinyuWang, YohanLee, JuneyoungPark",9 May 2022,Computation and Language (cs.CL)," This paper surveys and organizes research works in an under- studied area, which we call automated evaluation for student argumentative writing. Unlike traditional automated writing evaluation that focuses on holistic essay scoring, this field is more specific: it focuses on evaluating argumentative essays and offers specific feedback, including argumentation structures, argument strength trait score, etc. The focused and detailed evaluation is useful for helping students acquire important argumentation skill. In this paper we organize existing works around tasks, data and methods. We further experiment with BERT on representative datasets, aiming to provide up-to-date baselines for this field."
Improved error estimates for the finite volume and the MAC schemes forthe compressible Navier-Stokes system,"EduardFeireisl, Mária Lukáčová-Medviďová, Bangwei She",9 May 2022,Numerical Analysis (math.NA)," We present new error estimates for the finite volume and finite difference methods applied to the compressible Navier-Stokes equations. The main innovative ingredients of the improved error estimates are a refined consistency analysis combined with a continuous version of the relative energy inequality. Consequently, we obtain better convergence rates than those available in the literature so far. Moreover, the error estimates hold in the whole physically relevant range of the adiabatic coefficient."
Beyond Bounding Box: Multimodal Knowledge Learning for ObjectDetection,"WeixinFeng, Xingyuan Bu, ChenchenZhang, XubinLi",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Multimodal supervision has achieved promising results in many visual language understanding tasks, where the language plays an essential role as a hint or context for recognizing and locating instances. However, due to the defects of the human-annotated language corpus, multimodal supervision remains unexplored in fully supervised object detection scenarios. In this paper, we take advantage of language prompt to introduce effective and unbiased linguistic supervision into object detection, and propose a new mechanism called multimodal knowledge learning (\textbf{MKL}), which is required to learn knowledge from language supervision. Specifically, we design prompts and fill them with the bounding box annotations to generate descriptions containing extensive hints and context for instances recognition and localization. The knowledge from language is then distilled into the detection model via maximizing cross-modal mutual information in both image- and object-level. Moreover, the generated descriptions are manipulated to produce hard negatives to further boost the detector performance. Extensive experiments demonstrate that the proposed method yields a consistent performance gain by 1.6\% $\sim$ 2.1\% and achieves state-of-the-art on MS-COCO and OpenImages datasets."
Sub-Word Alignment Is Still Useful: A Vest-Pocket Method for EnhancingLow-Resource Machine Translation,"MinhanXu, YuHong",9 May 2022,Computation and Language (cs.CL)," We leverage embedding duplication between aligned sub-words to extend the Parent-Child transfer learning method, so as to improve low- resource machine translation. We conduct experiments on benchmark datasets of My-En, Id-En and Tr-En translation scenarios. The test results show that our method produces substantial improvements, achieving the BLEU scores of 22.5, 28.0 and 18.1 respectively. In addition, the method is computationally efficient which reduces the consumption of training time by 63.8%, reaching the duration of 1.6 hours when training on a Tesla 16GB P100 GPU. All the models and source codes in the experiments will be made publicly available to support reproducible research."
Multi-level Consistency Learning for Semi-supervised Domain Adaptation,"ZizhengYan, YushuangWu, GuanbinLi, YipengQin, XiaoguangHan, ShuguangCui",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Semi-supervised domain adaptation (SSDA) aims to apply knowledge learned from a fully labeled source domain to a scarcely labeled target domain. In this paper, we propose a Multi-level Consistency Learning (MCL) framework for SSDA. Specifically, our MCL regularizes the consistency of different views of target domain samples at three levels: (i) at inter- domain level, we robustly and accurately align the source and target domains using a prototype-based optimal transport method that utilizes the pros and cons of different views of target samples; (ii) at intra-domain level, we facilitate the learning of both discriminative and compact target feature representations by proposing a novel class-wise contrastive clustering loss; (iii) at sample level, we follow standard practice and improve the prediction accuracy by conducting a consistency-based self-training. Empirically, we verified the effectiveness of our MCL framework on three popular SSDA benchmarks, i.e., VisDA2017, DomainNet, and Office-Home datasets, and the experimental results demonstrate that our MCL framework achieves the state-of-the-art performance."
Augmentations: An Insight into their Effectiveness on ConvolutionNeural Networks,"SabeeshEthiraj, Bharath KumarBolla",9 May 2022,Machine Learning (cs.LG)," Augmentations are the key factor in determining the performance of any neural network as they provide a model with a critical edge in boosting its performance. Their ability to boost a model's robustness depends on two factors, viz-a-viz, the model architecture, and the type of augmentations. Augmentations are very specific to a dataset, and it is not imperative that all kinds of augmentation would necessarily produce a positive effect on a model's performance. Hence there is a need to identify augmentations that perform consistently well across a variety of datasets and also remain invariant to the type of architecture, convolutions, and the number of parameters used. Hence there is a need to identify augmentations that perform consistently well across a variety of datasets and also remain invariant to the type of architecture, convolutions, and the number of parameters used. This paper evaluates the effect of parameters using 3x3 and depth-wise separable convolutions on different augmentation techniques on MNIST, FMNIST, and CIFAR10 datasets. Statistical Evidence shows that techniques such as Cutouts and Random horizontal flip were consistent on both parametrically low and high architectures. Depth-wise separable convolutions outperformed 3x3 convolutions at higher parameters due to their ability to create deeper networks. Augmentations resulted in bridging the accuracy gap between the 3x3 and depth-wise separable convolutions, thus establishing their role in model generalization. At higher number augmentations did not produce a significant change in performance. The synergistic effect of multiple augmentations at higher parameters, with antagonistic effect at lower parameters, was also evaluated. The work proves that a delicate balance between architectural supremacy and augmentations needs to be achieved to enhance a model's performance in any given deep learning task."
Multilevel Hierarchical Network with Multiscale Sampling for VideoQuestion Answering,"MinPeng, ChongyangWang, YuanGao, YuShi, Xiang-Dong Zhou",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Video question answering (VideoQA) is challenging given its multimodal combination of visual understanding and natural language processing. While most existing approaches ignore the visual appearance- motion information at different temporal scales, it is unknown how to incorporate the multilevel processing capacity of a deep learning model with such multiscale information. Targeting these issues, this paper proposes a novel Multilevel Hierarchical Network (MHN) with multiscale sampling for VideoQA. MHN comprises two modules, namely Recurrent Multimodal Interaction (RMI) and Parallel Visual Reasoning (PVR). With a multiscale sampling, RMI iterates the interaction of appearance-motion information at each scale and the question embeddings to build the multilevel question-guided visual representations. Thereon, with a shared transformer encoder, PVR infers the visual cues at each level in parallel to fit with answering different question types that may rely on the visual information at relevant levels. Through extensive experiments on three VideoQA datasets, we demonstrate improved performances than previous state-of-the-arts and justify the effectiveness of each part of our method."
Exploiting Digital Surface Models for Inferring Super-Resolution forRemotely Sensed Images,"SavvasKaratsiolis, ChiragPadubidri, AndreasKamilaris",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Despite the plethora of successful Super-Resolution Reconstruction (SRR) models applied to natural images, their application to remote sensing imagery tends to produce poor results. Remote sensing imagery is often more complicated than natural images and has its peculiarities such as being of lower resolution, it contains noise, and often depicting large textured surfaces. As a result, applying non-specialized SRR models on remote sensing imagery results in artifacts and poor reconstructions. To address these problems, this paper proposes an architecture inspired by previous research work, introducing a novel approach for forcing an SRR model to output realistic remote sensing images: instead of relying on feature-space similarities as a perceptual loss, the model considers pixel-level information inferred from the normalized Digital Surface Model (nDSM) of the image. This strategy allows the application of better-informed updates during the training of the model which sources from a task (elevation map inference) that is closely related to remote sensing. Nonetheless, the nDSM auxiliary information is not required during production and thus the model infers a super-resolution image without any additional data besides its low- resolution pairs. We assess our model on two remotely sensed datasets of different spatial resolutions that also contain the DSM pairs of the images: the DFC2018 dataset and the dataset containing the national Lidar fly-by of Luxembourg. Based on visual inspection, the inferred super-resolution images exhibit particularly superior quality. In particular, the results for the high-resolution DFC2018 dataset are realistic and almost indistinguishable from the ground truth images."
Realization of Lattice Formation in Nonlinear Two-dimensionalPotential by Mobile Robots,"YanranWang, TatsuyaBaba, TakashiHikihara",9 May 2022,Robotics (cs.RO)," Formation control in multi-agent system has earned significant research interests in both theorical aspect and applications over the past two decades. However, the study on how the external environment shapes swarm formation dynamics, and the design of formation control algorithm for multi- agent system in nonlinear external potential have not been rigorously investigated. In this paper, we present a formation control algorithm for mobile robots travelling in nonlinear external potential. Experiments are performed on real mobile robots to verify the algorithm, and the effectiveness of Dynamic Mode Decomposition in robot's velocity prediction in unknown environment is demonstrated."
Few-shot Mining of Naturally Occurring Inputs and Outputs,"MandarJoshi, TerraBlevins, Mike Lewis, Daniel S.Weld, LukeZettlemoyer",9 May 2022,Computation and Language (cs.CL)," Creating labeled natural language training data is expensive and requires significant human effort. We mine input output examples from large corpora using a supervised mining function trained using a small seed set of only 100 examples. The mining consists of two stages -- (1) a biencoder- based recall-oriented dense search which pairs inputs with potential outputs, and (2) a crossencoder-based filter which re-ranks the output of the biencoder stage for better precision. Unlike model-generated data augmentation, our method mines naturally occurring high-quality input output pairs to mimic the style of the seed set for multiple tasks. On SQuAD-style reading comprehension, augmenting the seed set with the mined data results in an improvement of 13 F1 over a BART-large baseline fine-tuned only on the seed set. Likewise, we see improvements of 1.46 ROUGE-L on Xsum abstractive summarization."
Test Generation for SystemC designs by interlaced Greybox Fuzzing andConcolic Execution,"MuktaDebnath, Animesh BasakChowdhury, Debasri Saha, Susmita Sur-Kolay","9 May 2022 (v1(https://arxiv.org/abs/2205.04047v1)), lastrevised 10 May 2022 (this version, v2)",Software Engineering (cs.SE)," Recent success in high-level synthesis ( HLS ) has enabled designing complex hardware with better abstraction and configurability in high-level languages (e.g. SystemC/C++) compared to low-level register- transfer level ( RTL ) languages. Nevertheless, verification and testing HLS designs are challenging and arduous due to their object oriented nature and inherent concurrency. Test engineers aim to generate qualitative test-cases satisfying various code coverage metrics to ensure minimal presence of bugs in a design. Recent works have demonstrated the success of software testing techniques such as greybox fuzzing and concolic execution to obtain better coverage on SystemC designs. However, each of these techniques is time inefficient which obstructs achieving the desired coverage in shorter time- span. We propose a hybrid approach: interleave greybox fuzzing and concolic execution in an systematic manner, thereby reinforcing both the engines by exchanging intermediate test vectors to alleviate the individual inefficiency of the techniques. We evaluate our framework on a wide spectrum of SystemC benchmarks and show that our technique outperforms existing state-of-the-art methods in terms of number of test cases, branch-coverage and runtime."
Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning,"NaDong, YongqiangZhang, Mingli Ding, Gim Hee Lee",9 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Incremental few-shot object detection aims at detecting novel classes without forgetting knowledge of the base classes with only a few labeled training data from the novel classes. Most related prior works are on incremental object detection that rely on the availability of abundant training samples per novel class that substantially limits the scalability to real-world setting where novel data can be scarce. In this paper, we propose the Incremental-DETR that does incremental few-shot object detection via fine-tuning and self-supervised learning on the DETR object detector. To alleviate severe over-fitting with few novel class data, we first fine-tune the class-specific components of DETR with self-supervision from additional object proposals generated using Selective Search as pseudo labels. We further introduce a incremental few-shot fine-tuning strategy with knowledge distillation on the class-specific components of DETR to encourage the network in detecting novel classes without catastrophic forgetting. Extensive experiments conducted on standard incremental object detection and incremental few-shot object detection settings show that our approach significantly outperforms state-of-the-art methods by a large margin."
Deep Federated Anomaly Detection for Multivariate Time Series Data,"WeiZhu, DongjinSong, YuncongChen, WeiCheng, BoZong, TakehikoMizoguchi, CristianLumezanu, Haifeng Chen, Jiebo Luo",9 May 2022,Machine Learning (cs.LG)," Despite the fact that many anomaly detection approaches have been developed for multivariate time series data, limited effort has been made on federated settings in which multivariate time series data are heterogeneously distributed among different edge devices while data sharing is prohibited. In this paper, we investigate the problem of federated unsupervised anomaly detection and present a Federated Exemplar-based Deep Neural Network (Fed-ExDNN) to conduct anomaly detection for multivariate time series data on different edge devices. Specifically, we first design an Exemplar-based Deep Neural network (ExDNN) to learn local time series representations based on their compatibility with an exemplar module which consists of hidden parameters learned to capture varieties of normal patterns on each edge device. Next, a constrained clustering mechanism (FedCC) is employed on the centralized server to align and aggregate the parameters of different local exemplar modules to obtain a unified global exemplar module. Finally, the global exemplar module is deployed together with a shared feature encoder to each edge device and anomaly detection is conducted by examining the compatibility of testing data to the exemplar module. Fed-ExDNN captures local normal time series patterns with ExDNN and aggregates these patterns by FedCC, and thus can handle the heterogeneous data distributed over different edge devices simultaneously. Thoroughly empirical studies on six public datasets show that ExDNN and Fed-ExDNN can outperform state-of-the-art anomaly detection algorithms and federated learning techniques."
ProQA: Structural Prompt-based Pre-training for Unified QuestionAnswering,"WanjunZhong, YifanGao, NingDing, YujiaQin, ZhiyuanLiu, MingZhou, JiahaiWang, JianYin, NanDuan",9 May 2022,Computation and Language (cs.CL)," Question Answering (QA) is a longstanding challenge in natural language processing. Existing QA works mostly focus on specific question types, knowledge domains, or reasoning skills. The specialty in QA research hinders systems from modeling commonalities between tasks and generalization for wider applications. To address this issue, we present ProQA, a unified QA paradigm that solves various tasks through a single model. ProQA takes a unified structural prompt as the bridge and improves the QA-centric ability by structural prompt-based pre-training. Through a structurally designed prompt-based input schema, ProQA concurrently models the knowledge generalization for all QA tasks while keeping the knowledge customization for every specific QA task. Furthermore, ProQA is pre-trained with structural prompt-formatted large-scale synthesized corpus, which empowers the model with the commonly-required QA ability. Experimental results on 11 QA benchmarks demonstrate that ProQA consistently boosts performance on both full data fine-tuning, few-shot learning, and zero-shot testing scenarios. Furthermore, ProQA exhibits strong ability in both continual learning and transfer learning by taking the advantages of the structural prompt."
Visualization of Decision Trees based on General Line Coordinates toSupport Explainable Models,"AlexWorland, SrideviWagle, BorisKovalerchuk",9 May 2022,Machine Learning (cs.LG)," Visualization of Machine Learning (ML) models is an important part of the ML process to enhance the interpretability and prediction accuracy of the ML models. This paper proposes a new method SPC-DT to visualize the Decision Tree (DT) as interpretable models. These methods use a version of General Line Coordinates called Shifted Paired Coordinates (SPC). In SPC, each n-D point is visualized in a set of shifted pairs of 2-D Cartesian coordinates as a directed graph. The new method expands and complements the capabilities of existing methods, to visualize DT models. It shows: (1) relations between attributes, (2) individual cases relative to the DT structure, (3) data flow in the DT, (4) how tight each split is to thresholds in the DT nodes, and (5) the density of cases in parts of the n-D space. This information is important for domain experts for evaluating and improving the DT models, including avoiding overgeneralization and overfitting of models, along with their performance. The benefits of the methods are demonstrated in the case studies, using three real datasets."
AI Based Digital Twin Model for Cattle Caring,"XueHan, ZihuaiLin",9 May 2022,Artificial Intelligence (cs.AI)," In this paper, we developed innovative digital twins of cattle status that are powered by artificial intelligence (AI). The work was built on a farm IoT system that remotely monitors and tracks the state of cattle. A digital twin model of cattle health based on Deep Learning (DL) was generated using the sensor data acquired from the farm IoT system. The health and physiological cycle of cattle can be monitored in real time, and the state of the next physiological cycle of cattle can be anticipated using this model. The basis of this work is the vast amount of data which is required to validate the legitimacy of the digital twins model. In terms of behavioural state, it was found that the cattle treated with a combination of topical anaesthetic and meloxicam exhibits the least pain reaction. The digital twins model developed in this work can be used to monitor the health of cattle"
A Contraction-constrained Model Predictive Control for NonlinearProcesses using Disturbance Forecasts,"LaiWei, RyanMcCloy, Jie Bao",9 May 2022,Systems and Control (eess.SY)," Model predictive control (MPC) has become the most widely used advanced control method in process industry. In many cases, forecasts of the disturbances are available, e.g., predicted renewable power generation based on weather forecast. While the predictions of disturbances may not be accurate, utilizing the information can significantly improve the control performance in response to the disturbances. By exploiting process and disturbance models, future system behaviour can be predicted and used to optimise control actions via minimisation of an economical cost function which incorporates these predictions. However, stability guarantee of the resulting closed-loop system is often difficult in this approach when the processes are nonlinear. Proposed in the following article is a contraction- constrained predictive controller which optimises process economy whilst ensuring stabilisation to operating targets subject to disturbance measurements and forecasts."
Interpretable Machine Learning for Self-Service High-Risk Decision-Making,"CharlesRecaido, BorisKovalerchuk",9 May 2022,Machine Learning (cs.LG)," This paper contributes to interpretable machine learning via visual knowledge discovery in general line coordinates (GLC). The concepts of hyperblocks as interpretable dataset units and general line coordinates are combined to create a visual self-service machine learning model. The DSC1 and DSC2 lossless multidimensional coordinate systems are proposed. DSC1 and DSC2 can map multiple dataset attributes to a single two- dimensional (X, Y) Cartesian plane using a graph construction algorithm. The hyperblock analysis was used to determine visually appealing dataset attribute orders and to reduce line occlusion. It is shown that hyperblocks can generalize decision tree rules and a series of DSC1 or DSC2 plots can visualize a decision tree. The DSC1 and DSC2 plots were tested on benchmark datasets from the UCI ML repository. They allowed for visual classification of data. Additionally, areas of hyperblock impurity were discovered and used to establish dataset splits that highlight the upper estimate of worst-case model accuracy to guide model selection for high-risk decision-making. Major benefits of DSC1 and DSC2 is their highly interpretable nature. They allow domain experts to control or establish new machine learning models through visual pattern discovery."
Muskits: an End-to-End Music Processing Toolkit for Singing VoiceSynthesis,"JiatongShi, ShuaiGuo, TaoQian, NanHuo, TomokiHayashi, Yuning Wu, Frank Xu, XuankaiChang, Huazhe Li, Peter Wu, ShinjiWatanabe, Qin Jin",9 May 2022,Sound (cs.SD)," This paper introduces a new open-source platform named Muskits for end-to-end music processing, which mainly focuses on end-to-end singing voice synthesis (E2E-SVS). Muskits supports state-of-the-art SVS models, including RNN SVS, transformer SVS, and XiaoiceSing. The design of Muskits follows the style of widely-used speech processing toolkits, ESPnet and Kaldi, for data prepossessing, training, and recipe pipelines. To the best of our knowledge, this toolkit is the first platform that allows a fair and highly-reproducible comparison between several published works in SVS. In addition, we also demonstrate several advanced usages based on the toolkit functionalities, including multilingual training and transfer learning. This paper describes the major framework of Muskits, its functionalities, and experimental results in single-singer, multi-singer, multilingual, and transfer learning scenarios. The toolkit is publicly available at [this https URL](https://github.com/SJTMusicTeam/Muskits)."
Learning 6-DoF Object Poses to Grasp Category-level Objects byLanguage Instructions,"ChilamCheang, Haitao Lin, Yanwei Fu, Xiangyang Xue",9 May 2022,Robotics (cs.RO)," This paper studies the task of any objects grasping from the known categories by free-form language instructions. This task demands the technique in computer vision, natural language processing, and robotics. We bring these disciplines together on this open challenge, which is essential to human-robot interaction. Critically, the key challenge lies in inferring the category of objects from linguistic instructions and accurately estimating the 6-DoF information of unseen objects from the known classes. In contrast, previous works focus on inferring the pose of object candidates at the instance level. This significantly limits its applications in real- world [this http URL](http://scenarios.In) this paper, we propose a language-guided 6-DoF category-level object localization model to achieve robotic grasping by comprehending human intention. To this end, we propose a novel two-stage method. Particularly, the first stage grounds the target in the RGB image through language description of names, attributes, and spatial relations of objects. The second stage extracts and segments point clouds from the cropped depth image and estimates the full 6-DoF object pose at category-level. Under such a manner, our approach can locate the specific object by following human instructions, and estimate the full 6-DoF pose of a category-known but unseen instance which is not utilized for training the model. Extensive experimental results show that our method is competitive with the state-of-the-art language-conditioned grasp method. Importantly, we deploy our approach on a physical robot to validate the usability of our framework in real-world applications. Please refer to the supplementary for the demo videos of our robot experiments."
I Know What You Draw: Learning Grasp Detection Conditioned on a FewFreehand Sketches,"HaitaoLin, ChilamCheang, Yanwei Fu, Xiangyang Xue",9 May 2022,Robotics (cs.RO)," In this paper, we are interested in the problem of generating target grasps by understanding freehand sketches. The sketch is useful for the persons who cannot formulate language and the cases where a textual description is not available on the fly. However, very few works are aware of the usability of this novel interactive way between humans and robots. To this end, we propose a method to generate a potential grasp configuration relevant to the sketch-depicted objects. Due to the inherent ambiguity of sketches with abstract details, we take the advantage of the graph by incorporating the structure of the sketch to enhance the representation ability. This graph-represented sketch is further validated to improve the generalization of the network, capable of learning the sketch-queried grasp detection by using a small collection (around 100 samples) of hand-drawn sketches. Additionally, our model is trained and tested in an end-to-end manner which is easy to be implemented in real-world applications. Experiments on the multi-object VMRD and GraspNet-1Billion datasets demonstrate the good generalization of the proposed method. The physical robot experiments confirm the utility of our method in object-cluttered scenes."
CoCoA-MT: A Dataset and Benchmark for Contrastive Controlled MT withApplication to Formality,"MariaNădejde, AnnaCurrey, Benjamin Hsu, Xing Niu, MarcelloFederico, GeorgianaDinu",9 May 2022,Computation and Language (cs.CL)," The machine translation (MT) task is typically formulated as that of returning a single translation for an input segment. However, in many cases, multiple different translations are valid and the appropriate translation may depend on the intended target audience, characteristics of the speaker, or even the relationship between speakers. Specific problems arise when dealing with honorifics, particularly translating from English into languages with formality markers. For example, the sentence ""Are you sure?"" can be translated in German as ""Sind Sie sich sicher?"" (formal register) or ""Bist du dir sicher?"" (informal). Using wrong or inconsistent tone may be perceived as inappropriate or jarring for users of certain cultures and demographics. This work addresses the problem of learning to control target language attributes, in this case formality, from a small amount of labeled contrastive data. We introduce an annotated dataset (CoCoA-MT) and an associated evaluation metric for training and evaluating formality-controlled MT models for six diverse target languages. We show that we can train formality-controlled models by fine-tuning on labeled contrastive data, achieving high accuracy (82% in-domain and 73% out-of- domain) while maintaining overall quality."
Photo-to-Shape Material Transfer for Diverse Structures,"RuizhenHu, XiangyuSu, XiangkaiChen, OliverVanKaick, Hui Huang",9 May 2022,Graphics (cs.GR)," We introduce a method for assigning photorealistic relightable materials to 3D shapes in an automatic manner. Our method takes as input a photo exemplar of a real object and a 3D object with segmentation, and uses the exemplar to guide the assignment of materials to the parts of the shape, so that the appearance of the resulting shape is as similar as possible to the exemplar. To accomplish this goal, our method combines an image translation neural network with a material assignment neural network. The image translation network translates the color from the exemplar to a projection of the 3D shape and the part segmentation from the projection to the exemplar. Then, the material prediction network assigns materials from a collection of realistic materials to the projected parts, based on the translated images and perceptual similarity of the materials. One key idea of our method is to use the translation network to establish a correspondence between the exemplar and shape projection, which allows us to transfer materials between objects with diverse structures. Another key idea of our method is to use the two pairs of (color, segmentation) images provided by the image translation to guide the material assignment, which enables us to ensure the consistency in the assignment. We demonstrate that our method allows us to assign materials to shapes so that their appearances better resemble the input exemplars, improving the quality of the results over the state-of-the-art method, and allowing us to automatically create thousands of shapes with high-quality photorealistic materials. Code and data for this paper are available at [this https URL](https://github.com/XiangyuSu611/TMT)."
What Do You Get from Turning on Your Video? Effects ofVideoconferencing Affordances on Remote Class Experience During COVID-19,"YantingWu, YuanSun, S. ShyamSundar","9 May 2022 (v1(https://arxiv.org/abs/2205.04017v1)), lastrevised 11 May 2022 (this version, v2)",Human-Computer Interaction (cs.HC)," The outbreak of COVID-19 forced schools to swiftly transition from in-person classes to online or remote offerings, making educators and learners alike rely on online videoconferencing platforms. Platforms like Zoom offer audio-visual channels of communication and include features that are designed to approximate the classroom experience. However, it is not clear how students' learning experiences are affected by affordances of the videoconferencing platforms or what underlying factors explain the differential effects of these affordances on class experiences of engagement, interaction, and satisfaction. In order to find out, we conducted two online survey studies: Study 1 (N = 176) investigated the effects of three types of videoconferencing affordances (i.e., modality, interactivity, and agency affordances) on class experience during the first two months after the transition to online learning. Results showed that usage of the three kinds of affordances was positively correlated with students' class engagement, interaction, and satisfaction. Perceived anonymity, nonverbal cues, and comfort level were found to be the key mediators. In addition, students' usage of video cameras in class was influenced by their classmates. Study 2 (N = 256) tested the proposed relationships at a later stage of the pandemic and found similar results, thus serving as a constructive replication. This paper focuses on reporting the results of Study 1 since it captures the timely reactions from students when they first went online, and the second study plays a supplementary role in verifying Study 1 and thereby extending its external validity. Together, the two studies provide insights for instructors on how to leverage different videoconferencing affordances to enhance the virtual learning experience. Design implications for digital tools in online education are also discussed."
Improving negation detection with negation-focused pre-training,"Thinh HungTruong, TimothyBaldwin, Trevor Cohn, KarinVerspoor",9 May 2022,Computation and Language (cs.CL)," Negation is a common linguistic feature that is crucial in many language understanding tasks, yet it remains a hard problem due to diversity in its expression in different types of text. Recent work has shown that state-of-the-art NLP models underperform on samples containing negation in various tasks, and that negation detection models do not transfer well across domains. We propose a new negation-focused pre-training strategy, involving targeted data augmentation and negation masking, to better incorporate negation information into language models. Extensive experiments on common benchmarks show that our proposed approach improves negation detection performance and generalizability over the strong baseline NegBERT (Khandewal and Sawant, 2020)."
The Degrees-of-Freedom in Monostatic ISAC Channels: NLoS Exploitationvs. Reduction,"ShihangLu, FanLiu, LajosHanzo",9 May 2022,Information Theory (cs.IT)," The degrees of freedom (DoFs) attained in monostatic integrated sensing and communications (ISAC) are analyzed. Specifically, monostatic sensing aims for extracting target-orientation information from the line of sight (LoS) channel between the transmitter and the target, since the Non- LoS (NLoS) paths only contain clutter or interference. By contrast, in wireless communications, typically, both the LoS and NLoS paths are exploited for achieving diversity or multiplexing gains. Hence, we shed light on the NLoS exploitation vs. reduction tradeoffs in a monostatic ISAC scenario. In particular, we optimize the transmit power of each signal path to maximize the communication rate, while guaranteeing the sensing performance for the target. The non-convex problem formulated is firstly solved in closed form for a single-NLoS-link scenario, then we harness the popular successive convex approximation (SCA) method for a general multiple- NLoS-link scenario. Our simulation results characterize the fundamental performance tradeoffs between sensing and communication, demonstrating that the available DoFs in the ISAC channel should be efficiently exploited in a way that is distinctly different from that of communication-only scenarios."
Posterior Collapse of a Linear Latent Variable Model,"ZihaoWang, LiuZiyin",9 May 2022,Machine Learning (cs.LG)," This work identifies the existence and cause of a type of posterior collapse that frequently occurs in the Bayesian deep learning practice. For a general linear latent variable model that includes linear variational autoencoders as a special case, we precisely identify the nature of posterior collapse to be the competition between the likelihood and the regularization of the mean due to the prior. Our result also suggests that posterior collapse may be a general problem of learning for deeper architectures and deepens our understanding of Bayesian deep learning."
ResSFL: A Resistance Transfer Framework for Defending Model InversionAttack in Split Federated Learning,"JingtaoLi, Adnan SirajRakin, Xing Chen, Zhezhi He, Deliang Fan, ChaitaliChakrabarti",9 May 2022,Machine Learning (cs.LG)," This work aims to tackle Model Inversion (MI) attack on Split Federated Learning (SFL). SFL is a recent distributed training scheme where multiple clients send intermediate activations (i.e., feature map), instead of raw data, to a central server. While such a scheme helps reduce the computational load at the client end, it opens itself to reconstruction of raw data from intermediate activation by the server. Existing works on protecting SFL only consider inference and do not handle attacks during training. So we propose ResSFL, a Split Federated Learning Framework that is designed to be MI-resistant during training. It is based on deriving a resistant feature extractor via attacker-aware training, and using this extractor to initialize the client-side model prior to standard SFL training. Such a method helps in reducing the computational complexity due to use of strong inversion model in client-side adversarial training as well as vulnerability of attacks launched in early training epochs. On CIFAR-100 dataset, our proposed framework successfully mitigates MI attack on a VGG-11 model with a high reconstruction Mean-Square-Error of 0.050 compared to 0.005 obtained by the baseline system. The framework achieves 67.5% accuracy (only 1% accuracy drop) with very low computation overhead. Code is released at: [this https URL](https://github.com/zlijingtao/ResSFL)."
Data Augmentation with Paraphrase Generation and Entity Extraction forMultimodal Dialogue System,"EdaOkur, SauravSahay, LamaNachman",9 May 2022,Computation and Language (cs.CL)," Contextually aware intelligent agents are often required to understand the users and their surroundings in real-time. Our goal is to build Artificial Intelligence (AI) systems that can assist children in their learning process. Within such complex frameworks, Spoken Dialogue Systems (SDS) are crucial building blocks to handle efficient task-oriented communication with children in game-based learning settings. We are working towards a multimodal dialogue system for younger kids learning basic math concepts. Our focus is on improving the Natural Language Understanding (NLU) module of the task-oriented SDS pipeline with limited datasets. This work explores the potential benefits of data augmentation with paraphrase generation for the NLU models trained on small task-specific datasets. We also investigate the effects of extracting entities for conceivably further data expansion. We have shown that paraphrasing with model-in-the-loop (MITL) strategies using small seed data is a promising approach yielding improved performance results for the Intent Recognition task."
A Hybrid Approach: Utilising Kmeans Clustering and Naive Bayes for IoTAnomaly Detection,"LincolnBest, ErnestFoo, HuiTian",9 May 2022,Cryptography and Security (cs.CR)," The proliferation and variety of Internet of Things devices means that they have increasingly become a viable target for malicious users. This has created a need for anomaly detection algorithms that can work across multiple devices. This thesis suggests a potential alternative to the current anomaly detection algorithms to be implemented within IoT systems that can be applied across different types of devices. This algorithm is comprised of both unsupverised and supervised machine areas of machine learning combining the strongest facet of each. The algorithm involves the initial k-means clustering of attacks and assigns them to clusters. Next, the clusters are then used by the AdaBoosted Naive Bayes supervised learning algorithm in order to teach itself which piece of data should be clustered to which specific attack. This increases the accuracy of the proposed algorithm by adding clustered data before the final classification step, ensuring a more accurate algorithm. The correct indentification percentage scores for this proposed algorithm range anywhere from 90% to 100%, as well as rating the proposed algorithms accuracy, precision and recall. These high scores achieve an accurate, flexible, scalable, optimised algorithm that could potentially be in different IoT devices, ensuring strong data integrity and privacy."
Global Model Learning for Large Deformation Control of ElasticDeformable Linear Objects: An Efficient and Adaptive Approach,"MingruiYu, KangchenLv, HanzhongZhong, XiangLi",9 May 2022,Robotics (cs.RO)," Robotic manipulation of deformable linear objects (DLOs) has broad application prospects in many fields. However, a key issue is to obtain the exact deformation models (i.e., how robot motion affects DLO deformation), which are hard to theoretically calculate and vary among different DLOs. Thus, shape control of DLOs is challenging, especially for large deformation control which requires global and more accurate models. In this paper, we propose a coupled offline and online data-driven method for efficiently learning a global deformation model, allowing for both accurate modeling through offline learning and further updating for new DLOs via online adaptation. Specifically, the model approximated by a neural network is first trained offline on random data, then seamlessly migrated to the online phase, and further updated online during actual manipulation. Several strategies are introduced to improve the model's efficiency and generalization ability. We propose a convex-optimization-based controller, and analyze the system's stability using the Lyapunov method. Detailed simulations and real-world experiments demonstrate that our method can efficiently and precisely estimate the deformation model, and achieve large deformation control of untrained DLOs in 2D and 3D dual-arm manipulation tasks better than the existing methods. It accomplishes all 24 tasks with different desired shapes on different DLOs in the real world, using only simulation data for the offline learning."
A Novel Generative Convolutional Neural Network for Robot GraspDetection on Gaussian Guidance,"YuanhaoLi, YuLiu, ZhiqiangMa, PanfengHuang",9 May 2022,Robotics (cs.RO)," The vision-based grasp detection method is an important research direction in the field of robotics. However, due to the rectangle metric of the grasp detection rectangle's limitation, a false-positive grasp occurs, resulting in the failure of the real-world robot grasp task. In this paper, we propose a novel generative convolutional neural network model to improve the accuracy and robustness of robot grasp detection in real-world scenes. First, a Gaussian-based guided training method is used to encode the quality of the grasp point and grasp angle in the grasp pose, highlighting the highest-quality grasp point position and grasp angle and reducing the generation of false-positive grasps. Simultaneously, deformable convolution is used to obtain the shape features of the object in order to guide the subsequent network to the position. Furthermore, a global-local feature fusion method is introduced in order to efficiently obtain finer features during the feature reconstruction stage, allowing the network to focus on the features of the grasped objects. On the Cornell Grasping Datasets and Jacquard Datasets, our method achieves excellent performance of 99.0$\%$ and 95.9$\%$, respectively. Finally, the proposed method is put to the test in a real-world robot grasping scenario."
Towards a High-performance and Secure Memory System and Architecturefor Emerging Applications,"ZhendongWang, YangHu",9 May 2022,Cryptography and Security (cs.CR)," In this dissertation, we propose a memory and computing coordinated methodology to thoroughly exploit the characteristics and capabilities of the GPU-based heterogeneous system to effectively optimize applications' performance and privacy. Specifically, 1) we propose a task- aware and dynamic memory management mechanism to co-optimize applications' latency and memory footprint, especially in multitasking scenarios. 2) We propose a novel latency-aware memory management framework that analyzes the application characteristics and hardware features to reduce applications' initialization latency and response time. 3) We develop a new model extraction attack that explores the vulnerability of the GPU unified memory system to accurately steal private DNN models. 4) We propose a CPU/GPU Co- Encryption mechanism that can defend against a timing-correlation attack in an integrated CPU/GPU platform to provide a secure execution environment for the edge applications.   This dissertation aims at developing a high-performance and secure memory system and architecture in GPU heterogeneous platforms to deploy emerging AI-enabled applications efficiently and safely."
Learning from Drivers to Tackle the Amazon Last Mile Routing ResearchChallenge,"ChenWu, YinSong, VerdiMarch, EdenDuthie","9 May 2022 (v1(https://arxiv.org/abs/2205.04001v1)), lastrevised 10 May 2022 (this version, v2)",Artificial Intelligence (cs.AI)," The goal of the Amazon Last Mile Routing Research Challenge is to integrate the real-life experience of Amazon drivers into the solution of optimal route planning and optimization. This paper presents our method that tackles this challenge by hierarchically combining machine learning and conventional Traveling Salesperson Problem (TSP) solvers. Our method reaps the benefits from both worlds. On the one hand, our method encodes driver know-how by learning a sequential probability model from historical routes at the zone level, where each zone contains a few parcel stops. It then uses a single step policy iteration method, known as the Rollout algorithm, to generate plausible zone sequences sampled from the learned probability model. On the other hand, our method utilizes proven methods developed in the rich TSP literature to sequence stops within each zone efficiently. The outcome of such a combination appeared to be promising. Our method obtained an evaluation score of $0.0374$, which is comparable to what the top three teams have achieved on the official Challenge leaderboard. Moreover, our learning-based method is applicable to driving routes that may exhibit distinct sequential patterns beyond the scope of this Challenge. The source code of our method is publicly available at [this https URL](https://github.com/aws-samples/amazon-sagemaker-amazon-routing- challenge-sol)"
Row-wise Accelerator for Vision Transformer,"Hong-YiWang, Tian-Sheuan Chang",9 May 2022,Hardware Architecture (cs.AR)," Following the success of the natural language processing, the transformer for vision applications has attracted significant attention in recent years due to its excellent performance. However, existing deep learning hardware accelerators for vision cannot execute this structure efficiently due to significant model architecture differences. As a result, this paper proposes the hardware accelerator for vision transformers with row-wise scheduling, which decomposes major operations in vision transformers as a single dot product primitive for a unified and efficient execution. Furthermore, by sharing weights in columns, we can reuse the data and reduce the usage of memory. The implementation with TSMC 40nm CMOS technology only requires 262K gate count and 149KB SRAM buffer for 403.2 GOPS throughput at 600MHz clock frequency."
A Real Time Super Resolution Accelerator with Tilted Layer Fusion,"An-JungHuang, Kai-Chieh Hsu, Tian-SheuanChang",9 May 2022,Hardware Architecture (cs.AR)," Deep learning based superresolution achieves high-quality results, but its heavy computational workload, large buffer, and high external memory bandwidth inhibit its usage in mobile devices. To solve the above issues, this paper proposes a real-time hardware accelerator with the tilted layer fusion method that reduces the external DRAM bandwidth by 92\% and just needs 102KB on-chip memory. The design implemented with a 40nm CMOS process achieves 1920x1080@60fps throughput with 544.3K gate count when running at 600MHz; it has higher throughput and lower area cost than previous designs."
Hardware-Robust In-RRAM-Computing for Object Detection,"Yu-HsiangChiang, Cheng En Ni, Yun Sung, Tuo-Hung Hou, Tian-SheuanChang, ShyhJye Jou",9 May 2022,Hardware Architecture (cs.AR)," In-memory computing is becoming a popular architecture for deep- learning hardware accelerators recently due to its highly parallel computing, low power, and low area cost. However, in-RRAM computing (IRC) suffered from large device variation and numerous nonideal effects in hardware. Although previous approaches including these effects in model training successfully improved variation tolerance, they only considered part of the nonideal effects and relatively simple classification tasks. This paper proposes a joint hardware and software optimization strategy to design a hardware-robust IRC macro for object detection. We lower the cell current by using a low word-line voltage to enable a complete convolution calculation in one operation that minimizes the impact of nonlinear addition. We also implement ternary weight mapping and remove batch normalization for better tolerance against device variation, sense amplifier variation, and IR drop problem. An extra bias is included to overcome the limitation of the current sensing range. The proposed approach has been successfully applied to a complex object detection task with only 3.85\% mAP drop, whereas a naive design suffers catastrophic failure under these nonideal effects."
Layer-wised Model Aggregation for Personalized Federated Learning,"XiaosongMa, JieZhang, SongGuo, WenchaoXu",9 May 2022,"Distributed, Parallel, and Cluster Computing (cs.DC)"," Personalized Federated Learning (pFL) not only can capture the common priors from broad range of distributed data, but also support customized models for heterogeneous clients. Researches over the past few years have applied the weighted aggregation manner to produce personalized models, where the weights are determined by calibrating the distance of the entire model parameters or loss values, and have yet to consider the layer- level impacts to the aggregation process, leading to lagged model convergence and inadequate personalization over non-IID datasets. In this paper, we propose a novel pFL training framework dubbed Layer-wised Personalized Federated learning (pFedLA) that can discern the importance of each layer from different clients, and thus is able to optimize the personalized model aggregation for clients with heterogeneous data. Specifically, we employ a dedicated hypernetwork per client on the server side, which is trained to identify the mutual contribution factors at layer granularity. Meanwhile, a parameterized mechanism is introduced to update the layer-wised aggregation weights to progressively exploit the inter-user similarity and realize accurate model personalization. Extensive experiments are conducted over different models and learning tasks, and we show that the proposed methods achieve significantly higher performance than state-of-the- art pFL methods."
Predicting parametric spatiotemporal dynamics by multi-resolution PDEstructure-preserved deep learning,"Xin-YangLiu, HaoSun, Jian-XunWang",9 May 2022,Machine Learning (cs.LG)," Although recent advances in deep learning (DL) have shown a great promise for learning physics exhibiting complex spatiotemporal dynamics, the high training cost, unsatisfying extrapolability for long-term predictions, and poor generalizability in out-of-sample regimes significantly limit their applications in science/engineering problems. A more promising way is to leverage available physical prior and domain knowledge to develop scientific DL models, known as physics-informed deep learning (PiDL). In most existing PiDL frameworks, e.g., physics-informed neural networks, the physics prior is mainly utilized to regularize neural network training by incorporating governing equations into the loss function in a soft manner. In this work, we propose a new direction to leverage physics prior knowledge by baking the mathematical structures of governing equations into the neural network architecture design. In particular, we develop a novel PDE-preserved neural network (PPNN) for rapidly predicting parametric spatiotemporal dynamics, given the governing PDEs are (partially) known. The discretized PDE structures are preserved in PPNN as convolutional residual network (ConvResNet) blocks, which are formulated in a multi-resolution setting. This physics-inspired learning architecture design endows PPNN with excellent generalizability and long-term prediction accuracy compared to the state-of-the-art black-box ConvResNet baseline. The effectiveness and merit of the proposed methods have been demonstrated over a handful of spatiotemporal dynamical systems governed by unsteady PDEs, including reaction-diffusion, Burgers', and Navier-Stokes equations."
Methodology to Create Analysis-Naive Holdout Records as well as Trainand Test Records for Machine Learning Analyses in Healthcare,"MicheleBennett, MehdiNekouei, Armand Prieditis RajeshMehta, EwaKleczyk, Karin Hayes",9 May 2022,Machine Learning (cs.LG)," It is common for researchers to holdout data from a study pool to be used for external validation as well as for future research, and the same desire is true to those using machine learning modeling research. For this discussion, the purpose of the holdout sample it is preserve data for research studies that will be analysis-naive and randomly selected from the full dataset. Analysis-naive are records that are not used for testing or training machine learning (ML) models and records that do not participate in any aspect of the current machine learning study. The methodology suggested for creating holdouts is a modification of k-fold cross validation, which takes into account randomization and efficiently allows a three-way split (holdout, test and training) as part of the method without forcing. The paper also provides a working example using set of automated functions in Python and some scenarios for applicability in healthcare."
A novel quantitative inverse scattering scheme using interior resonantmodes,"YouziHe, HongyuLiu, XianchaoWang",9 May 2022,Numerical Analysis (math.NA)," This paper is devoted to a novel quantitative imaging scheme of identifying impenetrable obstacles in time-harmonic acoustic scattering from the associated far-field data. The proposed method consists of two phases. In the first phase, we determine the interior eigenvalues of the underlying unknown obstacle from the far-field data via the indicating behaviour of the linear sampling method. Then we further determine the associated interior eigenfunctions by solving a constrained optimization problem, again only involving the far-field data. In the second phase, we propose a novel iteration scheme of Newton's type to identify the boundary surface of the obstacle. By using the interior eigenfunctions determined in the first phase, we can avoid computing any direct scattering problem at each Newton's iteration. The proposed method is particularly valuable for recovering a sound-hard obstacle, where the Newton's formula involves the geometric quantities of the unknown boundary surface in a natural way. We provide rigorous theoretical justifications of the proposed method. Numerical experiments in both 2D and 3D are conducted, which confirm the promising features of the proposed imaging scheme. In particular, it can produce quantitative reconstructions of high accuracy in a very efficient manner."
Building Machine Translation Systems for the Next Thousand Languages,"AnkurBapna, IsaacCaswell, JuliaKreutzer, Orhan Firat, Daan vanEsch, AdityaSiddhant, Mengmeng Niu, PallaviBaljekar, XavierGarcia, WolfgangMacherey, TheresaBreiner, VeraAxelrod, Jason Riesa, Yuan Cao, MiaXu Chen, KlausMacherey, MaximKrikun, Pidong Wang, AlexanderGutkin, Apurva Shah, YanpingHuang, Zhifeng Chen, Yonghui Wu, MacduffHughes",9 May 2022,Computation and Language (cs.CL)," In this paper we share findings from our effort to build practical machine translation (MT) systems capable of translating across over one thousand languages. We describe results in three research domains: (i) Building clean, web-mined datasets for 1500+ languages by leveraging semi- supervised pre-training for language identification and developing data- driven filtering techniques; (ii) Developing practical MT models for under- served languages by leveraging massively multilingual models trained with supervised parallel data for over 100 high-resource languages and monolingual datasets for an additional 1000+ languages; and (iii) Studying the limitations of evaluation metrics for these languages and conducting qualitative analysis of the outputs from our MT models, highlighting several frequent error modes of these types of models. We hope that our work provides useful insights to practitioners working towards building MT systems for currently understudied languages, and highlights research directions that can complement the weaknesses of massively multilingual models in data-sparse settings."
ACM -- Attribute Conditioning for Abstractive Multi DocumentSummarization,"AiswaryaSankar, AnkitChadha",9 May 2022,Computation and Language (cs.CL)," Abstractive multi document summarization has evolved as a task through the basic sequence to sequence approaches to transformer and graph based techniques. Each of these approaches has primarily focused on the issues of multi document information synthesis and attention based approaches to extract salient information. A challenge that arises with multi document summarization which is not prevalent in single document summarization is the need to effectively summarize multiple documents that might have conflicting polarity, sentiment or subjective information about a given topic. In this paper we propose ACM, attribute conditioned multi document summarization,a model that incorporates attribute conditioning modules in order to decouple conflicting information by conditioning for a certain attribute in the output summary. This approach shows strong gains in ROUGE score over baseline multi document summarization approaches and shows gains in fluency, informativeness and reduction in repetitiveness as shown through a human annotation analysis study."
A Structured Span Selector,"TianyuLiu, YuchenEleanorJiang, RyanCotterell, MrinmayaSachan",8 May 2022,Computation and Language (cs.CL)," Many natural language processing tasks, e.g., coreference resolution and semantic role labeling, require selecting text spans and making decisions about them. A typical approach to such tasks is to score all possible spans and greedily select spans for task-specific downstream processing. This approach, however, does not incorporate any inductive bias about what sort of spans ought to be selected, e.g., that selected spans tend to be syntactic constituents. In this paper, we propose a novel grammar-based structured span selection model which learns to make use of the partial span-level annotation provided for such problems. Compared to previous approaches, our approach gets rid of the heuristic greedy span selection scheme, allowing us to model the downstream task on an optimal set of spans. We evaluate our model on two popular span prediction tasks: coreference resolution and semantic role labeling; and show improvements on both."
Robust (Controlled) Table-to-Text Generation with Structure-AwareEquivariance Learning,"FeiWang, ZheweiXu, PedroSzekely, Muhao Chen",8 May 2022,Computation and Language (cs.CL)," Controlled table-to-text generation seeks to generate natural language descriptions for highlighted subparts of a table. Previous SOTA systems still employ a sequence-to-sequence generation method, which merely captures the table as a linear structure and is brittle when table layouts change. We seek to go beyond this paradigm by (1) effectively expressing the relations of content pieces in the table, and (2) making our model robust to content-invariant structural transformations. Accordingly, we propose an equivariance learning framework, which encodes tables with a structure-aware self-attention mechanism. This prunes the full self-attention structure into an order-invariant graph attention that captures the connected graph structure of cells belonging to the same row or column, and it differentiates between relevant cells and irrelevant cells from the structural perspective. Our framework also modifies the positional encoding mechanism to preserve the relative position of tokens in the same cell but enforce position invariance among different cells. Our technology is free to be plugged into existing table-to-text generation models, and has improved T5-based models to offer better performance on ToTTo and HiTab. Moreover, on a harder version of ToTTo, we preserve promising performance, while previous SOTA systems, even with transformation-based data augmentation, have seen significant performance drops. Our code is available at [this https URL](https://github.com/luka-group/Lattice)."
Private Eye: On the Limits of Textual Screen Peeking via EyeglassReflections in Video Conferencing,"YanLong, ChenYan, ShivanPrasad, Wenyuan Xu, Kevin Fu",8 May 2022,Cryptography and Security (cs.CR)," Personal video conferencing has become the new norm after COVID-19 caused a seismic shift from in-person meetings and phone calls to video conferencing for daily communications and sensitive business. Video leaks participants' on-screen information because eyeglasses and other reflective objects unwittingly expose partial screen contents. Using mathematical modeling and human subjects experiments, this research explores the extent to which emerging webcams might leak recognizable textual information gleamed from eyeglass reflections captured by webcams. The primary goal of our work is to measure, compute, and predict the factors, limits, and thresholds of recognizability as webcam technology evolves in the future. Our work explores and characterizes the viable threat models based on optical attacks using multi-frame super resolution techniques on sequences of video frames. Our experimental results and models show it is possible to reconstruct and recognize on-screen text with a height as small as 10 mm with a 720p webcam. We further apply this threat model to web textual content with varying attacker capabilities to find thresholds at which text becomes recognizable. Our user study with 20 participants suggests present- day 720p webcams are sufficient for adversaries to reconstruct textual content on big-font websites. Our models further show that the evolution toward 4K cameras will tip the threshold of text leakage to reconstruction of most header texts on popular websites. Our research proposes near-term mitigations, and justifies the importance of following the principle of least privilege for long-term defense against this attack. For privacy- sensitive scenarios, it's further recommended to develop technologies that blur all objects by default, then only unblur what is absolutely necessary to facilitate natural-looking conversations."
Rebellion and Disobedience as Useful Tools in Human-Robot InteractionResearch -- The Handheld Robotics Case,Walterio W. Mayol-Cuevas,8 May 2022,Robotics (cs.RO)," This position paper argues on the utility of rebellion and disobedience (RaD) in human-robot interaction (HRI). In general, we see two main opportunities in the use of controlled and well designed rebellion and disobedience: i) illuminate insight into the effectiveness of the collaboration (or lack of) and ii) prevent mistakes and correct user actions when in the user's own interest. Through the use of a close interaction modality, that of handheld robots, we discuss use cases for utility of rebellion and disobedience that can be applicable to other instances of HRI."
Chart Question Answering: State of the Art and Future Directions,"E.Hoque, P.Kavehzadeh, A. Masry",8 May 2022,Computation and Language (cs.CL)," Information visualizations such as bar charts and line charts are very common for analyzing data and discovering critical insights. Often people analyze charts to answer questions that they have in mind. Answering such questions can be challenging as they often require a significant amount of perceptual and cognitive effort. Chart Question Answering (CQA) systems typically take a chart and a natural language question as input and automatically generate the answer to facilitate visual data analysis. Over the last few years, there has been a growing body of literature on the task of CQA. In this survey, we systematically review the current state-of-the- art research focusing on the problem of chart question answering. We provide a taxonomy by identifying several important dimensions of the problem domain including possible inputs and outputs of the task and discuss the advantages and limitations of proposed solutions. We then summarize various evaluation techniques used in the surveyed papers. Finally, we outline the open challenges and future research opportunities related to chart question answering."
NOVA: A Practical Method for Creating Notebook-Ready Visual Analytics,"Zijie J.Wang, DavidMunechika, Seongmin Lee, Duen HorngChau",8 May 2022,Human-Computer Interaction (cs.HC)," How can we develop visual analytics (VA) tools that can be easily adopted? Visualization researchers have developed a large number of web- based VA tools to help data scientists in a wide range of tasks. However, adopting these standalone systems can be challenging, as they require data scientists to create new workflows to streamline the VA processes. Recent surveys suggest computational notebooks have been dominating data scientists' analytical workflows, as these notebooks seamlessly combine text, code, and visualization, allowing users to rapidly iterate code experiments. To help visualization researchers develop VA tools that can be easily integrated into existing data science workflows, we present NOVA, a simple and flexible method to adapt web-based VA systems for notebooks. We provide detailed examples of using this method with diverse web development technologies and different types of computational notebooks. Deployed application examples highlight that NOVA is easy to adopt, and data scientists appreciate in-notebook VA. NOVA is available at [this https URL](https://github.com/poloclub/nova)."
Towards Racially Unbiased Skin Tone Estimation via SceneDisambiguation,"HaiwenFeng, TimoBolkart, JoachimTesch, Michael J.Black, VictoriaAbrevaya",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Virtual facial avatars will play an increasingly important role in immersive communication, games and the metaverse, and it is therefore critical that they be inclusive. This requires accurate recovery of the appearance, represented by albedo, regardless of age, sex, or ethnicity. While significant progress has been made on estimating 3D facial geometry, albedo estimation has received less attention. The task is fundamentally ambiguous because the observed color is a function of albedo and lighting, both of which are unknown. We find that current methods are biased towards light skin tones due to (1) strongly biased priors that prefer lighter pigmentation and (2) algorithmic solutions that disregard the light/albedo ambiguity. To address this, we propose a new evaluation dataset (FAIR) and an algorithm (TRUST) to improve albedo estimation and, hence, fairness. Specifically, we create the first facial albedo evaluation benchmark where subjects are balanced in terms of skin color, and measure accuracy using the Individual Typology Angle (ITA) metric. We then address the light/albedo ambiguity by building on a key observation: the image of the full scene -- as opposed to a cropped image of the face -- contains important information about lighting that can be used for disambiguation. TRUST regresses facial albedo by conditioning both on the face region and a global illumination signal obtained from the scene image. Our experimental results show significant improvement compared to state-of-the-art methods on albedo estimation, both in terms of accuracy and fairness. The evaluation benchmark and code will be made available for research purposes at [this https URL](https://trust.is.tue.mpg.de)."
An STL-based Formulation of Resilience in Cyber-Physical Systems,HongkaiChen (1)Shan Lin (1)Scott A.Smolka(1) NicolaPaoletti(2) ((1) Stony Brook University Stony Brook USA ,8 May 2022,Logic in Computer Science (cs.LO)," Resiliency is the ability to quickly recover from a violation and avoid future violations for as long as possible. Such a property is of fundamental importance for Cyber-Physical Systems (CPS), and yet, to date, there is no widely agreed-upon formal treatment of CPS resiliency. We present an STL-based framework for reasoning about resiliency in CPS in which resiliency has a syntactic characterization in the form of an STL- based Resiliency Specification (SRS). Given an arbitrary STL formula $\varphi$, time bounds $\alpha$ and $\beta$, the SRS of $\varphi$, $R_{\alpha,\beta}(\varphi)$, is the STL formula $\neg\varphi\mathbf{U}_{[0,\alpha]}\mathbf{G}_{[0,\beta)}\varphi$, specifying that recovery from a violation of $\varphi$ occur within time $\alpha$ (recoverability), and subsequently that $\varphi$ be maintained for duration $\beta$ (durability). These $R$-expressions, which are atoms in our SRS logic, can be combined using STL operators, allowing one to express composite resiliency specifications, e.g., multiple SRSs must hold simultaneously, or the system must eventually be resilient. We define a quantitative semantics for SRSs in the form of a Resilience Satisfaction Value (ReSV) function $r$ and prove its soundness and completeness w.r.t. STL's Boolean semantics. The $r$-value for $R_{\alpha,\beta}(\varphi)$ atoms is a singleton set containing a pair quantifying recoverability and durability. The $r$-value for a composite SRS formula results in a set of non-dominated recoverability-durability pairs, given that the ReSVs of subformulas might not be directly comparable (e.g., one subformula has superior durability but worse recoverability than another). To the best of our knowledge, this is the first multi-dimensional quantitative semantics for an STL-based logic. Two case studies demonstrate the practical utility of our approach."
$α$NAS: Neural Architecture Search using Property Guided Synthesis,"CharlesJin, PhitchayaMangpoPhothilimthana, Sudip Roy",8 May 2022,Machine Learning (cs.LG)," In the past few years, neural architecture search (NAS) has become an increasingly important tool within the deep learning community. Despite the many recent successes of NAS, current approaches still fall far short of the dream of automating an entire neural network architecture design from scratch. Most existing approaches require highly structured design spaces formulated manually by domain experts. In this work, we develop techniques that enable efficient NAS in a significantly larger design space. To accomplish this, we propose to perform NAS in an abstract search space of program properties. Our key insights are as follows: (1) the abstract search space is significantly smaller than the original search space, and (2) architectures with similar program properties also have similar performance; thus, we can search more efficiently in the abstract search space. To enable this approach, we also propose an efficient synthesis procedure, which accepts a set of promising program properties, and returns a satisfying neural architecture. We implement our approach, $\alpha$NAS, within an evolutionary framework, where the mutations are guided by the program properties. Starting with a ResNet-34 model, $\alpha$NAS produces a model with slightly improved accuracy on CIFAR-10 but 96% fewer parameters. On ImageNet, $\alpha$NAS is able to improve over Vision Transformer (30% fewer FLOPS and parameters), ResNet-50 (23% fewer FLOPS, 14% fewer parameters), and EfficientNet (7% fewer FLOPS and parameters) without any degradation in accuracy."
MASALA: Modelling and Analysing the Semantics of Adpositions inLinguistic Annotation of Hindi,"AryamanArora, NitinVenkateswaran, NathanSchneider",8 May 2022,Computation and Language (cs.CL)," We present a completed, publicly available corpus of annotated semantic relations of adpositions and case markers in Hindi. We used the multilingual SNACS annotation scheme, which has been applied to a variety of typologically diverse languages. Building on past work examining linguistic problems in SNACS annotation, we use language models to attempt automatic labelling of SNACS supersenses in Hindi and achieve results competitive with past work on English. We look towards upstream applications in semantic role labelling and extension to related languages such as Gujarati."
High-Resolution UAV Image Generation for Sorghum Panicle Detection,"EnyuCai, ZhankunLuo, SriramBaireddy, Jiaqi Guo, Changye Yang, Edward J.Delp",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," The number of panicles (or heads) of Sorghum plants is an important phenotypic trait for plant development and grain yield estimation. The use of Unmanned Aerial Vehicles (UAVs) enables the capability of collecting and analyzing Sorghum images on a large scale. Deep learning can provide methods for estimating phenotypic traits from UAV images but requires a large amount of labeled data. The lack of training data due to the labor-intensive ground truthing of UAV images causes a major bottleneck in developing methods for Sorghum panicle detection and counting. In this paper, we present an approach that uses synthetic training images from generative adversarial networks (GANs) for data augmentation to enhance the performance of Sorghum panicle detection and counting. Our method can generate synthetic high-resolution UAV RGB images with panicle labels by using image-to-image translation GANs with a limited ground truth dataset of real UAV RGB images. The results show the improvements in panicle detection and counting using our data augmentation approach."
What does it mean to be an AI Ethicist: An ontology of existing roles,"ShalalehRismani, AJung Moon",8 May 2022,Computers and Society (cs.CY)," With the increasing adoption of Artificial Intelligence systems (AIS) in various application and the growing efforts to regulate such systems, a new set of occupations has emerged in the industry. This new set of roles take different titles and hold varying responsibilities. However, the individuals in these roles are tasked with interpreting and operationalizing best practices for developing ethical and safe AI systems. We will broadly refer to this new set of occupations as AI ethicists and recognize that they often hold a specific role in the intersection of technology development, business needs, and societal implications. In this work, we examine what it means to be an AI ethicist in the industry and propose an ontology of existing roles under this broad title along with their required competencies. We create this ontology by examining the job postings for such roles over the past two years and conduct expert interviews with fourteen individuals who currently hold such a role in the industry. The proposed ontology will inform executives and leaders who are looking to build responsible AI teams and provide educators the necessary information for creating new learning objectives and curriculum."
Learning to Brachiate via Simplified Model Imitation,"DanieleReda, Hung YuLing, Michiel van dePanne",8 May 2022,Machine Learning (cs.LG)," Brachiation is the primary form of locomotion for gibbons and siamangs, in which these primates swing from tree limb to tree limb using only their arms. It is challenging to control because of the limited control authority, the required advance planning, and the precision of the required grasps. We present a novel approach to this problem using reinforcement learning, and as demonstrated on a finger-less 14-link planar model that learns to brachiate across challenging handhold sequences. Key to our method is the use of a simplified model, a point mass with a virtual arm, for which we first learn a policy that can brachiate across handhold sequences with a prescribed order. This facilitates the learning of the policy for the full model, for which it provides guidance by providing an overall center-of-mass trajectory to imitate, as well as for the timing of the holds. Lastly, the simplified model can also readily be used for planning suitable sequences of handholds in a given environment. Our results demonstrate brachiation motions with a variety of durations for the flight and hold phases, as well as emergent extra back-and-forth swings when this proves useful. The system is evaluated with a variety of ablations. The method enables future work towards more general 3D brachiation, as well as using simplified model imitation in other settings."
Investigating Generalization by Controlling Normalized Margin,"AlexanderFarhang, JeremyBernstein, KushalTirumala, Yang Liu, Yisong Yue",8 May 2022,Machine Learning (cs.LG)," Weight norm $\|w\|$ and margin $\gamma$ participate in learning theory via the normalized margin $\gamma/\|w\|$. Since standard neural net optimizers do not control normalized margin, it is hard to test whether this quantity causally relates to generalization. This paper designs a series of experimental studies that explicitly control normalized margin and thereby tackle two central questions. First: does normalized margin always have a causal effect on generalization? The paper finds that no -- networks can be produced where normalized margin has seemingly no relationship with generalization, counter to the theory of Bartlett et al. (2017). Second: does normalized margin ever have a causal effect on generalization? The paper finds that yes -- in a standard training setup, test performance closely tracks normalized margin. The paper suggests a Gaussian process model as a promising explanation for this behavior."
A Re-examination of the Census Bureau Reconstruction andReidentification Attack,KrishMuralidhar,8 May 2022,Databases (cs.DB)," Recent analysis by researchers at the U.S. Census Bureau claims that by reconstructing the tabular data released from the 2010 Census, it is possible to reconstruct the original data and, using an accurate external data file with identity, reidentify 179 million respondents (approximately 58% of the population). This study shows that there are a practically infinite number of possible reconstructions, and each reconstruction leads to assigning a different identity to the respondents in the reconstructed data. The results reported by the Census Bureau researchers are based on just one of these infinite possible reconstructions and is easily refuted by an alternate reconstruction. Without definitive proof that the reconstruction is unique, or at the very least, that most reconstructions lead to the assignment of the same identity to the same respondent, claims of confirmed reidentification are highly suspect and easily refuted."
Reconstruction from Substrings with Partial Overlap,"YonatanYehezkeally, Daniella Bar-Lev, SagiMarcovich, EitanYaakobi",8 May 2022,Information Theory (cs.IT)," This paper introduces a new family of reconstruction codes which is motivated by applications in DNA data storage and sequencing. In such applications, DNA strands are sequenced by reading some subset of their substrings. While previous works considered two extreme cases in which \emph{all} substrings of some fixed length are read or substrings are read with no overlap, this work considers the setup in which consecutive substrings are read with some given minimum overlap. First, upper bounds are provided on the attainable rates of codes that guarantee unique reconstruction. Then, we present efficient constructions of asymptotically optimal codes that meet the upper bound."
Mission-Critical Public Safety Networking: An Intent-Driven ServiceOrchestration Perspective,"KashifMehmood, David Palma, KatinaKralevska",8 May 2022,Networking and Internet Architecture (cs.NI)," Intent-based networking (IBN) provides a promising approach for managing networks and orchestrating services in beyond 5G (B5G) deployments using modern service-based architectures. Public safety (PS) services form the basis of keeping society functional, owing to the responsiveness and availability throughout the network. The provisioning of these services requires efficient and agile network management techniques with low-overhead and embedded intelligence. IBN incorporates the service subscribers in a model-driven approach to provision different user-centric services. However, it requires domain-specific and contextual processing of intents for abstracted management of network functions. This work proposes an intent definition for PS and mission critical (MC) services in beyond B5G networks, as well as a processing and orchestration architecture on top of MC push-to- talk (PTT) use case. The simulation results show that MC PTT services adhere to the key performance indicators of access time and mouth-to-ear latency bounded by approximately 250 and 150 milliseconds, respectively, with an additional overhead experienced during the intent processing in the range of 20- 40 milliseconds. This validates the premise of IBN in providing flexible and scalable management and service orchestration solution for PS next generation networks."
Write It Like You See It: Detectable Differences in Clinical Notes ByRace Lead To Differential Model Recommendations,"HammaadAdam, MingYing Yang, Kenrick Cato, IoanaBaldini, CharlesSenteio, Leo AnthonyCeli, Jiaming Zeng, MoninderSingh, MarzyehGhassemi",8 May 2022,Artificial Intelligence (cs.AI)," Clinical notes are becoming an increasingly important data source for machine learning (ML) applications in healthcare. Prior research has shown that deploying ML models can perpetuate existing biases against racial minorities, as bias can be implicitly embedded in data. In this study, we investigate the level of implicit race information available to ML models and human experts and the implications of model-detectable differences in clinical notes. Our work makes three key contributions. First, we find that models can identify patient self-reported race from clinical notes even when the notes are stripped of explicit indicators of race. Second, we determine that human experts are not able to accurately predict patient race from the same redacted clinical notes. Finally, we demonstrate the potential harm of this implicit information in a simulation study, and show that models trained on these race-redacted clinical notes can still perpetuate existing biases in clinical treatment decisions."
Near-Optimal Deterministic Vertex-Failure Connectivity Oracles,"YaoweiLong, ThatchapholSaranurak",8 May 2022,Data Structures and Algorithms (cs.DS)," We revisit the vertex-failure connectivity oracle problem. This is one of the most basic graph data structure problems under vertex updates, yet its complexity is still not well-understood. We essentially settle the complexity of this problem by showing a new data structure whose space, preprocessing time, update time, and query time are simultaneously optimal up to sub-polynomial factors assuming popular conjectures. Moreover, the data structure is deterministic.   More precisely, for any integer $d_{\star}$, the data structure preprocesses a graph $G$ with $n$ vertices and $m$ edges in $\hat{O}(md_{\star})$ time and uses $\tilde{O}(\min\\{m,nd_{\star}\\})$ space. Then, given the vertex set $D$ to be deleted where $|D|=d\le d_{\star}$, it takes $\hat{O}(d^{2})$ updates time. Finally, given any vertex pair $(u,v)$, it checks if $u$ and $v$ are connected in $G\setminus D$ in $O(d)$ time. This improves the previously best deterministic algorithm by Duan and Pettie (SODA 2017) in both space and update time by a factor of $d$. It also significantly speeds up the $\Omega(\min\\{mn,n^{\omega}\\})$ preprocessing time of all known (even randomized) algorithms with update time at most $\tilde{O}(d^{5})$."
RobotCore: An Open Architecture for Hardware Acceleration in ROS 2,"Víctor Mayoral-Vilches, Sabrina M.Neuman, BrianPlancher, Vijay JanapaReddi",8 May 2022,Robotics (cs.RO)," Hardware acceleration can revolutionize robotics, enabling new applications by speeding up robot response times while remaining power- efficient. However, the diversity of acceleration options makes it difficult for roboticists to easily deploy accelerated systems without expertise in each specific hardware platform. In this work, we address this challenge with RobotCore, an architecture to integrate hardware acceleration in the widely-used ROS 2 robotics software framework. This architecture is target- agnostic (supports edge, workstation, data center, or cloud targets) and accelerator-agnostic (supports both FPGAs and GPUs). It builds on top of the common ROS 2 build system and tools and is easily portable across different research and commercial solutions through a new firmware layer. We also leverage the Linux Tracing Toolkit next generation (LTTng) for low-overhead real-time tracing and benchmarking. To demonstrate the acceleration enabled by this architecture, we use it to deploy a ROS 2 perception computational graph on a CPU and FPGA. We employ our integrated tracing and benchmarking to analyze bottlenecks, uncovering insights that guide us to improve FPGA communication efficiency. In particular, we design an intra-FPGA ROS 2 node communication queue to enable faster data flows, and use it in conjunction with FPGA-accelerated nodes to achieve a 24.42% speedup over a CPU."
"Transparency, Compliance, And Contestability When Code Is Law",AlexanderHicks,8 May 2022,Computers and Society (cs.CY)," Both technical security mechanisms and legal processes serve as mechanisms to deal with misbehaviour according to a set of norms. While they share general similarities, there are also clear differences in how they are defined, act, and the effect they have on subjects. This paper considers the similarities and differences between both types of mechanisms as ways of dealing with misbehaviour, and where they interact with each other. Taking into consideration the idea of code as law, we discuss accountability mechanisms for code, and how they must relate to both security principles and legal principles. In particular, we identify the ability to contest norms enforced by code as an important part of accountability in this context. Based on this analysis, we make the case for transparency enhancing technologies as security mechanisms that can support legal processes, in contrast to other types of accountability mechanisms for code. We illustrate this through two examples based on recent court cases that involved Post Office in the United Kingdom and Uber in the Netherlands, and discuss some practical considerations."
Unsupervised Discovery and Composition of Object Light Fields,"CameronSmith, Hong-Xing Yu, SergeyZakharov, FredoDurand, Joshua B.Tenenbaum, Jiajun Wu, VincentSitzmann",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Neural scene representations, both continuous and discrete, have recently emerged as a powerful new paradigm for 3D scene understanding. Recent efforts have tackled unsupervised discovery of object-centric neural scene representations. However, the high cost of ray-marching, exacerbated by the fact that each object representation has to be ray-marched separately, leads to insufficiently sampled radiance fields and thus, noisy renderings, poor framerates, and high memory and time complexity during training and rendering. Here, we propose to represent objects in an object- centric, compositional scene representation as light fields. We propose a novel light field compositor module that enables reconstructing the global light field from a set of object-centric light fields. Dubbed Compositional Object Light Fields (COLF), our method enables unsupervised learning of object-centric neural scene representations, state-of-the-art reconstruction and novel view synthesis performance on standard datasets, and rendering and training speeds at orders of magnitude faster than existing 3D approaches."
Online Algorithms with Multiple Predictions,"KeertiAnand, RongGe, AmitKumar, DebmalyaPanigrahi",8 May 2022,Machine Learning (cs.LG)," This paper studies online algorithms augmented with multiple machine-learned predictions. While online algorithms augmented with a single prediction have been extensively studied in recent years, the literature for the multiple predictions setting is sparse. In this paper, we give a generic algorithmic framework for online covering problems with multiple predictions that obtains an online solution that is competitive against the performance of the best predictor. Our algorithm incorporates the use of predictions in the classic potential-based analysis of online algorithms. We apply our algorithmic framework to solve classical problems such as online set cover, (weighted) caching, and online facility location in the multiple predictions setting. Our algorithm can also be robustified, i.e., the algorithm can be simultaneously made competitive against the best prediction and the performance of the best online algorithm (without prediction)."
Network-Coding-based Forwarding for LoRaWAN Gateways,Louai Al-Awami,8 May 2022,Networking and Internet Architecture (cs.NI), LoRaWAN is a promising IoT access technology that is growing in popularity. This study addresses the issue of duplicate packets forwarding by LoRaWAN gateways and proposes a novel forwarding scheme to eliminate forwarding duplicate packets by utilizing inter-flow network coding. The proposed scheme is distributed and requires no coordination between gateways. The proposed scheme is evaluated under different network and traffic conditions. The results show that substantial savings can be achieved in bandwidth leading to enhanced scalability of the network without increasing outgoing traffic.
FOLPETTI: A Novel Multi-Armed Bandit Smart Attack for WirelessNetworks,"BoutEmilie, BrighenteAlessandro, Conti Mauro, LoscriValeria",8 May 2022,Cryptography and Security (cs.CR)," Channel hopping provides a defense mechanism against jamming attacks in large scale \ac{iot} networks.} However, a sufficiently powerful attacker may be able to learn the channel hopping pattern and efficiently predict the channel to jam. In this paper, we present FOLPETTI, a MAB-based attack to dynamically follow the victim's channel selection in real-time. Compared to previous attacks implemented via DRL, FOLPETTI does not require recurrent training phases to capture the victim's behavior, allowing hence a continuous attack. We assess the validity of FOLPETTI by implementing it to launch a jamming attack. We evaluate its performance against a victim performing random channel selection and a victim implementing a MAB defence strategy. We assume that the victim detects an attack when more than $20\%$ of the transmitted packets are not received, therefore this represents the limit for the attack to be stealthy. In this scenario, FOLPETTI achieves a $15\%$ success rate for the victim's random channel selection strategy, close to the $17.5\%$ obtained with a genie-aided approach. Conversely, the DRL-based approach reaches a success rate of $12.5\%$, which is $5.5\%$ less than FOLPETTI. We also confirm the results by confronting FOLPETTI with a MAB based channel hopping method. Finally, we show that FOLPETTI creates an additional energy demand independently from its success rate, therefore decreasing the lifetime of IoT devices."
Federated Random Reshuffling with Compression and Variance Reduction,"GrigoryMalinovsky, PeterRichtárik","8 May 2022 (v1(https://arxiv.org/abs/2205.03914v1)), lastrevised 10 May 2022 (this version, v2)",Machine Learning (cs.LG)," Random Reshuffling (RR), which is a variant of Stochastic Gradient Descent (SGD) employing sampling without replacement, is an immensely popular method for training supervised machine learning models via empirical risk minimization. Due to its superior practical performance, it is embedded and often set as default in standard machine learning software. Under the name FedRR, this method was recently shown to be applicable to federated learning (Mishchenko et al.,2021), with superior performance when compared to common baselines such as Local SGD. Inspired by this development, we design three new algorithms to improve FedRR further: compressed FedRR and two variance reduced extensions: one for taming the variance coming from shuffling and the other for taming the variance due to compression. The variance reduction mechanism for compression allows us to eliminate dependence on the compression parameter, and applying additional controlled linear perturbations for Random Reshuffling, introduced by Malinovsky et al.(2021) helps to eliminate variance at the optimum. We provide the first analysis of compressed local methods under standard assumptions without bounded gradient assumptions and for heterogeneous data, overcoming the limitations of the compression operator. We corroborate our theoretical results with experiments on synthetic and real data sets."
Codes for Constrained Periodicity,"AdirKobovich, OrianLeitersdorf, Daniella Bar-Lev, EitanYaakobi",8 May 2022,Information Theory (cs.IT)," Reliability is an inherent challenge for the emerging nonvolatile technology of racetrack memories, and there exists a fundamental relationship between codes designed for racetrack memories and codes with constrained periodicity. Previous works have sought to construct codes that avoid periodicity in windows, yet have either only provided existence proofs or required high redundancy. This paper provides the first constructions for avoiding periodicity that are both efficient (average-linear time) and with low redundancy (near the lower bound). The proposed algorithms are based on iteratively repairing windows which contain periodicity until all the windows are valid. Intuitively, such algorithms should not converge as there is no monotonic progression; yet, we prove convergence with average-linear time complexity by exploiting subtle properties of the encoder. Overall, we both provide constructions that avoid periodicity in all windows, and we also study the cardinality of such constraints."
Network Traffic Anomaly Detection Method Based on Multi scale ResidualFeature,"XueyuanDuan, Yu Fu (1)Kun Wang ((1) Department of Information Security Naval University ofEngineering Wuhan Hubei 430033 China (2) College of Computer andInformation Technology Xinyang Normal University Xinyang Henan 464000China ",8 May 2022,Networking and Internet Architecture (cs.NI)," To address the problem that traditional network traffic anomaly detection algorithms do not suffi-ciently mine potential features in long time domain, an anomaly detection method based on mul-ti-scale residual features of network traffic is proposed. The original traffic is divided into subse-quences of different time spans using sliding windows, and each subsequence is decomposed and reconstructed into data sequences of different levels using wavelet transform technique; the stacked autoencoder (SAE) constructs similar feature space using normal network traffic, and gen- erates reconstructed error vector using the difference between reconstructed samples and input samples in the similar feature space; the multi-path residual group is used to learn reconstructed error The traffic classification is completed by a lightweight classifier. The experimental results show that the detection performance of the proposed method for anomalous network traffic is sig-nificantly improved compared with traditional methods; it confirms that the longer time span and more S transformation scales have positive effects on discovering potential diversity information in the original network traffic."
Inverse Multislice Ptychography by Layer-wise Optimisation and SparseMatrix Decomposition,"AryaBangun, OlehMelnyk, BenjaminMärz, BenediktDiederichs, AlexanderClausen, DieterWeber, FrankFilbir, Knut MÜller-Caspary",8 May 2022,Information Theory (cs.IT)," We propose algorithms based on an optimisation method for inverse multislice ptychography in, e.g. electron microscopy. The multislice method is widely used to model the interaction between relativistic electrons and thick specimens. Since only the intensity of diffraction patterns can be recorded, the challenge in applying inverse multislice ptychography is to uniquely reconstruct the electrostatic potential in each slice up to some ambiguities. In this conceptual study, we show that a unique separation of atomic layers for simulated data is possible when considering a low acceleration voltage. We also introduce an adaptation for estimating the illuminating probe. For the sake of practical application, we finally present slice reconstructions using experimental 4D scanning transmission electron microscopy (STEM) data."
SoftPool++: An Encoder-Decoder Network for Point Cloud Completion,"YidaWang, DavidJoseph Tan, NassirNavab, FedericoTombari",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," We propose a novel convolutional operator for the task of point cloud completion. One striking characteristic of our approach is that, conversely to related work it does not require any max-pooling or voxelization operation. Instead, the proposed operator used to learn the point cloud embedding in the encoder extracts permutation-invariant features from the point cloud via a soft-pooling of feature activations, which are able to preserve fine-grained geometric details. These features are then passed on to a decoder architecture. Due to the compression in the encoder, a typical limitation of this type of architectures is that they tend to lose parts of the input shape structure. We propose to overcome this limitation by using skip connections specifically devised for point clouds, where links between corresponding layers in the encoder and the decoder are established. As part of these connections, we introduce a transformation matrix that projects the features from the encoder to the decoder and vice-versa. The quantitative and qualitative results on the task of object completion from partial scans on the ShapeNet dataset show that incorporating our approach achieves state-of-the-art performance in shape completion both at low and high resolutions."
VPN: Verification of Poisoning in Neural Networks,"YouchengSun, MuhammadUsman, DivyaGopinath, Corina S.Păsăreanu",8 May 2022,Cryptography and Security (cs.CR)," Neural networks are successfully used in a variety of applications, many of them having safety and security concerns. As a result researchers have proposed formal verification techniques for verifying neural network properties. While previous efforts have mainly focused on checking local robustness in neural networks, we instead study another neural network security issue, namely data poisoning. In this case an attacker inserts a trigger into a subset of the training data, in such a way that at test time, this trigger in an input causes the trained model to misclassify to some target class. We show how to formulate the check for data poisoning as a property that can be checked with off-the-shelf verification tools, such as Marabou and nneum, where counterexamples of failed checks constitute the triggers. We further show that the discovered triggers are `transferable' from a small model to a larger, better-trained model, allowing us to analyze state-of-the art performant models trained for image classification tasks."
ConvMAE: Masked Convolution Meets Masked Autoencoders,"PengGao, TeliMa, HongshengLi, JifengDai, YuQiao",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Vision Transformers (ViT) become widely-adopted architectures for various vision tasks. Masked auto-encoding for feature pretraining and multi-scale hybrid convolution-transformer architectures can further unleash the potentials of ViT, leading to state-of-the-art performances on image classification, detection and semantic segmentation. In this paper, our ConvMAE framework demonstrates that multi-scale hybrid convolution- transformer can learn more discriminative representations via the mask auto- encoding scheme. However, directly using the original masking strategy leads to the heavy computational cost and pretraining-finetuning discrepancy. To tackle the issue, we adopt the masked convolution to prevent information leakage in the convolution blocks. A simple block-wise masking strategy is proposed to ensure computational efficiency. We also propose to more directly supervise the multi-scale features of the encoder to boost multi- scale features. Based on our pretrained ConvMAE models, ConvMAE-Base improves ImageNet-1K finetuning accuracy by 1.4% compared with MAE-Base. On object detection, ConvMAE-Base finetuned for only 25 epochs surpasses MAE- Base fined-tuned for 100 epochs by 2.9% box AP and 2.2% mask AP respectively. Code and pretrained models are available at [this https URL](https://github.com/Alpha-VL/ConvMAE)."
Cross-lingual Adaptation for Recipe Retrieval with Mixup,"BinZhu, Chong-WahNgo, JingjingChen, Wing-Kwong Chan",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Cross-modal recipe retrieval has attracted research attention in recent years, thanks to the availability of large-scale paired data for training. Nevertheless, obtaining adequate recipe-image pairs covering the majority of cuisines for supervised learning is difficult if not impossible. By transferring knowledge learnt from a data-rich cuisine to a data-scarce cuisine, domain adaptation sheds light on this practical problem. Nevertheless, existing works assume recipes in source and target domains are mostly originated from the same cuisine and written in the same language. This paper studies unsupervised domain adaptation for image-to-recipe retrieval, where recipes in source and target domains are in different languages. Moreover, only recipes are available for training in the target domain. A novel recipe mixup method is proposed to learn transferable embedding features between the two domains. Specifically, recipe mixup produces mixed recipes to form an intermediate domain by discretely exchanging the section(s) between source and target recipes. To bridge the domain gap, recipe mixup loss is proposed to enforce the intermediate domain to locate in the shortest geodesic path between source and target domains in the recipe embedding space. By using Recipe 1M dataset as source domain (English) and Vireo-FoodTransfer dataset as target domain (Chinese), empirical experiments verify the effectiveness of recipe mixup for cross- lingual adaptation in the context of image-to-recipe retrieval."
Entropically secure cipher for messages generated by Markov chainswith unknown statistics,BorisRyabko,8 May 2022,Cryptography and Security (cs.CR)," In 2002, Russell and Wang proposed a definition of entropically security that was developed within the framework of secret key cryptography. An entropically-secure system is unconditionally secure, that is, unbreakable, regardless of the enemy's computing power. In 2004, Dodis and Smith developed the results of Russell and Wang and, in particular, stated that the concept of an entropy-protected symmetric encryption scheme is extremely important for cryptography, since it is possible to construct entropy-protected symmetric encryption schemes with keys much shorter than the keys. the length of the input data, which allows you to bypass the famous lower bound on the length of the Shannon key. In this report, we propose an entropy-protected scheme for the case where the encrypted message is generated by a Markov chain with unknown statistics. The length of the required secret key is proportional to the logarithm of the length of the message (as opposed to the length of the message itself for the one-time pad)."
Decentralized Stochastic Optimization with Inherent Privacy Protection,"YongqiangWang, H.Vincent Poor",8 May 2022,Machine Learning (cs.LG)," Decentralized stochastic optimization is the basic building block of modern collaborative machine learning, distributed estimation and control, and large-scale sensing. Since involved data usually contain sensitive information like user locations, healthcare records and financial transactions, privacy protection has become an increasingly pressing need in the implementation of decentralized stochastic optimization algorithms. In this paper, we propose a decentralized stochastic gradient descent algorithm which is embedded with inherent privacy protection for every participating agent against other participating agents and external eavesdroppers. This proposed algorithm builds in a dynamics based gradient-obfuscation mechanism to enable privacy protection without compromising optimization accuracy, which is in significant difference from differential-privacy based privacy solutions for decentralized optimization that have to trade optimization accuracy for privacy. The dynamics based privacy approach is encryption- free, and hence avoids incurring heavy communication or computation overhead, which is a common problem with encryption based privacy solutions for decentralized stochastic optimization. Besides rigorously characterizing the convergence performance of the proposed decentralized stochastic gradient descent algorithm under both convex objective functions and non- convex objective functions, we also provide rigorous information-theoretic analysis of its strength of privacy protection. Simulation results for a distributed estimation problem as well as numerical experiments for decentralized learning on a benchmark machine learning dataset confirm the effectiveness of the proposed approach."
It's the Same Old Story! Enriching Event-Centric Knowledge Graphs byNarrative Aspects,"FlorianPlötzky, Wolf-TiloBalke",8 May 2022,Information Retrieval (cs.IR)," Our lives are ruled by events of varying importance ranging from simple everyday occurrences to incidents of societal dimension. And a lot of effort is taken to exchange information and discuss about such events: generally speaking, stringent narratives are formed to reduce complexity. But when considering complex events like the current conflict between Russia and Ukraine it is easy to see that those events cannot be grasped by objective facts alone, like the start of the conflict or respective troop sizes. There are different viewpoints and assessments to consider, a different understanding of the roles taken by individual participants, etc. So how can such subjective and viewpoint-dependent information be effectively represented together with all objective information? Recently event-centric knowledge graphs have been proposed for objective event representation in the otherwise primarily entity-centric domain of knowledge graphs. In this paper we introduce a novel and lightweight structure for event-centric knowledge graphs, which for the first time allows for queries incorporating viewpoint-dependent and narrative aspects. Our experiments prove the effective incorporation of subjective attributions for event participants and show the benefits of specifically tailored indexes for narrative query processing."
Multimodal Semi-Supervised Learning for Text Recognition,"AviadAberdam, Roy Ganz, Shai Mazor, Ron Litman",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Until recently, the number of public real-world text images was insufficient for training scene text recognizers. Therefore, most modern training methods rely on synthetic data and operate in a fully supervised manner. Nevertheless, the amount of public real-world text images has increased significantly lately, including a great deal of unlabeled data. Leveraging these resources requires semi-supervised approaches; however, the few existing methods do not account for vision-language multimodality structure and therefore suboptimal for state-of-the-art multimodal architectures. To bridge this gap, we present semi-supervised learning for multimodal text recognizers (SemiMTR) that leverages unlabeled data at each modality training phase. Notably, our method refrains from extra training stages and maintains the current three-stage multimodal training procedure. Our algorithm starts by pretraining the vision model through a single-stage training that unifies self-supervised learning with supervised training. More specifically, we extend an existing visual representation learning algorithm and propose the first contrastive-based method for scene text recognition. After pretraining the language model on a text corpus, we fine- tune the entire network via a sequential, character-level, consistency regularization between weakly and strongly augmented views of text images. In a novel setup, consistency is enforced on each modality separately. Extensive experiments validate that our method outperforms the current training schemes and achieves state-of-the-art results on multiple scene text recognition benchmarks."
Adversarial Learning of Hard Positives for Place Recognition,"WenxuanFang, KaiZhang, YoliShavit, Wensen Feng",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Image retrieval methods for place recognition learn global image descriptors that are used for fetching geo-tagged images at inference time. Recent works have suggested employing weak and self-supervision for mining hard positives and hard negatives in order to improve localization accuracy and robustness to visibility changes (e.g. in illumination or view point). However, generating hard positives, which is essential for obtaining robustness, is still limited to hard-coded or global augmentations. In this work we propose an adversarial method to guide the creation of hard positives for training image retrieval networks. Our method learns local and global augmentation policies which will increase the training loss, while the image retrieval network is forced to learn more powerful features for discriminating increasingly difficult examples. This approach allows the image retrieval network to generalize beyond the hard examples presented in the data and learn features that are robust to a wide range of variations. Our method achieves state-of-the-art recalls on the Pitts250 and Tokyo 24/7 benchmarks and outperforms recent image retrieval methods on the rOxford and rParis datasets by a noticeable margin."
Zero and R2D2: A Large-scale Chinese Cross-modal Benchmark and AVision-Language Framework,"ChunyuXie, HengCai, JianfeiSong, Jincheng Li, Fanjing Kong, Xiaoyu Wu, HenriqueMorimitsu, Lin Yao, Dexin Wang, Dawei Leng, Xiangyang Ji, Yafeng Deng",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Vision-language pre-training (VLP) relying on large-scale pre- training datasets has shown premier performance on various downstream tasks. In this sense, a complete and fair benchmark (i.e., including large-scale pre-training datasets and a variety of downstream datasets) is essential for VLP. But how to construct such a benchmark in Chinese remains a critical problem. To this end, we develop a large-scale Chinese cross-modal benchmark called Zero for AI researchers to fairly compare VLP models. We release two pre-training datasets and five fine-tuning datasets for downstream tasks. Furthermore, we propose a novel pre-training framework of pre-Ranking + Ranking for cross-modal learning. Specifically, we apply global contrastive pre-ranking to learn the individual representations of images and Chinese texts, respectively. We then fuse the representations in a fine-grained ranking manner via an image-text cross encoder and a text-image cross encoder. To further enhance the capability of the model, we propose a two- way distillation strategy consisting of target-guided Distillation and feature-guided Distillation. For simplicity, we call our model R2D2. We achieve state-of-the-art performance on four public cross-modal datasets and our five downstream datasets. The datasets, models and codes will be made available."
On Conditioning the Input Noise for Controlled Image Generation withDiffusion Models,"VedantSingh, SurganJandial, AyushChopra, SiddharthRamesh, BalajiKrishnamurthy, Vineeth N.Balasubramanian",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Conditional image generation has paved the way for several breakthroughs in image editing, generating stock photos and 3-D object generation. This continues to be a significant area of interest with the rise of new state-of-the-art methods that are based on diffusion models. However, diffusion models provide very little control over the generated image, which led to subsequent works exploring techniques like classifier guidance, that provides a way to trade off diversity with fidelity. In this work, we explore techniques to condition diffusion models with carefully crafted input noise artifacts. This allows generation of images conditioned on semantic attributes. This is different from existing approaches that input Gaussian noise and further introduce conditioning at the diffusion model's inference step. Our experiments over several examples and conditional settings show the potential of our approach."
Introduction to Soar,John E.Laird,8 May 2022,Artificial Intelligence (cs.AI)," This paper is the recommended initial reading for a functional overview of Soar, version 9.6. It includes an abstract overview of the architectural structure of Soar including its processing, memories, learning modules, their interfaces, and the representations of knowledge used by those modules. From there it describes the processing supported by those modules, including decision making, impasses and substates, procedure learning via chunking, reinforcement learning, semantic memory, episodic memory, and spatial-visual reasoning. It then reviews the levels of decision making and variety of learning in Soar, and analysis of Soar as an architecture supporting general human-level AI. Following the references is an appendix that contains short descriptions of recent Soar agents and a glossary of the terminology we use in describing Soar."
Assigning Species Information to Corresponding Genes by a SequenceLabeling Framework,"LingLuo, Chih-Hsuan Wei, Po-Ting Lai, Qingyu Chen, Rezarta IslamajDoğan, Zhiyong Lu",8 May 2022,Computation and Language (cs.CL)," The automatic assignment of species information to the corresponding genes in a research article is a critically important step in the gene normalization task, whereby a gene mention is normalized and linked to a database record or identifier by a text-mining algorithm. Existing methods typically rely on heuristic rules based on gene and species co- occurrence in the article, but their accuracy is suboptimal. We therefore developed a high-performance method, using a novel deep learning-based framework, to classify whether there is a relation between a gene and a species. Instead of the traditional binary classification framework in which all possible pairs of genes and species in the same article are evaluated, we treat the problem as a sequence-labeling task such that only a fraction of the pairs needs to be considered. Our benchmarking results show that our approach obtains significantly higher performance compared to that of the rule-based baseline method for the species assignment task (from 65.8% to 81.3% in accuracy). The source code and data for species assignment are freely available at [this https URL](https://github.com/ncbi/SpeciesAssignment)."
Randomized geometric tools for anomaly detection in stock markets,"CyrilBachelard, ApostolosChalkis, VissarionFisikopoulos, EliasTsigaridas",8 May 2022,Computational Geometry (cs.CG)," We propose novel randomized geometric tools to detect low- volatility anomalies in stock markets; a principal problem in financial economics. Our modeling of the (detection) problem results in sampling and estimating the (relative) volume of geodesically non-convex and non- connected spherical patches that arise by intersecting a non-standard simplex with a sphere. To sample, we introduce two novel Markov Chain Monte Carlo (MCMC) algorithms that exploit the geometry of the problem and employ state-of-the-art continuous geometric random walks (such as Billiard walk and Hit-and-Run) adapted on spherical patches. To our knowledge, this is the first geometric formulation and MCMC-based analysis of the volatility puzzle in stock markets. We have implemented our algorithms in C++ (along with an R interface) and we illustrate the power of our approach by performing extensive experiments on real data. Our analyses provide accurate detection and new insights into the distribution of portfolios' performance characteristics. Moreover, we use our tools to show that classical methods for low-volatility anomaly detection in finance form bad proxies that could lead to misleading or inaccurate results."
SeqNet: An Efficient Neural Network for Automatic Malware Detection,"JiaweiXu, WenxuanFu, HaoyuBu, ZhiWang, LingyunYing",8 May 2022,Cryptography and Security (cs.CR)," Malware continues to evolve rapidly, and more than 450,000 new samples are captured every day, which makes manual malware analysis impractical. However, existing deep learning detection models need manual feature engineering or require high computational overhead for long training processes, which might be laborious to select feature space and difficult to retrain for mitigating model aging. Therefore, a crucial requirement for a detector is to realize automatic and efficient detection. In this paper, we propose a lightweight malware detection model called SeqNet which could be trained at high speed with low memory required on the raw binaries. By avoiding contextual confusion and reducing semantic loss, SeqNet maintains the detection accuracy when reducing the number of parameters to only 136K. We demonstrate the effectiveness of our methods and the low training cost requirement of SeqNet in our experiments. Besides, we make our datasets and codes public to stimulate further academic research."
Fully Automated Binary Pattern Extraction For Finger VeinIdentification using Double Optimization Stages-Based Unsupervised LearningApproach,"Ali SalahHameed, Adil Al-Azzawi",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Today, finger vein identification is gaining popularity as a potential biometric identification framework solution. Machine learning- based unsupervised, supervised, and deep learning algorithms have had a significant influence on finger vein detection and recognition at the moment. Deep learning, on the other hand, necessitates a large number of training datasets that must be manually produced and labeled. In this research, we offer a completely automated unsupervised learning strategy for training dataset creation. Our method is intended to extract and build a decent binary mask training dataset completely automated. In this technique, two optimization steps are devised and employed. The initial stage of optimization is to create a completely automated unsupervised image clustering based on finger vein image localization. Worldwide finger vein pattern orientation estimation is employed in the second optimization to optimize the retrieved finger vein lines. Finally, the proposed system achieves 99.6 - percent pattern extraction accuracy, which is significantly higher than other common unsupervised learning methods like k-means and Fuzzy C-Means (FCM)."
On the Use of BERT for Automated Essay Scoring: Joint Learning ofMulti-Scale Essay Representation,"YongjieWang, ChuanWang, RuobingLi, HuiLin",8 May 2022,Computation and Language (cs.CL)," In recent years, pre-trained models have become dominant in most natural language processing (NLP) tasks. However, in the area of Automated Essay Scoring (AES), pre-trained models such as BERT have not been properly used to outperform other deep learning models such as LSTM. In this paper, we introduce a novel multi-scale essay representation for BERT that can be jointly learned. We also employ multiple losses and transfer learning from out-of-domain essays to further improve the performance. Experiment results show that our approach derives much benefit from joint learning of multi- scale essay representation and obtains almost the state-of-the-art result among all deep learning models in the ASAP task. Our multi-scale essay representation also generalizes well to CommonLit Readability Prize data set, which suggests that the novel text representation proposed in this paper may be a new and effective choice for long-text tasks."
Blockchain Application on the Internet of Vehicles (IoV),"NyothiriAung, TaharKechadi, SahraouiDhelim, TaoZhu, Aymen DiaEddineBerini, TaharGuerbouz",8 May 2022,Networking and Internet Architecture (cs.NI)," With the rapid development of the Internet of Things (IoT) and its potential integration with the traditional Vehicular Ad-Hoc Networks (VANETs), we have witnessed the emergence of the Internet of Vehicles (IoV), which promises to seamlessly integrate into smart transportation systems. However, the key characteristics of IoV, such as high-speed mobility and frequent disconnections make it difficult to manage its security and privacy. The Blockchain, as a distributed tamper-resistant ledge, has been proposed as an innovative solution that guarantees privacy-preserving yet secure schemes. In this paper, we review recent literature on the application of blockchain to IoV, in particular, and intelligent transportation systems in general."
Characterizing the Energy-Efficiency Region of Symbiotic RadioCommunications,"SihanWang, JingranXu, YongZeng",8 May 2022,Information Theory (cs.IT)," Symbiotic radio (SR) communication is a promising technology to achieve spectrum- and energy-efficient wireless communication, by enabling passive backscatter devices (BDs) reuse not only the spectrum, but also the power of active primary transmitters (PTs). In this paper, we aim to characterize the energy-efficiency (EE) region of multiple-input single- output (MISO) SR systems, which is defined as all the achievable EE pairs by the active PT and passive BD. To this end, we first derive the maximum individual EE of the PT and BD, respectively, and show that there exists a non-trivial trade-off between these two EEs. To characterize such a trade- off, an optimization problem is formulated to find the Pareto boundary of the EE region by optimizing the transmit beamforming and power allocation. The formulated problem is non-convex and difficult to be directly solved. An efficient algorithm based on successive convex approximation (SCA) is proposed to find a Karush-Kuhn-Tucker (KKT) solution. Simulation results are provided to show that the proposed algorithm is able to effectively characterize the EE region of SR communication systems."
Iterative Geometry-Aware Cross Guidance Network for Stereo ImageInpainting,"Ang Li, ShanshanZhao, QingjieZhang, Qiuhong Ke","8 May 2022 (v1(https://arxiv.org/abs/2205.03825v1)), lastrevised 11 May 2022 (this version, v2)",Computer Vision and Pattern Recognition (cs.CV)," Currently, single image inpainting has achieved promising results based on deep convolutional neural networks. However, inpainting on stereo images with missing regions has not been explored thoroughly, which is also a significant but different problem. One crucial requirement for stereo image inpainting is stereo consistency. To achieve it, we propose an Iterative Geometry-Aware Cross Guidance Network (IGGNet). The IGGNet contains two key ingredients, i.e., a Geometry-Aware Attention (GAA) module and an Iterative Cross Guidance (ICG) strategy. The GAA module relies on the epipolar geometry cues and learns the geometry-aware guidance from one view to another, which is beneficial to make the corresponding regions in two views consistent. However, learning guidance from co-existing missing regions is challenging. To address this issue, the ICG strategy is proposed, which can alternately narrow down the missing regions of the two views in an iterative manner. Experimental results demonstrate that our proposed network outperforms the latest stereo image inpainting model and state-of-the-art single image inpainting models."
A Survey on AI Sustainability: Emerging Trends on Learning Algorithmsand Research Challenges,"ZhenghuaChen, MinWu, AlvinChan, XiaoliLi, Yew-SoonOng",8 May 2022,Artificial Intelligence (cs.AI)," Artificial Intelligence (AI) is a fast-growing research and development (R&D) discipline which is attracting increasing attention because of its promises to bring vast benefits for consumers and businesses, with considerable benefits promised in productivity growth and innovation. To date it has reported significant accomplishments in many areas that have been deemed as challenging for machines, ranging from computer vision, natural language processing, audio analysis to smart sensing and many others. The technical trend in realizing the successes has been towards increasing complex and large size AI models so as to solve more complex problems at superior performance and robustness. This rapid progress, however, has taken place at the expense of substantial environmental costs and resources. Besides, debates on the societal impacts of AI, such as fairness, safety and privacy, have continued to grow in intensity. These issues have presented major concerns pertaining to the sustainable development of AI. In this work, we review major trends in machine learning approaches that can address the sustainability problem of AI. Specifically, we examine emerging AI methodologies and algorithms for addressing the sustainability issue of AI in two major aspects, i.e., environmental sustainability and social sustainability of AI. We will also highlight the major limitations of existing studies and propose potential research challenges and directions for the development of next generation of sustainable AI techniques. We believe that this technical review can help to promote a sustainable development of AI R&D activities for the research community."
Challenges and Opportunities of Blockchain for Cyber ThreatIntelligence Sharing,"KealanDunnett, Shantanu Pal, ZahraJadidi",8 May 2022,Cryptography and Security (cs.CR)," The emergence of the Internet of Things (IoT) technology has caused a powerful transition in the cyber threat landscape. As a result, organisations have had to find new ways to better manage the risks associated with their infrastructure. In response, a significant amount of research has focused on developing efficient Cyber Threat Intelligence (CTI) sharing platforms. However, most existing solutions are highly centralised and do not provide a way to exchange information in a distributed way. In this chapter, we subsequently seek to evaluate how blockchain technology can be used to address a number of limitations present in existing CTI sharing platforms. To determine the role of blockchain-based sharing moving forward, we present a number of general CTI sharing challenges, and discuss how blockchain can bring opportunities to address these challenges in a secure and efficient manner. Finally, we discuss a list of relevant works and note some unique future research questions."
Unsupervised Homography Estimation with Coplanarity-Aware GAN,"MingboHong, YuhangLu, NianjinYe, ChunyuLin, QijunZhao, Shuaicheng Liu",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Estimating homography from an image pair is a fundamental problem in image alignment. Unsupervised learning methods have received increasing attention in this field due to their promising performance and label-free training. However, existing methods do not explicitly consider the problem of plane-induced parallax, which will make the predicted homography compromised on multiple planes. In this work, we propose a novel method HomoGAN to guide unsupervised homography estimation to focus on the dominant plane. First, a multi-scale transformer network is designed to predict homography from the feature pyramids of input images in a coarse-to-fine fashion. Moreover, we propose an unsupervised GAN to impose coplanarity constraint on the predicted homography, which is realized by using a generator to predict a mask of aligned regions, and then a discriminator to check if two masked feature maps are induced by a single homography. To validate the effectiveness of HomoGAN and its components, we conduct extensive experiments on a large-scale dataset, and the results show that our matching error is 22% lower than the previous SOTA method. Code is available at [this https URL](https://github.com/megvii-research/HomoGAN)."
Simultaneous Double Q-learning with Conservative Advantage Learningfor Actor-Critic Methods,"QingLi, WengangZhou, ZhenboLu, HouqiangLi",8 May 2022,Machine Learning (cs.LG)," Actor-critic Reinforcement Learning (RL) algorithms have achieved impressive performance in continuous control tasks. However, they still suffer two nontrivial obstacles, i.e., low sample efficiency and overestimation bias. To this end, we propose Simultaneous Double Q-learning with Conservative Advantage Learning (SDQ-CAL). Our SDQ-CAL boosts the Double Q-learning for off-policy actor-critic RL based on a modification of the Bellman optimality operator with Advantage Learning. Specifically, SDQ- CAL improves sample efficiency by modifying the reward to facilitate the distinction from experience between the optimal actions and the others. Besides, it mitigates the overestimation issue by updating a pair of critics simultaneously upon double estimators. Extensive experiments reveal that our algorithm realizes less biased value estimation and achieves state-of-the- art performance in a range of continuous control benchmark tasks. We release the source code of our method at: \url{[this https URL](https://github.com/LQNew/SDQ-CAL)}."
PGADA: Perturbation-Guided Adversarial Alignment for Few-shot LearningUnder the Support-Query Shift,"SiyangJiang, WeiDing, Hsi-WenChen, Ming-Syan Chen",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Few-shot learning methods aim to embed the data to a low- dimensional embedding space and then classify the unseen query data to the seen support set. While these works assume that the support set and the query set lie in the same embedding space, a distribution shift usually occurs between the support set and the query set, i.e., the Support-Query Shift, in the real world. Though optimal transportation has shown convincing results in aligning different distributions, we find that the small perturbations in the images would significantly misguide the optimal transportation and thus degrade the model performance. To relieve the misalignment, we first propose a novel adversarial data augmentation method, namely Perturbation-Guided Adversarial Alignment (PGADA), which generates the hard examples in a self-supervised manner. In addition, we introduce Regularized Optimal Transportation to derive a smooth optimal transportation plan. Extensive experiments on three benchmark datasets manifest that our framework significantly outperforms the eleven state-of-the-art methods on three datasets."
Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence,"MyeongjunJang, FrankMtumbuka, ThomasLukasiewicz",8 May 2022,Computation and Language (cs.CL)," The logical negation property (LNP), which implies generating different predictions for semantically opposite inputs, is an important property that a trustworthy language model must satisfy. However, much recent evidence shows that large-size pre-trained language models (PLMs) do not satisfy this property. In this paper, we perform experiments using probing tasks to assess PLM's LNP understanding. Unlike previous studies that only examined negation expressions, we expand the boundary of the investigation to lexical semantics. Through experiments, we observe that PLMs violate the LNP frequently. To alleviate the issue, we propose a novel intermediate training task, names meaning-matching, designed to directly learn a meaning-text correspondence, instead of relying on the distributional hypothesis. Through multiple experiments, we find that the task enables PLMs to learn lexical semantic information. Also, through fine- tuning experiments on 7 GLUE tasks, we confirm that it is a safe intermediate task that guarantees a similar or better performance of downstream tasks. Finally, we observe that our proposed approach outperforms our previous counterparts despite its time and resource efficiency."
Data-Free Adversarial Knowledge Distillation for Graph Neural Networks,"YuanxinZhuang, Lingjuan Lyu, Chuan Shi, Carl Yang, Lichao Sun",8 May 2022,Machine Learning (cs.LG)," Graph neural networks (GNNs) have been widely used in modeling graph structured data, owing to its impressive performance in a wide range of practical applications. Recently, knowledge distillation (KD) for GNNs has enabled remarkable progress in graph model compression and knowledge transfer. However, most of the existing KD methods require a large volume of real data, which are not readily available in practice, and may preclude their applicability in scenarios where the teacher model is trained on rare or hard to acquire datasets. To address this problem, we propose the first end-to-end framework for data-free adversarial knowledge distillation on graph structured data (DFAD-GNN). To be specific, our DFAD-GNN employs a generative adversarial network, which mainly consists of three components: a pre-trained teacher model and a student model are regarded as two discriminators, and a generator is utilized for deriving training graphs to distill knowledge from the teacher model into the student model. Extensive experiments on various benchmark models and six representative datasets demonstrate that our DFAD-GNN significantly surpasses state-of-the-art data- free baselines in the graph classification task."
Over-the-Air Federated Multi-Task Learning via Model Sparsificationand Turbo Compressed Sensing,"HaomingMa, XiaojunYuan, ZhiDing, DianFan, JunFang",8 May 2022,Information Theory (cs.IT)," To achieve communication-efficient federated multitask learning (FMTL), we propose an over-the-air FMTL (OAFMTL) framework, where multiple learning tasks deployed on edge devices share a non-orthogonal fading channel under the coordination of an edge server (ES). In OA-FMTL, the local updates of edge devices are sparsified, compressed, and then sent over the uplink channel in a superimposed fashion. The ES employs over-the-air computation in the presence of intertask interference. More specifically, the model aggregations of all the tasks are reconstructed from the channel observations concurrently, based on a modified version of the turbo compressed sensing (Turbo-CS) algorithm (named as M-Turbo-CS). We analyze the performance of the proposed OA-FMTL framework together with the M-Turbo- CS algorithm. Furthermore, based on the analysis, we formulate a communication-learning optimization problem to improve the system performance by adjusting the power allocation among the tasks at the edge devices. Numerical simulations show that our proposed OAFMTL effectively suppresses the inter-task interference, and achieves a learning performance comparable to its counterpart with orthogonal multi-task transmission. It is also shown that the proposed inter-task power allocation optimization algorithm substantially reduces the overall communication overhead by appropriately adjusting the power allocation among the tasks."
Fingerprint Template Invertibility: Minutiae vs. Deep Templates,"Kanishka P.Wijewardena, Steven A.Grosz, KaiCao, Anil K.Jain",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Much of the success of fingerprint recognition is attributed to minutiae-based fingerprint representation. It was believed that minutiae templates could not be inverted to obtain a high fidelity fingerprint image, but this assumption has been shown to be false. The success of deep learning has resulted in alternative fingerprint representations (embeddings), in the hope that they might offer better recognition accuracy as well as non- invertibility of deep network-based templates. We evaluate whether deep fingerprint templates suffer from the same reconstruction attacks as the minutiae templates. We show that while a deep template can be inverted to produce a fingerprint image that could be matched to its source image, deep templates are more resistant to reconstruction attacks than minutiae templates. In particular, reconstructed fingerprint images from minutiae templates yield a TAR of about 100.0% (98.3%) @ FAR of 0.01% for type-I (type-II) attacks using a state-of-the-art commercial fingerprint matcher, when tested on NIST SD4. The corresponding attack performance for reconstructed fingerprint images from deep templates using the same commercial matcher yields a TAR of less than 1% for both type-I and type-II attacks; however, when the reconstructed images are matched using the same deep network, they achieve a TAR of 85.95% (68.10%) for type-I (type-II) attacks. Furthermore, what is missing from previous fingerprint template inversion studies is an evaluation of the black-box attack performance, which we perform using 3 different state-of-the-art fingerprint matchers. We conclude that fingerprint images generated by inverting minutiae templates are highly susceptible to both white-box and black-box attack evaluations, while fingerprint images generated by deep templates are resistant to black- box evaluations and comparatively less susceptible to white-box evaluations."
Transformer Tracking with Cyclic Shifting Window Attention,"ZikaiSong, JunqingYu, Yi-PingPhoebe Chen, Wei Yang",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Transformer architecture has been showing its great strength in visual object tracking, for its effective attention mechanism. Existing transformer-based approaches adopt the pixel-to-pixel attention strategy on flattened image features and unavoidably ignore the integrity of objects. In this paper, we propose a new transformer architecture with multi-scale cyclic shifting window attention for visual object tracking, elevating the attention from pixel to window level. The cross-window multi-scale attention has the advantage of aggregating attention at different scales and generates the best fine-scale match for the target object. Furthermore, the cyclic shifting strategy brings greater accuracy by expanding the window samples with positional information, and at the same time saves huge amounts of computational power by removing redundant calculations. Extensive experiments demonstrate the superior performance of our method, which also sets the new state-of-the-art records on five challenging datasets, along with the VOT2020, UAV123, LaSOT, TrackingNet, and GOT-10k benchmarks."
A Closer Look at Few-shot Image Generation,"YunqingZhao, HenghuiDing, HoujingHuang, Ngai-Man Cheung",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Modern GANs excel at generating high quality and diverse images. However, when transferring the pretrained GANs on small target data (e.g., 10-shot), the generator tends to replicate the training samples.   Several methods have been proposed to address this few-shot image generation task, but there is a lack of effort to analyze them under a unified framework.   As our first contribution, we propose a framework to analyze existing methods during the adaptation. Our analysis discovers that while some methods have disproportionate focus on diversity preserving which impede quality improvement, all methods achieve similar quality after convergence.   Therefore, the better methods are those that can slow down diversity degradation. Furthermore, our analysis reveals that there is still plenty of room to further slow down diversity degradation.   Informed by our analysis and to slow down the diversity degradation of the target generator during adaptation, our second contribution proposes to apply mutual information (MI) maximization to retain the source domain's rich multi-level diversity information in the target domain generator.   We propose to perform MI maximization by contrastive loss (CL), leverage the generator and discriminator as two feature encoders to extract different multi-level features for computing CL. We refer to our method as Dual Contrastive Learning (DCL).   Extensive experiments on several public datasets show that, while leading to a slower diversity-degrading generator during adaptation, our proposed DCL brings visually pleasant quality and state-of-the-art quantitative performance."
Multi-Domain Targeted Sentiment Analysis,"Orith Toledo-Ronen, MatanOrbach, Yoav Katz, Noam Slonim",8 May 2022,Computation and Language (cs.CL)," Targeted Sentiment Analysis (TSA) is a central task for generating insights from consumer reviews. Such content is extremely diverse, with sites like Amazon or Yelp containing reviews on products and businesses from many different domains. A real-world TSA system should gracefully handle that diversity. This can be achieved by a multi-domain model -- one that is robust to the domain of the analyzed texts, and performs well on various domains. To address this scenario, we present a multi-domain TSA system based on augmenting a given training set with diverse weak labels from assorted domains. These are obtained through self-training on the Yelp reviews corpus. Extensive experiments with our approach on three evaluation datasets across different domains demonstrate the effectiveness of our solution. We further analyze how restrictions imposed on the available labeled data affect the performance, and compare the proposed method to the costly alternative of manually gathering diverse TSA labeled data. Our results and analysis show that our approach is a promising step towards a practical domain-robust TSA system."
Deep Embedded Multi-View Clustering via Jointly Learning LatentRepresentations and Graphs,"ZongmoHuang, Yazhou Ren, Xiaorong Pu, Lifang He",8 May 2022,Machine Learning (cs.LG)," With the representation learning capability of the deep learning models, deep embedded multi-view clustering (MVC) achieves impressive performance in many scenarios and has become increasingly popular in recent years. Although great progress has been made in this field, most existing methods merely focus on learning the latent representations and ignore that learning the latent graph of nodes also provides available information for the clustering task. To address this issue, in this paper we propose Deep Embedded Multi-view Clustering via Jointly Learning Latent Representations and Graphs (DMVCJ), which utilizes the latent graphs to promote the performance of deep embedded MVC models from two aspects. Firstly, by learning the latent graphs and feature representations jointly, the graph convolution network (GCN) technique becomes available for our model. With the capability of GCN in exploiting the information from both graphs and features, the clustering performance of our model is significantly promoted. Secondly, based on the adjacency relations of nodes shown in the latent graphs, we design a sample-weighting strategy to alleviate the noisy issue, and further improve the effectiveness and robustness of the model. Experimental results on different types of real-world multi-view datasets demonstrate the effectiveness of DMVCJ."
Past and Future Motion Guided Network for Audio Visual EventLocalization,"TingxiuChen, JianqinYin, JinTang",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," In recent years, audio-visual event localization has attracted much attention. It's purpose is to detect the segment containing audio- visual events and recognize the event category from untrimmed videos. Existing methods use audio-guided visual attention to lead the model pay attention to the spatial area of the ongoing event, devoting to the correlation between audio and visual information but ignoring the correlation between audio and spatial motion. We propose a past and future motion extraction (pf-ME) module to mine the visual motion from videos ,embedded into the past and future motion guided network (PFAGN), and motion guided audio attention (MGAA) module to achieve focusing on the information related to interesting events in audio modality through the past and future visual motion. We choose AVE as the experimental verification dataset and the experiments show that our method outperforms the state-of-the-arts in both supervised and weakly-supervised settings."
Fuzzy-Logic Based IDS for Detecting Jamming Attacks in Wireless MeshIoT Networks,"MichaelSavva, IacovosIoannou, VasosVassiliou",8 May 2022,Networking and Internet Architecture (cs.NI)," The investigation in this paper targets the design and the evaluation of jamming intrusion detection based on Fuzzy Logic in wireless mesh IoT Networks in a distributed manner. Our approach uses information collected at local nodes and from the sink as input to the fuzzy logic controller. In order to find the best set of inputs, distributed or centralized, we made a comparison between five different combinations of parameters. The investigation uses the values of the ETX, Retransmissions, Packets Drop per terminal (PDPT) and Packet Delivery Ratio (PDR) as inputs to a fuzzy inference system to get Jamming Index (JI) as the system's output. The proposed method was evaluated based on the following metrics: Accuracy, Precision, Specificity, False positive rate (FPR), Recall, False negative rate (FNR) and ROC curve. In order to evaluate this approach, we implement experiments in various scenarios using the Contiki OS and the Cooja simulator tool."
Pervasive Machine Learning for Smart Radio Environments Enabled byReconfigurable Intelligent Surfaces,"George C.Alexandropoulos, KyriakosStylianopoulos, ChongwenHuang, ChauYuen, MehdiBennis, MérouaneDebbah",8 May 2022,Information Theory (cs.IT)," The emerging technology of Reconfigurable Intelligent Surfaces (RISs) is provisioned as an enabler of smart wireless environments, offering a highly scalable, low-cost, hardware-efficient, and almost energy-neutral solution for dynamic control of the propagation of electromagnetic signals over the wireless medium, ultimately providing increased environmental intelligence for diverse operation objectives. One of the major challenges with the envisioned dense deployment of RISs in such reconfigurable radio environments is the efficient configuration of multiple metasurfaces with limited, or even the absence of, computing hardware. In this paper, we consider multi-user and multi-RIS-empowered wireless systems, and present a thorough survey of the online machine learning approaches for the orchestration of their various tunable components. Focusing on the sum-rate maximization as a representative design objective, we present a comprehensive problem formulation based on Deep Reinforcement Learning (DRL). We detail the correspondences among the parameters of the wireless system and the DRL terminology, and devise generic algorithmic steps for the artificial neural network training and deployment, while discussing their implementation details. Further practical considerations for multi-RIS- empowered wireless communications in the sixth Generation (6G) era are presented along with some key open research challenges. Differently from the DRL-based status quo, we leverage the independence between the configuration of the system design parameters and the future states of the wireless environment, and present efficient multi-armed bandits approaches, whose resulting sum-rate performances are numerically shown to outperform random configurations, while being sufficiently close to the conventional Deep Q-Network (DQN) algorithm, but with lower implementation complexity."
One-Class Knowledge Distillation for Face Presentation AttackDetection,"Zhi Li, Rizhao Cai, Haoliang Li, Kwok-Yan Lam, Yongjian Hu, Alex C. Kot",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Face presentation attack detection (PAD) has been extensively studied by research communities to enhance the security of face recognition systems. Although existing methods have achieved good performance on testing data with similar distribution as the training data, their performance degrades severely in application scenarios with data of unseen distributions. In situations where the training and testing data are drawn from different domains, a typical approach is to apply domain adaptation techniques to improve face PAD performance with the help of target domain data. However, it has always been a non-trivial challenge to collect sufficient data samples in the target domain, especially for attack samples. This paper introduces a teacher-student framework to improve the cross- domain performance of face PAD with one-class domain adaptation. In addition to the source domain data, the framework utilizes only a few genuine face samples of the target domain. Under this framework, a teacher network is trained with source domain samples to provide discriminative feature representations for face PAD. Student networks are trained to mimic the teacher network and learn similar representations for genuine face samples of the target domain. In the test phase, the similarity score between the representations of the teacher and student networks is used to distinguish attacks from genuine ones. To evaluate the proposed framework under one- class domain adaptation settings, we devised two new protocols and conducted extensive experiments. The experimental results show that our method outperforms baselines under one-class domain adaptation settings and even state-of-the-art methods with unsupervised domain adaptation."
MLSmellHound: A Context-Aware Code Analysis Tool,"JaiKannan, ScottBarnett, Luís Cruz, AnjSimmons, AkashAgarwal",8 May 2022,Software Engineering (cs.SE)," Meeting the rise of industry demand to incorporate machine learning (ML) components into software systems requires interdisciplinary teams contributing to a shared code base. To maintain consistency, reduce defects and ensure maintainability, developers use code analysis tools to aid them in identifying defects and maintaining standards. With the inclusion of machine learning, tools must account for the cultural differences within the teams which manifests as multiple programming languages, and conflicting definitions and objectives. Existing tools fail to identify these cultural differences and are geared towards software engineering which reduces their adoption in ML projects. In our approach we attempt to resolve this problem by exploring the use of context which includes i) purpose of the source code, ii) technical domain, iii) problem domain, iv) team norms, v) operational environment, and vi) development lifecycle stage to provide contextualised error reporting for code analysis. To demonstrate our approach, we adapt Pylint as an example and apply a set of contextual transformations to the linting results based on the domain of individual project files under analysis. This allows for contextualised and meaningful error reporting for the end-user."
Privacy Preserving Data Analytics in 5G-Enabled IoT for the FinancialIndustry,Cheng LockLim,8 May 2022,Cryptography and Security (cs.CR)," Next-generation wireless networks like 5G promise faster speed, shorter latency, and the ability to connect more devices. Such benefits are set to make drastic changes to the future society, empowering smart cities, enabling autonomous cars, enhancing business processes, changing consumer behaviors, etc. In the financial industry, banks evaluate the deployment of Internet of Things (IoT) technologies and edge computing for better customer engagement, e.g., mobile branches on a vehicle, micro-ATM, self-service digital panel, etc. One of the trends is breaking down monolithic business application systems into micro-services for deployment on distributed edge servers, thus reducing network latency and improving services. Such movements pose challenges in protecting the security and privacy of business data between access points. This paper introduces a new architecture and protocol to tackle a use case for the financial industry. The solution assumes deploying a credit assessment model on an edge server. The model accepts and processes encrypted data submitted by potential customers seeking online credit assessments. The encrypted assessment results are sent back to the customers for decryption and interpretation. The data transmission rides on asynchronous communication, and the data protection uses Homomorphic Encryption. A proof-of-concept experiment shows that the proposed method can be achieved with a short response time and a reasonable prediction accuracy."
Learning Regionally Decentralized AC Optimal Power Flows with ADMM,"Terrence W.K.Mak, MinasChatzos, MathieuTanneau, Pascal VanHentenryck",8 May 2022,Systems and Control (eess.SY)," One potential future for the next generation of smart grids is the use of decentralized optimization algorithms and secured communications for coordinating renewable generation (e.g., wind/solar), dispatchable devices (e.g., coal/gas/nuclear generations), demand response, battery & storage facilities, and topology optimization. The Alternating Direction Method of Multipliers (ADMM) has been widely used in the community to address such decentralized optimization problems and, in particular, the AC Optimal Power Flow (AC-OPF). This paper studies how machine learning may help in speeding up the convergence of ADMM for solving AC-OPF. It proposes a novel decentralized machine-learning approach, namely ML-ADMM, where each agent uses deep learning to learn the consensus parameters on the coupling branches. The paper also explores the idea of learning only from ADMM runs that exhibit high-quality convergence properties, and proposes filtering mechanisms to select these runs. Experimental results on test cases based on the French system demonstrate the potential of the approach in speeding up the convergence of ADMM significantly."
GRAPHCACHE: Message Passing as Caching for Sentence-Level RelationExtraction,"YiweiWang, MuhaoChen, WenxuanZhou, YujunCai, YuxuanLiang, BryanHooi",8 May 2022,Computation and Language (cs.CL)," Entity types and textual context are essential properties for sentence-level relation extraction (RE). Existing work only encodes these properties within individual instances, which limits the performance of RE given the insufficient features in a single sentence. In contrast, we model these properties from the whole dataset and use the dataset-level information to enrich the semantics of every instance. We propose the GRAPHCACHE (Graph Neural Network as Caching) module, that propagates the features across sentences to learn better representations for RE. GRAPHCACHE aggregates the features from sentences in the whole dataset to learn global representations of properties, and use them to augment the local features within individual sentences. The global property features act as dataset- level prior knowledge for RE, and a complement to the sentence-level features. Inspired by the classical caching technique in computer systems, we develop GRAPHCACHE to update the property representations in an online manner. Overall, GRAPHCACHE yields significant effectiveness gains on RE and enables efficient message passing across all sentences in the dataset."
Should We Rely on Entity Mentions for Relation Extraction? DebiasingRelation Extraction with Counterfactual Analysis,"YiweiWang, MuhaoChen, WenxuanZhou, YujunCai, YuxuanLiang, Dayiheng Liu, Baosong Yang, Juncheng Liu, Bryan Hooi",8 May 2022,Computation and Language (cs.CL)," Recent literature focuses on utilizing the entity information in the sentence-level relation extraction (RE), but this risks leaking superficial and spurious clues of relations. As a result, RE still suffers from unintended entity bias, i.e., the spurious correlation between entity mentions (names) and relations. Entity bias can mislead the RE models to extract the relations that do not exist in the text. To combat this issue, some previous work masks the entity mentions to prevent the RE models from overfitting entity mentions. However, this strategy degrades the RE performance because it loses the semantic information of entities. In this paper, we propose the CORE (Counterfactual Analysis based Relation Extraction) debiasing method that guides the RE models to focus on the main effects of textual context without losing the entity information. We first construct a causal graph for RE, which models the dependencies between variables in RE models. Then, we propose to conduct counterfactual analysis on our causal graph to distill and mitigate the entity bias, that captures the causal effects of specific entity mentions in each instance. Note that our CORE method is model-agnostic to debias existing RE systems during inference without changing their training processes. Extensive experimental results demonstrate that our CORE yields significant gains on both effectiveness and generalization for RE. The source code is provided at: [this https URL](https://github.com/vanoracai/CoRE)."
Non-parametric Depth Distribution Modelling based Depth Inference forMulti-view Stereo,"JiayuYang, Jose M.Alvarez, Miaomiao Liu",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Recent cost volume pyramid based deep neural networks have unlocked the potential of efficiently leveraging high-resolution images for depth inference from multi-view stereo. In general, those approaches assume that the depth of each pixel follows a unimodal distribution. Boundary pixels usually follow a multi-modal distribution as they represent different depths; Therefore, the assumption results in an erroneous depth prediction at the coarser level of the cost volume pyramid and can not be corrected in the refinement levels leading to wrong depth predictions. In contrast, we propose constructing the cost volume by non-parametric depth distribution modeling to handle pixels with unimodal and multi-modal distributions. Our approach outputs multiple depth hypotheses at the coarser level to avoid errors in the early stage. As we perform local search around these multiple hypotheses in subsequent levels, our approach does not maintain the rigid depth spatial ordering and, therefore, we introduce a sparse cost aggregation network to derive information within each volume. We evaluate our approach extensively on two benchmark datasets: DTU and Tanks & Temples. Our experimental results show that our model outperforms existing methods by a large margin and achieves superior performance on boundary regions. Code is available at [this https URL](https://github.com/NVlabs/NP-CVP-MVSNet)"
SSIM-Variation-Based Complexity Optimization for Versatile VideoCoding,"JielianLin, HongbinLin, ZhichenZhang, YiwenXu, TiesongZhao",8 May 2022,Multimedia (cs.MM)," To date, Versatile Video Coding (VVC) has a more magnificent overall performance than High Efficiency Video Coding (HEVC). The Quadtree with Nested Multi-Type Tree (QTMT) coding block structure can substantially enhance video coding quality in VVC. However, the coding gain also leads to a greater coding complexity. Therefore, this letter proposes a Fast Decision Scheme Based on Structural Similarity Index Metric Variation (FDS-SSIMV) to solve this problem. Firstly, the Structural Similarity Index Metric Variation (SSIMV) characteristic among the sub coding units of the spit mode is illustrated. Next, to evaluate the SSIMV value, SSIMV measure strategies are designed for different split modes in this letter. Then, the desired split modes are selected by the SSIMV values. Experimental results show that the proposed method achieves 64.74\% average encoding Time Saving (TS) with a 2.79\% Bj$\varnothing$ntegaard Delta Bit Rate (BDBR), outperforming the benchmarks."
A Multi-User Effective Computation Offloading Mechanism for MECSystem: Batched Multi-Armed Bandits Approach,"HangfanLi, XiaoxiongZhong, Xinghan Wang, Yun Ji, ShengZhang",8 May 2022,Networking and Internet Architecture (cs.NI)," With the development of 5G technology, mobile edge computing (MEC) is becoming a useful architecture, which is envisioned as a cloud computing extension version. Users within MEC system could deal with data processing at edge terminals, which can reduce time for communication or data transmission. Multi-armed bandits (MAB) algorithms are powerful tools helping users offloading tasks to their best servers in MEC. However, as the number of users and tasks growing, the frequency of selecting servers and the cost of making decision is growing rapidly under traditional MAB algorithms. Inspired by this, in this paper, we propose a Batch-based Multi- user Server Elimination (BMSE) algorithm to solve such problem, which includes two sub-algorithms. We firstly propose a sub-algorithm in user level (BMSE-UL) to reduce the time cost. In BMSE-UL, users can simplify its own available server groups and offload tasks collectively. Then another sub-algorithm in system level (BMSE-SL) is proposed to reduce the frequency of making decision. In BMSE-SL, the system can cut down all the suboptimal task offloading actions and make the choosing option unique. Furthermore, we establish the optimality of the proposed algorithms by proving the sub- linearity convergence of their regrets and demonstrate the effectiveness of BMSE by extensive experiments."
Neural operator learning of heterogeneous mechanobiological insultscontributing to aortic aneurysms,"SomdattaGoswami, David S. Li, Bruno V.Rego, MarcosLatorre, Jay D.Humphrey, George EmKarniadakis",8 May 2022,Machine Learning (cs.LG)," Thoracic aortic aneurysm (TAA) is a localized dilatation of the aorta resulting from compromised wall composition, structure, and function, which can lead to life-threatening dissection or rupture. Several genetic mutations and predisposing factors that contribute to TAA have been studied in mouse models to characterize specific changes in aortic microstructure and material properties that result from a wide range of mechanobiological insults. Assessments of TAA progression in vivo is largely limited to measurements of aneurysm size and growth rate. It has been shown that aortic geometry alone is not sufficient to predict the patient-specific progression of TAA but computational modeling of the evolving biomechanics of the aorta could predict future geometry and properties from initiating insults. In this work, we present an integrated framework to train a deep operator network (DeepONet)-based surrogate model to identify contributing factors for TAA by using FE-based datasets of aortic growth and remodeling resulting from prescribed insults. For training data, we investigate multiple types of TAA risk factors and spatial distributions within a constrained mixture model to generate axial--azimuthal maps of aortic dilatation and distensibility. The trained network is then capable of predicting the initial distribution and extent of the insult from a given set of dilatation and distensibility information. Two DeepONet frameworks are proposed, one trained on sparse information and one on full-field grayscale images, to gain insight into a preferred neural operator-based approach. Performance of the surrogate models is evaluated through multiple simulations carried out on insult distributions varying from fusiform to complex. We show that the proposed approach can predict patient-specific mechanobiological insult profile with a high accuracy, particularly when based on full-field images."
Communication Compression for Decentralized Learning with OperatorSplitting Methods,"YukiTakezawa, Kenta Niwa, MakotoYamada",8 May 2022,Machine Learning (cs.LG)," In decentralized learning, operator splitting methods using a primal-dual formulation (e.g., the Edge-Consensus Learning (ECL)) has been shown to be robust to heterogeneous data and has attracted significant attention in recent years. However, in the ECL, a node needs to exchange dual variables with its neighbors. These exchanges incur significant communication costs. For the Gossip-based algorithms, many compression methods have been proposed, but these Gossip-based algorithm do not perform well when the data distribution held by each node is statistically heterogeneous. In this work, we propose the novel framework of the compression methods for the ECL, called the Communication Compressed ECL (C-ECL). Specifically, we reformulate the update formulas of the ECL, and propose to compress the update values of the dual variables. We demonstrate experimentally that the C-ECL can achieve a nearly equivalent performance with fewer parameter exchanges than the ECL. Moreover, we demonstrate that the C-ECL is more robust to heterogeneous data than the Gossip-based algorithms."
FuDFEND: Fuzzy-domain for Multi-domain Fake News Detection,"ChaoqiLiang, YuZhang, Xinyuan Li, Jinyu Zhang, Yongqi Yu",8 May 2022,Social and Information Networks (cs.SI)," On the Internet, fake news exists in various domain (e.g., education, health). Since news in different domains has different features, researchers have be-gun to use single domain label for fake news detection recently. This emerg-ing field is called multi-domain fake news detection (MFND). Existing works show that using single domain label can improve the accuracy of fake news detection model. However, there are two problems in previous works. Firstly, they ignore that a piece of news may have features from different domains. The single domain label focuses only on the features of the news on particu-lar domain. This may reduce the performance of the model. Secondly, their model cannot transfer the domain knowledge to the other dataset without domain label. In this paper, we propose a novel model, FuDFEND, which solves the limitations above by introducing the fuzzy inference mechanism. Specifically, FuDFEND utilizes a neural network to fit the fuzzy inference process which constructs a fuzzy domain label for each news item. Then, the feature extraction module uses the fuzzy domain label to extract the multi-domain features of the news and obtain the total feature representation. Fi-nally, the discriminator module uses the total feature representation to dis-criminate whether the news item is fake news. The results on the Weibo21 show that our model works better than the model using only single domain label. In addition, our model transfers domain knowledge better to Thu da-taset which has no domain label."
Semi-Cycled Generative Adversarial Networks for Real-World Face Super-Resolution,"HaoHou, XiaotaoHu, JunXu, YingkunHou, BenzhengWei, DinggangShen",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Real-world face super-resolution (SR) is a highly ill-posed image restoration task. The fully-cycled Cycle-GAN architecture is widely employed to achieve promising performance on face SR, but prone to produce artifacts upon challenging cases in real-world scenarios, since joint participation in the same degradation branch will impact final performance due to huge domain gap between real-world and synthetic LR ones obtained by generators. To better exploit the powerful generative capability of GAN for real-world face SR, in this paper, we establish two independent degradation branches in the forward and backward cycle-consistent reconstruction processes, respectively, while the two processes share the same restoration branch. Our Semi-Cycled Generative Adversarial Networks (SCGAN) is able to alleviate the adverse effects of the domain gap between the real-world LR face images and the synthetic LR ones, and to achieve accurate and robust face SR performance by the shared restoration branch regularized by both the forward and backward cycle-consistent learning processes. Experiments on two synthetic and two real-world datasets demonstrate that, our SCGAN outperforms the state-of-the-art methods on recovering the face structures/details and quantitative metrics for real-world face SR. The code will be publicly released at [this https URL](https://github.com/HaoHou-98/SCGAN)."
SparseTT: Visual Tracking with Sparse Transformers,"ZhihongFu, ZehuaFu, QingjieLiu, WenruiCai, YunhongWang",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Transformers have been successfully applied to the visual tracking task and significantly promote tracking performance. The self-attention mechanism designed to model long-range dependencies is the key to the success of Transformers. However, self-attention lacks focusing on the most relevant information in the search regions, making it easy to be distracted by background. In this paper, we relieve this issue with a sparse attention mechanism by focusing the most relevant information in the search regions, which enables a much accurate tracking. Furthermore, we introduce a double- head predictor to boost the accuracy of foreground-background classification and regression of target bounding boxes, which further improve the tracking performance. Extensive experiments show that, without bells and whistles, our method significantly outperforms the state-of-the-art approaches on LaSOT, GOT-10k, TrackingNet, and UAV123, while running at 40 FPS. Notably, the training time of our method is reduced by 75% compared to that of TransT. The source code and models are available at [this https URL](https://github.com/fzh0917/SparseTT)."
RoViST:Learning Robust Metrics for Visual Storytelling,"EileenWang, CarenHan, JosiahPoon",8 May 2022,Computer Vision and Pattern Recognition (cs.CV)," Visual storytelling (VST) is the task of generating a story paragraph that describes a given image sequence. Most existing storytelling approaches have evaluated their models using traditional natural language generation metrics like BLEU or CIDEr. However, such metrics based on n-gram matching tend to have poor correlation with human evaluation scores and do not explicitly consider other criteria necessary for storytelling such as sentence structure or topic coherence. Moreover, a single score is not enough to assess a story as it does not inform us about what specific errors were made by the model. In this paper, we propose 3 evaluation metrics sets that analyses which aspects we would look for in a good story: 1) visual grounding, 2) coherence, and 3) non-redundancy. We measure the reliability of our metric sets by analysing its correlation with human judgement scores on a sample of machine stories obtained from 4 state-of-the-arts models trained on the Visual Storytelling Dataset (VIST). Our metric sets outperforms other metrics on human correlation, and could be served as a learning based evaluation metric set that is complementary to existing rule- based metrics."
Mutual Distillation Learning Network for Trajectory-User Linking,"WeiChen, ShuzheLi, ChaoHuang, Yanwei Yu, YongguoJiang, JunyuDong",8 May 2022,Machine Learning (cs.LG)," Trajectory-User Linking (TUL), which links trajectories to users who generate them, has been a challenging problem due to the sparsity in check-in mobility data. Existing methods ignore the utilization of historical data or rich contextual features in check-in data, resulting in poor performance for TUL task. In this paper, we propose a novel Mutual distillation learning network to solve the TUL problem for sparse check-in mobility data, named MainTUL. Specifically, MainTUL is composed of a Recurrent Neural Network (RNN) trajectory encoder that models sequential patterns of input trajectory and a temporal-aware Transformer trajectory encoder that captures long-term time dependencies for the corresponding augmented historical trajectories. Then, the knowledge learned on historical trajectories is transferred between the two trajectory encoders to guide the learning of both encoders to achieve mutual distillation of information. Experimental results on two real-world check-in mobility datasets demonstrate the superiority of MainTUL against state-of-the-art baselines. The source code of our model is available at [this https URL](https://github.com/Onedean/MainTUL)."
Math-KG: Construction and Applications of Mathematical Knowledge Graph,JianingWang,8 May 2022,Computation and Language (cs.CL)," Recently, the explosion of online education platforms makes a success in encouraging us to easily access online education resources. However, most of them ignore the integration of massive unstructured information, which inevitably brings the problem of \textit{information overload} and \textit{knowledge trek}. In this paper, we proposed a mathematical knowledge graph named Math-KG, which automatically constructed by the pipeline method with the natural language processing technology to integrate the resources of the mathematics. It is built from the corpora of Baidu Baike, Wikipedia. We implement a simple application system to validate the proposed Math-KG can make contributions on a series of scenes, including faults analysis and semantic search. The system is publicly available at GitHub \footnote{\url{[this https URL](https://github.com/wjn1996/Mathematical-Knowledge-Entity- Recognition)}.}."
Transformer-Empowered 6G Intelligent Networks: From Massive MIMOProcessing to Semantic Communication,"YangWang, ZhenGao, DezhiZheng, ShengChen, DenizGündüz, H. VincentPoor",8 May 2022,Information Theory (cs.IT)," 6G wireless networks are foreseen to speed up the convergence of the physical and cyber worlds and to enable a paradigm-shift in the way we deploy and exploit communication networks. Machine learning, in particular deep learning (DL), is going to be one of the key technological enablers of 6G by offering a new paradigm for the design and optimization of networks with a high level of intelligence. In this article, we introduce an emerging DL architecture, known as the transformer, and discuss its potential impact on 6G network design. We first discuss the differences between the transformer and classical DL architectures, and emphasize the transformer's self-attention mechanism and strong representation capabilities, which make it particularly appealing in tackling various challenges in wireless network design. Specifically, we propose transformer-based solutions for massive multiple-input multiple-output (MIMO) systems and various semantic communication problems in 6G networks. Finally, we discuss key challenges and open issues in transformer-based solutions, and identify future research directions for their deployment in intelligent 6G networks."
On the Performance Optimization of Two-way Hybrid VLC/RF based IoTSystem over Cellular Spectrum,"SutanuGhosh, Mohamed-SlimAlouini","8 May 2022 (v1(https://arxiv.org/abs/2205.03769v1)), lastrevised 10 May 2022 (this version, v2)",Networking and Internet Architecture (cs.NI)," This paper investigates the system outage performance of a useful architecture of two-way hybrid visible light communication/radio frequency (VLC/RF) communication using overlay mode of cooperative cognitive radio network (CCRN). The demand of high data rate application can be fulfilled using VLC link and communication over a wide area of coverage with high reliability can be achieved through RF link. In the proposed architecture, cooperative communication between two licensed user (LU) nodes is accomplished via an aggregation agent (AA). AA can perform like a relay node and in return, it can access the LU spectrum for two-way communications with Internet-of-Things (IoT) device. First, closed form expressions of outage probability of both LU and IoT communication are established. On the basis of these expressions, optimization problems are formulated to achieve minimum outage probability of both LU and IoT network. The impacts of both VLC and RF system parameters on these systems outage probability and throughput are finally shown in simulation results."
