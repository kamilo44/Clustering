{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Xe_oykWle6Sn",
   "metadata": {
    "id": "Xe_oykWle6Sn"
   },
   "source": [
    "# Subir información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "PxyRUH8de_7X",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PxyRUH8de_7X",
    "outputId": "b431ca70-5668-4fa0-cdc3-bfd17ce7433b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ti­tulo</th>\n",
       "      <th>Autores</th>\n",
       "      <th>Fecha</th>\n",
       "      <th>Tema</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>URL</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Text-Free Learning of a Natural Language Inter...</td>\n",
       "      <td>XiaodanDu, Raymond A.Yeh, NicholasKolkin, EliS...</td>\n",
       "      <td>08-sep-22</td>\n",
       "      <td>Computer Vision and Pattern Recognition (cs.CV)</td>\n",
       "      <td>We propose Fast text2StyleGAN, a natural lang...</td>\n",
       "      <td>https://arxiv.org/abs/2209.03954</td>\n",
       "      <td>-0.133026</td>\n",
       "      <td>12.838505</td>\n",
       "      <td>8.597036</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TF-GridNet: Making Time-Frequency Domain Model...</td>\n",
       "      <td>Zhong-QiuWang, SamueleCornell, Shukjae Choi, Y...</td>\n",
       "      <td>08-sep-22</td>\n",
       "      <td>Sound (cs.SD)</td>\n",
       "      <td>We propose TF-GridNet, a novel multi-path dee...</td>\n",
       "      <td>https://arxiv.org/abs/2209.03953</td>\n",
       "      <td>0.720193</td>\n",
       "      <td>11.198787</td>\n",
       "      <td>8.964970</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Opponent Indifference in Rating Systems: A The...</td>\n",
       "      <td>GregBodwin, Forest Zhang</td>\n",
       "      <td>08-sep-22</td>\n",
       "      <td>Data Structures and Algorithms (cs.DS)</td>\n",
       "      <td>In competitive games, it is common to assign ...</td>\n",
       "      <td>https://arxiv.org/abs/2209.03952</td>\n",
       "      <td>3.492056</td>\n",
       "      <td>12.100753</td>\n",
       "      <td>10.243726</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W-Transformers : A Wavelet-based Transformer F...</td>\n",
       "      <td>LenaSasal, TanujitChakraborty, AbdenourHadid</td>\n",
       "      <td>08-sep-22</td>\n",
       "      <td>Machine Learning (cs.LG)</td>\n",
       "      <td>Deep learning utilizing transformers has rece...</td>\n",
       "      <td>https://arxiv.org/abs/2209.03950</td>\n",
       "      <td>-0.172460</td>\n",
       "      <td>12.353977</td>\n",
       "      <td>8.506672</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Utility of Explainable AI in Ad Hoc Human-...</td>\n",
       "      <td>RohanPaleja, Muyleng Ghuy, Nadun RanawakaArach...</td>\n",
       "      <td>08-sep-22</td>\n",
       "      <td>Artificial Intelligence (cs.AI)</td>\n",
       "      <td>Recent advances in machine learning have led ...</td>\n",
       "      <td>https://arxiv.org/abs/2209.03945</td>\n",
       "      <td>1.879730</td>\n",
       "      <td>14.187939</td>\n",
       "      <td>9.244943</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>Deep Stable Representation Learning on Electro...</td>\n",
       "      <td>YingtaoLuo, ZhaochengLiu, QiangLiu</td>\n",
       "      <td>03-sep-22</td>\n",
       "      <td>Machine Learning (cs.LG)</td>\n",
       "      <td>Deep learning models have achieved promising ...</td>\n",
       "      <td>https://arxiv.org/abs/2209.01322</td>\n",
       "      <td>1.175182</td>\n",
       "      <td>12.658815</td>\n",
       "      <td>8.864402</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1035</th>\n",
       "      <td>Synthesizing Photorealistic Virtual Humans Thr...</td>\n",
       "      <td>SiddarthRavichandran, OndÅ™ejTexler, DimitarDi...</td>\n",
       "      <td>03-sep-22</td>\n",
       "      <td>Computer Vision and Pattern Recognition (cs.CV)</td>\n",
       "      <td>Over the last few decades, many aspects of hu...</td>\n",
       "      <td>https://arxiv.org/abs/2209.01321</td>\n",
       "      <td>0.112720</td>\n",
       "      <td>13.020833</td>\n",
       "      <td>8.585153</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>Kinova Gemini: Interactive Robot Grasping with...</td>\n",
       "      <td>HanxiaoChen, JiankunWang, MaxQ.-H. Meng</td>\n",
       "      <td>03-sep-22</td>\n",
       "      <td>Robotics (cs.RO)</td>\n",
       "      <td>To facilitate recent advances in robotics and...</td>\n",
       "      <td>https://arxiv.org/abs/2209.01320</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>12.350246</td>\n",
       "      <td>9.464796</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1037</th>\n",
       "      <td>Illegal But Not Malware: An Underground Econom...</td>\n",
       "      <td>ZhuoChen, JieLiu, YuboHu, LeiWu, YajinZhou, Xi...</td>\n",
       "      <td>03-sep-22</td>\n",
       "      <td>Cryptography and Security (cs.CR)</td>\n",
       "      <td>This paper focuses on mobile apps serving the...</td>\n",
       "      <td>https://arxiv.org/abs/2209.01319</td>\n",
       "      <td>0.813636</td>\n",
       "      <td>13.319372</td>\n",
       "      <td>9.412595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1038</th>\n",
       "      <td>The Folded Pneumatic Artificial Muscle (foldPA...</td>\n",
       "      <td>SichengWang, EugenioFriasMiranda, Laura H.Blum...</td>\n",
       "      <td>03-sep-22</td>\n",
       "      <td>Robotics (cs.RO)</td>\n",
       "      <td>Soft pneumatic actuators have seen applicatio...</td>\n",
       "      <td>https://arxiv.org/abs/2209.01317</td>\n",
       "      <td>2.228337</td>\n",
       "      <td>12.333520</td>\n",
       "      <td>11.220233</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1039 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Ti­tulo  \\\n",
       "0     Text-Free Learning of a Natural Language Inter...   \n",
       "1     TF-GridNet: Making Time-Frequency Domain Model...   \n",
       "2     Opponent Indifference in Rating Systems: A The...   \n",
       "3     W-Transformers : A Wavelet-based Transformer F...   \n",
       "4     The Utility of Explainable AI in Ad Hoc Human-...   \n",
       "...                                                 ...   \n",
       "1034  Deep Stable Representation Learning on Electro...   \n",
       "1035  Synthesizing Photorealistic Virtual Humans Thr...   \n",
       "1036  Kinova Gemini: Interactive Robot Grasping with...   \n",
       "1037  Illegal But Not Malware: An Underground Econom...   \n",
       "1038  The Folded Pneumatic Artificial Muscle (foldPA...   \n",
       "\n",
       "                                                Autores      Fecha  \\\n",
       "0     XiaodanDu, Raymond A.Yeh, NicholasKolkin, EliS...  08-sep-22   \n",
       "1     Zhong-QiuWang, SamueleCornell, Shukjae Choi, Y...  08-sep-22   \n",
       "2                              GregBodwin, Forest Zhang  08-sep-22   \n",
       "3          LenaSasal, TanujitChakraborty, AbdenourHadid  08-sep-22   \n",
       "4     RohanPaleja, Muyleng Ghuy, Nadun RanawakaArach...  08-sep-22   \n",
       "...                                                 ...        ...   \n",
       "1034                 YingtaoLuo, ZhaochengLiu, QiangLiu  03-sep-22   \n",
       "1035  SiddarthRavichandran, OndÅ™ejTexler, DimitarDi...  03-sep-22   \n",
       "1036            HanxiaoChen, JiankunWang, MaxQ.-H. Meng  03-sep-22   \n",
       "1037  ZhuoChen, JieLiu, YuboHu, LeiWu, YajinZhou, Xi...  03-sep-22   \n",
       "1038  SichengWang, EugenioFriasMiranda, Laura H.Blum...  03-sep-22   \n",
       "\n",
       "                                                 Tema  \\\n",
       "0     Computer Vision and Pattern Recognition (cs.CV)   \n",
       "1                                       Sound (cs.SD)   \n",
       "2              Data Structures and Algorithms (cs.DS)   \n",
       "3                            Machine Learning (cs.LG)   \n",
       "4                     Artificial Intelligence (cs.AI)   \n",
       "...                                               ...   \n",
       "1034                         Machine Learning (cs.LG)   \n",
       "1035  Computer Vision and Pattern Recognition (cs.CV)   \n",
       "1036                                 Robotics (cs.RO)   \n",
       "1037                Cryptography and Security (cs.CR)   \n",
       "1038                                 Robotics (cs.RO)   \n",
       "\n",
       "                                               Abstract  \\\n",
       "0      We propose Fast text2StyleGAN, a natural lang...   \n",
       "1      We propose TF-GridNet, a novel multi-path dee...   \n",
       "2      In competitive games, it is common to assign ...   \n",
       "3      Deep learning utilizing transformers has rece...   \n",
       "4      Recent advances in machine learning have led ...   \n",
       "...                                                 ...   \n",
       "1034   Deep learning models have achieved promising ...   \n",
       "1035   Over the last few decades, many aspects of hu...   \n",
       "1036   To facilitate recent advances in robotics and...   \n",
       "1037   This paper focuses on mobile apps serving the...   \n",
       "1038   Soft pneumatic actuators have seen applicatio...   \n",
       "\n",
       "                                   URL         x          y          z  labels  \n",
       "0     https://arxiv.org/abs/2209.03954 -0.133026  12.838505   8.597036      19  \n",
       "1     https://arxiv.org/abs/2209.03953  0.720193  11.198787   8.964970      14  \n",
       "2     https://arxiv.org/abs/2209.03952  3.492056  12.100753  10.243726      -1  \n",
       "3     https://arxiv.org/abs/2209.03950 -0.172460  12.353977   8.506672      19  \n",
       "4     https://arxiv.org/abs/2209.03945  1.879730  14.187939   9.244943      -1  \n",
       "...                                ...       ...        ...        ...     ...  \n",
       "1034  https://arxiv.org/abs/2209.01322  1.175182  12.658815   8.864402      -1  \n",
       "1035  https://arxiv.org/abs/2209.01321  0.112720  13.020833   8.585153      -1  \n",
       "1036  https://arxiv.org/abs/2209.01320  0.007679  12.350246   9.464796      19  \n",
       "1037  https://arxiv.org/abs/2209.01319  0.813636  13.319372   9.412595       5  \n",
       "1038  https://arxiv.org/abs/2209.01317  2.228337  12.333520  11.220233       7  \n",
       "\n",
       "[1039 rows x 10 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_3d = pd.read_csv(\"data.csv\", engine='python', encoding='utf-8')\n",
    "\n",
    "result_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mFCEQsjH8aZK",
   "metadata": {
    "id": "mFCEQsjH8aZK"
   },
   "source": [
    "# Calcular centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dHN5zYEK8aZL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "dHN5zYEK8aZL",
    "outputId": "06c5c396-fab9-460e-80b4-91a526de6400"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_126882/617419144.py:7: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  centroid_3d = result_3d.loc[result_3d.labels == i].mean()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.171264</td>\n",
       "      <td>12.341680</td>\n",
       "      <td>10.130203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.045001</td>\n",
       "      <td>11.045838</td>\n",
       "      <td>8.481167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.159225</td>\n",
       "      <td>10.606573</td>\n",
       "      <td>11.386884</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.444870</td>\n",
       "      <td>11.770501</td>\n",
       "      <td>8.533359</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.406632</td>\n",
       "      <td>12.493494</td>\n",
       "      <td>9.122105</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.812657</td>\n",
       "      <td>13.166517</td>\n",
       "      <td>9.530015</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.813922</td>\n",
       "      <td>12.271316</td>\n",
       "      <td>9.805761</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.580813</td>\n",
       "      <td>12.169434</td>\n",
       "      <td>10.873902</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.775257</td>\n",
       "      <td>12.856174</td>\n",
       "      <td>9.554393</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.903225</td>\n",
       "      <td>13.851298</td>\n",
       "      <td>8.744010</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.098006</td>\n",
       "      <td>11.365009</td>\n",
       "      <td>8.105718</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.125506</td>\n",
       "      <td>11.975733</td>\n",
       "      <td>9.429613</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.144160</td>\n",
       "      <td>13.965803</td>\n",
       "      <td>8.643666</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.630747</td>\n",
       "      <td>13.633385</td>\n",
       "      <td>8.762109</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.732191</td>\n",
       "      <td>11.423579</td>\n",
       "      <td>8.935338</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.179642</td>\n",
       "      <td>14.045422</td>\n",
       "      <td>8.944237</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.256325</td>\n",
       "      <td>13.801882</td>\n",
       "      <td>9.715402</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.528493</td>\n",
       "      <td>12.224964</td>\n",
       "      <td>8.645874</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.059532</td>\n",
       "      <td>12.290976</td>\n",
       "      <td>8.311931</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.070786</td>\n",
       "      <td>12.497156</td>\n",
       "      <td>254.230827</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.123628</td>\n",
       "      <td>11.721467</td>\n",
       "      <td>9.163691</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.948831</td>\n",
       "      <td>13.283905</td>\n",
       "      <td>7.728970</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.382286</td>\n",
       "      <td>13.347645</td>\n",
       "      <td>8.025513</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           x          y           z  labels\n",
       "0   4.171264  12.341680   10.130203     0.0\n",
       "1   3.045001  11.045838    8.481167     1.0\n",
       "2   2.159225  10.606573   11.386884     2.0\n",
       "3   2.444870  11.770501    8.533359     3.0\n",
       "4   3.406632  12.493494    9.122105     4.0\n",
       "5   0.812657  13.166517    9.530015     5.0\n",
       "6   2.813922  12.271316    9.805761     6.0\n",
       "7   2.580813  12.169434   10.873902     7.0\n",
       "8   1.775257  12.856174    9.554393     8.0\n",
       "9   2.903225  13.851298    8.744010     9.0\n",
       "10  1.098006  11.365009    8.105718    10.0\n",
       "11  1.125506  11.975733    9.429613    11.0\n",
       "12  1.144160  13.965803    8.643666    12.0\n",
       "13  0.630747  13.633385    8.762109    13.0\n",
       "14  0.732191  11.423579    8.935338    14.0\n",
       "15  2.179642  14.045422    8.944237    15.0\n",
       "16  2.256325  13.801882    9.715402    16.0\n",
       "17  0.528493  12.224964    8.645874    17.0\n",
       "18  1.059532  12.290976    8.311931    18.0\n",
       "19 -0.070786  12.497156  254.230827    19.0\n",
       "20  0.123628  11.721467    9.163691    20.0\n",
       "21  0.948831  13.283905    7.728970    21.0\n",
       "22  1.382286  13.347645    8.025513    22.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "centroids_3d = []\n",
    "number_centroids_3d = len(result_3d['labels'].unique())-1\n",
    "\n",
    "for i in range(number_centroids_3d):\n",
    "    centroid_3d = result_3d.loc[result_3d.labels == i].mean()\n",
    "    centroids_3d.append(centroid_3d)\n",
    "\n",
    "centroids_3d = pd.DataFrame(centroids_3d)\n",
    "\n",
    "centroids_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "en_COtKI8aZL",
   "metadata": {
    "id": "en_COtKI8aZL"
   },
   "source": [
    "# Número de tópicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9xSy45MB8aZL",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xSy45MB8aZL",
    "outputId": "d5ba8b5c-9bf5-4154-bd1a-cdd72c06cb80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 24 Tópicos.\n"
     ]
    }
   ],
   "source": [
    "print(\"Se encontraron\", len(result_3d['labels'].unique()), \"Tópicos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X4v_llvo0Edp",
   "metadata": {
    "id": "X4v_llvo0Edp"
   },
   "source": [
    "# Añadir los outliers  al centroide más cercano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2lp5qerd0Edq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lp5qerd0Edq",
    "outputId": "b3a0b6a5-e7e2-470c-b7ad-881c27334f24"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "outliers_3d = result_3d.loc[result_3d.labels == -1, :]\n",
    "clustered_3d = result_3d.loc[result_3d.labels != -1, :]\n",
    "\n",
    "outliers_3d_T = outliers_3d.drop(['labels'], axis=1).T\n",
    "centroids_3d_T = centroids_3d.drop(['labels'], axis=1).T\n",
    "\n",
    "for i in result_3d.loc[result_3d.labels == -1, :].index:\n",
    "    label_3d = centroids_3d['labels'][0]\n",
    "    dist_3d = np.linalg.norm(pd.Series(outliers_3d_T[i])-centroids_3d_T[0])\n",
    "\n",
    "    for j in range(1,len(centroids_3d)):\n",
    "        label_3d = centroids_3d['labels'][j]\n",
    "        n = np.linalg.norm(pd.Series(outliers_3d_T[i])-centroids_3d_T[j])\n",
    "        if n < dist_3d:\n",
    "            dist_3d = n\n",
    "            result_3d.loc['labels'][i] = label_3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7NGm7NxbxMUw",
   "metadata": {
    "id": "7NGm7NxbxMUw",
    "tags": []
   },
   "source": [
    "# Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hwq1QV1ZNaEo",
   "metadata": {
    "id": "hwq1QV1ZNaEo"
   },
   "outputs": [],
   "source": [
    "papers = pd.DataFrame()\n",
    "\n",
    "papers['Topic'] = result_3d['labels'].copy()\n",
    "#papers['Doc_ID'] = range(len(papers))\n",
    "papers['Abstract'] = result_3d['Abstract'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "EhU3HWvRNhz8",
   "metadata": {
    "id": "EhU3HWvRNhz8"
   },
   "outputs": [],
   "source": [
    "# Juntar documentos de cada clase\n",
    "docs_per_topic = result_3d.groupby(['labels'], as_index = False).agg({'Abstract': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "taulFURWxIZV",
   "metadata": {
    "id": "taulFURWxIZV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamilo44/anaconda3/envs/plotly_pruebas/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def c_tf_idf(documents, m, ngram_range=(1, 1)):\n",
    "    # Contar palabras mediante un iterador\n",
    "    count = CountVectorizer(ngram_range=ngram_range, stop_words=\"english\").fit(documents)\n",
    "    # Aplicar y transformar hacia un array\n",
    "    t = count.transform(documents).toarray()\n",
    "    # Sumar frecuencias de cada documento (Categoría cuando se junta el texto)\n",
    "    w = t.sum(axis=1)\n",
    "    # Dividir la frecuencia del término entre la frecuencia total\n",
    "    tf = np.divide(t.T, w)\n",
    "    # Sumar frecuencias en cada tópico\n",
    "    sum_t = t.sum(axis=0)\n",
    "    # Frecuencia inversa (IDF)\n",
    "    idf = np.log(np.divide(m, sum_t)).reshape(-1, 1)\n",
    "    # c-TF-IDF\n",
    "    tf_idf = np.multiply(tf, idf)\n",
    "\n",
    "    return tf_idf, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mhFAYVxON6FO",
   "metadata": {
    "id": "mhFAYVxON6FO"
   },
   "outputs": [],
   "source": [
    "tf_idf, count = c_tf_idf(docs_per_topic.Abstract.values, m=len(papers)+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "qxMuXJMVNzC8",
   "metadata": {
    "id": "qxMuXJMVNzC8"
   },
   "outputs": [],
   "source": [
    "def extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20):\n",
    "    # extraer palabras relevantes\n",
    "    words = count.get_feature_names()\n",
    "    labels = list(docs_per_topic.labels)\n",
    "    tf_idf_transposed = tf_idf.T\n",
    "    # Ordenar por importancia y tomar los más relevantes\n",
    "    indices = tf_idf_transposed.argsort()[:, -n:]\n",
    "    top_n_words = {label: [(words[j], tf_idf_transposed[i][j]) for j in indices[i]][::-1] for i, label in enumerate(labels)}\n",
    "    return top_n_words\n",
    "\n",
    "def extract_topic_sizes(df):\n",
    "    topic_sizes = (df.groupby(['labels'])\n",
    "                     .Abstract\n",
    "                     .count()\n",
    "                     .reset_index()\n",
    "                     .rename({\"labels\": \"labels\", \"Abstract\": \"Size\"}, axis='columns')\n",
    "                     .sort_values(\"Size\", ascending=False))\n",
    "    return topic_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "qsL5rYl5N_qg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "qsL5rYl5N_qg",
    "outputId": "23a50209-5856-403e-e7ee-61a064becf27"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kamilo44/anaconda3/envs/plotly_pruebas/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "top_n_words = extract_top_n_words_per_topic(tf_idf, count, docs_per_topic, n=20)\n",
    "topic_sizes = extract_topic_sizes(result_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "F8LIMzqFFXSh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F8LIMzqFFXSh",
    "outputId": "974b6d97-7347-4308-bb36-80e7cbc64bcb"
   },
   "outputs": [],
   "source": [
    "top_words=[]\n",
    "\n",
    "for topic in topic_sizes.labels:\n",
    "  top_words.append(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3avLwdLLtuNb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3avLwdLLtuNb",
    "outputId": "e90e3372-907a-40b3-cf81-c6b7873149d2"
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "\n",
    "for i in range(len(top_words)-1):\n",
    "  word_list.append(top_n_words[i][0][0].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "Bx4NNtWJ6xYi",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "id": "Bx4NNtWJ6xYi",
    "outputId": "ba52e3a9-b6db-46b0-d99d-bb76bafa32b5"
   },
   "outputs": [],
   "source": [
    "centroids_3d['word'] = word_list\n",
    "\n",
    "centroids_3d.to_csv(\"centroids_3d.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5a0f3",
   "metadata": {},
   "source": [
    "# Plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3615e2ae",
   "metadata": {},
   "source": [
    "## Ordenar saltos de línea para mostrar correctamente los títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e73536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "n = 1000   # Número de abstracts \n",
    "\n",
    "titulos = pd.DataFrame(papers['Título'].iloc[0:n]).to_numpy().flatten()\n",
    "\n",
    "iteraciones = len(titulos.max()) % 50\n",
    "\n",
    "for k in range(iteraciones):\n",
    "    m = 40 + 50*k\n",
    "    titulos = [i[:i.index(' ', m)] + '<br>' + i[i.index(' ', m)+1:] \n",
    "           if len(i)>50*k and \" \" in i[m:]\n",
    "           else i \n",
    "           for i in titulos]\n",
    "\n",
    "result_3d['titulos'] = titulos.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a0bd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import webbrowser\n",
    "import numpy as np\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Configuración de la visualización de los vectores\n",
    "fig.update_layout(\n",
    "    title=dict(\n",
    "            text='Clustering',\n",
    "            font=dict(\n",
    "                    family='Courier New',\n",
    "                    size=40),\n",
    "            pad=dict(l=300, r=0, b=0,t=40)),\n",
    "    hoverlabel=dict(\n",
    "                align='left',\n",
    "                font_size=12,\n",
    "                font_family=\"Courier New\"),\n",
    "    scene = dict(\n",
    "            xaxis = dict(\n",
    "                title=\"\",                             # Etiqueta del eje\n",
    "                backgroundcolor=\"rgb(200, 200, 230)\", # Color de fondo\n",
    "                gridcolor=\"blue\",                     # Color de lineas del eje de coordenadas en el plano\n",
    "                showbackground=False,                 # Mostrar fondo \n",
    "                showspikes=False,                     # Mostrar lineas del eje de coordenadas en el espacio\n",
    "                showgrid=False,                       # Mostrar lineas del eje de coordenadas en el plano\n",
    "                showticklabels=False),                # Mostrar etiquetas del eje (recta numérica)\n",
    "            yaxis = dict(\n",
    "                title=\"\",\n",
    "                backgroundcolor=\"rgb(200, 200, 230)\",\n",
    "                gridcolor=\"blue\",\n",
    "                showbackground=False,\n",
    "                showspikes=False,\n",
    "                showgrid=False,\n",
    "                showticklabels=False),\n",
    "            zaxis = dict(\n",
    "                title=\"\",\n",
    "                backgroundcolor=\"rgb(200, 200, 230)\",\n",
    "                gridcolor=\"blue\",\n",
    "                showbackground=False,\n",
    "                showspikes=False,\n",
    "                showgrid=False,\n",
    "                showticklabels=False)),\n",
    "    hovermode='closest',\n",
    "    height=500,\n",
    "    width=900,\n",
    "    margin=dict(r=10, l=0,b=10, t=60)\n",
    ")\n",
    "\n",
    "# Añadimos cada uno de los clusteres\n",
    "\n",
    "for uid, i in enumerate(centroids_3d['labels']):\n",
    "    fig.add_trace(go.Scatter3d(\n",
    "        x=result_3d.loc[result_3d.labels == i, :].x,   # Coordenadas x\n",
    "        y=result_3d.loc[result_3d.labels == i, :].y,   # Coordenadas y\n",
    "        z=result_3d.loc[result_3d.labels == i, :].z,   # Coordenadas z\n",
    "        text =result_3d.loc[result_3d.labels == i, :].titulos,   # Texto que se muestra al pasar el cursor\n",
    "        #text=titulo,                   # Texto que se muestra al pasar el cursor\n",
    "        hoverinfo='text',               # Listado de información a mostrar al pasar el cursor\n",
    "        name=centroids_3d['word'][i],   # Nombre del grupo\n",
    "        uid=str(uid),            # Identificador del cluster\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=2,                   # tamaño del punto\n",
    "            #color=df['labels'],      # subconjuntos en los cuales se divide el total de los datos\n",
    "            color=px.colors.qualitative.Alphabet[int(i)],    # color de los subconjuntos\n",
    "            opacity=0.8              # opacidad\n",
    "            )\n",
    "    ))\n",
    "\n",
    "# Conficuración click action\n",
    "scatter3d = fig.data\n",
    "\n",
    "fig.layout.hovermode = 'closest'\n",
    "\n",
    "def do_click(trace, points, state):\n",
    "    print('points.point_inds')\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        #url = df.link.iloc[ind]\n",
    "        url = 'https://google.com'\n",
    "        webbrowser.open_new_tab(url)\n",
    "\n",
    "for scatter_ in scatter3d:\n",
    "    scatter_.on_click(do_click)\n",
    "\n",
    "fig\n",
    "\n",
    "#fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da59865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "df = pd.DataFrame({'x': [1, 2, 3],\n",
    "                   'y': [1, 3, 2],\n",
    "                   'z': [2, 3, 2],\n",
    "                   'link': ['https://google.com', 'https://bing.com', 'https://duckduckgo.com']})\n",
    "\n",
    "fig = go.FigureWidget([go.Scatter3d(x=df.x, y=df.y, z=df.z, mode='markers', marker={'size': 20})])\n",
    "\n",
    "scatter = fig.data[0]\n",
    "\n",
    "print(fig.data)\n",
    "\n",
    "fig.layout.hovermode = 'closest'\n",
    "\n",
    "def do_click(trace, points, state):\n",
    "    print(points.point_inds)\n",
    "    if points.point_inds:\n",
    "        ind = points.point_inds[0]\n",
    "        url = df.link.iloc[ind]\n",
    "        #url = \"<a href='https://www.youtube.com'>https://www.youtube.com</a>\"\n",
    "        #url = 'https://www.youtube.com'\n",
    "        #print(str(url))\n",
    "        webbrowser.open_new_tab(url)\n",
    "        \n",
    "scatter.on_click(do_click)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcc6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(go.FigureWidget)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Hj8EGioN0hqa",
    "b02aabd5",
    "c7b06e32",
    "5o0hotszZi_9",
    "Xe_oykWle6Sn",
    "QwYv6Pa4Jaeq",
    "24pmarByw_vx",
    "DzsDNcrFA36e",
    "RfcxBTnCAPYa",
    "4mBAkIpkEk9Z",
    "p0xMbV5bpPI7",
    "N4YAugJvDbqb",
    "BcDbuMb_v24m",
    "YB6oKzfVLSN_",
    "n3n_hsmzwvyZ",
    "wBk_s24C5dcs",
    "vILV-oyK8aY_",
    "NvQDGGha8aZI",
    "dF8shcrA8aZJ",
    "t_-OVs8cygTv",
    "mFCEQsjH8aZK",
    "A-SBRU_IBBI1",
    "2P_A5Bjyh9G-"
   ],
   "name": "Proyecto_Scraping_AP.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
